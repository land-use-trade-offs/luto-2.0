This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-10-27 18:04:01

# File Summary

## Purpose:

This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

## File Format:

The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
   a. A header with the file path (## File: path/to/file)
   b. The full contents of the file in a code block

## Usage Guidelines:

- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

## Notes:

- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

## Additional Information:

For more information about Repomix, visit: https://github.com/andersonby/python-repomix


# Repository Structure

```
.gitignore
.repomix
  bundles.json
CITATION.cff
CLAUDE.md
COPYING
docs
  luto2-overview.tex
luto
  data.py
  economics
    agricultural
      biodiversity.py
      cost.py
      ghg.py
      quantity.py
      revenue.py
      transitions.py
      water.py
    land_use_culling.py
    non_agricultural
      biodiversity.py
      cost.py
      ghg.py
      quantity.py
      revenue.py
      transitions.py
      water.py
    off_land_commodity
      __init__.py
  helpers.py
  memory_test.py
  settings.py
  simulation.py
  solvers
    input_data.py
    solver.py
  tests
    README.md
    test_land_use_culling.py
  tools
    create_task_runs
      bash_scripts
        conda_env.yml
        conver_raw_data.sh
        create_env.sh
        install_pkg.sh
        python_script.py
        task_cmd.sh
      create_grid_search_tasks.py
      helpers.py
      parameters.py
    Manual_jupyter_books
      Add_tags_to_jb.ipynb
      asset
        sa2_2011_aus
          SA2_2011_AUST_continental_simplified.cpg
          SA2_2011_AUST_continental_simplified.prj
          SA2_2011_AUST_continental_simplified.shp.xml
      helpers
        parameters.py
        __init__.py
    plotmap.py
    report
      create_report_data.py
      create_report_layers.py
      data_tools
        parameters.py
        __init__.py
      VUE_modules
        assets
          AUS_STATE_SIMPLIFIED
            STE11aAust_mercator_simplified.cpg
            STE11aAust_mercator_simplified.prj
          NRM_SIMPLIFY_FILTER
            NRM_AUS_SIMPLIFIED.cpg
            NRM_AUS_SIMPLIFIED.prj
            NRM_AUS_SIMPLIFIED.shp.xml
        components
          chart_container.js
          filterable_dropdown.js
          helpers.js
          map_geojson.js
          ranking_cards.js
          regions_map.js
          sidebar.js
        dataTransform
          01_JSON2JS_dataTrans.py
          02_SHP2GEOJSON.py
        index.html
        index.js
        README.md
        resources
          icons.js
        routes
          route.js
        services
          DataConstructor.js
          DataService.js
          MapService.js
        views
          Area.js
          Biodiversity.js
          Economics.js
          GHG.js
          Home.js
          Map.js
          NotFound.js
          Production.js
          Settings.js
          Test.js
          Water.js
    spatializers.py
    write.py
    __init__.py
README.md
requirements.txt
```

# Repository Files


## .gitignore

```text
# Ignore the following folders:
.spyproject/
**/__pycache__/
.vscode/**
.vscode-upload.json

/jinzhu_inspect_code/*
/jinzhu_inspect_code

luto/.ipynb_checkpoints/*
pyproject.toml
anthropic.yml

# Report js files
luto/tools/report/VUE_modules/data/*.js
luto/tools/report/VUE_modules/data/map_layers

# Virtual environments
venv

# History files
.history/

# Input/output data
input/**
output/**

# Gurobi environment & logging
gurobi.env
gurobi.log

# Testing
.hypothesis

# Except this very file:
!.gitignore

# Some potential temporary files
*.zip
*.dat
*.log

# The mannual build files
/docs/manual/*

*.tmp
**/*.7z
.vscode-upload.json
.claude/settings.local.json
```

## .repomix/bundles.json

```json
{
  "bundles": {
    "agricultural_land_use-571": {
      "name": "agricultural_land_use",
      "created": "2025-10-27T06:47:16.469Z",
      "lastUsed": "2025-10-27T06:47:16.469Z",
      "tags": [],
      "files": []
    }
  }
}
```

## CITATION.cff

```text
cff-version: 1.2.0
message: "Please cite the LUTO 2.0 codebase as below."

authors:
  - family-names: de Haan
    given-names: Fjalar J.
    email: fjalar@fjalar.org
    orcid: 'https://orcid.org/0000-0003-4715-0842'
    affiliation: "Deakin University"

  - family-names: Archibald
    given-names: Carla L.
    email: c.archibald@deakin.edu.au
    orcid: 'https://orcid.org/0000-0003-1640-8396'
    affiliation: "Centre for Integrative Ecology, School of Life & Environmental Science, Deakin University"

  - family-names: Hadjikakou
    given-names: Michalis
    email: m.hadjikakou@deakin.edu.au
    orcid: 'https://orcid.org/0000-0002-3667-3982'
    affiliation: "Centre for Integrative Ecology (CIE), School of Life and Environmental Sciences, Deakin University, Burwood, Victoria, Australia"

  - family-names: Khan
    given-names : Md Shakil
    email: shakil.khan.rmit@gmail.com
    affiliation: "Deakin University"

  - family-names: Marcos-Martinez
    given-names: Raymundo
    email: mar77v@csiro.au
    orcid: 'https://orcid.org/0000-0002-7925-7081'
    affiliation: "CSIRO Land and Water"

  - family-names: Navarro
    given-names: Javier
    email: javi.navarro@csiro.au
    orcid: 'https://orcid.org/0000-0001-7945-0693'
    affiliation: "CSIRO Agriculture and Food"

  - family-names: Nazari
    given-names: Asef
    email: asef.nazari@deakin.edu.au
    orcid: 'https://orcid.org/0000-0003-4955-9684'
    affiliation: "Deakin University, School of IT"

  - family-names: Thiruvady
    given-names: Dhananjay Raghavan
    email: dhananjay.thiruvady@deakin.edu.au
    orcid: 'https://orcid.org/0000-0002-8011-933X'
    affiliation: "Deakin University"

  - family-names: Bryan
    given-names: Brett A.
    email: b.bryan@deakin.edu.au
    orcid: 'https://orcid.org/0000-0003-4834-5641'
    affiliation: "Deakin University"

title: "LUTO 2.0 (Land-Use Trade-Offs Model Version 2.0)"
license: GPL-3.0+
```

## CLAUDE.md

````markdown
# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Overview

LUTO2 is the Land-Use Trade-Offs Model Version 2, an integrated land systems optimization model for Australia. It simulates optimal spatial arrangement of land use and management decisions to achieve climate and biodiversity targets while maintaining economic productivity. The model uses GUROBI optimization solver and processes large spatial datasets.

## Development Environment Setup

### Environment Creation
```bash
# Create and activate conda environment
conda env create -f luto/tools/create_task_runs/bash_scripts/conda_env.yml
conda activate luto

# Install additional pip dependencies (gurobipy, numpy_financial, tables)
pip install gurobipy==11.0.2 numpy_financial==1.0.0 tables==3.9.2
```

### GUROBI License
LUTO2 requires a GUROBI optimization solver license. Academic licenses are available at gurobi.com. Place your `gurobi.lic` file in the appropriate directory as specified by GUROBI documentation.

### Input Data
The model requires approximately 40GB of input data that must be obtained separately by contacting b.bryan@deakin.edu.au. Input data goes in the `/input/` directory.

## Common Development Commands

### Testing
```bash
# Run all tests from repository root
python -m pytest

# Run tests with specific patterns
python -m pytest luto/tests/
```

### Running Simulations
```python
# Basic simulation
import luto.simulation as sim
data = sim.load_data()
results = sim.run(data=data)

# With custom settings
import luto.settings as settings
settings.RESFACTOR = 10  # Coarser spatial resolution
settings.SIM_YEARS = [2010, 2020, 2030]
data = sim.load_data()
sim.run(data=data)
```

### Batch Processing
```bash
# Use tools for creating and managing batch runs
python luto/tools/create_task_runs/create_grid_search_tasks.py
```

## Architecture Overview

### Core Modules
- **`luto/simulation.py`**: Main simulation engine and state management singleton
- **`luto/data.py`**: Core data management, loading, and spatial data structures
- **`luto/settings.py`**: Configuration parameters for all model aspects
- **`luto/solvers/`**: Optimization solver interface and input data preparation
  - `solver.py`: GUROBI solver wrapper (LutoSolver class)
  - `input_data.py`: Prepares optimization model input data

### Economic Modules
- **`luto/economics/agricultural/`**: Agricultural land use economics
  - Revenue, cost, quantity, water, biodiversity, GHG calculations
  - Transition costs between agricultural land uses
- **`luto/economics/non_agricultural/`**: Non-agricultural land use economics
  - Environmental plantings, carbon plantings, etc.
- **`luto/economics/off_land_commodity/`**: Off-land commodity economics

### Data Processing
- **`luto/dataprep.py`**: Data preprocessing utilities
- **`luto/tools/spatializers.py`**: Spatial data processing and upsampling
- **`luto/tools/write.py`**: Output writing and file generation

### Utilities
- **`luto/tools/create_task_runs/`**: Batch processing and grid search utilities
- **`luto/tools/report/`**: Report generation and visualization
  - `data_tools/`: Data processing for reports
  - `map_tools/`: Spatial visualization utilities
- **`luto/helpers.py`**: General utility functions

## Key Configuration Parameters

### Core Settings (`luto/settings.py`)
- `SIM_YEARS`: Simulation time periods (default: 2020-2050 in 5-year steps)
- `RESFACTOR`: Spatial resolution factor (1 = full resolution, >1 = coarser)
- `SCENARIO`: Shared Socioeconomic Pathway (SSP1-SSP5)
- `RCP`: Representative Concentration Pathway (e.g., 'rcp4p5')
- `OBJECTIVE`: Optimization objective ('maxprofit' or 'mincost')

### Environmental Constraints
- `GHG_EMISSIONS_LIMITS`: Greenhouse gas targets ('off', 'low', 'medium', 'high')
- `WATER_LIMITS`: Water yield constraints ('on' or 'off')
- `BIODIVERSITY_TARGET_GBF_*`: Various Global Biodiversity Framework targets

### Solver Configuration
- `SOLVE_METHOD`: GUROBI algorithm (default: 2 for barrier method)
- `THREADS`: Parallel threads for optimization
- `FEASIBILITY_TOLERANCE`: Solver tolerance settings

## Data Flow

1. **Data Loading**: `luto.data.Data` class loads spatial datasets from `/input/`
2. **Preprocessing**: `dataprep.py` processes raw data into model-ready formats
3. **Economic Calculations**: Economics modules calculate costs, revenues, transitions
4. **Solver Input**: `solvers/input_data.py` prepares optimization model data
5. **Optimization**: `solvers/solver.py` runs GUROBI optimization
6. **Output Generation**: `tools/write.py` writes results to `/output/`

## Output Structure

Results are saved in `/output/<timestamp>/`:
- `DATA_REPORT/REPORT_HTML/index.html`: Interactive HTML dashboard
- Spatial outputs: GeoTIFF files for mapping
- Data tables: CSV files with numerical results
- Logs: Execution logs and performance metrics

## Memory and Performance

- Minimum 16GB RAM (32GB recommended for large simulations)
- Model complexity requires substantial computational resources
- Use `RESFACTOR > 1` for testing and development to reduce memory usage
- Monitor memory usage with built-in logging utilities

## Testing Framework

- Uses pytest with hypothesis for property-based testing
- Tests focus on robustness of core functionality
- Run tests before making significant changes to ensure model integrity

## Vue.js Reporting System Architecture

The LUTO reporting system uses Vue.js 3 with a progressive selection pattern for data visualization.

### Progressive Selection Pattern

All reporting views follow the progressive selection pattern:

1. **Data Loading**: Use `chartRegister`/`mapRegister` from `DataService`/`MapService`
2. **Progressive Buttons**: Dynamic buttons generated from data structure keys
3. **Cascading Watchers**: Downstream selections auto-update when upstream changes
4. **Reactive Data**: `selectMapData`/`selectChartData` computed properties
5. **Data Readiness**: `mapReady`/`chartReady` computed validation

### Complete Data Structure Hierarchies

#### AREA MODULE
- **Chart Data**:
  - `Area_Ag`: `Region → Water → [series]`
  - `Area_Am`: `Region → AgMgt → Water → [series]`
  - `Area_NonAg`: `Region → [series]` (simplified, no Water level)
- **Map Data**: `Water → Landuse → Year → {img_str, bounds, min_max}`

#### ECONOMICS MODULE (Special Case - Complex Validation Required)
- **Chart Data (SINGLE FILES containing BOTH Cost & Revenue)**:
  - `Economics_Ag`: `Region → "ALL" → "ALL" → [mixed series array]` (aggregated, no Water/Landuse selection needed)
  - `Economics_Am`: `Region → "ALL" → "ALL" → [mixed series array]` (aggregated, no AgMgt selection needed)
  - `Economics_overview_Non_Ag`: `Region → [mixed series array]` (simplified)
  - **Dual Series Structure**: Cost (`id: null`) + Revenue (`id: name`) mixed in same array
  - **Chart Independence**: Cost/Revenue button does NOT affect chart data access - always shows both
- **Map Data (SEPARATE FILES for Cost vs Revenue)**:
  - `map_cost_Ag`: `Water → Landuse → Year → {img_str, bounds, min_max}`
  - `map_cost_Am`: `AgMgt → Water → Landuse → Year → {img_str, bounds, min_max}`
  - `map_cost_NonAg`: `Landuse → Year → {img_str, bounds, min_max}` (simplified)
  - `map_revenue_Ag`: `Water → Landuse → Year → {img_str, bounds, min_max}` 
  - `map_revenue_Am`: `AgMgt → Water → Landuse → Year → {img_str, bounds, min_max}`
  - `map_revenue_NonAg`: `Landuse → Year → {img_str, bounds, min_max}` (simplified)
- **Critical Implementation Details**:
  - **Different AgMgt Categories**: Cost and Revenue have DIFFERENT AgMgt categories (MAP data only):
    - **Cost AgMgt**: `"ALL"`, `"Agricultural technology (energy)"`, `"Agricultural technology (fertiliser)"`, `"Biochar (soil amendment)"`, `"Early dry-season savanna burning"`, `"Human-induced regeneration (Beef)"`, `"Human-induced regeneration (Sheep)"`, `"Methane reduction (livestock)"`
    - **Revenue AgMgt**: `"ALL"`, `"Agricultural technology (energy)"`, `"Agricultural technology (fertiliser)"`, `"Biochar (soil amendment)"`, `"Human-induced regeneration (Beef)"`, `"Human-induced regeneration (Sheep)"`, `"Methane reduction (livestock)"` (missing `"Early dry-season savanna burning"`)
  - **Chart vs Map Structure Mismatch**: Ag Mgt chart data is aggregated while map data uses AgMgt hierarchy
  - **Validation Required**: Must validate AgMgt selection exists in current Cost/Revenue data (MAP only)
  - **Combined Watcher**: Watch both `[selectCostRevenue, selectCategory]` with immediate: true
  - **Selection Reset**: Reset AgMgt selection if it doesn't exist in new data structure
  - **Safe Access**: Use optional chaining (`?.`) in selectMapData with fallback `|| {}`
  - **Chart Access**: Both Ag and Ag Mgt charts use `chartData["ALL"]["ALL"]` (no selections needed)
- **UI Pattern**: Cost/Revenue buttons affect MAP selection ONLY, charts ALWAYS show both cost & revenue series

#### GHG MODULE
- **Chart Data**:
  - `GHG_Ag`: `Region → "ALL" → Water → [series]` (no Landuse breakdown)
  - `GHG_Am`: `Region → AgMgt → Water → [series]` (has AgMgt breakdown)
  - `GHG_NonAg`: `Region → [series]` (simplified)
- **Map Data**: 
  - `map_GHG_Ag`: `Water → Landuse → Year → {img_str, bounds, min_max}`
  - `map_GHG_Am`: `AgMgt → Water → Landuse → Year → {img_str, bounds, min_max}` (AgMgt first, then Water)
  - `map_GHG_NonAg`: `Landuse → Year → {img_str, bounds, min_max}` (simplified)

#### PRODUCTION MODULE
- **Chart Data**:
  - `Production_Ag`: `Region → Water → [series]`
  - `Production_Am`: `Region → AgMgt → Water → [series]`
  - `Production_NonAg`: `Region → [series]` (simplified)
- **Map Data**: `map_quantities_*` follows standard Water → Landuse → Year pattern

#### WATER MODULE
- **Chart Data**:
  - `Water_Ag_NRM`: `Region → Water → [series]` (water property included)
  - `Water_Am_NRM`: `Region → AgMgt → Water → [series]`
  - `Water_NonAg_NRM`: `Region → [series]` (simplified)
- **Map Data**: 
  - `map_water_yield_Ag`: `Water → Landuse → Year → {img_str, bounds, min_max}`
  - `map_water_yield_Am`: `AgMgt → Water → Landuse → Year → {img_str, bounds, min_max}` (AgMgt first, then Water)
  - `map_water_yield_NonAg`: `Landuse → Year → {img_str, bounds, min_max}` (simplified)

#### BIODIVERSITY MODULE
- **Chart Data**:
  - `BIO_GBF2_overview_1_Type`: `Region → [series]` (simplified overview - Agricultural Landuse, Agricultural Management, Non-Agricultural land-use)
  - `BIO_GBF2_split_Ag_1_Landuse`: `Region → [series]` (simplified, no Water/AgMgt levels)
  - `BIO_GBF2_split_Am_1_Landuse`: `Region → [series]` (simplified, no Water/AgMgt levels) 
  - `BIO_GBF2_split_Am_2_Agri-Management`: `Region → [series]` with AgMgt categories: `"ALL"`, `"Early dry-season savanna burning"`, `"Human-induced regeneration (Beef)"`, `"Human-induced regeneration (Sheep)"`
  - `BIO_GBF2_split_NonAg_1_Landuse`: `Region → [series]` (simplified)
  - `BIO_quality_overview_1_Type`: `Region → [series]` (simplified overview)
  - `BIO_quality_split_*`: Similar structure to GBF2 files
- **Map Data**: 
  - `map_bio_GBF2_Ag`: `Water → Landuse → Year → {img_str, bounds, min_max}` (standard pattern)
  - `map_bio_GBF2_Am`: `Water → Landuse → Year → {img_str, bounds, min_max}` (standard pattern)
  - `map_bio_GBF2_NonAg`: `Landuse → Year → {img_str, bounds, min_max}` (simplified, no Water level)
  - `map_bio_overall_*`: Similar structures for overview maps

#### DVAR MODULE (Decision Variables - Map-Only Module)
- **Map Data (Simplified Hierarchy)**:
  - `map_dvar_Ag`: `Landuse → Year → {img_str, bounds, min_max}` (direct landuse access)
  - `map_dvar_Am`: `AgMgt → Year → {img_str, bounds, min_max}` (direct agmgt access)  
  - `map_dvar_NonAg`: `Landuse → Year → {img_str, bounds, min_max}` (direct landuse access)
  - `map_dvar_mosaic`: Contains overview categories:
    - `"Land-use"`: `Year → {img_str, bounds, min_max}`
    - `"Water-supply"`: `Year → {img_str, bounds, min_max}` 
    - `"Agricultural Land-use"`: `Year → {img_str, bounds, min_max}`
    - `"Agricultural Management"`: `Year → {img_str, bounds, min_max}`
    - `"Non-agricultural Land-use"`: `Year → {img_str, bounds, min_max}`
- **Composite Structure**: Map.js creates combined structure:
  - Categories: `"Land-use"`, `"Water-supply"`, `"Ag"`, `"Ag Mgt"`, `"Non-Ag"`
  - Each category combines "ALL" from mosaic + individual items from specific files
  - Final hierarchy: `Category → Landuse/AgMgt → Year → {img_str, bounds, min_max}`

### Key Patterns

#### Progressive Selection Hierarchies
1. **Standard Full**: Category → AgMgt → Water → Landuse
2. **Standard Simple**: Category → Water → Landuse  
3. **NonAg Simplified**: Category → Landuse (no Water/AgMgt levels)
4. **DVAR Simplified**: Category → Landuse/AgMgt → Year (map-only, direct access)

#### Water Level Options
- **Ag/AgMgt**: `"ALL"`, `"Dryland"`, `"Irrigated"`
- **NonAg**: No Water level (simplified structure)

#### AgMgt Options (where applicable)
- `"ALL"`, `"AgTech EI"`, `"Asparagopsis taxiformis"`, `"Biochar"`, `"Precision Agriculture"`

#### Map vs Chart Data
- **Charts**: Always end with array of series objects `[{name, data, type, color}]`
- **Maps**: Always end with object `{img_str: "base64...", bounds: [...], min_max: [...]}`

### Implementation Guidelines

1. **Data Validation**: Always check data readiness at each hierarchy level before accessing
2. **Progressive Watchers**: Use cascading watchers that clear downstream selections when upstream changes
3. **Special Cases**:
   - Economics: Handle dual Cost/Revenue series in same array
   - NonAg: Handle simplified structures without Water/AgMgt levels
   - Biodiversity: Mixed structures - most use simplified `Region → [series]`, but `BIO_*_Am_2_Agri-Management` files have AgMgt categories; map data follows standard patterns with some NonAg files simplified
4. **UI Conditions**: Use proper `v-if` conditions based on category selections
5. **Data Access**: Use optional chaining (`?.`) for safe property access

### File Structure
- **Views**: `/luto/tools/report/VUE_modules/views/` - Main view components
- **Chart Data**: `/luto/tools/report/VUE_modules/data/` - Chart data files (68 total)
- **Map Data**: `/luto/tools/report/VUE_modules/data/map_layers/` - Map layer files
- **Services**: `/luto/tools/report/VUE_modules/services/` - DataService/MapService registrations
- **Routes**: `/luto/tools/report/VUE_modules/routes/route.js` - Vue router configuration
````

## COPYING

```text
GNU GENERAL PUBLIC LICENSE
                       Version 3, 29 June 2007

 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

                            Preamble

  The GNU General Public License is a free, copyleft license for
software and other kinds of works.

  The licenses for most software and other practical works are designed
to take away your freedom to share and change the works.  By contrast,
the GNU General Public License is intended to guarantee your freedom to
share and change all versions of a program--to make sure it remains free
software for all its users.  We, the Free Software Foundation, use the
GNU General Public License for most of our software; it applies also to
any other work released this way by its authors.  You can apply it to
your programs, too.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
them if you wish), that you receive source code or can get it if you
want it, that you can change the software or use pieces of it in new
free programs, and that you know you can do these things.

  To protect your rights, we need to prevent others from denying you
these rights or asking you to surrender the rights.  Therefore, you have
certain responsibilities if you distribute copies of the software, or if
you modify it: responsibilities to respect the freedom of others.

  For example, if you distribute copies of such a program, whether
gratis or for a fee, you must pass on to the recipients the same
freedoms that you received.  You must make sure that they, too, receive
or can get the source code.  And you must show them these terms so they
know their rights.

  Developers that use the GNU GPL protect your rights with two steps:
(1) assert copyright on the software, and (2) offer you this License
giving you legal permission to copy, distribute and/or modify it.

  For the developers' and authors' protection, the GPL clearly explains
that there is no warranty for this free software.  For both users' and
authors' sake, the GPL requires that modified versions be marked as
changed, so that their problems will not be attributed erroneously to
authors of previous versions.

  Some devices are designed to deny users access to install or run
modified versions of the software inside them, although the manufacturer
can do so.  This is fundamentally incompatible with the aim of
protecting users' freedom to change the software.  The systematic
pattern of such abuse occurs in the area of products for individuals to
use, which is precisely where it is most unacceptable.  Therefore, we
have designed this version of the GPL to prohibit the practice for those
products.  If such problems arise substantially in other domains, we
stand ready to extend this provision to those domains in future versions
of the GPL, as needed to protect the freedom of users.

  Finally, every program is threatened constantly by software patents.
States should not allow patents to restrict development and use of
software on general-purpose computers, but in those that do, we wish to
avoid the special danger that patents applied to a free program could
make it effectively proprietary.  To prevent this, the GPL assures that
patents cannot be used to render the program non-free.

  The precise terms and conditions for copying, distribution and
modification follow.

                       TERMS AND CONDITIONS

  0. Definitions.

  "This License" refers to version 3 of the GNU General Public License.

  "Copyright" also means copyright-like laws that apply to other kinds of
works, such as semiconductor masks.

  "The Program" refers to any copyrightable work licensed under this
License.  Each licensee is addressed as "you".  "Licensees" and
"recipients" may be individuals or organizations.

  To "modify" a work means to copy from or adapt all or part of the work
in a fashion requiring copyright permission, other than the making of an
exact copy.  The resulting work is called a "modified version" of the
earlier work or a work "based on" the earlier work.

  A "covered work" means either the unmodified Program or a work based
on the Program.

  To "propagate" a work means to do anything with it that, without
permission, would make you directly or secondarily liable for
infringement under applicable copyright law, except executing it on a
computer or modifying a private copy.  Propagation includes copying,
distribution (with or without modification), making available to the
public, and in some countries other activities as well.

  To "convey" a work means any kind of propagation that enables other
parties to make or receive copies.  Mere interaction with a user through
a computer network, with no transfer of a copy, is not conveying.

  An interactive user interface displays "Appropriate Legal Notices"
to the extent that it includes a convenient and prominently visible
feature that (1) displays an appropriate copyright notice, and (2)
tells the user that there is no warranty for the work (except to the
extent that warranties are provided), that licensees may convey the
work under this License, and how to view a copy of this License.  If
the interface presents a list of user commands or options, such as a
menu, a prominent item in the list meets this criterion.

  1. Source Code.

  The "source code" for a work means the preferred form of the work
for making modifications to it.  "Object code" means any non-source
form of a work.

  A "Standard Interface" means an interface that either is an official
standard defined by a recognized standards body, or, in the case of
interfaces specified for a particular programming language, one that
is widely used among developers working in that language.

  The "System Libraries" of an executable work include anything, other
than the work as a whole, that (a) is included in the normal form of
packaging a Major Component, but which is not part of that Major
Component, and (b) serves only to enable use of the work with that
Major Component, or to implement a Standard Interface for which an
implementation is available to the public in source code form.  A
"Major Component", in this context, means a major essential component
(kernel, window system, and so on) of the specific operating system
(if any) on which the executable work runs, or a compiler used to
produce the work, or an object code interpreter used to run it.

  The "Corresponding Source" for a work in object code form means all
the source code needed to generate, install, and (for an executable
work) run the object code and to modify the work, including scripts to
control those activities.  However, it does not include the work's
System Libraries, or general-purpose tools or generally available free
programs which are used unmodified in performing those activities but
which are not part of the work.  For example, Corresponding Source
includes interface definition files associated with source files for
the work, and the source code for shared libraries and dynamically
linked subprograms that the work is specifically designed to require,
such as by intimate data communication or control flow between those
subprograms and other parts of the work.

  The Corresponding Source need not include anything that users
can regenerate automatically from other parts of the Corresponding
Source.

  The Corresponding Source for a work in source code form is that
same work.

  2. Basic Permissions.

  All rights granted under this License are granted for the term of
copyright on the Program, and are irrevocable provided the stated
conditions are met.  This License explicitly affirms your unlimited
permission to run the unmodified Program.  The output from running a
covered work is covered by this License only if the output, given its
content, constitutes a covered work.  This License acknowledges your
rights of fair use or other equivalent, as provided by copyright law.

  You may make, run and propagate covered works that you do not
convey, without conditions so long as your license otherwise remains
in force.  You may convey covered works to others for the sole purpose
of having them make modifications exclusively for you, or provide you
with facilities for running those works, provided that you comply with
the terms of this License in conveying all material for which you do
not control copyright.  Those thus making or running the covered works
for you must do so exclusively on your behalf, under your direction
and control, on terms that prohibit them from making any copies of
your copyrighted material outside their relationship with you.

  Conveying under any other circumstances is permitted solely under
the conditions stated below.  Sublicensing is not allowed; section 10
makes it unnecessary.

  3. Protecting Users' Legal Rights From Anti-Circumvention Law.

  No covered work shall be deemed part of an effective technological
measure under any applicable law fulfilling obligations under article
11 of the WIPO copyright treaty adopted on 20 December 1996, or
similar laws prohibiting or restricting circumvention of such
measures.

  When you convey a covered work, you waive any legal power to forbid
circumvention of technological measures to the extent such circumvention
is effected by exercising rights under this License with respect to
the covered work, and you disclaim any intention to limit operation or
modification of the work as a means of enforcing, against the work's
users, your or third parties' legal rights to forbid circumvention of
technological measures.

  4. Conveying Verbatim Copies.

  You may convey verbatim copies of the Program's source code as you
receive it, in any medium, provided that you conspicuously and
appropriately publish on each copy an appropriate copyright notice;
keep intact all notices stating that this License and any
non-permissive terms added in accord with section 7 apply to the code;
keep intact all notices of the absence of any warranty; and give all
recipients a copy of this License along with the Program.

  You may charge any price or no price for each copy that you convey,
and you may offer support or warranty protection for a fee.

  5. Conveying Modified Source Versions.

  You may convey a work based on the Program, or the modifications to
produce it from the Program, in the form of source code under the
terms of section 4, provided that you also meet all of these conditions:

    a) The work must carry prominent notices stating that you modified
    it, and giving a relevant date.

    b) The work must carry prominent notices stating that it is
    released under this License and any conditions added under section
    7.  This requirement modifies the requirement in section 4 to
    "keep intact all notices".

    c) You must license the entire work, as a whole, under this
    License to anyone who comes into possession of a copy.  This
    License will therefore apply, along with any applicable section 7
    additional terms, to the whole of the work, and all its parts,
    regardless of how they are packaged.  This License gives no
    permission to license the work in any other way, but it does not
    invalidate such permission if you have separately received it.

    d) If the work has interactive user interfaces, each must display
    Appropriate Legal Notices; however, if the Program has interactive
    interfaces that do not display Appropriate Legal Notices, your
    work need not make them do so.

  A compilation of a covered work with other separate and independent
works, which are not by their nature extensions of the covered work,
and which are not combined with it such as to form a larger program,
in or on a volume of a storage or distribution medium, is called an
"aggregate" if the compilation and its resulting copyright are not
used to limit the access or legal rights of the compilation's users
beyond what the individual works permit.  Inclusion of a covered work
in an aggregate does not cause this License to apply to the other
parts of the aggregate.

  6. Conveying Non-Source Forms.

  You may convey a covered work in object code form under the terms
of sections 4 and 5, provided that you also convey the
machine-readable Corresponding Source under the terms of this License,
in one of these ways:

    a) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by the
    Corresponding Source fixed on a durable physical medium
    customarily used for software interchange.

    b) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by a
    written offer, valid for at least three years and valid for as
    long as you offer spare parts or customer support for that product
    model, to give anyone who possesses the object code either (1) a
    copy of the Corresponding Source for all the software in the
    product that is covered by this License, on a durable physical
    medium customarily used for software interchange, for a price no
    more than your reasonable cost of physically performing this
    conveying of source, or (2) access to copy the
    Corresponding Source from a network server at no charge.

    c) Convey individual copies of the object code with a copy of the
    written offer to provide the Corresponding Source.  This
    alternative is allowed only occasionally and noncommercially, and
    only if you received the object code with such an offer, in accord
    with subsection 6b.

    d) Convey the object code by offering access from a designated
    place (gratis or for a charge), and offer equivalent access to the
    Corresponding Source in the same way through the same place at no
    further charge.  You need not require recipients to copy the
    Corresponding Source along with the object code.  If the place to
    copy the object code is a network server, the Corresponding Source
    may be on a different server (operated by you or a third party)
    that supports equivalent copying facilities, provided you maintain
    clear directions next to the object code saying where to find the
    Corresponding Source.  Regardless of what server hosts the
    Corresponding Source, you remain obligated to ensure that it is
    available for as long as needed to satisfy these requirements.

    e) Convey the object code using peer-to-peer transmission, provided
    you inform other peers where the object code and Corresponding
    Source of the work are being offered to the general public at no
    charge under subsection 6d.

  A separable portion of the object code, whose source code is excluded
from the Corresponding Source as a System Library, need not be
included in conveying the object code work.

  A "User Product" is either (1) a "consumer product", which means any
tangible personal property which is normally used for personal, family,
or household purposes, or (2) anything designed or sold for incorporation
into a dwelling.  In determining whether a product is a consumer product,
doubtful cases shall be resolved in favor of coverage.  For a particular
product received by a particular user, "normally used" refers to a
typical or common use of that class of product, regardless of the status
of the particular user or of the way in which the particular user
actually uses, or expects or is expected to use, the product.  A product
is a consumer product regardless of whether the product has substantial
commercial, industrial or non-consumer uses, unless such uses represent
the only significant mode of use of the product.

  "Installation Information" for a User Product means any methods,
procedures, authorization keys, or other information required to install
and execute modified versions of a covered work in that User Product from
a modified version of its Corresponding Source.  The information must
suffice to ensure that the continued functioning of the modified object
code is in no case prevented or interfered with solely because
modification has been made.

  If you convey an object code work under this section in, or with, or
specifically for use in, a User Product, and the conveying occurs as
part of a transaction in which the right of possession and use of the
User Product is transferred to the recipient in perpetuity or for a
fixed term (regardless of how the transaction is characterized), the
Corresponding Source conveyed under this section must be accompanied
by the Installation Information.  But this requirement does not apply
if neither you nor any third party retains the ability to install
modified object code on the User Product (for example, the work has
been installed in ROM).

  The requirement to provide Installation Information does not include a
requirement to continue to provide support service, warranty, or updates
for a work that has been modified or installed by the recipient, or for
the User Product in which it has been modified or installed.  Access to a
network may be denied when the modification itself materially and
adversely affects the operation of the network or violates the rules and
protocols for communication across the network.

  Corresponding Source conveyed, and Installation Information provided,
in accord with this section must be in a format that is publicly
documented (and with an implementation available to the public in
source code form), and must require no special password or key for
unpacking, reading or copying.

  7. Additional Terms.

  "Additional permissions" are terms that supplement the terms of this
License by making exceptions from one or more of its conditions.
Additional permissions that are applicable to the entire Program shall
be treated as though they were included in this License, to the extent
that they are valid under applicable law.  If additional permissions
apply only to part of the Program, that part may be used separately
under those permissions, but the entire Program remains governed by
this License without regard to the additional permissions.

  When you convey a copy of a covered work, you may at your option
remove any additional permissions from that copy, or from any part of
it.  (Additional permissions may be written to require their own
removal in certain cases when you modify the work.)  You may place
additional permissions on material, added by you to a covered work,
for which you have or can give appropriate copyright permission.

  Notwithstanding any other provision of this License, for material you
add to a covered work, you may (if authorized by the copyright holders of
that material) supplement the terms of this License with terms:

    a) Disclaiming warranty or limiting liability differently from the
    terms of sections 15 and 16 of this License; or

    b) Requiring preservation of specified reasonable legal notices or
    author attributions in that material or in the Appropriate Legal
    Notices displayed by works containing it; or

    c) Prohibiting misrepresentation of the origin of that material, or
    requiring that modified versions of such material be marked in
    reasonable ways as different from the original version; or

    d) Limiting the use for publicity purposes of names of licensors or
    authors of the material; or

    e) Declining to grant rights under trademark law for use of some
    trade names, trademarks, or service marks; or

    f) Requiring indemnification of licensors and authors of that
    material by anyone who conveys the material (or modified versions of
    it) with contractual assumptions of liability to the recipient, for
    any liability that these contractual assumptions directly impose on
    those licensors and authors.

  All other non-permissive additional terms are considered "further
restrictions" within the meaning of section 10.  If the Program as you
received it, or any part of it, contains a notice stating that it is
governed by this License along with a term that is a further
restriction, you may remove that term.  If a license document contains
a further restriction but permits relicensing or conveying under this
License, you may add to a covered work material governed by the terms
of that license document, provided that the further restriction does
not survive such relicensing or conveying.

  If you add terms to a covered work in accord with this section, you
must place, in the relevant source files, a statement of the
additional terms that apply to those files, or a notice indicating
where to find the applicable terms.

  Additional terms, permissive or non-permissive, may be stated in the
form of a separately written license, or stated as exceptions;
the above requirements apply either way.

  8. Termination.

  You may not propagate or modify a covered work except as expressly
provided under this License.  Any attempt otherwise to propagate or
modify it is void, and will automatically terminate your rights under
this License (including any patent licenses granted under the third
paragraph of section 11).

  However, if you cease all violation of this License, then your
license from a particular copyright holder is reinstated (a)
provisionally, unless and until the copyright holder explicitly and
finally terminates your license, and (b) permanently, if the copyright
holder fails to notify you of the violation by some reasonable means
prior to 60 days after the cessation.

  Moreover, your license from a particular copyright holder is
reinstated permanently if the copyright holder notifies you of the
violation by some reasonable means, this is the first time you have
received notice of violation of this License (for any work) from that
copyright holder, and you cure the violation prior to 30 days after
your receipt of the notice.

  Termination of your rights under this section does not terminate the
licenses of parties who have received copies or rights from you under
this License.  If your rights have been terminated and not permanently
reinstated, you do not qualify to receive new licenses for the same
material under section 10.

  9. Acceptance Not Required for Having Copies.

  You are not required to accept this License in order to receive or
run a copy of the Program.  Ancillary propagation of a covered work
occurring solely as a consequence of using peer-to-peer transmission
to receive a copy likewise does not require acceptance.  However,
nothing other than this License grants you permission to propagate or
modify any covered work.  These actions infringe copyright if you do
not accept this License.  Therefore, by modifying or propagating a
covered work, you indicate your acceptance of this License to do so.

  10. Automatic Licensing of Downstream Recipients.

  Each time you convey a covered work, the recipient automatically
receives a license from the original licensors, to run, modify and
propagate that work, subject to this License.  You are not responsible
for enforcing compliance by third parties with this License.

  An "entity transaction" is a transaction transferring control of an
organization, or substantially all assets of one, or subdividing an
organization, or merging organizations.  If propagation of a covered
work results from an entity transaction, each party to that
transaction who receives a copy of the work also receives whatever
licenses to the work the party's predecessor in interest had or could
give under the previous paragraph, plus a right to possession of the
Corresponding Source of the work from the predecessor in interest, if
the predecessor has it or can get it with reasonable efforts.

  You may not impose any further restrictions on the exercise of the
rights granted or affirmed under this License.  For example, you may
not impose a license fee, royalty, or other charge for exercise of
rights granted under this License, and you may not initiate litigation
(including a cross-claim or counterclaim in a lawsuit) alleging that
any patent claim is infringed by making, using, selling, offering for
sale, or importing the Program or any portion of it.

  11. Patents.

  A "contributor" is a copyright holder who authorizes use under this
License of the Program or a work on which the Program is based.  The
work thus licensed is called the contributor's "contributor version".

  A contributor's "essential patent claims" are all patent claims
owned or controlled by the contributor, whether already acquired or
hereafter acquired, that would be infringed by some manner, permitted
by this License, of making, using, or selling its contributor version,
but do not include claims that would be infringed only as a
consequence of further modification of the contributor version.  For
purposes of this definition, "control" includes the right to grant
patent sublicenses in a manner consistent with the requirements of
this License.

  Each contributor grants you a non-exclusive, worldwide, royalty-free
patent license under the contributor's essential patent claims, to
make, use, sell, offer for sale, import and otherwise run, modify and
propagate the contents of its contributor version.

  In the following three paragraphs, a "patent license" is any express
agreement or commitment, however denominated, not to enforce a patent
(such as an express permission to practice a patent or covenant not to
sue for patent infringement).  To "grant" such a patent license to a
party means to make such an agreement or commitment not to enforce a
patent against the party.

  If you convey a covered work, knowingly relying on a patent license,
and the Corresponding Source of the work is not available for anyone
to copy, free of charge and under the terms of this License, through a
publicly available network server or other readily accessible means,
then you must either (1) cause the Corresponding Source to be so
available, or (2) arrange to deprive yourself of the benefit of the
patent license for this particular work, or (3) arrange, in a manner
consistent with the requirements of this License, to extend the patent
license to downstream recipients.  "Knowingly relying" means you have
actual knowledge that, but for the patent license, your conveying the
covered work in a country, or your recipient's use of the covered work
in a country, would infringe one or more identifiable patents in that
country that you have reason to believe are valid.

  If, pursuant to or in connection with a single transaction or
arrangement, you convey, or propagate by procuring conveyance of, a
covered work, and grant a patent license to some of the parties
receiving the covered work authorizing them to use, propagate, modify
or convey a specific copy of the covered work, then the patent license
you grant is automatically extended to all recipients of the covered
work and works based on it.

  A patent license is "discriminatory" if it does not include within
the scope of its coverage, prohibits the exercise of, or is
conditioned on the non-exercise of one or more of the rights that are
specifically granted under this License.  You may not convey a covered
work if you are a party to an arrangement with a third party that is
in the business of distributing software, under which you make payment
to the third party based on the extent of your activity of conveying
the work, and under which the third party grants, to any of the
parties who would receive the covered work from you, a discriminatory
patent license (a) in connection with copies of the covered work
conveyed by you (or copies made from those copies), or (b) primarily
for and in connection with specific products or compilations that
contain the covered work, unless you entered into that arrangement,
or that patent license was granted, prior to 28 March 2007.

  Nothing in this License shall be construed as excluding or limiting
any implied license or other defenses to infringement that may
otherwise be available to you under applicable patent law.

  12. No Surrender of Others' Freedom.

  If conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot convey a
covered work so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you may
not convey it at all.  For example, if you agree to terms that obligate you
to collect a royalty for further conveying from those to whom you convey
the Program, the only way you could satisfy both those terms and this
License would be to refrain entirely from conveying the Program.

  13. Use with the GNU Affero General Public License.

  Notwithstanding any other provision of this License, you have
permission to link or combine any covered work with a work licensed
under version 3 of the GNU Affero General Public License into a single
combined work, and to convey the resulting work.  The terms of this
License will continue to apply to the part which is the covered work,
but the special requirements of the GNU Affero General Public License,
section 13, concerning interaction through a network will apply to the
combination as such.

  14. Revised Versions of this License.

  The Free Software Foundation may publish revised and/or new versions of
the GNU General Public License from time to time.  Such new versions will
be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

  Each version is given a distinguishing version number.  If the
Program specifies that a certain numbered version of the GNU General
Public License "or any later version" applies to it, you have the
option of following the terms and conditions either of that numbered
version or of any later version published by the Free Software
Foundation.  If the Program does not specify a version number of the
GNU General Public License, you may choose any version ever published
by the Free Software Foundation.

  If the Program specifies that a proxy can decide which future
versions of the GNU General Public License can be used, that proxy's
public statement of acceptance of a version permanently authorizes you
to choose that version for the Program.

  Later license versions may give you additional or different
permissions.  However, no additional obligations are imposed on any
author or copyright holder as a result of your choosing to follow a
later version.

  15. Disclaimer of Warranty.

  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

  16. Limitation of Liability.

  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
SUCH DAMAGES.

  17. Interpretation of Sections 15 and 16.

  If the disclaimer of warranty and limitation of liability provided
above cannot be given local legal effect according to their terms,
reviewing courts shall apply local law that most closely approximates
an absolute waiver of all civil liability in connection with the
Program, unless a warranty or assumption of liability accompanies a
copy of the Program in return for a fee.

                     END OF TERMS AND CONDITIONS

            How to Apply These Terms to Your New Programs

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
state the exclusion of warranty; and each file should have at least
the "copyright" line and a pointer to where the full notice is found.

    <one line to give the program's name and a brief idea of what it does.>
    Copyright (C) <year>  <name of author>

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.

Also add information on how to contact you by electronic and paper mail.

  If the program does terminal interaction, make it output a short
notice like this when it starts in an interactive mode:

    <program>  Copyright (C) <year>  <name of author>
    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
    This is free software, and you are welcome to redistribute it
    under certain conditions; type `show c' for details.

The hypothetical commands `show w' and `show c' should show the appropriate
parts of the General Public License.  Of course, your program's commands
might be different; for a GUI interface, you would use an "about box".

  You should also get your employer (if you work as a programmer) or school,
if any, to sign a "copyright disclaimer" for the program, if necessary.
For more information on this, and how to apply and follow the GNU GPL, see
<https://www.gnu.org/licenses/>.

  The GNU General Public License does not permit incorporating your program
into proprietary programs.  If your program is a subroutine library, you
may consider it more useful to permit linking proprietary applications with
the library.  If this is what you want to do, use the GNU Lesser General
Public License instead of this License.  But first, please read
<https://www.gnu.org/licenses/why-not-lgpl.html>.
```

## docs/luto2-overview.tex

```text
\documentclass[12pt,a4paper,twoside]{article}

\usepackage[round]{natbib}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{comment}
\usepackage{authblk}
\usepackage{balance}
\usepackage[shortlabels]{enumitem}
\usepackage[parfill]{parskip}
\usepackage{appendix}
\usepackage{float}
\usepackage[labelfont=bf]{caption}
\usepackage{enumitem}
\usepackage{framed}
\usepackage{tcolorbox}
\usepackage{xfrac}
\usepackage{dirtree}
\usepackage{underscore}
\usepackage{setspace}
\usepackage{minted}
\usemintedstyle{trac}
\newminted{python}{fontsize=\scriptsize, linenos}
\usepackage{hyperref}
\floatstyle{boxed}
\restylefloat{figure}

\author[]{Fjalar~J~de~Haan\thanks{\textit{Corresponding author. Email:}fjalar@fjalar.org}}

\affil[]{Planet A, Centre for Integrative Ecology, \mbox{Deakin University, Australia}}

\date{}

\begin{document}

\title{LUTO II (neoLUTO)}

\maketitle

\tableofcontents

\newpage

\section{Introduction}
This document provides an overview of the software package of LUTO II\@. It describes its architecture, the mathematical model behind the cost-minimising dynamics, the data required and how to build them from the raw datasets. It also gives instructions on how to set up and run the model.

% more on luto pedigree

The LUTO II model simulates land-use change. The model is spatially explicit and the modelled territory is discretised into $1 \times 1$ km\textsuperscript{2} (approximately) grid cells. These grid cells are represented in the model as 1D arrays, with the array entry representing the land use. A \emph{land use} is, as the name suggests, the way land is used, which typically means what kind of crop is grown or what type of livestock grazes on it. Associated with the land use are production costs and yields, both annual, which allow the model to decide which land use is optimal for a cell. There is a list of land uses considered and these are represented by integer values (e.g. `Apples' $ = 1$, `Dairy' $ = 7$). Thus, at the heart of it, land-use change is modelled by a changing integer array. This integer array is called the land-use map or \emph{lumap} for short.

In addition to the land use, the model also takes into account \emph{land management}. Apples, for example, can be cultivated with (or without) irrigation, using organic methods (or not) and so on as well as combinations of such land managements. Depending on the land management, there will typically be different production costs and different yields associated with the land use. Irrigation is more expensive but may be expected to increase yields. There is a list of land managements and these are, like land uses, represented by integer values. Conventional, dry-land agriculture is the default and represented by zero, while irrigation is represented by one. The model currently only considers conventional dry land and irrigation as land managements. Thus there is also a land-management map, or \emph{lmmap} for short.

The \emph{lumap} and \emph{lmmap} are the dependent variables of the model. Everything else is calculated on the basis of these two 1D arrays. The mechanisms driving the dynamics are economic. In the original CSIRO LUTO, the economic rationale was profit maximisation, i.e.\ farmers were supposed to cultivate whatever would profit them most (subject to some risk-based thresholds). In LUTO II the economic rationale is more systemic. The idea is that the agricultural system tries to meet demands (inputs to the model) the best it can, subject to certain constraints, while trying to minimise the total cost of production. Thus, using a yearly time step, the model is fed new demands and the model's solver produces a new land-use map.

Minimising cost while meeting demand means the model is trading off the expenditure of production against the yield of the crop or livestock. In addition to this, there are \emph{transition costs} associated with switching from one land use to another. This means that if a grid cell changes from growing apples to raising cattle, there is not only the new production cost to be paid (which may be lower) but also a transition cost. These transition costs subsume various costs of switching (including infrastructural investments and changed irrigation costs). Transition costs introduce `memory' into the model, avoiding that the land-use map changes unrealistically much at each time step as it attempts to meet demand at lowest cost.

LUTO II, like its progenitor, is an optimisation model. The economic rationale is formalised as a linear programme, which is then solved using external, commercial, black-box, closed-source solver software (GUROBI for LUTO II and CPLEX for LUTO I). The mathematical model of LUTO II is an actual linear programme but an alternative solver prototype using binary decision variables is also part of the package.

The model is solved under various constraints. One constraint ensures that all of every cell is in use. That is, there is always \emph{some} land use on a cell and all of it is used. In principle, a cell can multiple `fractional' land uses, though in practice, if the territory consists of many cells this seems not to occur. Another constraint is that the deviation of production from the demanded quantities should be minimal. This is a so-called soft constraint. These two constraints are an essential part of the model formulation. The remaining constraints are concerned with environmental targets and they can be switched on or off. Of these, water use is the first considered and the only one currently implemented. The water constraint demands that current water use relative to the water yield (how much runs of) in a river region should not exceed the water use in 2010 relative to pre-European yields (which are estimated using 1985 data and assuming deeply-rooted vegetation). Water is implemented as a hard constraint.

\section{Architecture of the model}
The LUTO II software is contained in a Python 3 package. The package structure (see Figure \ref{fig:package}) is meant to reflect the different stages of the modelling process. The various sub packages live under a main package called \mintinline{python}{luto}. Thus there is a sub package concerned with the loading of data (\mintinline{python}{luto.data}), one with cost calculations (\mintinline{python}{luto.economics}) and so on. Each sub package typically contains several modules, each with several functions.

A small number of design principles has generally been adhered to, though not into the extreme. The most important were:
\begin{itemize}
	\item Avoiding global variables and avoiding statefullness. The only exception to this being the \mintinline{python}{luto.solvers.simulation} module which has the express purpose of keeping the state of a simulation.
	\item Avoiding object orientation where possible. The notable exception is again \mintinline{python}{luto.solvers.simulation} which uses a \mintinline{python}{class Data}.
	\item Functions should be \emph{pure}. This means that a function should return something, it should always return the same thing if given the same arguments and it should do nothing else (`no side effects'). Deviations from this principle are typically explicit (e.g.\ setters and functions to write to file).
	\item Dependencies should be few. Generally, the external dependencies are limited to Numpy and Pandas (almost everything uses these) and things like HDF5 libraries. Dependencies on other LUTO modules are used where unavoidable, e.g.\ in a module where many things come together. Again, in \mintinline{python}{luto.solvers.simulation} there are of course plenty of internal imports.
\end{itemize}

The user interface of the model is the \mintinline{python}{luto.solvers.simulation} module. Importing this module will implicitly load the \mintinline{python}{data} module. It will use the parameters set in the \mintinline{python}{luto.settings} module. At this point, those parameters are limited to directory locations and some settings relating to the water constraints. If all the requisite data is available where it should be (\texttt{input/} by default), this is sufficient to run the model. One can run `interactively', that is, from the prompt of a Python interpreter or call the functions of the \mintinline{python}{luto.solvers.simulation} module from a run script. Preparing the input data and setting up the model to run is discussed in Section~\ref{sec:running}.

\floatstyle{plain}
\restylefloat{figure}
\begin{figure}
\vbox{%
\dirtree{%
.1 /.
.2 \textbf{luto/} \DTcomment{main sub-package, i.e.\ `src'}.
	.3 \textbf{data/} \DTcomment{loading of inputs}.
		.4 __init__.py \DTcomment{actual data module}.
		.4 economic.py \DTcomment{data preparation functions}.
	.3 \textbf{economics/} \DTcomment{costs, yields and water calculations}.
		.4 cost.py \DTcomment{production cost functions}.
		.4 quantity.py \DTcomment{yield functions}.
		.4 transitions.py \DTcomment{transition cost functions}.
		.4 water.py \DTcomment{water use and yield functions}.
	.3 \textbf{reporting/} \DTcomment{derivative output calculations}.
	.3 \textbf{solvers/} \DTcomment{functions and interface to run model}.
		.4 simulation.py \DTcomment{interface module for running simulations}.
		.4 solvers.py \DTcomment{solver function calling GUROBI}.
		.4 stacksolver.py \DTcomment{alternative solver (toy model stage)}.
	.3 \textbf{tools/} \DTcomment{utility functions}.
		.4 __init__.py \DTcomment{various utility functions}.
		.4 compmap.py \DTcomment{cross-tabulation functions}.
		.4 highposgtiff.py \DTcomment{to write lumaps to geotiffs}.
		.4 plotmap.py \DTcomment{lumap viewer using matplotlib}.
		.4 write.py \DTcomment{write simulation output to files in a dir}.
	.3 settings.py \DTcomment{settings like file locations and parameters}.
.2 \textbf{input/} \DTcomment{*.npy, *.csv and *.hdf5 data files}.
.2 \textbf{output/} \DTcomment{model results, lumaps and lmmaps etc.}.
.2 \textbf{docs/} \DTcomment{documentation, including this file}.
}
}
\caption{Directory structure of LUTO II Python package.}
\label{fig:package}
\end{figure}

\subsection{Loading data (\mintinline{python}{luto.data})}\label{subsec:data}
The main idea behind the \mintinline{python}{luto.data} module is to have a namespace for all input data and parameters. For example, importing the module, by issuing
\begin{minted}{python}
import luto.data as data
\end{minted}
will make the list of land uses available as \mintinline{python}{data.LANDUSES}. Data is made available in three ways, (1) by reading the data directly from a file, typically a *.npy, *.csv or *.hdf5 file, by (2) post-processing data read from file to some extent, or (3) by defining variables in the code directly (i.e.\ `magic numbers'). This third option is obviously to be avoided and the only magic number is the starting year, 2010, which is added to the year index (zero-based) whenever an actual calendar year is required.

The \mintinline{python}{luto.data} module needs a number of input files to be present at the right place. See Section~\ref{sec:running} and in specific Section~\ref{subsec:dataprep} for more information on the data preparation.

The data in the files are used to \emph{infer} various parameters of the modelling problem. In other words, in principle, the code knows nothing about the particulars of the modelling problem under consideration. Things like the spatial extent (number of grid cells), the lists of land uses and land managements and so on, the model obtains from inspecting the data files. (More precisely, the data build script does this. See Section~\ref{subsec:dataprep}.) This has the obvious advantage that the model is not tied to a certain number of cells or a particular set of land uses.

There are complications to this picture. The most notable being the following. The list of \emph{land uses} (whatever lives on the land) is not the same as, and not in a one-one relation with, the list of \emph{products} those land uses yield. For example, `Sheep - natural land' (a land use) yields `SHEEP - NATURAL LAND MEAT' as well as `SHEEP - NATURAL LAND WOOL'. To complicate matters further, the list of \emph{commodities} that are demanded (the time series of which are a key input to the model) are not the same nor in a one-one relationshep with either the list of land uses or products. For example, the demand for wool is indifferent to whether the sheep grazed on natural or modified land. So, in the list of products there is just `sheep wool'.

To avoid confusion and force useful errors, the three lists (\mintinline{python}{data.LANDUSES}, \mintinline{python}{data.PRODUCTS}, \mintinline{python}{data.COMMODITIES}) use different cases (sentence, all upper and all lower case, respectively). Nevertheless, the lists are produced by inferring the list of land-uses from the agricultural data and a host of string manipulations. This is clearly error prone in light of future extensions. Moreover, the \emph{conversions} from e.g.\ land-use to product representation, which are necessary to set up the linear programme in the solver, employ conversion matrices. These matrices are defined in the \mintinline{python}{luto.data} module following the above logic.

The situation with the land-uses, products and commodities makes the \mintinline{python}{luto.data} module cluttered, hard to read and a potential source of future bugs. The schema can likely be simplified to just two lists and some processing could be factored out while other things can be turned into file reads. At the moment however, the module works and once loaded the complications are at any rate not so visible.

Since the model avoids global dependencies, the \mintinline{python}{luto.data} loaded module needs to be explicitly passed as an argument to all functions that need it. While this may appear as complicating things unnecessarily, there are two key advantages to this approach:
\begin{enumerate}
	\item Many functions would take very long to import if they had the \mintinline{python}{luto.data} module as a hard-coded dependency. Those functions are now fairly light weight.
	\item One can also pass a \emph{different} data object to those functions. For example, some small dummy object for testing purposes. The \mintinline{python}{luto.simulation} module makes extensive use of this possibility by creating derivative data objects with many grid cells masked out to save computational space and time (see Section~\ref{subsec:solvers}).
\end{enumerate}

The \mintinline{python}{luto.data} sub-package has several modules but only the \texttt{/__init__.py} is used to load it. The modules
\mintinline{python}{luto.data.spatial} and \mintinline{python}{luto.data.temporal} are legacy code. The \mintinline{python}{luto.data.economic} module, however, is used in the data preparation (see Section~\ref{subsec:dataprep}).

\subsection{Economic calculations (\mintinline{python}{luto.economics})}
The sub-package \mintinline{python}{luto.economics} is concerned with calculating the production costs, transition costs and yields related to the land uses. This sub-package also contains a module to calculate water uses and yields. All functions in these modules are pure and most require a data object as an argument.

The calculations in this sub-package are typically returned in a matrix format, including `matrices' with more than two indices. This is partially because it is the natural format from the perspective of the mathematical formulation and GUROBI solver API. It also enables the use of some linear algebra tools making for compacter code. This at the expense of a lot of matrices of various shapes in the model. To keep overview and avoid errors, the following convention were used: A matrix data type is denoted by a letter followed by an underscore and a list of indices, e.g. \mintinline{python}{c_mrj}. The letter relates to the quantity in question (here `cost') and the indices run over various ranges, depending on what the axis represents. See Table~\ref{tab:indices} for the constantly recurring indices and the sets they enumerate.
\begin{table}
\centering
\begin{tabular}{lllll}
Index   & Set         & Range                                                & Set in LUTO II                                           & Range in LUTO II                                     \\
$ r $ & Grid cells  & $7 \times 10^7$ &                                                          & \mintinline{python}{data.NCELLS}  \\
$ j $ & Land uses   & 28                                                   & \mintinline{python}{data.LANDUSES}    & \mintinline{python}{data.NLUS}    \\
$ m $ & Land man's   & 2                                                   & \mintinline{python}{data.LANDMANS}    & \mintinline{python}{data.NLMS}    \\
$ p $ & Products    & 32                                                   & \mintinline{python}{data.PRODUCTS}    & \mintinline{python}{data.NPRS}    \\
$ c $ & Commodities & 26                                                   & \mintinline{python}{data.COMMODITIES} & \mintinline{python}{data.NCMS}
\end{tabular}
\caption{Common indices for matrix-like quantities.}
\label{tab:indices}
\end{table}


\subsubsection{Production costs (\mintinline{python}{luto.economics.cost})}
A major part of the optimisation logic are the annual production costs, i.e.\ what it costs to have a certain crop or livestock on a particular grid cell. These costs depend not only on the land use, but also on spatial location as well as the land-management type (whether it is irrigated or not) and the year. The \mintinline{python}{cost} module provides several functions to calculate these annual production costs. Of these, \mintinline{python}{get_cost_matrices()} provides the costs in the matrix format used by the solver. The actual cost calculations are done in separate functions (\mintinline{python}{get_cost_crop()} and \mintinline{python}{get_cost_lvstk()}). If one wants just the production costs of a certain land use and land management combination in a certain year, there is the function \mintinline{python}{get_cost(data, lu, lm, year)}, which returns a 1D spatial array with the cost per grid cell.

Production costs of crops are computed as \emph{fixed} plus \emph{area} plus \emph{quantity} costs. The fixed costs in turn are the sum of fixed \emph{labour}, \emph{operational} and \emph{depreciation} costs. These component costs come from data and only few operations are involved in the computation of the total production cost. Additionally, if it concerns an irrigated crop, there are water costs which are the product of the volume of water required and the delivery costs.

A similar breakdown holds for livestock production costs, with some amendments. The quantity costs in the data are now given per head so multiplication by a `yield potential' (number of heads per hectare) is necessary. In the water costs, now drinking water also needs to be included (regardless of whether the pasture is irrigated or not).

\subsubsection{Transition costs (\mintinline{python}{luto.economics.transitions})}
The transition costs are the costs of changing the land-use or land-management on a certain cell. The key function in this module is \mintinline{python}{get_transition_matrices()} which returns the transition matrices in a $t_{mrj}$ format. Thus the entry $t_{1, 3, 7}$ is the cost of switching cell number 3 (which is the fourth cell, arrays are zero based) to land use 7 (`Grapes') under land management 1 (`irr', i.e.\ irrigation). The knowledge about what the land-use and land-management it is switching \emph{from} is subsumed in the $t_{mrj}$ matrix, so naturally the current lumap and lmmap are arguments to the \mintinline{python}{get_transition_matrices()} function.

The actual transition costs are computed from a number of parts:
\begin{enumerate}
	\item `Raw' transition costs from one land use to another
	\item The difference in water licence costs after and before
	\item Irrigation infrastructure costs, if applicable
	\item Foregone income at 3 times the annual production costs
\end{enumerate}

Finally, the costs are amortised at 5\% with a horizon of 30 years.

\subsubsection{Yields (\mintinline{python}{luto.economics.quantity})}

Yields refer to the quantities of \emph{product} that can be obtained from a land use on a certain grid cell. While a land use has only one associated production cost, it can have several associated yields --- for example, as mentioned before, a land use like `Sheep - natural land' yields `SHEEP - NATURAL LAND MEAT' as well as `SHEEP - NATURAL LAND WOOL'.

The functions in the \mintinline{python}{luto.economics.quantity} module are parallel to their counterparts in the \mintinline{python}{costs} module --- with the crucial distinction that costs are for land uses, while yields pertain to products. Thus the module features the following functions. \mintinline{python}{get_quantity_matrices()} provides the yields in the matrix format used by the solver. The actual yield calculations are done in separate functions (\mintinline{python}{get_quantity_crop()} and \mintinline{python}{get_quantity_lvstk()}). If one wants just the yields of a certain product and land management combination in a certain year, there is the function \mintinline{python}{get_quantity(data, pr, lm, year)}, which returns a 1D spatial array with the cost per grid cell.

The yields for crops come directly from the input data and are only converted from per hectare to per cell units (in \mintinline{python}{get_quantity_crop()}). Also, for crops the correspondence between land uses and products is one-one. The calculations for livestock (in \mintinline{python}{get_quantity_lvstk()}) yields are a bit more involved and will be discussed below. The function \mintinline{python}{get_quantity()}, which branches to the before mentioned functions, additionally applies two multipliers, (1) the climate change impacts (via \mintinline{python}{get_ccimpact()}, interpolating input data) and (2) yield increases, i.e.\ productivity increases (directly from data).

The function \mintinline{python}{get_quantity_lvstk()} first infers which livestock and vegetation type are involved by calling the function \mintinline{python}{lvs_veg_types()} which determines this based on the product string. So, `SHEEP - NATURAL LAND WOOL' corresponds to livestock type `SHEEP' and vegetation type `NATL' (i.e.\ natural). This information is then used to calculate a \emph{yield potential} using the function \mintinline{python}{get_yield_pot()} which effectively is how many heads per hectare can be yielded.

The livestock yield data holds both the total herd size and the fraction available for use (e.g.\ slaughter or export). The product of these to factors gives a per-head, per-hectare yield. Thus \mintinline{python}{get_quantity_lvstk()} multiplies this by the yield potential and converts from per-hectare to per-cell units.

\subsection{Solving and running (\mintinline{python}{luto.solvers})}\label{subsec:solvers}

The heart of the model, that is, where the next land use map is actually computed is the \mintinline{python}{solve()} function --- `the solver' --- in the \mintinline{python}{luto.solvers.solver} module. This function takes all relevant input matrices, the demands, constraints and two conversion matrices as arguments and returns the new land-use and land-man' maps. Since this function solves the system for one time step at a time and a considerable list of arguments is required, there is an interface to solving the model provided in \mintinline{python}{luto.solvers.simulation}. The \mintinline{python}{simulation} module takes care of computing the input matrices, keeps track of the solved lumaps and lmmaps and provides a number of convenience functions. Section~\ref{sec:running} describes in some detail how to use the \mintinline{python}{simulation} module.

\subsubsection{The solver (\mintinline{python}{luto.solvers.solver})}

The full signature of the \mintinline{python}{solve()} function is:

\begin{minted}{python}
def solve( t_mrj  # Transition cost matrices.
         , c_mrj  # Production cost matrices.
         , q_mrp  # Yield matrices (n.b.\ `p' index not `j').
         , d_c    # Demands (n.b.\ `c' index not `j').
         , p      # Penalty factor.
         , x_mrj  # Exclude matrices.
         , lu2pr_pj # Conversion matrix: land-use to product(s).
         , pr2cm_cp # Conversion matrix: product(s) to commodity.
         , limits = None # Targets to use.
         , verbose = False # Print Gurobi output if True.
         )
\end{minted}

The first three arguments are the data matrices. Note the indexing convention indicating that these are 3D arrays, indexed by $m$ for the land-management (irrigation or dry land), $r$ for the grid cell number and either $j$ or $p$ for the land-use or product index. The \mintinline{python}{luto.economics} modules have functions that return these matrices in precisely the desired format. They are \mintinline{python}{get_transition_matrices()}, \mintinline{python}{get_cost_matrices()} and \mintinline{python}{get_quantity_matrices()}, respectively (in the appropriately named modules in the \mintinline{python}{luto.economics} sub package).

The fourth (`d_c') and fifth (`p') argument are the demands and the penalty factor, respectively. The demands need to be provided as a 1D array indexed by the commodities in \mintinline{python}{data.COMMODITIES} in lexicographic order. The penalty factor penalises over- and under production. The size of the penalty is the maximum (across the spatial domain) cost per tonne deviation from demand of a commodity times the penalty factor. Setting the penalty factor higher will urge the solver to try harder to meet demands exactly. Penalty factors of the order of 100 or 1000 were typical in testing situations.

The sixth argument, `x_mrj', is obtained using a \mintinline{python}{get_to_ag_exclude_matrices()} function, which can be found in the \mintinline{python}{luto.economics.transitions} module. The exclude matrices do what their name suggests, the tell the solver which cells cannot have certain land-use and land-management combinations. These exclusions are implemented consisely by making the upper bounds of the decision variables equal to the corresponding values (either zero or one) in the exclude matrices. Thus, if a cell---land-use---land-man combination is disallowed, its upper bound is equal to its lower bound is equal to zero. Testing suggests that the GUROBI solver, then, disregards these decision variables altogether, possibly giving some performance gain.

The seventh (`lu2pr_pj') and eighth (`pr2cm_cp') arguments are conversion matrices. What is converted is `vectors' of quantities of agricultural `stuff' from one representation (land-use, product or commodity) to another. The \mintinline{python}{lu2pr_pj} matrix is used to convert `vectors' of land-uses ($j$-index) to `vectors' of products ($p$-index). The \mintinline{python}{pr2cm_cp} matrix is used to convert `vectors' of products ($p$-index) to `vectors' of commodities ($c$-index). The conversion is by way of matrix multiplication. For example, if \mintinline{python}{v_j} are quantities in land-use representation, then \mintinline{python}{v_p = lu2pr_pj @ v_j} (the `\mintinline{python}{@}' denoting Python matrix multiplication) gives the quantities in the product representation (hence the $p$-index). These matrices are vailable from the \mintinline{python}{luto.data} module as \mintinline{python}{data.LU2PR} and \mintinline{python}{data.PR2CM}. These mappings between representations are not one-to-one so these matrices are \emph{not} invertible (they are not even square).

The ninth argument, `limits', asks for a dictionary of the environmental limits to include in the solving process. If \mintinline{python}{None} is passed, the solver just solves without any environmental constraints. The only environmental constraint currently implemented is water use. To use water constraints, pass a limits dictionary with an appropriate value set under the key `water'. The format of the limits for water can be inferred from the \mintinline{python}{simulation.get_limits()} method. One can set the limits per catchment (`river region').

Water limits are calculated by comparing the water use (from irrigation and drinking water) divided by a water yield (how much still runs off into the catchment with a reference fraction --- the base fraction. The limits dictionary should provide, for each catchment, the base fraction (which is not to be exceeded) and the use and yield matrices in $u_{mrj}$ and $y_{mrj}$ format, respectively. These matrices and the base fraction can be obtained from the \mintinline{python}{luto.economics.water} module via the \mintinline{python}{get_water_stress()} and \mintinline{python}{get_water_basefrac()} functions. These functions accept masks as arguments to tailor their outputs to the appropriate catchment.

The tenth and last argument, the `verbose' option, switches whether the GUROBI solver output is printed to the terminal. If set to \mintinline{python}{False} (the default) the solver (that is, \mintinline{python}{solve()}) will still print relevant information to the terminal (what year is being solved etc.)

Apart from the complications of the conversions between representations discussed above, the solver is a relatively straightforward implementation of the linear programme discussed in Section~\ref{sec:mathematics}. It should be noted that the decision variables (split out explicitly as a `dryland' and `irrigated' set) are continuous. This means that, in principle, fractional allocation of land uses is possible. In other words, it is technically possible that a cell is $\frac{4}{7}$ apples and $\frac{3}{7}$ sugarcane. For larger lumaps (in the order of thousands of cells or more) this does not seem to occur much anymore. The solver, in fact, \emph{flattens} the lumap before returning it so any fractional allocations are not detectable in the output lumap anymore. However, the decision variables are also returned for inspection, if one is interested.

\emph{The stacksolver}
An alternative solver is provided in the module \mintinline{python}{luto.solvers.stacksolver}. This module contains a \mintinline{python}{solver()} function very much like the one described above. The difference is the way in which it deals with the land-managements. This solver is only a proof-of-principle toy model and the module is self contained. The stacksolver can be run using the provide function \mintinline{python}{runstack_random()} which runs it with random number entries for the various input matrices. One passes it the size of the problem (how many cells, how many land uses) as well as the penalty factor and it returns the lumap and lmmap.

The stacksolver was written to circumvent a scaling problem with the normal solver. The way the normal solver is set up involves making a set of decision variables and accompanying data matrices for every \emph{combination} of land managements. This quickly gets too computationally and memory intense. The stacksolver instead introduces a set of binary decision variables for each new land management and computes the associated costs and yields of every combination adding up the \emph{increments} each land management would entail. This scales much more favourably in the number of land managements.

\subsubsection{Spatial coarse graining and spatial sub-setting}

\emph{Resfactor (lossy)}

To facilitate faster testing, one can run the model in a `coarse-grained' fashion. The idea is simply to present the solver with a sampled subset of the spatial domain and correspondingly sliced matrices. This facility is called `resfactor' after a similar functionality in LUTO I. The sampling can be either linear or quadratic, which means that if a sampling rate of $n$ is given, either every $n$\textsuperscript{th} or every $n \times n$\textsuperscript{th} cell is included. The linear mode produces sampling artefacts, so the quadratic mode should always be used. The sampling is implemented with a multiplicative mask. The following three functions are involved in recovering the maps from the coarse-grained solver output: \mintinline{python}{simulation.uncourse1D()}, \mintinline{python}{simulation.uncourse2D()} and \mintinline{python}{simulation.uncoursify()}.

Thought the resfactor can be set manually with the \mintinline{python}{simulation.set_resfactor()} function, for consistent settings it is recommended to instead pass the resfactor as an argument to \mintinline{python}{simulation.run()}.

The speed up is slightly better than proportional to the fraction of cells sampled. It should be superfluous to note that solving a coarse-grained map and then resizing the outputs does not provide the same results as an actual solve on the full map. Simulation results obtained with spatial coarse graining are to be used for quick inspections and sense checking in testing contexts only.

\emph{Subsetting (lossless)}

Since the grid cells with land use `Non-agricultural land' are not changed by the solver, there is no loss in solving the lumap with these cells excluded and reinserting them afterwards. This is precisely what is done when the solving is done using the \mintinline{python}{luto.solvers.simulation} interface. Like the spatial coarse graining, the sub-setting of the input map is achieved with a multiplicative map. In fact, when coarse graining is on, the two masks are indeed multiplied. The removed cells are re-inserted post-solve by the \mintinline{python}{simulation.reconstitute()} function. The speed up is proportional to the fraction of `Non-agricultural land' cells in the lumap and there is no loss of accuracy as there is no approximation.

Not only the lumap and lmmap are spatially explicit and therefore amenable to this sort of sub-setting or coarse-graining. In fact, many of the input data are spatially explicit and calculations could be sped up considerably if e.g.\ costs and yields were computed on the same fraction of the cells as the lumap and lmmap. The functions in the \mintinline{python}{luto.economics} module are agnostic to the spatial extent and pure, so if they were passed a data object on a different, smaller, spatial domain, they would not mind.

\emph{The} \mintinline{python}{class Data}

To make use of this, the \mintinline{python}{luto.solvers.simulation} module contains a class definition for a data object that can be spatially subsetted. This is a simple class with no methods. All it aims to do is to expose the same fields (at any rate the upper-case fields) as the \mintinline{python}{luto.data} module but defined on the masked spatial domain. To achieve this, it copies all the upper-case fields and applies the combined (multiplied) masks of resfactor and the lossless subsetting described earlier to the spatial fields.

For convenience, the \mintinline{python}{luto.solvers.simulation} module has four local getter methods to get the current production cost, yield or transition cost matrices (\mintinline{python}{get_c_mrj()}, \mintinline{python}{get_q_mrp()}, \mintinline{python}{get_t_mrj()} and \mintinline{python}{get_x_mrj()} respectively). These getter take no arguments and exploit the state kept in the \mintinline{python}{luto.solvers.simulation} to ensure the right data object, base and target years and coarse-graining multipliers are used. The \mintinline{python}{simulation.step()} and thus \mintinline{python}{simulation.run()} methods call these local matrix getters.

\subsubsection{Stepping and running using the simulation module}\label{subsubsec:steprun}

\emph{The} \mintinline{python}{simulation.step()} \emph{method}

To call the solver, the \mintinline{python}{luto.solvers.simulation} module uses a stepper function called \mintinline{python}{simulation.step()}. This is a simple wrapper around a call to the solver. It synchronises the simulation module (Which makes sure the right matrices are used), it undoes the effects of spatial coarse graining and subsetting whenever relevant and stores the outputs in the right places.

The synchronisation is achieved with a call to the \mintinline{python}{simulation.sync_years()} function. This function wants the \emph{base} and \emph{target} years as arguments. The base year is the year from which the lumap and lmmap are used. The target year is the year that is solved for. The supporting data, e.g.\ the cost and yield matrices, from the year before the target year are used. This is because there are year-dependent multipliers (e.g.\ yield increases) that act on the data. Thus, if the base year is 2010 and the target year is 2011, then the lumap and lmmap as well as the supporting data of 2010 will be used as the starting point. If the base year is 2010 and the target year is 2030, then the lumap and lmmap of 2010 are used with the supporting data of 2029. The \mintinline{python}{simulation.sync_years()} function synchronises those years across the module and instantiates a new \mintinline{python}{Data} object. This object takes into account any coarse graining and subsetting as discussed earlier. Note that the coarse graining (resfactor) has to be set seperately. Either by calling \mintinline{python}{simulation.set_resfactor()} or by providing it as an argument to the \mintinline{python}{simulation.run()} function --- this latter option is to be preferred.

The \mintinline{python}{simulation.step()} method places the solved maps in dictionaries called \mintinline{python}{simulation.lumaps} and \mintinline{python}{simulation.lmmaps} both of which use the calendar years as keys. When first loaded, the \mintinline{python}{luto.solvers.simulation} automatically places the lumap and lmmap from the \mintinline{python}{luto.data} module in the dictionary under the starting year set in \mintinline{python}{data.YR_CAL_BASE}, which is 2010 by default. Similarly the shapes (i.e.\ the spatial extents) as well as the decision variables are stored in dictionaries (again with years as keys) called \mintinline{python}{shapes} and \mintinline{python}{dvars}, respectively.

In addition to the base and target year, two additional arguments need to be passed to the \mintinline{python}{simulation.step()} method: the demands and the penalty factor. The stepper wants the demands and the penalty factor in the same format as the solver itself, see above for the details.

\emph{The} \mintinline{python}{simulation.run()} \emph{method}

The \mintinline{python}{simulation.step()} method is really only for internal or testing use. Actual simulations should be carried out with the \mintinline{python}{simulation.run()} method. The full signature with some explanatory comments is:

\begin{minted}{python}
def run( base               # Base year.
       , target             # Target year.
       , demands            # Demands, 1D or 2D array.
       , penalty            # Penalty factor.
       , style='sequential' # Solve target year or all years.
       , resfactor=False    # Coarse graining factor (quadratic).
       , verbose=False      # Whether to print GUROBI output.
       )
\end{minted}

The `base', `target' and `penalty' arguments are like explained for the \mintinline{python}{simulation.step()} method. The coarse graining factor can be set here using the \mintinline{python}{resfactor=...} option. If it is set to \mintinline{python}{False}, coarse graining is bypassed altogether. If one fills out, e.g.\ \mintinline{python}{resfactor=3}, each $3 \times 3$ square is treated as a single grid cell. The `verbose' option switches whether the GUROBI solver output is printed to the terminal, it is passed directly to the solver.

An important switch is the \mintinline{python}{style=...} option. If this is set \mintinline{python}{style='direct'} only the target year will be solved for. That is, one output lumap and one lmmap will be produced. If \mintinline{python}{style='sequential'}, however, all intermediate years are also solved and each subsequent year takes the previous output map as its basis. To match these options, the demands can be passed either as a 1D, commodity indexed, array (see \mintinline{python}{simulation.step()} above) or as a 2D time series --- i.e.\ a stacked array of 1D demand arrays. The shape of a 2D time series demands array is \mintinline{python}{(number_of_years, number_of_commodities)}. If \mintinline{python}{simulation.run()} is given a time series demands array but \mintinline{python}{style='direct'} is set, then the appropriate entry in the 2D array will be chosen automatically. Thus, if a demand time series is provided, one can run either `direct' or `sequential' style runs. If a 1D demand array is provided, one can only run `direct' style.

\newpage
\section{Optimisation mathematics}\label{sec:mathematics}

This section describes the linear programme at the heart of the solver. However, the formulae in the following are not \emph{precisely} what is implemented in code. Differences to keep in mind are:
\begin{itemize}
	\item The equations in Section~\ref{subsec:cbwevc} do not explicitly mention the land managements. That is, the $m$-index is not used. One can just think of the set of land uses to be twice as large, with every land use occuring once as a dryland and once as an irrigated version. (Indeed, an earlier implementation treated irrigated land uses like this.)
	\item The complications regarding land-uses, products and commodities (see Section\ref{subsec:data}) are completely ignored.
	\item Not all constraints in Sections~\ref{subsec:cbwevc} and~\ref{subsec:cbwslm} are implemented and all environmental constraints are ignored in Section~\ref{subsec:comparison}.
\end{itemize}

This section first presents the linear programme that is actually implemented (Section~\ref{subsec:cbwevc}). Then the stacksolver mathematical programme is presented (Section~\ref{subsec:cbwslm}). Then a comparison is made between the two approaches (Section~\ref{subsec:comparison}).

\newpage

\subsection{Cost-Based With Environmental Constraints}\label{subsec:cbwevc}

\everymath{\displaystyle}
\begin{equation}
	{\setstretch{2}
	\begin{array}{l c}
	\text{Minimise} \quad & \sum_{r \in R, j \in J} c_{rj} x_{rj}
					+ \sum_{r \in R, j \in J} t_{rj} x_{rj}
					+ \sum_{j \in J} \Delta_j, \\

	\text{subject to} \quad
	& \sum_{j \in J} x_{rj}  = 1, \\
	& 0 \leq x_{rj} \leq 1, \\
	& \Delta_j \leq p_j (d_j - \sum_{r \in R} q_{rj} x_{rj}) \leq \Delta_j \quad (j \in J \backslash B), \\
	& \sum_{r \in C_c, j \in J} w_{rj} x_{rj} \leq \bar{w}_c, \\
	& \sum_{r \in C_c, j \in J} n_{rj} x_{rj} \leq \bar{n}_c, \\
	& \sum_{r \in R, j \in J} k_{rj} x_{rj} \leq \bar{k}, \\
	& \sum_{j \in B} b_{rj} x_{rj} \geq \bar{b}_j.

	\end{array}}
\end{equation}
\everymath{}

\textbf{Sets and indices:}
\begin{itemize}
	\item $R$ is the set of all cells, indexed by $r$.
	\item $C_c \subset R$ is the (sub) set of cells in catchment $C_c$, indexed by $r$. The $c$ run over all the catchments considered.
	\item $J$ is the set of all land uses, indexed by $j$.
	\item $B \subset J$ is the (sub) set of biodiversity land uses, indexed by $j$.
\end{itemize}

\textbf{Decision variables:}
\begin{itemize}
	\item $x_{rj}$ is the proportion of cell $r$ allocated to land-use $j$.
\end{itemize}

\textbf{Coefficients:}
\begin{itemize}
	\item $c_{rj}$ is the cost per cell of producing land use $j$ at cell $r$.
	\item $t_{rj}$ is the cost of switching cell $r$ to land use $j$ (this incorporates knowledge of the current land use).
	\item $\Delta_j$ is a dummy variable representing how much production deviates from demand. This because the deviation is an absolute value. See the corresponding constraints.
	\item $d_{j}$ is the demand for land use $j$.
	\item $p_j$ is a penalty factor representing the cost of producing a unit too much or too little of land use $j$. E.g.\ an export or import cost.
	\item $q_{rj}$ is the yield of land use $j$ at cell $r$.
	\item $w_{rj}$ is the water use by land use $j$ at cell $r$.
	\item $\bar{w}_c$ is the limit to water use in catchment $C_c$.
	\item $n_{rj}$ is the nutrient runoff from land use $j$ at cell $r$.
	\item $\bar{n}_c$ is the limit to nutrient runoffs in catchment $C_c$.
	\item $k_{rj}$ is the carbon emissions at cell $r$ for land use $j$.
	\item $\bar{k}$ is the carbon budget.
	\item $b_{rj}$ is the conversion factor from cell to the natural units of a land-use $j \in B$. For example, if the target for land-use $j$ is in tonnes, the factor measures how many tonnes would be yielded at cell $r$.
	\item $\bar{b}_j$. The target for land use $j \in B$ in the relevant units.
\end{itemize}

\newpage

\subsection{Cost-Based With Stackable Land-Managements}\label{subsec:cbwslm}

The same notation conventions are used as in Section\~ref{subsec:cbwevc} with the addition of the $m_{rj}$ decision variables representing the land managements.

\everymath{\displaystyle}
\begin{equation}
	{\setstretch{2}
	\begin{array}{l c}
	\text{Minimise} \quad & \sum_{r \in R, j \in J} c_{rj} x_{rj}
				    + \sum_{r \in R, j \in J} c'_{rj} m_{rj}
					+ \sum_{r \in R, j \in J} t_{rj} x_{rj}
					+ \sum_{j \in J} \Delta_j, \\

	\text{subject to} \quad
	& x_{rj}, m_{rj} \in \{0, 1\}, \\
	& \sum_{j \in J} x_{rj}  = 1, \\
	& m_{rj} - x_{rj} \leq 0, \\
	& \Delta_j \leq p_j (d_j - \sum_{r \in R} q_{rj} x_{rj}) \leq \Delta_j \quad (j \in J \backslash B), \\
	& \sum_{r \in C_c, j \in J} w_{rj} x_{rj} \leq \bar{w}_c, \\
	& \sum_{r \in C_c, j \in J} n_{rj} x_{rj} \leq \bar{n}_c, \\
	& \sum_{r \in R, j \in J} k_{rj} x_{rj} \leq \bar{k}, \\
	& \sum_{j \in B} b_{rj} x_{rj} \geq \bar{b}_j.

	\end{array}}
\end{equation}
\everymath{}

\newpage

\subsection{Two Ways to Include Land-Managements}\label{subsec:comparison}

1. Each land-man (indexed by $m$) has its own $rj$-indexed set of decision variables and accompanying cost data. Since a combination of land-mans is also a land-man, this grows as $2^m$ --- exponential in $m$.

\everymath{\displaystyle}
\begin{equation}
	{\setstretch{2}
	\begin{array}{l c}
	\text{Minimise} \quad & \sum_{m \in M, r \in R, j \in J} c_{mrj} x_{mrj}
					+ \sum_{r \in R, j \in J} t_{mrj} x_{mrj}
					+ \sum_{j \in J} \Delta_j, \\

	\text{subject to} \quad
	& 0 \leq x_{mrj} \leq 1, \\
	& \sum_{m \in M, j \in J} x_{mrj}  = 1, \\
	& \Delta_j \leq p_j (d_j - \sum_{m \in M, r \in R} q_{mrj} x_{mrj}) \leq \Delta_j.

	\end{array}}
\end{equation}
\everymath{}

2. Each land-man is represented by its own $rj$-indexed boolean decision variable. Combinations are now a matter of switching the relevant land-mans on or off. This grows linear in $m$.

\everymath{\displaystyle}
\begin{equation}
	{\setstretch{2}
	\begin{array}{l c}
	\text{Minimise} \quad &
	                  \sum_{r \in R, j \in J} c_{rj} x_{rj}
				    + \sum_{m \in M, r \in R, j \in J} c'_{mrj} x'_{mrj}
					\\
					\quad &
					+ \sum_{r \in R, j \in J} t_{rj} x_{rj}
					+ \sum_{m \in M, r \in R, j \in J} t'_{mrj} x'_{mrj}
					\\
					\quad &
					+ \sum_{j \in J} \Delta_j, \\

	\text{subject to} \quad
	& x_{rj}, x'_{mrj} \in \{0, 1\}, \\
	& \sum_{j \in J} x_{rj}  = 1, \\
	& x'_{mrj} - x_{rj} \leq 0, \\
	& \Delta_j \leq p_j (d_j - q_j) \leq \Delta_j, \\
	& \text{where } q_j = \sum_{r \in R} q_{rj} x_{rj}
	                    + \sum_{m \in M, r \in R} q'_{mrj} x'_{mrj}.
	\end{array}}
\end{equation}
\everymath{}

\section{Setting up and running the model}\label{sec:running}

This section aims to provide a step plan to setting up and running LUTO II from scratch. From scratch is understood as having access to the source (in which this documentation ought to be included) and to, at least, the raw input data. A Unix-like environment (i.e.\ bash) is assumed.

\subsection{Setting up the source code}

The LUTO II code is hosted on GitHub at \url{https://github.com/land-use-trade-offs}. The exact location of the repository may change but at the time of writing the url is \url{https://github.com/land-use-trade-offs/luto2-dev.git}. Thus to download the entire LUTO II package in a directory (inside the present working directory) called \mintinline{bash}{neoluto} issue:
\begin{minted}{bash}
git clone https://github.com/land-use-trade-offs/luto2-dev.git neoluto
\end{minted}
The directory \mintinline{bash}{neoluto} (or whatever other name was chosen) does not need to exist yet but if it exists it needs to be empty. Note that the LUTO II package contains a directory \mintinline{bash}{luto} so cloning into a directory also named \mintinline{bash}{luto} creates confusing paths. When this cloning has been successfully completed, the directory \mintinline{bash}{neoluto} contains the directory structure listed in Figure~\ref{fig:package} with some extra, licence-related, files and a readme and such.

In principle, nothing needs to be changed to the code or the directory structure. Once the input data is in place, the model can run.

\subsection{Building and copying the input data}\label{subsec:dataprep}

LUTO II needs the following files to be present:
\begin{itemize}
\setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}\setlength{\itemindent}{-.3cm}
	\item \mintinline{bash}{agec-crops-c9.hdf5}
	\item \mintinline{bash}{agec-lvstk-c9.hdf5}
	\item \mintinline{bash}{climate-change-impacts-rcp2p6.hdf5}
	\item \mintinline{bash}{climate-change-impacts-rcp4p5.hdf5}
	\item \mintinline{bash}{climate-change-impacts-rcp6p0.hdf5}
	\item \mintinline{bash}{climate-change-impacts-rcp8p5.hdf5}
	\item \mintinline{bash}{draindivs.hdf5}
	\item \mintinline{bash}{feed-req.npy}
	\item \mintinline{bash}{landuses.npy}
	\item \mintinline{bash}{lmmap.npy}
	\item \mintinline{bash}{lumap.npy}
	\item \mintinline{bash}{pasture-kg-dm-ha.npy}
	\item \mintinline{bash}{potential-irrigation-areas.npy}
	\item \mintinline{bash}{prec-over-175mm.npy}
	\item \mintinline{bash}{real-area.npy}
	\item \mintinline{bash}{rivregs.hdf5}
	\item \mintinline{bash}{safe-pur-modl.npy}
	\item \mintinline{bash}{safe-pur-natl.npy}
	\item \mintinline{bash}{tmatrix.npy}
	\item \mintinline{bash}{water-delivery-price.npy}
	\item \mintinline{bash}{water-licence-price.npy}
	\item \mintinline{bash}{water-yield-baselines.hdf5}
	\item \mintinline{bash}{x-mrj.npy}
	\item [] ---
	\item \mintinline{bash}{NLUM_2010-11_mask.tif}
	\item \mintinline{bash}{Water_yield_GCM-Ensemble_ssp245_2010-2100_DR_ML_HA_mean.h5}
	\item \mintinline{bash}{Water_yield_GCM-Ensemble_ssp245_2010-2100_SR_ML_HA_mean.h5}
	\item \mintinline{bash}{yieldincreases-bau2022.csv}
\end{itemize}
These input files are expected in \mintinline{bash}{input} directory but a different directory can be set in the \mintinline{bash}{settings.py} file. The files \emph{above} the dash can be copied into the \mintinline{bash}{input} directory if they are available pre-made. If they are not available they can be \emph{built} using the build script in \mintinline{bash}{luto/data/build.ipynb} (more on this below). The files \emph{under} the dash need to be available and copied in the \mintinline{bash}{input} directory directly.

Note that the yield-increases file is simply a CSV file with yearly multipliers. The `bau2022' label is because the model was being set up for a BAU run in 2022, a different name can be set in the \mintinline{bash}{luto.data} module that loads it. The RCP can be set in the \mintinline{bash}{settings.py} file but this only affects the choice of climate change impacts HDF5 file. If another RCP is chosen, one can change the accompanying water yield file name in the \mintinline{bash}{luto.data} module.

The format for the yield-increases CSV is the following: First row, each cell contains either 'dry' or 'irr'. Second row, each cell contains the product name --- \emph{not} the land-use name, multiple things may be yielded from a land use with different multipliers. (See the code of the \mintinline{python}{luto.data} module for how the product names are generated from the land-use names.) Product names are in all upper case. The first two rows are the headers which will be read in as a multi-indexed Pandas dataframe. Subsequent rows are the multipliers, the first one of those being all ones. See also Table~\ref{tab:yieldincreases}.

\begin{table}
\centering
\begin{tabular}{rrr}
dry    & dry                        & $\ldots$ \\
APPLES & BEEF - MODIFIED LAND LEXP  & \\
1      & 1                          & \\
1.00372497691957 & 1.00984498317271 & \\
$\vdots$      &                       & $\ddots$
\end{tabular}
\caption{Format of the yield-increases CSV file.}
\label{tab:yieldincreases}
\end{table}

To build the files listed \emph{above} the dash, one needs the raw data files and the build script (\mintinline{bash}{luto/data/build.ipynb}). The build script also provides information about the format the model expects the input data to have. One exception being the yield-increases CSV file. The raw data files required are:
\begin{itemize}
\setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}\setlength{\itemindent}{-.3cm}
	\item \mintinline{bash}{cell_LU_mapping.h5}
	\item \mintinline{bash}{cell_zones_df.h5}
	\item \mintinline{bash}{tmatrix-categories.csv}
	\item \mintinline{bash}{tmatrix-cat2lus.csv}
	\item \mintinline{bash}{cell_livestock_data.h5}
	\item \mintinline{bash}{SA2_crop_data.h5}
	\item \mintinline{bash}{cell_biophysical_df.h5}
	\item \mintinline{bash}{NLUM_SPREAD_LU_ID_Mapped_Concordance.h5}
	\item \mintinline{bash}{SA2_climate_damage_mult.h5}
\end{itemize}
One straightforward way to produce the required input files is to copy the build script into the same directory as the raw data files. Then simply run the script, for example by issuing:

\begin{minted}{bash}
ipython build.ipynb
\end{minted}
This produces all the required files above the dash (and a few others). Then simply move or copy the produced files into the \mintinline{bash}{input} directory.

\subsection{Running LUTO II}
When all the input files are present, the LUTO II model can be run. To do this, first start a Python interpreter in the root of the package (the directory into which the code was cloned, e.g.\ \mintinline{bash}{neoluto}).Then load the \mintinline{python}{simulation} module, for example, like this:
\begin{minted}{python}
import luto.simulation as sim
\end{minted}
See Section~\ref{subsubsec:steprun} for more on stepping and running with the \mintinline{python}{simulation} module. Assuming one has loaded a demand vector into a variable called \mintinline{python}{demands}, one can now do a targeted run for, say, 2030 by issuing:
\begin{minted}{python}
sim.run( 2010
       , 2030
       , demands
       , 1000
       , style='direct'
       , resfactor=False
       , verbose=True )
\end{minted}
This run uses 2010 as the base year, a penalty level of 1000, no spatial coarse graining and prints the GUROBI output to the terminal. If one wants a run from 2010 to 2030 including all intervening years, one can issue:
\begin{minted}{python}
sim.run( 2010
       , 2030
       , demands
       , 1000
       , style='sequential'
       , resfactor=False
       , verbose=True )
\end{minted}
Either way, now one can use \mintinline{python}{sim.info()} to see which output lumaps and lmmaps are now available. After a single targeted run, there should be two sets of maps (base and target), while a sequential run would yield target $-$ base $+1$ maps. A map can be inspected using \mintinline{python}{sim.show_map(year)} (the legend and colour scheme may not be correct).

The lumaps and lmmaps are stored in \mintinline{python}{sim.lumaps} and \mintinline{python}{lmmaps}, respectively. The \mintinline{python}{luto.tools.write} module provides a convenience function to extract the results for a specific target year and produce maps and statistics. To do this for the year 2030, issue:
\begin{minted}{python}
from luto.tools.write import write
write(sim.data, sim, 2030)
\end{minted}
Where for \mintinline{python}{sim.data} one can also pass the normal data module (if it is loaded). The results will then be written in a directory with the present date as the name (e.g.\ 20220224) in the root directory of the package. This directory contains the maps as well as some crosstabulations for testing.






\end{document}
```

## luto/data.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import os
import xarray as xr
import numpy as np
import pandas as pd
import rasterio
import rasterio.features
import geopandas as gpd
import netCDF4 # necessary for running luto in Denethor

from luto import tools
import luto.settings as settings
import luto.economics.agricultural.quantity as ag_quantity
import luto.economics.non_agricultural.quantity as non_ag_quantity
import luto.economics.agricultural.water as ag_water
from luto.tools.spatializers import upsample_array

from collections import defaultdict
from typing import Any, Literal, Optional
from affine import Affine
from scipy.interpolate import interp1d
from math import ceil
from dataclasses import dataclass
from scipy.ndimage import distance_transform_edt



def dict2matrix(d, fromlist, tolist):
    """Return 0-1 matrix mapping 'from-vectors' to 'to-vectors' using dict d."""
    A = np.zeros((len(tolist), len(fromlist)), dtype=np.int8)
    for j, jstr in enumerate(fromlist):
        for istr in d[jstr]:
            i = tolist.index(istr)
            A[i, j] = True
    return A


def get_base_am_vars(ncells, ncms, n_ag_lus):
    """
    Get the 2010 agricultural management option vars.
    It is assumed that no agricultural management options were used in 2010,
    so get zero arrays in the correct format.
    """
    am_vars = {}
    for am in settings.AG_MANAGEMENTS_TO_LAND_USES:
        am_vars[am] = np.zeros((ncms, ncells, n_ag_lus))

    return am_vars



def lumap2non_ag_l_mk(lumap, num_non_ag_land_uses: int):
    """
    Convert the land-use map to a decision variable X_rk, where 'r' indexes cell and
    'k' indexes non-agricultural land use.

    Cells used for agricultural purposes have value 0 for all k.
    """
    base_code = settings.NON_AGRICULTURAL_LU_BASE_CODE
    non_ag_lu_codes = list(range(base_code, base_code + num_non_ag_land_uses))

    # Set up a container array of shape r, k.
    x_rk = np.zeros((lumap.shape[0], num_non_ag_land_uses), dtype=bool)

    for i,k in enumerate(non_ag_lu_codes):
        kmap = np.where(lumap == k, True, False)
        x_rk[:, i] = kmap

    return x_rk.astype(bool)


@dataclass
class Data:
    """
    Contains all data required for the LUTO model to run. Loads all data upon initialisation.
    """

    def __init__(self) -> None:
        """
        Sets up output containers (lumaps, lmmaps, etc) and loads all LUTO data, adjusted
        for resfactor.
        """
        # Path for write module - overwrite when provided with a base and target year
        self.path = None

        # The latest simulation year; 
        #   For simulation between 2010-2050, if the run stops at 2030, then it will be 2030
        #   The last_year is updated in the solve_timeseries.simulation module
        self.last_year = None

        # Setup output containers
        self.lumaps = {}
        self.lmmaps = {}
        self.ammaps = {}
        self.ag_dvars = {}
        self.non_ag_dvars = {}
        self.ag_man_dvars = {}
        self.prod_data = {}
        self.obj_vals = {}

        print('')
        print(f'Beginning data initialisation at RES{settings.RESFACTOR}...')

        self.YR_CAL_BASE = 2010  # The base year, i.e. where year index yr_idx == 0.

        ###############################################################
        # Masking and spatial coarse graining.
        ###############################################################
        print("\tSetting up masking and spatial course graining data...", flush=True)

        # Set resfactor multiplier
        self.RESMULT = settings.RESFACTOR ** 2

        # Set the nodata and non-ag code
        self.NODATA = -9999
        self.MASK_LU_CODE = -1

        # Load LUMAP without resfactor
        self.LUMAP_NO_RESFACTOR = pd.read_hdf(os.path.join(settings.INPUT_DIR, "lumap.h5")).to_numpy().astype(np.int8)   # 1D (ij flattend),  0-27 for land uses; -1 for non-agricultural land uses; All cells in Australia (land only)

        # NLUM mask.
        with rasterio.open(os.path.join(settings.INPUT_DIR, "NLUM_2010-11_mask.tif")) as rst:
            self.NLUM_MASK = rst.read(1).astype(np.int8)                                                                # 2D map,  0 for ocean, 1 for land
            self.LUMAP_2D_FULLRES = np.full_like(self.NLUM_MASK, self.NODATA, dtype=np.int16)                           # 2D map,  full of nodata (-9999)
            np.place(self.LUMAP_2D_FULLRES, self.NLUM_MASK == 1, self.LUMAP_NO_RESFACTOR)                               # 2D map,  -9999 for ocean; -1 for desert, urban, water, etc; 0-27 for land uses
            self.GEO_META_FULLRES = rst.meta                                                                            # dict,  key-value pairs of geospatial metadata for the full resolution land-use map
            self.GEO_META_FULLRES['dtype'] = 'float32'                                                                  # Set the data type to float32
            self.GEO_META_FULLRES['nodata'] = self.NODATA                                                               # Set the nodata value to -9999

        # Mask out non-agricultural, non-environmental plantings land (i.e., -1) from lumap 
        # (True means included cells. Boolean dtype.)
        self.LUMASK = self.LUMAP_NO_RESFACTOR != self.MASK_LU_CODE                                                      # 1D (ij flattend);  `True` for land uses; `False` for desert, urban, water, etc

        # Return combined land-use and resfactor mask
        if settings.RESFACTOR > 1:
            rf_mask = self.NLUM_MASK.copy()
            nonzeroes = np.nonzero(rf_mask)
            rf_mask[int(settings.RESFACTOR/2)::settings.RESFACTOR, int(settings.RESFACTOR/2)::settings.RESFACTOR] = 0
            resmask = np.where(rf_mask[nonzeroes] == 0, True, False)
            self.MASK = self.LUMASK * resmask
            self.LUMAP_2D_RESFACTORED = self.LUMAP_2D_FULLRES[int(settings.RESFACTOR/2)::settings.RESFACTOR, int(settings.RESFACTOR/2)::settings.RESFACTOR]
            self.GEO_META = self.update_geo_meta()
        elif settings.RESFACTOR == 1:
            self.MASK = self.LUMASK
            self.GEO_META = self.GEO_META_FULLRES
            self.LUMAP_2D_RESFACTORED = self.LUMAP_2D_FULLRES
        else:
            raise KeyError("Resfactor setting invalid")
        
        
        # Get the lon/lat coordinates.
        self.COORD_LON_LAT_2D_FULLRES = self.get_coord(np.nonzero(self.NLUM_MASK), self.GEO_META_FULLRES['transform'])     # 2D array([lon, ...], [lat, ...]);  lon/lat coordinates for each cell in Australia (land only)
        self.COORD_LON_LAT = [i[self.MASK] for i in self.COORD_LON_LAT_2D_FULLRES]  # Only keep the coordinates for the cells that are not masked out (i.e., land uses). 2D array([lon, ...], [lat, ...]);  lon/lat coordinates for each cell in Australia (land only) and not masked out
        
        

        ###############################################################
        # Load agricultural crop and livestock economic and yield data.
        ###############################################################
        print("\tLoading agricultural crop and livestock data...", flush=True)
        self.AGEC_CROPS = pd.read_hdf(os.path.join(settings.INPUT_DIR, "agec_crops.h5"), where=self.MASK)
        self.AGEC_LVSTK = pd.read_hdf(os.path.join(settings.INPUT_DIR, "agec_lvstk.h5"), where=self.MASK)
        
        # Price multipliers for livestock and crops over the years.
        self.CROP_PRICE_MULTIPLIERS = pd.read_excel(os.path.join(settings.INPUT_DIR, "ag_price_multipliers.xlsx"), sheet_name="AGEC_CROPS", index_col="Year")
        self.LVSTK_PRICE_MULTIPLIERS = pd.read_excel(os.path.join(settings.INPUT_DIR, "ag_price_multipliers.xlsx"), sheet_name="AGEC_LVSTK", index_col="Year")



        ###############################################################
        # Set up lists of land-uses, commodities etc.
        ###############################################################
        print("\tSetting up lists of land uses, commodities, etc...", flush=True)

        # Read in lexicographically ordered list of land-uses.
        self.AGRICULTURAL_LANDUSES = pd.read_csv((os.path.join(settings.INPUT_DIR, 'ag_landuses.csv')), header = None)[0].to_list()
        self.NON_AGRICULTURAL_LANDUSES = list(settings.NON_AG_LAND_USES.keys())

        self.NONAGLU2DESC = dict(zip(range(settings.NON_AGRICULTURAL_LU_BASE_CODE, settings.NON_AGRICULTURAL_LU_BASE_CODE + len(self.NON_AGRICULTURAL_LANDUSES)), self.NON_AGRICULTURAL_LANDUSES))
        self.DESC2NONAGLU = {value: key for key, value in self.NONAGLU2DESC.items()}
 
        # Get number of land-uses
        self.N_AG_LUS = len(self.AGRICULTURAL_LANDUSES)
        self.N_NON_AG_LUS = len(self.NON_AGRICULTURAL_LANDUSES)

        # Construct land-use index dictionary (distinct from LU_IDs!)
        self.AGLU2DESC = {i: lu for i, lu in enumerate(self.AGRICULTURAL_LANDUSES)}
        self.DESC2AGLU = {value: key for key, value in self.AGLU2DESC.items()}
        self.AGLU2DESC[-1] = 'Non-agricultural land'
        
        # Combine ag and non-ag landuses
        self.ALL_LANDUSES = self.AGRICULTURAL_LANDUSES + self.NON_AGRICULTURAL_LANDUSES
        self.ALLDESC2LU = {**self.DESC2AGLU, **self.DESC2NONAGLU}
        self.ALLLU2DESC = {**self.AGLU2DESC, **self.NONAGLU2DESC}

        # Some useful sub-sets of the land uses.
        self.LU_CROPS = [ lu for lu in self.AGRICULTURAL_LANDUSES if 'Beef' not in lu
                                                                  and 'Sheep' not in lu
                                                                  and 'Dairy' not in lu
                                                                  and 'Unallocated' not in lu
                                                                  and 'Non-agricultural' not in lu ]
        self.LU_LVSTK = [ lu for lu in self.AGRICULTURAL_LANDUSES if 'Beef' in lu
                                                        or 'Sheep' in lu
                                                        or 'Dairy' in lu ]
        self.LU_UNALL = [ lu for lu in self.AGRICULTURAL_LANDUSES if 'Unallocated' in lu ]
        self.LU_NATURAL = [
            self.DESC2AGLU["Beef - natural land"],
            self.DESC2AGLU["Dairy - natural land"],
            self.DESC2AGLU["Sheep - natural land"],
            self.DESC2AGLU["Unallocated - natural land"],
        ]
        self.LU_LVSTK_NATURAL = [lu for lu in self.LU_NATURAL if self.AGLU2DESC[lu] != 'Unallocated - natural land']
        self.LU_LVSTK_NATURAL_DESC = [self.AGLU2DESC[lu] for lu in self.LU_LVSTK_NATURAL]
        self.LU_MODIFIED_LAND = [self.DESC2AGLU[lu] for lu in self.AGRICULTURAL_LANDUSES if self.DESC2AGLU[lu] not in self.LU_NATURAL]
        
        self.LU_CROPS_INDICES = [self.AGRICULTURAL_LANDUSES.index(lu) for lu in self.AGRICULTURAL_LANDUSES if lu in self.LU_CROPS]
        self.LU_LVSTK_INDICES = [self.AGRICULTURAL_LANDUSES.index(lu) for lu in self.AGRICULTURAL_LANDUSES if lu in self.LU_LVSTK]
        self.LU_UNALL_INDICES = [self.AGRICULTURAL_LANDUSES.index(lu) for lu in self.AGRICULTURAL_LANDUSES if lu in self.LU_UNALL]

        self.NON_AG_LU_NATURAL = [
            self.DESC2NONAGLU["Environmental Plantings"],
            self.DESC2NONAGLU["Riparian Plantings"],
            self.DESC2NONAGLU["Sheep Agroforestry"],
            self.DESC2NONAGLU["Beef Agroforestry"],
            self.DESC2NONAGLU["Carbon Plantings (Block)"],
            self.DESC2NONAGLU["Sheep Carbon Plantings (Belt)"],
            self.DESC2NONAGLU["Beef Carbon Plantings (Belt)"],
            self.DESC2NONAGLU["BECCS"],
        ]

        # Define which land uses correspond to deep/shallow rooted water yield.
        self.LU_SHALLOW_ROOTED = [
            self.DESC2AGLU["Hay"], self.DESC2AGLU["Summer cereals"], self.DESC2AGLU["Summer legumes"],
            self.DESC2AGLU["Summer oilseeds"], self.DESC2AGLU["Winter cereals"], self.DESC2AGLU["Winter legumes"],
            self.DESC2AGLU["Winter oilseeds"], self.DESC2AGLU["Cotton"], self.DESC2AGLU["Other non-cereal crops"],
            self.DESC2AGLU["Rice"], self.DESC2AGLU["Vegetables"], self.DESC2AGLU["Dairy - modified land"],
            self.DESC2AGLU["Beef - modified land"], self.DESC2AGLU["Sheep - modified land"],
            self.DESC2AGLU["Unallocated - modified land"],
        ]
        self.LU_DEEP_ROOTED = [
            self.DESC2AGLU["Apples"], self.DESC2AGLU["Citrus"], self.DESC2AGLU["Grapes"], self.DESC2AGLU["Nuts"],
            self.DESC2AGLU["Pears"], self.DESC2AGLU["Plantation fruit"], self.DESC2AGLU["Stone fruit"],
            self.DESC2AGLU["Sugar"], self.DESC2AGLU["Tropical stone fruit"],
        ]

        # Derive land management types from AGEC.
        self.LANDMANS = {t[1] for t in self.AGEC_CROPS.columns}  # Set comp., unique entries.
        self.LANDMANS = list(self.LANDMANS)  # Turn into list.
        self.LANDMANS.sort()  # Ensure lexicographic order.

        # Get number of land management types
        self.NLMS = len(self.LANDMANS)

        # List of products. Everything upper case to avoid mistakes.
        self.PR_CROPS = [s.upper() for s in self.LU_CROPS]
        self.PR_LVSTK = [
            'BEEF - MODIFIED LAND LEXP',
            'BEEF - MODIFIED LAND MEAT',
            'BEEF - NATURAL LAND LEXP',
            'BEEF - NATURAL LAND MEAT',
            
            'DAIRY - MODIFIED LAND',
            'DAIRY - NATURAL LAND',
            
            'SHEEP - MODIFIED LAND LEXP',
            'SHEEP - MODIFIED LAND MEAT',
            'SHEEP - MODIFIED LAND WOOL',
            'SHEEP - NATURAL LAND LEXP',
            'SHEEP - NATURAL LAND MEAT',
            'SHEEP - NATURAL LAND WOOL'
        ]
        self.PR_RENEWABLES = [
            'UTILITY SOLAR PV - ELECTRICITY',
            'ONSHORE WIND - ELECTRICITY'
        ]
        # Sort each product category alphabetically, then concatenate
        self.PR_CROPS.sort()
        self.PR_LVSTK.sort()
        self.PR_RENEWABLES.sort()
        self.PRODUCTS = self.PR_CROPS + self.PR_LVSTK + self.PR_RENEWABLES

        # Get number of products
        self.NPRS = len(self.PRODUCTS)

        # Some land-uses map to multiple products -- a dict and matrix to capture this.
        # Crops land-uses and crop products are one-one. Livestock is more complicated.
        self.LU2PR_DICT = {key: [key.upper()] if key in self.LU_CROPS else [] for key in self.AGRICULTURAL_LANDUSES}
        for lu in self.LU_LVSTK:
            for PR in self.PR_LVSTK:
                if lu.upper() in PR:
                    self.LU2PR_DICT[lu] = self.LU2PR_DICT[lu] + [PR]

        # A reverse dictionary for convenience.
        self.PR2LU_DICT = {pr: key for key, val in self.LU2PR_DICT.items() for pr in val}

        self.LU2PR = dict2matrix(self.LU2PR_DICT, self.AGRICULTURAL_LANDUSES, self.PRODUCTS)


        # List of commodities. Everything lower case to avoid mistakes.
        # Basically collapse 'NATURAL LAND' and 'MODIFIED LAND' products and remove duplicates.
        self.COMMODITIES = { ( s.replace(' - NATURAL LAND', '')
                                .replace(' - MODIFIED LAND', '')
                                .lower() )
                                for s in self.PRODUCTS }
        self.COMMODITIES = list(self.COMMODITIES)
        self.COMMODITIES.sort()
        self.CM_CROPS = [s for s in self.COMMODITIES if s in [k.lower() for k in self.LU_CROPS]]

        # Get number of commodities
        self.NCMS = len(self.COMMODITIES)


        # Some commodities map to multiple products -- dict and matrix to capture this.
        # Crops commodities and products are one-one. Livestock is more complicated.
        self.CM2PR_DICT = { key.lower(): [key.upper()] if key in self.CM_CROPS else []
                    for key in self.COMMODITIES }
        for key, _ in self.CM2PR_DICT.items():
            if len(key.split())==1:
                head = key.split()[0]
                tail = 0
            else:
                head = key.split()[0]
                tail = key.split()[1]
            for PR in self.PR_LVSTK:
                if tail==0 and head.upper() in PR:
                    self.CM2PR_DICT[key] = self.CM2PR_DICT[key] + [PR]
                elif (head.upper()) in PR and (tail.upper() in PR):
                    self.CM2PR_DICT[key] = self.CM2PR_DICT[key] + [PR]
                else:
                    ... # Do nothing, this should be a crop.

        self.PR2CM = dict2matrix(self.CM2PR_DICT, self.COMMODITIES, self.PRODUCTS).T # Note the transpose.
        
        
        # Get the land-use indices for each commodity.
        self.CM2LU_IDX = defaultdict(list)
        for c in self.COMMODITIES:
            for lu in self.AGRICULTURAL_LANDUSES:
                if lu.split(' -')[0].lower() in c:
                    self.CM2LU_IDX[c].append(self.AGRICULTURAL_LANDUSES.index(lu))
                    
                    
        ###############################################################
        # Cost multiplier data.
        ###############################################################
        cost_mult_excel = pd.ExcelFile(os.path.join(settings.INPUT_DIR, 'cost_multipliers.xlsx'))
        self.AC_COST_MULTS = pd.read_excel(cost_mult_excel, "AC_multiplier", index_col="Year")
        self.QC_COST_MULTS = pd.read_excel(cost_mult_excel, "QC_multiplier", index_col="Year")
        self.FOC_COST_MULTS = pd.read_excel(cost_mult_excel, "FOC_multiplier", index_col="Year")
        self.FLC_COST_MULTS = pd.read_excel(cost_mult_excel, "FLC_multiplier", index_col="Year")
        self.FDC_COST_MULTS = pd.read_excel(cost_mult_excel, "FDC_multiplier", index_col="Year")
        self.WP_COST_MULTS = pd.read_excel(cost_mult_excel, "WP_multiplier", index_col="Year")["Water_delivery_price_multiplier"].to_dict()
        self.WATER_LICENSE_COST_MULTS = pd.read_excel(cost_mult_excel, "Water License Cost multiplier", index_col="Year")["Water_license_cost_multiplier"].to_dict()
        self.EST_COST_MULTS = pd.read_excel(cost_mult_excel, "Establishment cost multiplier", index_col="Year")["Establishment_cost_multiplier"].to_dict()
        self.MAINT_COST_MULTS = pd.read_excel(cost_mult_excel, "Maintennance cost multiplier", index_col="Year")["Maintennance_cost_multiplier"].to_dict()
        self.TRANS_COST_MULTS = pd.read_excel(cost_mult_excel, "Transitions cost multiplier", index_col="Year")["Transitions_cost_multiplier"].to_dict()
        self.SAVBURN_COST_MULTS = pd.read_excel(cost_mult_excel, "Savanna burning cost multiplier", index_col="Year")["Savanna_burning_cost_multiplier"].to_dict()
        self.IRRIG_COST_MULTS = pd.read_excel(cost_mult_excel, "Irrigation cost multiplier", index_col="Year")["Irrigation_cost_multiplier"].to_dict()
        self.BECCS_COST_MULTS = pd.read_excel(cost_mult_excel, "BECCS cost multiplier", index_col="Year")["BECCS_cost_multiplier"].to_dict()
        self.BECCS_REV_MULTS = pd.read_excel(cost_mult_excel, "BECCS revenue multiplier", index_col="Year")["BECCS_revenue_multiplier"].to_dict()
        self.FENCE_COST_MULTS = pd.read_excel(cost_mult_excel, "Fencing cost multiplier", index_col="Year")["Fencing_cost_multiplier"].to_dict()



        ###############################################################
        # Spatial layers.
        ###############################################################
        print("\tSetting up spatial layers data...", flush=True)

        # Actual hectares per cell, including projection corrections.
        self.REAL_AREA_NO_RESFACTOR = pd.read_hdf(os.path.join(settings.INPUT_DIR, "real_area.h5")).to_numpy()
        self.REAL_AREA = self.REAL_AREA_NO_RESFACTOR[self.MASK] * self.RESMULT  # TODO: adjusting using 

        # Derive NCELLS (number of spatial cells) from the area array.
        self.NCELLS = self.REAL_AREA.shape[0]
        
        # Initial (2010) ag decision variable (X_mrj).
        self.LMMAP_NO_RESFACTOR = pd.read_hdf(os.path.join(settings.INPUT_DIR, "lmmap.h5")).to_numpy()
        self.AG_L_MRJ = self.get_exact_resfactored_lumap_mrj() 
        self.add_ag_dvars(self.YR_CAL_BASE, self.AG_L_MRJ)

        # Initial (2010) land-use map, mapped as lexicographic land-use class indices.
        self.LU_RESFACTOR_CELLS = pd.DataFrame({
            'lu_code': list(self.DESC2AGLU.values()),
            'res_size': [ceil((self.LUMAP_NO_RESFACTOR == lu_code).sum() / self.RESMULT) for _,lu_code in self.DESC2AGLU.items()]
        }).sort_values('res_size').reset_index(drop=True)
        
        self.LUMAP = self.get_resfactored_lumap() if settings.RESFACTOR > 1 else self.LUMAP_NO_RESFACTOR[self.MASK]
        self.add_lumap(self.YR_CAL_BASE, self.LUMAP)

        # Initial (2010) land management map.
        self.LMMAP = self.LMMAP_NO_RESFACTOR[self.MASK]
        self.add_lmmap(self.YR_CAL_BASE, self.LMMAP)

        # Initial (2010) agricultural management maps - no cells are used for alternative agricultural management options.
        # Includes a separate AM map for each agricultural management option, because they can be stacked.
        self.AG_MAN_DESC = [am for am in settings.AG_MANAGEMENTS if settings.AG_MANAGEMENTS[am]]
        self.AG_MAN_LU_DESC = {am:settings.AG_MANAGEMENTS_TO_LAND_USES[am] for am in self.AG_MAN_DESC}
        self.AG_MAN_MAP = {am: np.zeros(self.NCELLS).astype("int8") for am in self.AG_MAN_DESC}
        self.N_AG_MANS = len(self.AG_MAN_DESC)
        self.add_ammaps(self.YR_CAL_BASE, self.AG_MAN_MAP)

        

        self.NON_AG_L_RK = lumap2non_ag_l_mk(
            self.LUMAP, len(self.NON_AGRICULTURAL_LANDUSES)     # Int8
        )
        self.add_non_ag_dvars(self.YR_CAL_BASE, self.NON_AG_L_RK)

        ###############################################################
        # Climate change impact data.
        ###############################################################
        print("\tLoading climate change data...", flush=True)

        self.CLIMATE_CHANGE_IMPACT = pd.read_hdf(
            os.path.join(settings.INPUT_DIR, "climate_change_impacts_" + settings.RCP + "_CO2_FERT_" + settings.CO2_FERT.upper() + ".h5"), where=self.MASK
        )
        
        
        ###############################################################
        # Regional coverage layers, mainly for regional reporting.
        ###############################################################
        REGION_NRM_r = pd.read_hdf(
            os.path.join(settings.INPUT_DIR, "REGION_NRM_r.h5"), where=self.MASK
        )        
        
        self.REGION_NRM_CODE = REGION_NRM_r['NRM_CODE']
        self.REGION_NRM_NAME = REGION_NRM_r['NRM_NAME']
        

        ###############################################################
        # No-Go areas; Regional adoption constraints.
        ###############################################################
        print("\tLoading no-go areas and regional adoption zones...", flush=True)
   
        ##################### No-go areas
        self.NO_GO_LANDUSE_AG = []
        self.NO_GO_LANDUSE_NON_AG = []

        for lu in settings.NO_GO_VECTORS.keys():
            if lu in self.AGRICULTURAL_LANDUSES:
                self.NO_GO_LANDUSE_AG.append(lu)
            elif lu in self.NON_AGRICULTURAL_LANDUSES:
                self.NO_GO_LANDUSE_NON_AG.append(lu)
            else:
                raise KeyError(f"Land use '{lu}' in no-go area vector does not match any land use in the model.")

        no_go_arrs_ag = []
        no_go_arrs_non_ag = []

        for lu, no_go_path in settings.NO_GO_VECTORS.items():
            # Read the no-go area shapefile
            no_go_shp = gpd.read_file(no_go_path)
            # Check if the CRS is defined
            if no_go_shp.crs is None:
                raise ValueError(f"{no_go_path} does not have a CRS defined")
            # Rasterize the reforestation vector; Fill with 1.  0 is no-go, 1 is 'free' cells.
            with rasterio.open(settings.INPUT_DIR + '/NLUM_2010-11_mask.tif') as src:
                src_arr = src.read(1)
                src_meta = src.meta.copy()
                no_go_shp = no_go_shp.to_crs(src_meta['crs'])
                no_go_arr = rasterio.features.rasterize(
                    ((row['geometry'], 0) for _,row in no_go_shp.iterrows()),
                    out_shape=(src_meta['height'], src_meta['width']),
                    transform=src_meta['transform'],
                    fill=1,
                    dtype=np.int16
                )
                # Add the no-go area to the ag or non_ag list.
                if lu in self.NO_GO_LANDUSE_AG:
                    no_go_arrs_ag.append(no_go_arr[np.nonzero(src_arr)].astype(np.bool_))
                elif lu in self.NO_GO_LANDUSE_NON_AG:
                    no_go_arrs_non_ag.append(no_go_arr[np.nonzero(src_arr)].astype(np.bool_))

        self.NO_GO_REGION_AG = np.stack(no_go_arrs_ag, axis=0)[:, self.MASK]
        self.NO_GO_REGION_NON_AG = np.stack(no_go_arrs_non_ag, axis=0)[:, self.MASK]
        

        
        ##################### Regional adoption zones
        if settings.REGIONAL_ADOPTION_CONSTRAINTS == "off":
            self.REGIONAL_ADOPTION_ZONES = None
            self.REGIONAL_ADOPTION_TARGETS = None
        else:
            self.REGIONAL_ADOPTION_ZONES = pd.read_hdf(
                os.path.join(settings.INPUT_DIR, "regional_adoption_zones.h5"), where=self.MASK
            )[settings.REGIONAL_ADOPTION_ZONE].to_numpy()

            regional_adoption_targets = pd.read_excel(os.path.join(settings.INPUT_DIR, "regional_adoption_zones.xlsx"), sheet_name=settings.REGIONAL_ADOPTION_ZONE)

            if (settings.REGIONAL_ADOPTION_CONSTRAINTS == 'NON_AG_UNIFORM') and (settings.REGIONAL_ADOPTION_NON_AG_UNIFORM is not None):
                regional_adoption_targets.loc[
                    regional_adoption_targets['TARGET_LANDUSE'].isin(settings.NON_AG_LAND_USES.keys()),
                    ['ADOPTION_PERCENTAGE_2030', 'ADOPTION_PERCENTAGE_2050', 'ADOPTION_PERCENTAGE_2100']
                ] = settings.REGIONAL_ADOPTION_NON_AG_UNIFORM

            self.REGIONAL_ADOPTION_TARGETS = regional_adoption_targets.iloc[
                [idx for idx, row in regional_adoption_targets.iterrows() if
                    all([row['ADOPTION_PERCENTAGE_2030']>=0, 
                        row['ADOPTION_PERCENTAGE_2050']>=0, 
                        row['ADOPTION_PERCENTAGE_2100']>=0])
                ]
            ]
            
            # Check missing zones due to high resfactor
            if len(self.REGIONAL_ADOPTION_TARGETS) > 0:
                lost_zones = np.setdiff1d(
                    self.REGIONAL_ADOPTION_TARGETS[settings.REGIONAL_ADOPTION_ZONE].unique(),
                    np.unique(self.REGIONAL_ADOPTION_ZONES)
                )
                
                if len(lost_zones) > 0:
                    print(f" 	    WARNING: {len(lost_zones)} regional adoption zones have no cells due to (RES{settings.RESFACTOR}). Please check if this is expected.")
                    self.REGIONAL_ADOPTION_TARGETS = self.REGIONAL_ADOPTION_TARGETS.query(f"{settings.REGIONAL_ADOPTION_ZONE} not in {list(lost_zones)}").reset_index(drop=True)
                
            



        ###############################################################
        # Livestock related data.
        ###############################################################
        print("\tLoading livestock related data...", flush=True)

        self.FEED_REQ = np.nan_to_num(
            pd.read_hdf(os.path.join(settings.INPUT_DIR, "feed_req.h5"), where=self.MASK).to_numpy()
        )
        self.PASTURE_KG_DM_HA = pd.read_hdf(
            os.path.join(settings.INPUT_DIR, "pasture_kg_dm_ha.h5"), where=self.MASK
        ).to_numpy()
        self.SAFE_PUR_NATL = pd.read_hdf(
            os.path.join(settings.INPUT_DIR, "safe_pur_natl.h5"), where=self.MASK
        ).to_numpy()
        self.SAFE_PUR_MODL = pd.read_hdf(
            os.path.join(settings.INPUT_DIR, "safe_pur_modl.h5"), where=self.MASK
        ).to_numpy()



        ###############################################################
        # Agricultural Management options data.
        ###############################################################
        print("\tLoading agricultural management options' data...", flush=True)

        # Asparagopsis taxiformis data
        asparagopsis_file = os.path.join(settings.INPUT_DIR, "20250415_Bundle_MR.xlsx")
        self.ASPARAGOPSIS_DATA = {}
        self.ASPARAGOPSIS_DATA["Beef - modified land"] = pd.read_excel(
            asparagopsis_file, sheet_name="MR bundle (ext cattle)", index_col="Year"
        )
        self.ASPARAGOPSIS_DATA["Sheep - modified land"] = pd.read_excel(
            asparagopsis_file, sheet_name="MR bundle (sheep)", index_col="Year"
        )
        self.ASPARAGOPSIS_DATA["Dairy - natural land"] = pd.read_excel(
            asparagopsis_file, sheet_name="MR bundle (dairy)", index_col="Year"
        )
        self.ASPARAGOPSIS_DATA["Dairy - modified land"] = self.ASPARAGOPSIS_DATA[
            "Dairy - natural land"
        ]

        # Precision agriculture data
        prec_agr_file = os.path.join(settings.INPUT_DIR, "20231101_Bundle_AgTech_NE.xlsx")
        self.PRECISION_AGRICULTURE_DATA = {}
        int_cropping_data = pd.read_excel(
            prec_agr_file, sheet_name="AgTech NE bundle (int cropping)", index_col="Year"
        )
        cropping_data = pd.read_excel(
            prec_agr_file, sheet_name="AgTech NE bundle (cropping)", index_col="Year"
        )
        horticulture_data = pd.read_excel(
            prec_agr_file, sheet_name="AgTech NE bundle (horticulture)", index_col="Year"
        )

        for lu in [
            "Hay",
            "Summer cereals",
            "Summer legumes",
            "Summer oilseeds",
            "Winter cereals",
            "Winter legumes",
            "Winter oilseeds",
        ]:
            # Cropping land uses
            self.PRECISION_AGRICULTURE_DATA[lu] = cropping_data

        for lu in ["Cotton", "Other non-cereal crops", "Rice", "Sugar", "Vegetables"]:
            # Intensive Cropping land uses
            self.PRECISION_AGRICULTURE_DATA[lu] = int_cropping_data

        for lu in [
            "Apples",
            "Citrus",
            "Grapes",
            "Nuts",
            "Pears",
            "Plantation fruit",
            "Stone fruit",
            "Tropical stone fruit",
        ]:
            # Horticulture land uses
            self.PRECISION_AGRICULTURE_DATA[lu] = horticulture_data

        # Ecological grazing data
        eco_grazing_file = os.path.join(settings.INPUT_DIR, "20231107_ECOGRAZE_Bundle.xlsx")
        self.ECOLOGICAL_GRAZING_DATA = {}
        self.ECOLOGICAL_GRAZING_DATA["Beef - modified land"] = pd.read_excel(
            eco_grazing_file, sheet_name="Ecograze bundle (ext cattle)", index_col="Year"
        )
        self.ECOLOGICAL_GRAZING_DATA["Sheep - modified land"] = pd.read_excel(
            eco_grazing_file, sheet_name="Ecograze bundle (sheep)", index_col="Year"
        )
        self.ECOLOGICAL_GRAZING_DATA["Dairy - modified land"] = pd.read_excel(
            eco_grazing_file, sheet_name="Ecograze bundle (dairy)", index_col="Year"
        )

        # Load soil carbon data, convert C to CO2e (x 44/12), and average over years
        self.SOIL_CARBON_AVG_T_CO2_HA = (
            pd.read_hdf(os.path.join(settings.INPUT_DIR, "soil_carbon_t_ha.h5"), where=self.MASK).to_numpy(dtype=np.float32) 
            * (44 / 12) 
            / settings.SOC_AMORTISATION
        )


        # Load AgTech EI data
        prec_agr_file = os.path.join(settings.INPUT_DIR, '20231107_Bundle_AgTech_EI.xlsx')
        self.AGTECH_EI_DATA = {}
        int_cropping_data = pd.read_excel( prec_agr_file, sheet_name='AgTech EI bundle (int cropping)', index_col='Year' )
        cropping_data = pd.read_excel( prec_agr_file, sheet_name='AgTech EI bundle (cropping)', index_col='Year' )
        horticulture_data = pd.read_excel( prec_agr_file, sheet_name='AgTech EI bundle (horticulture)', index_col='Year' )

        for lu in ['Hay', 'Summer cereals', 'Summer legumes', 'Summer oilseeds',
                'Winter cereals', 'Winter legumes', 'Winter oilseeds']:
            # Cropping land uses
            self.AGTECH_EI_DATA[lu] = cropping_data

        for lu in ['Cotton', 'Other non-cereal crops', 'Rice', 'Sugar', 'Vegetables']:
            # Intensive Cropping land uses
            self.AGTECH_EI_DATA[lu] = int_cropping_data

        for lu in ['Apples', 'Citrus', 'Grapes', 'Nuts', 'Pears',
                'Plantation fruit', 'Stone fruit', 'Tropical stone fruit']:
            # Horticulture land uses
            self.AGTECH_EI_DATA[lu] = horticulture_data

        # Load BioChar data
        biochar_file = os.path.join(settings.INPUT_DIR, '20240918_Bundle_BC.xlsx')
        self.BIOCHAR_DATA = {}
        cropping_data = pd.read_excel(biochar_file, sheet_name='Biochar (cropping)', index_col='Year' )
        horticulture_data = pd.read_excel(biochar_file, sheet_name='Biochar (horticulture)', index_col='Year' )

        for lu in ['Hay', 'Summer cereals', 'Summer legumes', 'Summer oilseeds',
                'Winter cereals', 'Winter legumes', 'Winter oilseeds']:
            # Cropping land uses
            self.BIOCHAR_DATA[lu] = cropping_data

        for lu in ['Apples', 'Citrus', 'Grapes', 'Nuts', 'Pears',
                'Plantation fruit', 'Stone fruit', 'Tropical stone fruit']:
            # Horticulture land uses
            self.BIOCHAR_DATA[lu] = horticulture_data

        ###############################################################
        # Renewable energy data.
        ###############################################################
        # Path dictionary for renewable target CSV by technology
        RE_TARGET_PATH = r"T:\GitHub\luto-2.0\input\RE Module\renewable_targets.csv"

        def load_renewable_targets():
            """
            Loads renewable targets CSV as is. Returns full DataFrame.
            """
            if not os.path.exists(RE_TARGET_PATH):
                raise FileNotFoundError(f"Renewable targets file not found: {RE_TARGET_PATH}")
            
            df = pd.read_csv(RE_TARGET_PATH)
            return df

        def filter_targets(df, use_nrm_level=False, state=None, region=None, product=None, selected_nrms=None):
            """
            Filters renewable targets DataFrame based on:
            - use_nrm_level: if True, filter by region (NRM); else filter by state level (region empty or 'statewide')
            - state: filter by STATE column
            - region: filter by REGION column
            - product: filter by PRODUCT column
            - selected_nrms: list of regions to include if filtering for NRM level
            """
            if state:
                df = df[df['STATE'] == state]
            if product:
                df = df[df['PRODUCT'] == product]

            if use_nrm_level:
                # Keep rows where REGION is not empty (assumed NRM-level)
                df = df[df['REGION'].notna() & (df['REGION'] != "")]
                if selected_nrms is not None:
                    df = df[df['REGION'].isin(selected_nrms)]
            else:
                # Keep rows where REGION is empty or null (state-level targets)
                df = df[df['REGION'].isna() | (df['REGION'] == "")]

            return df

        def get_yearly_targets(df):
            """
            Converts the wide dataframe with year columns to a tidy format or dict for target values.
            Returns a DataFrame melted or dictionary keyed by year.
            """
            year_cols = [col for col in df.columns if col.isdigit()]
            # Melt the dataframe (optional; depends on consumption structure)
            df_melted = df.melt(id_vars=['STATE', 'REGION', 'PRODUCT', 'UNIT'], value_vars=year_cols,
                                var_name='Year', value_name='Generation_Target')
            return df_melted

        ############# RE cost rasters #################
        # Paths to establishment cost rasters (update with correct paths)
        ESTABLISHMENT_COST_PATHS = {
            "solar": r"T:\GitHub\luto-2.0\input\RE Module\establishment_cost_solar.tif",
            "wind": r"T:\GitHub\luto-2.0\input\RE Module\establishment_cost_wind.tif",
        }

        def load_establishment_cost_raster(tech):
            path = ESTABLISHMENT_COST_PATHS.get(tech)
            if not path:
                raise ValueError(f"Establishment cost raster path not found for technology: {tech}")
            with rasterio.open(path) as src:
                cost_array = src.read(1)  # read first band
            return cost_array

        ############# Capacity factor and distance loss factor rasters #################
        # Paths for capacity factor rasters
        CF_RASTER_PATHS = {
            "Utility Solar PV": r"T:\GitHub\luto-2.0\input\RE Module\pv_capacity.tif",
            "Onshore Wind": r"T:\GitHub\luto-2.0\input\RE Module\AUS_capacity-factor_IEC2.tif"
        }

        # Paths for distribution loss factor rasters
        DLF_RASTER_PATHS = {
            "Utility Solar PV": r"T:\GitHub\luto-2.0\input\RE Module\dlf_aus_solar.tif",
            "Onshore Wind": r"T:\GitHub\luto-2.0\input\RE Module\dlf_aus_wind.tif"
        }

        def load_capacity_factor_raster(lm: int, data) -> np.ndarray:
            """
            Load capacity factor raster for given land management index `lm`.
            """
            tech_name = data.LANDMANS[lm]
            if "solar" in tech_name.lower():
                key = "Utility Solar PV"
            elif "wind" in tech_name.lower():
                key = "Onshore Wind"
            else:
                raise KeyError(f"No capacity factor raster defined for management '{tech_name}'")

            path = CF_RASTER_PATHS.get(key)
            if path is None:
                raise FileNotFoundError(f"Capacity factor raster file not found for '{key}'")

            with rasterio.open(path) as src:
                cf_data = src.read(1)
            return cf_data.astype(np.float32)

        def load_dlf_raster(lm: int, data) -> np.ndarray:
            """
            Load distribution loss factor raster for given land management index `lm`.
            """
            tech_name = data.LANDMANS[lm]
            if "solar" in tech_name.lower():
                key = "Utility Solar PV"
            elif "wind" in tech_name.lower():
                key = "Onshore Wind"
            else:
                raise KeyError(f"No distribution loss factor raster defined for management '{tech_name}'")

            path = DLF_RASTER_PATHS.get(key)
            if path is None:
                raise FileNotFoundError(f"Distribution loss factor raster file not found for '{key}'")

            with rasterio.open(path) as src:
                dlf_data = src.read(1)
            return dlf_data.astype(np.float32)


        ################ Load Utility solar PV data ######################
        solar_pv_file = os.path.join(settings.INPUT_DIR, 'XXXX_Bundle_SPV.xlsx')

        # Validate file exists
        if not os.path.exists(solar_pv_file):
            raise FileNotFoundError(f"Solar PV data file not found: {solar_pv_file}")

        self.SOLAR_PV_DATA = {}

        try:
            # Load with explicit error handling
            SOLAR_PV_CROPPING_DATA = pd.read_excel(solar_pv_file, sheet_name='Solar PV (cropping)', index_col='Year')
            SOLAR_PV_HORTICULTURE_DATA = pd.read_excel(solar_pv_file, sheet_name='Solar PV (horticulture)', index_col='Year') 
            SOLAR_PV_LIVESTOCK_DATA = pd.read_excel(solar_pv_file, sheet_name='Solar PV (livestock)', index_col='Year')
    
            # Validate required columns exist
            required_columns = ['Productivity', 'Revenue', 'Annual Cost Per Ha (A$2010/yr)', 'Biodiversity_compatability']
            for data_name, data in [('cropping', SOLAR_PV_CROPPING_DATA), ('horticulture', SOLAR_PV_HORTICULTURE_DATA), 
                            ('livestock', SOLAR_PV_LIVESTOCK_DATA)]:
                missing_cols = [col for col in required_columns if col not in data.columns]
                if missing_cols:
                    print(f"Warning: Missing columns in {data_name} data: {missing_cols}")

            # Assign data to land uses
            for lu in ['Hay', 'Summer cereals', 'Summer legumes', 'Summer oilseeds',
                'Winter cereals', 'Winter legumes', 'Winter oilseeds', 
                'Cotton', 'Other non-cereal crops', 'Rice', 'Sugar', 'Vegetables']:
                self.SOLAR_PV_DATA[lu] = SOLAR_PV_CROPPING_DATA
            
            for lu in ['Apples', 'Citrus', 'Grapes', 'Nuts', 'Pears',
                'Plantation fruit', 'Stone fruit', 'Tropical stone fruit']:
                self.SOLAR_PV_DATA[lu] = SOLAR_PV_HORTICULTURE_DATA
            
            for lu in ['Dairy - modified land', 'Beef - modified land', 'Sheep - modified land']:
                self.SOLAR_PV_DATA[lu] = SOLAR_PV_LIVESTOCK_DATA

            print(f"✓ Successfully loaded Solar PV data for {len(self.SOLAR_PV_DATA)} land use types")
    
        except Exception as e:
            raise ValueError(f"Error loading Solar PV data: {e}")

        ################## Load Onshore wind data ######################
        onshore_wind_file = os.path.join(settings.INPUT_DIR, 'XXXX_Bundle_Wind.xlsx')

        # Validate file exists
        if not os.path.exists(onshore_wind_file):
            raise FileNotFoundError(f"Onshore wind data file not found: {onshore_wind_file}")

        self.ONSHORE_WIND_DATA = {}

        try:
            # Load with explicit error handling
            ONSHORE_WIND_CROPPING_DATA = pd.read_excel(onshore_wind_file, sheet_name='Onshore Wind (cropping)', index_col='Year')
            ONSHORE_WIND_HORTICULTURE_DATA = pd.read_excel(onshore_wind_file, sheet_name='Onshore Wind (horticulture)', index_col='Year') 
            ONSHORE_WIND_LIVESTOCK_DATA = pd.read_excel(onshore_wind_file, sheet_name='Onshore Wind (livestock)', index_col='Year')

            # Validate required columns exist
            required_columns = ['Productivity', 'Revenue', 'Annual Cost Per Ha (A$2010/yr)', 'Biodiversity_compatability']
            for data_name, data in [('cropping', ONSHORE_WIND_CROPPING_DATA), 
                                ('horticulture', ONSHORE_WIND_HORTICULTURE_DATA), 
                                ('livestock', ONSHORE_WIND_LIVESTOCK_DATA)]:
                missing_cols = [col for col in required_columns if col not in data.columns]
                if missing_cols:
                    print(f"Warning: Missing columns in {data_name} wind data: {missing_cols}")

            # Assign data to land uses
            for lu in ['Hay', 'Summer cereals', 'Summer legumes', 'Summer oilseeds',
                    'Winter cereals', 'Winter legumes', 'Winter oilseeds', 
                    'Cotton', 'Other non-cereal crops', 'Rice', 'Sugar', 'Vegetables']:
                self.ONSHORE_WIND_DATA[lu] = ONSHORE_WIND_CROPPING_DATA
            
            for lu in ['Apples', 'Citrus', 'Grapes', 'Nuts', 'Pears',
                    'Plantation fruit', 'Stone fruit', 'Tropical stone fruit']:
                self.ONSHORE_WIND_DATA[lu] = ONSHORE_WIND_HORTICULTURE_DATA
            
            for lu in ['Dairy - modified land', 'Beef - modified land', 'Sheep - modified land']:
                self.ONSHORE_WIND_DATA[lu] = ONSHORE_WIND_LIVESTOCK_DATA

            print(f"✓ Successfully loaded onshore wind data for {len(self.ONSHORE_WIND_DATA)} land use types")

        except Exception as e:
            raise ValueError(f"Error loading onshore wind data: {e}")

    

        ###############################################################
        # Productivity data.
        ###############################################################
        print("\tLoading productivity data...", flush=True)

        # Yield increases.
        fpath = os.path.join(settings.INPUT_DIR, "yieldincreases_bau2022.csv")
        self.BAU_PROD_INCR = pd.read_csv(fpath, header=[0, 1]).astype(np.float32)




        ###############################################################
        # Auxiliary Spatial Layers
        # (spatial layers not required for production calculation)
        ###############################################################
        print("\tLoading auxiliary spatial layers data...", flush=True)

        # Load stream length data in metres of stream per cell
        self.STREAM_LENGTH = pd.read_hdf(
            os.path.join(settings.INPUT_DIR, "stream_length_m_cell.h5"), where=self.MASK
        ).to_numpy()

        # Calculate the proportion of the area of each cell within stream buffer (convert REAL_AREA from ha to m2 and divide m2 by m2)
        self.RP_PROPORTION =  (
            (2 * settings.RIPARIAN_PLANTING_BUFFER_WIDTH * self.STREAM_LENGTH) / (self.REAL_AREA_NO_RESFACTOR[self.MASK] * 10000)
        ).astype(np.float32)
        # Calculate the length of fencing required for each cell in per hectare terms for riparian plantings
        self.RP_FENCING_LENGTH = (
            (2 * settings.RIPARIAN_PLANTING_TORTUOSITY_FACTOR * self.STREAM_LENGTH) / self.REAL_AREA_NO_RESFACTOR[self.MASK]
        ).astype(np.float32)



        ###############################################################
        # Additional agricultural GHG data.
        ###############################################################
        print("\tLoading additional agricultural GHG data...", flush=True)


        # Load greenhouse gas emissions from agriculture
        self.AGGHG_CROPS = pd.read_hdf(os.path.join(settings.INPUT_DIR, "agGHG_crops.h5"), where=self.MASK)
        self.AGGHG_LVSTK = pd.read_hdf(os.path.join(settings.INPUT_DIR, "agGHG_lvstk.h5"), where=self.MASK)
        self.AGGHG_IRRPAST = pd.read_hdf(os.path.join(settings.INPUT_DIR, "agGHG_irrpast.h5"), where=self.MASK)


        # Raw transition cost matrix. In AUD/ha and ordered lexicographically.
        self.AG_TMATRIX = np.load(os.path.join(settings.INPUT_DIR, "ag_tmatrix.npy"))
        self.AG_TO_DESTOCKED_NATURAL_COSTS_HA = np.load(os.path.join(settings.INPUT_DIR, "ag_to_destock_tmatrix.npy"))
        
  
        # Boolean x_mrj matrix with allowed land uses j for each cell r under lm.
        self.EXCLUDE = np.load(os.path.join(settings.INPUT_DIR, "x_mrj.npy"))
        self.EXCLUDE = self.EXCLUDE[:, self.MASK, :]  # Apply resfactor specially for the exclude matrix



        ###############################################################
        # Non-agricultural data.
        ###############################################################
        print("\tLoading non-agricultural data...", flush=True)

        # Load plantings economic data
        self.EP_EST_COST_HA = pd.read_hdf(os.path.join(settings.INPUT_DIR, "ep_est_cost_ha.h5"), where=self.MASK).to_numpy(dtype=np.float32)
        self.RP_EST_COST_HA = self.EP_EST_COST_HA.copy()  # Riparian plantings have the same establishment cost as environmental plantings
        self.AF_EST_COST_HA = self.EP_EST_COST_HA.copy()  # Agroforestry plantings have the same establishment cost as environmental plantings
        self.CP_EST_COST_HA = pd.read_hdf(os.path.join(settings.INPUT_DIR, "cp_est_cost_ha.h5"), where=self.MASK).to_numpy(dtype=np.float32)

        # Load fire risk data (reduced carbon sequestration by this amount)
        fr_df = pd.read_hdf(os.path.join(settings.INPUT_DIR, "fire_risk.h5"), where=self.MASK)
        fr_dict = {"low": "FD_RISK_PERC_5TH", "med": "FD_RISK_MEDIAN", "high": "FD_RISK_PERC_95TH"}
        fire_risk = fr_df[fr_dict[settings.FIRE_RISK]]

        # Load environmental plantings (block) GHG sequestration (aboveground carbon discounted by settings.RISK_OF_REVERSAL and settings.FIRE_RISK)
        ep_df = pd.read_hdf(os.path.join(settings.INPUT_DIR, "ep_block_avg_t_co2_ha_yr.h5"), where=self.MASK)
        self.EP_BLOCK_AVG_T_CO2_HA = (
            ep_df.EP_BLOCK_AG_AVG_T_CO2_HA_YR * (fire_risk / 100) * (1 - settings.RISK_OF_REVERSAL)
            + ep_df.EP_BLOCK_BG_AVG_T_CO2_HA_YR
        ).to_numpy(dtype=np.float32)


        # Load environmental plantings (belt) GHG sequestration (aboveground carbon discounted by settings.RISK_OF_REVERSAL and settings.FIRE_RISK)
        ep_df = pd.read_hdf(os.path.join(settings.INPUT_DIR, "ep_belt_avg_t_co2_ha_yr.h5"), where=self.MASK)
        self.EP_BELT_AVG_T_CO2_HA = (
            (ep_df.EP_BELT_AG_AVG_T_CO2_HA_YR * (fire_risk / 100) * (1 - settings.RISK_OF_REVERSAL))
            + ep_df.EP_BELT_BG_AVG_T_CO2_HA_YR
        ).to_numpy(dtype=np.float32)

        # Load environmental plantings (riparian) GHG sequestration (aboveground carbon discounted by settings.RISK_OF_REVERSAL and settings.FIRE_RISK)
        ep_df = pd.read_hdf(os.path.join(settings.INPUT_DIR, "ep_rip_avg_t_co2_ha_yr.h5"), where=self.MASK)
        self.EP_RIP_AVG_T_CO2_HA = (
            (ep_df.EP_RIP_AG_AVG_T_CO2_HA_YR * (fire_risk / 100) * (1 - settings.RISK_OF_REVERSAL))
            + ep_df.EP_RIP_BG_AVG_T_CO2_HA_YR
        ).to_numpy(dtype=np.float32)

        # Load carbon plantings (block) GHG sequestration (aboveground carbon discounted by settings.RISK_OF_REVERSAL and settings.FIRE_RISK)
        cp_df = pd.read_hdf(os.path.join(settings.INPUT_DIR, "cp_block_avg_t_co2_ha_yr.h5"), where=self.MASK)
        self.CP_BLOCK_AVG_T_CO2_HA = (
            (cp_df.CP_BLOCK_AG_AVG_T_CO2_HA_YR * (fire_risk / 100) * (1 - settings.RISK_OF_REVERSAL))
            + cp_df.CP_BLOCK_BG_AVG_T_CO2_HA_YR
        ).to_numpy(dtype=np.float32)


        # Load farm forestry [i.e. carbon plantings (belt)] GHG sequestration (aboveground carbon discounted by settings.RISK_OF_REVERSAL and settings.FIRE_RISK)
        cp_df = pd.read_hdf(os.path.join(settings.INPUT_DIR, "cp_belt_avg_t_co2_ha_yr.h5"), where=self.MASK)
        self.CP_BELT_AVG_T_CO2_HA = (
            (cp_df.CP_BELT_AG_AVG_T_CO2_HA_YR * (fire_risk / 100) * (1 - settings.RISK_OF_REVERSAL))
            + cp_df.CP_BELT_BG_AVG_T_CO2_HA_YR
        ).to_numpy(dtype=np.float32)

        # Agricultural land use to plantings raw transition costs:
        self.AG2EP_TRANSITION_COSTS_HA = np.load(
            os.path.join(settings.INPUT_DIR, "ag_to_ep_tmatrix.npy")
        )  # shape: (28,)

        # EP to agricultural land use transition costs:
        self.EP2AG_TRANSITION_COSTS_HA = np.load(
            os.path.join(settings.INPUT_DIR, "ep_to_ag_tmatrix.npy")
        )  # shape: (28,)
        
        
        ##############################################################
        # Transition cost for all land use
        #############################################################
        
        # Transition matrix from ag
        tmat_ag2ag_xr = xr.DataArray(
            self.AG_TMATRIX,
            dims=['from_lu','to_lu'],
            coords={'from_lu':self.AGRICULTURAL_LANDUSES, 'to_lu':self.AGRICULTURAL_LANDUSES }
        )
        tmat_ag2non_ag_xr = xr.DataArray(
            np.repeat(self.AG2EP_TRANSITION_COSTS_HA.reshape(-1,1), len(self.NON_AGRICULTURAL_LANDUSES), axis=1),
            dims=['from_lu','to_lu'],
            coords={'from_lu':self.AGRICULTURAL_LANDUSES, 'to_lu':self.NON_AGRICULTURAL_LANDUSES}
        )
        tmat_from_ag_xr = xr.concat([tmat_ag2ag_xr, tmat_ag2non_ag_xr], dim='to_lu')                        # Combine ag2ag and ag2non-ag
        tmat_from_ag_xr.loc[:,'Destocked - natural land'] = self.AG_TO_DESTOCKED_NATURAL_COSTS_HA           # Ag to Destock-natural has its own values
        
        
        # Transition matrix of non-ag to unallocated-modified land (land clearing)
        tmat_wood_clear = np.load(os.path.join(settings.INPUT_DIR, 'transition_cost_clearing_forest.npz'))
        
        tmat_clear_EP = tmat_wood_clear['tmat_clear_wood_barrier'] + tmat_wood_clear['tmat_clear_dense_wood']
        tmat_clear_RP = tmat_wood_clear['tmat_clear_wood_barrier'] + tmat_wood_clear['tmat_clear_dense_wood']
        tmat_clear_sheep_ag_forest = (tmat_wood_clear['tmat_clear_wood_barrier'] + tmat_wood_clear['tmat_clear_dense_wood']) * settings.AF_PROPORTION
        tmat_clear_beef_ag_forest = (tmat_wood_clear['tmat_clear_wood_barrier'] + tmat_wood_clear['tmat_clear_dense_wood']) * settings.AF_PROPORTION
        tmat_clear_CP = tmat_wood_clear['tmat_clear_wood_barrier'] + tmat_wood_clear['tmat_clear_dense_wood']
        tmat_clear_sheep_CP = (tmat_wood_clear['tmat_clear_wood_barrier'] + tmat_wood_clear['tmat_clear_dense_wood']) * settings.CP_BELT_PROPORTION
        tmat_clear_beef_CP = (tmat_wood_clear['tmat_clear_wood_barrier'] + tmat_wood_clear['tmat_clear_dense_wood']) * settings.CP_BELT_PROPORTION
        tmat_clear_BECCS = tmat_wood_clear['tmat_clear_wood_barrier'] + tmat_wood_clear['tmat_clear_dense_wood']
        tmat_clear_destocked_nat = tmat_wood_clear['tmat_clear_light_wood'] + tmat_wood_clear['tmat_clear_dense_wood']
        
        tmat_costs = np.array([
            tmat_clear_EP, tmat_clear_RP, tmat_clear_sheep_ag_forest, tmat_clear_beef_ag_forest,
            tmat_clear_CP, tmat_clear_sheep_CP, tmat_clear_beef_CP, tmat_clear_BECCS, tmat_clear_destocked_nat
        ]).T
        
        
        
        
        # Transition matrix from non-ag
        tmat_non_ag2ag_xr = xr.DataArray(
            np.repeat(self.EP2AG_TRANSITION_COSTS_HA.reshape(1,-1), len(self.NON_AGRICULTURAL_LANDUSES), axis=0),
            dims=['from_lu','to_lu'],
            coords={'from_lu':self.NON_AGRICULTURAL_LANDUSES, 'to_lu':self.AGRICULTURAL_LANDUSES }
        )
        tmat_non_ag2non_ag_xr = xr.DataArray(
            np.full((len(self.NON_AGRICULTURAL_LANDUSES), len(self.NON_AGRICULTURAL_LANDUSES)), np.nan),
            dims=['from_lu','to_lu'],
            coords={'from_lu':self.NON_AGRICULTURAL_LANDUSES, 'to_lu':self.NON_AGRICULTURAL_LANDUSES }
        )


        np.fill_diagonal(tmat_non_ag2non_ag_xr.values, 0)                                                   # Lu staty the same has 0 cost
        tmat_from_non_ag_xr = xr.concat([tmat_non_ag2ag_xr, tmat_non_ag2non_ag_xr], dim='to_lu')            # Combine non-ag2ag and non-ag2non-ag
        tmat_from_non_ag_xr.loc['Destocked - natural land', 'Unallocated - natural land'] = np.nan          # Destocked-natural can not transit to unallow-natural
        
   
        # Get the full transition cost matrix
        self.T_MAT = xr.concat([tmat_from_ag_xr, tmat_from_non_ag_xr], dim='from_lu')
        self.T_MAT.loc[self.NON_AGRICULTURAL_LANDUSES, [self.AGLU2DESC[i] for i in self.LU_NATURAL]] = np.nan       # non-ag2natural is not allowed
        self.T_MAT.loc[self.NON_AGRICULTURAL_LANDUSES, 'Unallocated - modified land'] = tmat_costs                  # Clearing non-ag land requires such cost
        self.T_MAT.loc['Destocked - natural land', self.LU_LVSTK_NATURAL_DESC] = self.T_MAT.loc['Unallocated - natural land', self.LU_LVSTK_NATURAL_DESC]   # Destocked-natural transits to LVSTK-natural has the same cost as unallocated-natural to LVSTK-natural


        # tools.plot_t_mat(self.T_MAT)
        
        

        ###############################################################
        # Water data.
        ###############################################################
        print("\tLoading water data...", flush=True)
        
        # Initialize water constraints to avoid recalculating them every time.
        self.WATER_YIELD_LIMITS = None

        # Water requirements by land use -- LVSTK.
        wreq_lvstk_dry = pd.DataFrame()
        wreq_lvstk_irr = pd.DataFrame()

        # The rj-indexed arrays have zeroes where j is not livestock.
        for lu in self.AGRICULTURAL_LANDUSES:
            if lu in self.LU_LVSTK:
                # First find out which animal is involved.
                animal, _ = ag_quantity.lvs_veg_types(lu)
                # Water requirements per head are for drinking and irrigation.
                wreq_lvstk_dry[lu] = self.AGEC_LVSTK["WR_DRN", animal] * settings.LIVESTOCK_DRINKING_WATER
                wreq_lvstk_irr[lu] = (
                    self.AGEC_LVSTK["WR_IRR", animal] + self.AGEC_LVSTK["WR_DRN", animal] * settings.LIVESTOCK_DRINKING_WATER
                )
            else:
                wreq_lvstk_dry[lu] = 0.0
                wreq_lvstk_irr[lu] = 0.0

        # Water requirements by land use -- CROPS.
        wreq_crops_irr = pd.DataFrame()

        # The rj-indexed arrays have zeroes where j is not a crop.
        for lu in self.AGRICULTURAL_LANDUSES:
            if lu in self.LU_CROPS:
                wreq_crops_irr[lu] = self.AGEC_CROPS["WR", "irr", lu]
            else:
                wreq_crops_irr[lu] = 0.0

        # Add together as they have nans where not lvstk/crops
        self.WREQ_DRY_RJ = np.nan_to_num(wreq_lvstk_dry.to_numpy(dtype=np.float32))
        self.WREQ_IRR_RJ = np.nan_to_num(wreq_crops_irr.to_numpy(dtype=np.float32)) + np.nan_to_num(
            wreq_lvstk_irr.to_numpy(dtype=np.float32)
        )

        # Spatially explicit costs of a water licence per ML.
        self.WATER_LICENCE_PRICE = np.nan_to_num(
                pd.read_hdf(os.path.join(settings.INPUT_DIR, "water_licence_price.h5"), where=self.MASK).to_numpy()
        )

        # Spatially explicit costs of water delivery per ML.
        self.WATER_DELIVERY_PRICE = np.nan_to_num(
                pd.read_hdf(os.path.join(settings.INPUT_DIR, "water_delivery_price.h5"), where=self.MASK).to_numpy()
        )
       

        # Water yields -- run off from a cell into catchment by deep-rooted, shallow-rooted, and natural land
        water_yield_baselines = pd.read_hdf(os.path.join(settings.INPUT_DIR, "water_yield_baselines.h5"), where=self.MASK)
        self.WATER_YIELD_HIST_DR = water_yield_baselines['WATER_YIELD_HIST_DR_ML_HA'].to_numpy(dtype = np.float32)
        self.WATER_YIELD_HIST_SR = water_yield_baselines["WATER_YIELD_HIST_SR_ML_HA"].to_numpy(dtype = np.float32)
        self.DEEP_ROOTED_PROPORTION = water_yield_baselines['DEEP_ROOTED_PROPORTION'].to_numpy(dtype = np.float32)
        self.WATER_YIELD_HIST_NL = water_yield_baselines.eval(
            'WATER_YIELD_HIST_DR_ML_HA * DEEP_ROOTED_PROPORTION + WATER_YIELD_HIST_SR_ML_HA * (1 - DEEP_ROOTED_PROPORTION)'
        ).to_numpy(dtype = np.float32)

        wyield_fname_dr = os.path.join(settings.INPUT_DIR, 'water_yield_ssp' + str(settings.SSP) + '_2010-2100_dr_ml_ha.h5')
        wyield_fname_sr = os.path.join(settings.INPUT_DIR, 'water_yield_ssp' + str(settings.SSP) + '_2010-2100_sr_ml_ha.h5')
        
        # Read water yield data
        self.WATER_YIELD_DR_FILE = pd.read_hdf(wyield_fname_dr, where=self.MASK).T.values
        self.WATER_YIELD_SR_FILE = pd.read_hdf(wyield_fname_sr, where=self.MASK).T.values
        
        
        # Water yield from outside LUTO study area.
        self.WATER_YIELD_OUTSIDE_LUTO_HIST = pd.read_hdf(os.path.join(settings.INPUT_DIR, 'water_yield_outside_LUTO_study_area_hist_1970_2000.h5'))
        
        # Water use for domestic and industrial sectors.
        water_use_domestic = pd.read_csv(os.path.join(settings.INPUT_DIR, "Water_Use_Domestic.csv")).query('REGION_TYPE == @settings.WATER_REGION_DEF')
        self.WATER_USE_DOMESTIC = water_use_domestic.set_index('REGION_ID')['DOMESTIC_INDUSTRIAL_WATER_USE_ML'].to_dict()

        # Call the function to create watershed components
        self.VALID_WATERSHED_IDS = self.get_watershed_yield_components()

        # Get the water region index for each region
        self.WATER_REGION_INDEX_R = {k:(self.WATER_REGION_ID == k) for k in self.WATER_REGION_NAMES.keys()}

        # Place holder for Water Yield to avoid recalculating it every time.
        self.water_yield_regions_BASE_YR = None
        
        # Water yield targets for each region
        self.WATER_YIELD_TARGETS, self.WATER_RELAXED_REGION_RAW_TARGETS = ag_water.get_water_target_inside_LUTO_by_CCI(self)

        ###############################################################
        # Carbon sequestration by natural lands.
        ###############################################################
        print("\tLoading carbon sequestration by natural lands data...", flush=True)

        '''
        ['NATURAL_LAND_AGB_TCO2_HA']
            CO2 in aboveground living biomass in natural land i.e., the part impacted by livestock 
        ['NATURAL_LAND_AGB_DEBRIS_TCO2_HA']
            CO2 in aboveground living biomass and debris in natural land i.e., the part impacted by fire
        ['NATURAL_LAND_TREES_DEBRIS_SOIL_TCO2_HA']
            CO2 in aboveground living biomass and debris and soil in natural land i.e., the part impacted by land clearance
        '''
    
        # Load the natural land carbon data.
        nat_land_CO2 = pd.read_hdf(os.path.join(settings.INPUT_DIR, "natural_land_t_co2_ha.h5"), where=self.MASK)
        
        # Get the carbon stock of unallowcated natural land
        self.CO2E_STOCK_UNALL_NATURAL = np.array(
            nat_land_CO2['NATURAL_LAND_TREES_DEBRIS_SOIL_TCO2_HA'] - (nat_land_CO2['NATURAL_LAND_AGB_DEBRIS_TCO2_HA'] * (100 - fire_risk).to_numpy() / 100),  # everyting minus the fire DAMAGE
        )
        
        
        ###############################################################
        # Calculate base year production 
        ###############################################################

        self.AG_MAN_L_MRJ_DICT = get_base_am_vars(self.NCELLS, self.NLMS, self.N_AG_LUS)
        self.add_ag_man_dvars(self.YR_CAL_BASE, self.AG_MAN_L_MRJ_DICT)
        
        print(f"\tCalculating base year productivity...", flush=True)
        yr_cal_base_prod_data = self.get_production()        
        self.add_production_data(self.YR_CAL_BASE, "Production", yr_cal_base_prod_data)
        
        
        
        # Place holders for base year values; will be filled in the input_data module.
        self.BASE_YR_economic_value = None
        self.BASE_YR_production_t = yr_cal_base_prod_data
        self.BASE_YR_GHG_t = None
        self.BASE_YR_water_ML = None
        self.BASE_YR_overall_bio_value = None
        self.BASE_YR_GBF2_score = None

        ###############################################################
        # Demand data.
        ###############################################################
        print("\tLoading demand data...", flush=True)

        # Load demand data (actual production (tonnes, ML) by commodity) - from demand model
        dd = pd.read_hdf(os.path.join(settings.INPUT_DIR, 'demand_projections.h5'))

        # Select the demand data under the running scenariobbryan-January
        self.DEMAND_DATA = dd.loc[(settings.SCENARIO,
                                   settings.DIET_DOM,
                                   settings.DIET_GLOB,
                                   settings.CONVERGENCE,
                                   settings.IMPORT_TREND,
                                   settings.WASTE,
                                   settings.FEED_EFFICIENCY)].copy()

        # Convert eggs from count to tonnes
        self.DEMAND_DATA.loc['eggs'] = self.DEMAND_DATA.loc['eggs'] * settings.EGGS_AVG_WEIGHT / 1000 / 1000

        # Get the off-land commodities
        self.DEMAND_OFFLAND = self.DEMAND_DATA.loc[self.DEMAND_DATA.query("COMMODITY in @settings.OFF_LAND_COMMODITIES").index, 'PRODUCTION'].copy()

        # Remove off-land commodities
        self.DEMAND_C = self.DEMAND_DATA.loc[self.DEMAND_DATA.query("COMMODITY not in @settings.OFF_LAND_COMMODITIES").index, 'PRODUCTION'].copy()

        # Convert to numpy array of shape (91, 26)
        self.D_CY = self.DEMAND_C.to_numpy(dtype = np.float32).T
        
        # Adjust demand data to the production data calculated using the base year layers;
        # The mismatch is caused by resfactoring spatial layers. Land uses of small size (i.e., other non-cereal crops) 
        # are distorted more under higher resfactoring.
        self.D_CY *= (yr_cal_base_prod_data / self.D_CY[0])[None, :]


        ###############################################################
        # Carbon emissions from off-land commodities.
        ###############################################################
        print("\tLoading off-land commodities' carbon emissions data...", flush=True)

        # Read the greenhouse gas intensity data
        off_land_ghg_intensity = pd.read_csv(f'{settings.INPUT_DIR}/agGHG_lvstk_off_land.csv')
        # Split the Emission Source column into two columns
        off_land_ghg_intensity[['Emission Type', 'Emission Source']] = off_land_ghg_intensity['Emission Source'].str.extract(r'^(.*?)\s*\((.*?)\)')

        # Get the emissions from the off-land commodities
        demand_offland_long = self.DEMAND_OFFLAND.stack().reset_index()
        demand_offland_long = demand_offland_long.rename(columns={ 0: 'DEMAND (tonnes)'})

        # Merge the demand and GHG intensity, and calculate the total GHG emissions
        off_land_ghg_emissions = demand_offland_long.merge(off_land_ghg_intensity, on='COMMODITY')
        off_land_ghg_emissions['Total GHG Emissions (tCO2e)'] = off_land_ghg_emissions.eval('`DEMAND (tonnes)` * `Emission Intensity [ kg CO2eq / kg ]`')

        # Keep only the relevant columns
        self.OFF_LAND_GHG_EMISSION = off_land_ghg_emissions[['YEAR',
                                                             'COMMODITY',
                                                             'Emission Type',
                                                             'Emission Source',
                                                             'Total GHG Emissions (tCO2e)']]

        # Get the GHG constraints for luto, shape is (91, 1)
        self.OFF_LAND_GHG_EMISSION_C = self.OFF_LAND_GHG_EMISSION.groupby(['YEAR']).sum(numeric_only=True).values

        # Read the carbon price per tonne over the years (indexed by the relevant year)
        if settings.CARBON_PRICES_FIELD == 'CONSTANT':
            self.CARBON_PRICES = {yr: settings.CARBON_PRICE_COSTANT for yr in range(2010, 2101)}
        else:
            carbon_price_sheet = settings.CARBON_PRICES_FIELD or "Default"
            carbon_price_usecols = "A,B"
            carbon_price_col_names = ["Year", "Carbon_price_$_tCO2e"]
            carbon_price_sheet_index_col = "Year" # if carbon_price_sheet != "Default" else 0
            carbon_price_sheet_header = 0         # if carbon_price_sheet != "Default" else None

            self.CARBON_PRICES: dict[int, float] = pd.read_excel(
                os.path.join(settings.INPUT_DIR, 'carbon_prices.xlsx'),
                sheet_name=carbon_price_sheet,
                usecols=carbon_price_usecols,
                names=carbon_price_col_names,
                header=carbon_price_sheet_header,
                index_col=carbon_price_sheet_index_col,
            )["Carbon_price_$_tCO2e"].to_dict()
            


        ###############################################################
        # GHG targets data.
        ###############################################################
        print("\tLoading GHG targets data...", flush=True)
        if settings.GHG_EMISSIONS_LIMITS != 'off':
            self.GHG_TARGETS = pd.read_excel(
                os.path.join(settings.INPUT_DIR, "GHG_targets.xlsx"), sheet_name="Data", index_col="YEAR"
            )
            self.GHG_TARGETS = self.GHG_TARGETS[settings.GHG_TARGETS_DICT[settings.GHG_EMISSIONS_LIMITS]].to_dict()



        ###############################################################
        # Savanna burning data.
        ###############################################################
        print("\tLoading savanna burning data...", flush=True)

        # Read in the dataframe
        savburn_df = pd.read_hdf(os.path.join(settings.INPUT_DIR, 'cell_savanna_burning.h5'), where=self.MASK)

        # Load the columns as numpy arrays
        self.SAVBURN_ELIGIBLE =  savburn_df.ELIGIBLE_AREA.to_numpy()                    # 1 = areas eligible for early dry season savanna burning under the ERF, 0 = ineligible          
        self.SAVBURN_TOTAL_TCO2E_HA = savburn_df.AEA_TOTAL_TCO2E_HA.to_numpy()
        
        # # Avoided emissions from savanna burning
        # self.SAVBURN_AVEM_CH4_TCO2E_HA = savburn_df.SAV_AVEM_CH4_TCO2E_HA.to_numpy()  # Avoided emissions - methane
        # self.SAVBURN_AVEM_N2O_TCO2E_HA = savburn_df.SAV_AVEM_N2O_TCO2E_HA.to_numpy()  # Avoided emissions - nitrous oxide
        # self.SAVBURN_SEQ_CO2_TCO2E_HA = savburn_df.SAV_SEQ_CO2_TCO2E_HA.to_numpy()    # Additional carbon sequestration - carbon dioxide

        # Cost per hectare in dollars from settings
        self.SAVBURN_COST_HA = settings.SAVBURN_COST_HA_YR



        ###############################################################
        # Biodiversity priority conservation data. (GBF Target 2)
        ###############################################################
        
        print("\tLoading biodiversity data...", flush=True)
        """
        Kunming-Montreal Biodiversity Framework Target 2: Restore 30% of all Degraded Ecosystems
        Ensure that by 2030 at least 30 per cent of areas of degraded terrestrial, inland water, and coastal and marine ecosystems are under effective restoration,
        in order to enhance biodiversity and ecosystem functions and services, ecological integrity and connectivity.
        """

        biodiv_raw = pd.read_hdf(os.path.join(settings.INPUT_DIR, 'bio_OVERALL_PRIORITY_RANK_AND_AREA_CONNECTIVITY.h5'), where=self.MASK)
        biodiv_contribution_lookup = pd.read_csv(os.path.join(settings.INPUT_DIR, 'bio_OVERALL_CONTRIBUTION_OF_LANDUSES.csv'))                              
        

        # ------------- Biodiversity priority scores for maximising overall biodiversity conservation in Australia ----------------------------
        
        # Get connectivity score
        match settings.CONNECTIVITY_SOURCE:
            case 'NCI':
                connectivity_score = biodiv_raw['DCCEEW_NCI'].to_numpy(dtype=np.float32)
                connectivity_score = np.interp( biodiv_raw['DCCEEW_NCI'], (connectivity_score.min(), connectivity_score.max()), (settings.CONNECTIVITY_LB, 1)).astype('float32')
            case 'DWI':
                connectivity_score = biodiv_raw['NATURAL_AREA_CONNECTIVITY'].to_numpy(dtype=np.float32)
                connectivity_score = np.interp(connectivity_score, (connectivity_score.min(), connectivity_score.max()), (1, settings.CONNECTIVITY_LB)).astype('float32')
            case 'NONE':
                connectivity_score = np.ones(self.NCELLS, dtype=np.float32)
            case _:
                raise ValueError(f"Invalid connectivity source: {settings.CONNECTIVITY_SOURCE}, must be 'NCI', 'DWI' or 'NONE'")
            
        self.CONNECTIVITY_SCORE = connectivity_score

        # Get the HCAS contribution scale (0-1)
        match settings.HABITAT_CONDITION:
            case 10 | 25 | 50 | 75 | 90:
                bio_HCAS_contribution_lookup = biodiv_contribution_lookup.set_index('lu')[f'PERCENTILE_{settings.HABITAT_CONDITION}'].to_dict()         # Get the biodiversity degradation score at specified percentile (pd.DataFrame)
                unallow_nat_scale = bio_HCAS_contribution_lookup[self.DESC2AGLU['Unallocated - natural land']]                                          # Get the biodiversity degradation score for unallocated natural land (float)
                bio_HCAS_contribution_lookup = {int(k): v * (1 / unallow_nat_scale) for k, v in bio_HCAS_contribution_lookup.items()}                   # Normalise the biodiversity degradation score to the unallocated natural land score
            case 'USER_DEFINED':
                bio_HCAS_contribution_lookup = biodiv_contribution_lookup.set_index('lu')['USER_DEFINED'].to_dict()
            case _:
                print(f"WARNING!! Invalid habitat condition source: {settings.HABITAT_CONDITION}, must be one of [10, 25, 50, 75, 90], or 'USER_DEFINED'")
        
        self.BIO_HABITAT_CONTRIBUTION_LOOK_UP = {j: round(x, settings.ROUND_DECMIALS) for j, x in bio_HCAS_contribution_lookup.items()}             # Round to the specified decimal places to avoid numerical issues in the GUROBI solver
        
        
        # Get the biodiversity contribution score 
        bio_contribution_raw = biodiv_raw[f'BIODIV_PRIORITY_SSP{settings.SSP}'].values
        self.BIO_CONNECTIVITY_RAW = bio_contribution_raw * connectivity_score                                          
        self.BIO_CONNECTIVITY_LDS = np.where(                                                                     
            self.SAVBURN_ELIGIBLE, 
            self.BIO_CONNECTIVITY_RAW * settings.BIO_CONTRIBUTION_LDS, 
            self.BIO_CONNECTIVITY_RAW
        )
        
  
        # ------------------ Habitat condition impacts for habitat conservation (GBF2) in 'priority degraded areas' regions ---------------
        if settings.BIODIVERSITY_TARGET_GBF_2 != 'off':
        
            # Get the mask of 'priority degraded areas' for habitat conservation
            conservation_performance_curve = pd.read_excel(os.path.join(settings.INPUT_DIR, 'BIODIVERSITY_GBF2_conservation_performance.xlsx'), sheet_name=f'ssp{settings.SSP}'
            ).set_index('AREA_COVERAGE_PERCENT')['PRIORITY_RANK'].to_dict()
            
            priority_degraded_areas_mask = bio_contribution_raw >= conservation_performance_curve[settings.GBF2_PRIORITY_DEGRADED_AREAS_PERCENTAGE_CUT]
            
            self.BIO_PRIORITY_DEGRADED_AREAS_R = np.where(
                self.SAVBURN_ELIGIBLE,
                priority_degraded_areas_mask * self.REAL_AREA * settings.BIO_CONTRIBUTION_LDS,
                priority_degraded_areas_mask * self.REAL_AREA
            )
            
            self.BIO_PRIORITY_DEGRADED_CONTRIBUTION_WEIGHTED_AREAS_BASE_YR_R = np.einsum(
                'j,mrj,r->r',
                np.array(list(self.BIO_HABITAT_CONTRIBUTION_LOOK_UP.values())),
                self.AG_L_MRJ,
                self.BIO_PRIORITY_DEGRADED_AREAS_R
            )

        
        ###############################################################
        # Vegetation data (GBF3).
        ###############################################################
        if settings.BIODIVERSITY_TARGET_GBF_3 != 'off':
        
            print("\tLoading vegetation data...", flush=True)
            
            # Read in the pre-1750 vegetation statistics, and get NVIS class names and areas
            GBF3_targets_df = pd.read_excel(
                settings.INPUT_DIR + '/BIODIVERSITY_GBF3_SCORES_AND_TARGETS.xlsx',
                sheet_name = f'NVIS_{settings.GBF3_TARGET_CLASS}'
            ).sort_values(by='group', ascending=True)
            
            
            if settings.BIODIVERSITY_TARGET_GBF_3 == 'USER_DEFINED':
                self.GBF3_GROUPS_SEL = [row['group'] for _,row in GBF3_targets_df.iterrows()
                    if all([
                        row['USER_DEFINED_TARGET_PERCENT_2030']>0,
                        row['USER_DEFINED_TARGET_PERCENT_2050']>0,
                        row['USER_DEFINED_TARGET_PERCENT_2100']>0]
                    )]
                self.GBF3_BASELINE_AREA_AND_USERDEFINE_TARGETS = GBF3_targets_df.query('group.isin(@self.GBF3_GROUPS_SEL)')
            else:
                self.GBF3_GROUPS_SEL = GBF3_targets_df['group'].tolist()
                self.GBF3_BASELINE_AREA_AND_USERDEFINE_TARGETS = GBF3_targets_df.query('group.isin(@self.GBF3_GROUPS_SEL)')
                self.GBF3_BASELINE_AREA_AND_USERDEFINE_TARGETS[[
                    'USER_DEFINED_TARGET_PERCENT_2030',
                    'USER_DEFINED_TARGET_PERCENT_2050', 
                    'USER_DEFINED_TARGET_PERCENT_2100']] = settings.GBF3_TARGETS_DICT[settings.BIODIVERSITY_TARGET_GBF_3]
                

            self.BIO_GBF3_BASELINE_SCORE_ALL_AUSTRALIA = self.GBF3_BASELINE_AREA_AND_USERDEFINE_TARGETS['AREA_WEIGHTED_SCORE_ALL_AUSTRALIA_HA'].to_numpy()
            self.BIO_GBF3_BASELINE_SCORE_OUTSIDE_LUTO = self.GBF3_BASELINE_AREA_AND_USERDEFINE_TARGETS['AREA_WEIGHTED_SCORE_OUTSIDE_LUTO_NATURAL_HA'].to_numpy()
            self.BIO_GBF3_ID2DESC = dict(enumerate(self.GBF3_GROUPS_SEL))
            self.BIO_GBF3_N_CLASSES = len(self.GBF3_GROUPS_SEL) 
            
            
            
            # Read in vegetation layer data
            NVIS_layers = xr.open_dataarray(settings.INPUT_DIR + f"/NVIS_{settings.GBF3_TARGET_CLASS.split('_')[0]}.nc").sel(group=self.GBF3_GROUPS_SEL)
            NVIS_layers = np.array([self.get_exact_resfactored_average_arr_without_lu_mask(arr) for arr in NVIS_layers], dtype=np.float32) / 100.0  # divide by 100 to get the percentage of the area in each cell that is covered by the vegetation type

            # Apply Savanna Burning penalties
            self.NVIS_LAYERS_LDS = np.where(
                self.SAVBURN_ELIGIBLE,
                NVIS_layers * settings.BIO_CONTRIBUTION_LDS,
                NVIS_layers
            )
            
            # Container storing which cells apply to each major vegetation group
            epsilon = 1e-5
            self.MAJOR_VEG_INDECES = {
                v: np.where(NVIS_layers[v] > epsilon)[0]
                for v in range(NVIS_layers.shape[0])
            }
            
            
 
        
        ##########################################################################
        #  Biodiersity environmental significance (GBF4)                         #
        ##########################################################################
        if settings.BIODIVERSITY_TARGET_GBF_4_SNES != 'off':

            print("\tLoading environmental significance data (SNES)...", flush=True)
            
            # Read in the species data from DCCEEW National Environmental Significance (noted as GBF-4)
            BIO_GBF4_SNES_score = pd.read_csv(settings.INPUT_DIR + '/BIODIVERSITY_GBF4_TARGET_SNES.csv').sort_values(by='SCIENTIFIC_NAME', ascending=True)
            
            self.BIO_GBF4_SNES_LIKELY_SEL = [row['SCIENTIFIC_NAME'] for _,row in BIO_GBF4_SNES_score.iterrows()
                                                    if all([row['USER_DEFINED_TARGET_PERCENT_2030_LIKELY']>0,
                                                            row['USER_DEFINED_TARGET_PERCENT_2050_LIKELY']>0,
                                                            row['USER_DEFINED_TARGET_PERCENT_2100_LIKELY']>0])]
            
            self.BIO_GBF4_SNES_LIKELY_AND_MAYBE_SEL = [row['SCIENTIFIC_NAME'] for _,row in BIO_GBF4_SNES_score.iterrows()
                                                    if all([row['USER_DEFINED_TARGET_PERCENT_2030_LIKELY_MAYBE']>0,
                                                            row['USER_DEFINED_TARGET_PERCENT_2050_LIKELY_MAYBE']>0,
                                                            row['USER_DEFINED_TARGET_PERCENT_2100_LIKELY_MAYBE']>0])]
            
            if len(self.BIO_GBF4_SNES_LIKELY_SEL) == 0:
                raise ValueError("At least one of 'LIKELY' layers should be selected!")

            likely_maybe_union = set(self.BIO_GBF4_SNES_LIKELY_SEL).intersection(self.BIO_GBF4_SNES_LIKELY_AND_MAYBE_SEL)
            if likely_maybe_union:
                print(f"\tWARNING: {len(likely_maybe_union)} duplicate SNE species targets found, using 'LIKELY' targets only:")
                print("\n".join(f"    {idx+1}) {name}" for idx, name in enumerate(likely_maybe_union)))
                self.BIO_GBF4_SNES_LIKELY_AND_MAYBE_SEL = list(set(self.BIO_GBF4_SNES_LIKELY_AND_MAYBE_SEL) - likely_maybe_union)
                
            self.BIO_GBF4_SNES_SEL_ALL = self.BIO_GBF4_SNES_LIKELY_SEL + self.BIO_GBF4_SNES_LIKELY_AND_MAYBE_SEL
            self.BIO_GBF4_PRESENCE_SNES_SEL = ['LIKELY'] * len(self.BIO_GBF4_SNES_LIKELY_SEL) + ['LIKELY_MAYBE'] * len(self.BIO_GBF4_SNES_LIKELY_AND_MAYBE_SEL)  
            self.BIO_GBF4_SNES_BASELINE_SCORE_TARGET_PERCENT_LIKELY = BIO_GBF4_SNES_score.query(f'SCIENTIFIC_NAME in {self.BIO_GBF4_SNES_LIKELY_SEL}')
            self.BIO_GBF4_SNES_BASELINE_SCORE_TARGET_PERCENT_LIKELY_AND_MAYBE = BIO_GBF4_SNES_score.query(f'SCIENTIFIC_NAME in {self.BIO_GBF4_SNES_LIKELY_AND_MAYBE_SEL}') 
            
            BIO_GBF4_SPECIES_raw = xr.open_dataarray(f'{settings.INPUT_DIR}/bio_GBF4_SNES.nc', chunks={'species':1})
            snes_arr_likely = BIO_GBF4_SPECIES_raw.sel(species=self.BIO_GBF4_SNES_LIKELY_SEL, presence='LIKELY')
            snes_arr_likely_maybe = BIO_GBF4_SPECIES_raw.sel(species=self.BIO_GBF4_SNES_LIKELY_AND_MAYBE_SEL, presence='LIKELY_AND_MAYBE')
            snes_arr = xr.concat([snes_arr_likely, snes_arr_likely_maybe], dim='species')
            self.BIO_GBF4_SPECIES_LAYERS = np.array([self.get_exact_resfactored_average_arr_without_lu_mask(arr) for arr in snes_arr]) 
        
        
        if settings.BIODIVERSITY_TARGET_GBF_4_SNES != 'off':
            print("\tLoading environmental significance data (ECNES)...", flush=True)
        
        
            BIO_GBF4_ECNES_score = pd.read_csv(settings.INPUT_DIR + '/BIODIVERSITY_GBF4_TARGET_ECNES.csv').sort_values(by='COMMUNITY', ascending=True)
       
            self.BIO_GBF4_ECNES_LIKELY_SEL = [row['COMMUNITY'] for _,row in BIO_GBF4_ECNES_score.iterrows()
                                                    if all([row['USER_DEFINED_TARGET_PERCENT_2030_LIKELY']>0,
                                                            row['USER_DEFINED_TARGET_PERCENT_2050_LIKELY']>0,
                                                            row['USER_DEFINED_TARGET_PERCENT_2100_LIKELY']>0])]
            
            self.BIO_GBF4_ECNES_LIKELY_AND_MAYBE_SEL = [row['COMMUNITY'] for _,row in BIO_GBF4_ECNES_score.iterrows()
                                                    if all([row['USER_DEFINED_TARGET_PERCENT_2030_LIKELY_MAYBE']>0,
                                                            row['USER_DEFINED_TARGET_PERCENT_2050_LIKELY_MAYBE']>0,
                                                            row['USER_DEFINED_TARGET_PERCENT_2100_LIKELY_MAYBE']>0])]
            
            if len(self.BIO_GBF4_ECNES_LIKELY_SEL) == 0:
                raise ValueError("At least one of 'LIKELY' layers should be selected!")
  
            likely_maybe_union = set(self.BIO_GBF4_ECNES_LIKELY_SEL).intersection(self.BIO_GBF4_ECNES_LIKELY_AND_MAYBE_SEL)
            if likely_maybe_union:
                print(f"\tWARNING: {len(likely_maybe_union)} duplicate ECNES species targets found, using 'LIKELY' targets only:")
                print("\n".join(f"    {idx+1}) {name}" for idx, name in enumerate(likely_maybe_union)))
                self.BIO_GBF4_ECNES_LIKELY_AND_MAYBE_SEL = list(set(self.BIO_GBF4_ECNES_LIKELY_AND_MAYBE_SEL) - likely_maybe_union)
                 
            self.BIO_GBF4_ECNES_SEL_ALL = self.BIO_GBF4_ECNES_LIKELY_SEL + self.BIO_GBF4_ECNES_LIKELY_AND_MAYBE_SEL
            self.BIO_GBF4_PRESENCE_ECNES_SEL = ['LIKELY'] * len(self.BIO_GBF4_ECNES_LIKELY_SEL) + ['LIKELY_MAYBE'] * len(self.BIO_GBF4_ECNES_LIKELY_AND_MAYBE_SEL)
            self.BIO_GBF4_ECNES_BASELINE_SCORE_TARGET_PERCENT_LIKELY = BIO_GBF4_ECNES_score.query(f'COMMUNITY in {self.BIO_GBF4_ECNES_LIKELY_SEL}')
            self.BIO_GBF4_ECNES_BASELINE_SCORE_TARGET_PERCENT_LIKELY_AND_MAYBE = BIO_GBF4_ECNES_score.query(f'COMMUNITY in {self.BIO_GBF4_ECNES_LIKELY_AND_MAYBE_SEL}')
    
            BIO_GBF4_COMUNITY_raw = xr.open_dataarray(f'{settings.INPUT_DIR}/bio_GBF4_ECNES.nc', chunks={'species':1})
            ecnes_arr_likely = BIO_GBF4_COMUNITY_raw.sel(species=self.BIO_GBF4_ECNES_LIKELY_SEL, presence='LIKELY').compute()
            ecnes_arr_likely_maybe = BIO_GBF4_COMUNITY_raw.sel(species=self.BIO_GBF4_ECNES_LIKELY_AND_MAYBE_SEL, presence='LIKELY_AND_MAYBE').compute()
            ecnes_arr = xr.concat([ecnes_arr_likely, ecnes_arr_likely_maybe], dim='species')
            self.BIO_GBF4_COMUNITY_LAYERS = np.array([self.get_exact_resfactored_average_arr_without_lu_mask(arr) for arr in ecnes_arr])
        
  
        
        ##########################################################################
        # Biodiersity species suitability under climate change (GBF8)            #
        ##########################################################################
        
        if settings.BIODIVERSITY_TARGET_GBF_8 != 'off':
            
            print("\tLoading Species suitability data...", flush=True)
            
            # Read in the species data from Carla Archibald (noted as GBF-8)
            BIO_GBF8_SPECIES_raw = xr.open_dataset(f'{settings.INPUT_DIR}/bio_GBF8_ssp{settings.SSP}_EnviroSuit.nc', chunks={'year':1,'species':1})['data']        
            bio_GBF8_baseline_score = pd.read_csv(settings.INPUT_DIR + '/BIODIVERSITY_GBF8_SCORES.csv').sort_values(by='species', ascending=True)
            bio_GBF8_target_percent = pd.read_csv(settings.INPUT_DIR + '/BIODIVERSITY_GBF8_TARGET.csv').sort_values(by='species', ascending=True)
            
            self.BIO_GBF8_SEL_SPECIES = [row['species'] for _,row in bio_GBF8_target_percent.iterrows() 
                                        if all([row['USER_DEFINED_TARGET_PERCENT_2030']>0,
                                                row['USER_DEFINED_TARGET_PERCENT_2050']>0,
                                                row['USER_DEFINED_TARGET_PERCENT_2100']>0])]
            
            self.BIO_GBF8_OUTSDIE_LUTO_SCORE_SPECIES = bio_GBF8_baseline_score.query(f'species in {self.BIO_GBF8_SEL_SPECIES}')[['species', 'year', f'OUTSIDE_LUTO_NATURAL_SUITABILITY_AREA_WEIGHTED_HA_SSP{settings.SSP}']]
            self.BIO_GBF8_OUTSDIE_LUTO_SCORE_GROUPS = pd.read_csv(settings.INPUT_DIR + '/BIODIVERSITY_GBF8_SCORES_group.csv')[['group', 'year', f'OUTSIDE_LUTO_NATURAL_SUITABILITY_AREA_WEIGHTED_HA_SSP{settings.SSP}']]
            
            self.BIO_GBF8_BASELINE_SCORE_AND_TARGET_PERCENT_SPECIES = bio_GBF8_target_percent.query(f'species in {self.BIO_GBF8_SEL_SPECIES}')
            self.BIO_GBF8_BASELINE_SCORE_GROUPS = pd.read_csv(settings.INPUT_DIR + '/BIODIVERSITY_GBF8_TARGET_group.csv')
            
            self.BIO_GBF8_SPECIES_LAYER = BIO_GBF8_SPECIES_raw.sel(species=self.BIO_GBF8_SEL_SPECIES).compute()
            self.N_GBF8_SPECIES = len(self.BIO_GBF8_SEL_SPECIES)
            
            self.BIO_GBF8_GROUPS_LAYER = xr.load_dataset(f'{settings.INPUT_DIR}/bio_GBF8_ssp{settings.SSP}_EnviroSuit_group.nc')['data']
            self.BIO_GBF8_GROUPS_NAMES = [i.capitalize() for i in self.BIO_GBF8_GROUPS_LAYER['group'].values]
        

        ###############################################################
        # BECCS data.
        ###############################################################
        print("\tLoading BECCS data...", flush=True)

        # Load dataframe
        beccs_df = pd.read_hdf(os.path.join(settings.INPUT_DIR, 'cell_BECCS_df.h5'), where=self.MASK)

        # Capture as numpy arrays
        self.BECCS_COSTS_AUD_HA_YR = beccs_df['BECCS_COSTS_AUD_HA_YR'].to_numpy()
        self.BECCS_REV_AUD_HA_YR = beccs_df['BECCS_REV_AUD_HA_YR'].to_numpy()
        self.BECCS_TCO2E_HA_YR = beccs_df['BECCS_TCO2E_HA_YR'].to_numpy()
        self.BECCS_MWH_HA_YR = beccs_df['BECCS_MWH_HA_YR'].to_numpy()

 

    def get_coord(self, index_ij: np.ndarray, trans):
        """
        Calculate the coordinates [[lon,...],[lat,...]] based on
        the given index [[row,...],[col,...]] and transformation matrix.

        Parameters
        index_ij (np.ndarray): A numpy array containing the row and column indices.
        trans (affin): An instance of the Transformation class.
        resfactor (int, optional): The resolution factor. Defaults to 1.

        Returns
        tuple: A tuple containing the x and y coordinates.
        """
        coord_x = trans.c + trans.a * (index_ij[1] + 0.5)    # Move to the center of the cell
        coord_y = trans.f + trans.e * (index_ij[0] + 0.5)    # Move to the center of the cell
        return coord_x, coord_y


    def update_geo_meta(self):
        """
        Update the geographic metadata based on the current settings.

        Note: When this function is called, the RESFACTOR is assumend to be > 1,
        because there is no need to update the metadata if the RESFACTOR is 1.

        Returns
            dict: The updated geographic metadata.
        """
        meta = self.GEO_META_FULLRES.copy()
        height, width =  self.LUMAP_2D_RESFACTORED.shape
        trans = list(self.GEO_META_FULLRES['transform'])
        trans[0] = trans[0] * settings.RESFACTOR    # Adjust the X resolution
        trans[4] = trans[4] * settings.RESFACTOR    # Adjust the Y resolution
        trans = Affine(*trans)
        meta.update(width=width, height=height, compress='lzw', driver='GTiff', transform=trans, nodata=self.NODATA, dtype='float32')
        return meta


    def add_lumap(self, yr: int, lumap: np.ndarray):
        """
        Safely adds a land-use map to the the Data object.
        """
        self.lumaps[yr] = lumap

    def add_lmmap(self, yr: int, lmmap: np.ndarray):
        """
        Safely adds a land-management map to the Data object.
        """
        self.lmmaps[yr] = lmmap

    def add_ammaps(self, yr: int, ammap: np.ndarray):
        """
        Safely adds an agricultural management map to the Data object.
        """
        self.ammaps[yr] = ammap

    def add_ag_dvars(self, yr: int, ag_dvars: np.ndarray):
        """
        Safely adds agricultural decision variables' values to the Data object.
        """
        self.ag_dvars[yr] = ag_dvars

    def add_non_ag_dvars(self, yr: int, non_ag_dvars: np.ndarray):
        """
        Safely adds non-agricultural decision variables' values to the Data object.
        """
        self.non_ag_dvars[yr] = non_ag_dvars

    def add_ag_man_dvars(self, yr: int, ag_man_dvars: dict[str, np.ndarray]):
        """
        Safely adds agricultural management decision variables' values to the Data object.
        """
        self.ag_man_dvars[yr] = ag_man_dvars
        
    
    def get_exact_resfactored_lumap_mrj(self):
        """
        Rather than picking the center cell when resfactoring the lumap, this function
        calculate the exact value of each land-use cell based from lumap to create dvars.
        
        E.g., given a resfactor of 5, then each resfactored dvar cell will cover a 5x5 area.
        If there are 9 Apple cells in the 5x5 area, then the dvar cell for it will be 9/25. 
        
        """
        if settings.RESFACTOR == 1:
            return tools.lumap2ag_l_mrj(self.LUMAP_NO_RESFACTOR, self.LMMAP_NO_RESFACTOR)[:, self.MASK, :]

        lumap_mrj = np.zeros((self.NLMS, self.NCELLS, self.N_AG_LUS), dtype=np.float32)
        for idx_lu in self.DESC2AGLU.values():
            for idx_w, _ in enumerate(self.LANDMANS):
                # Get the cells with the same ID and water supply
                lu_arr = (self.LUMAP_NO_RESFACTOR == idx_lu) * (self.LMMAP_NO_RESFACTOR == idx_w)
                lumap_mrj[idx_w, :, idx_lu] = self.get_exact_resfactored_average_arr_consider_lu_mask(lu_arr)        
                    
        return lumap_mrj
    
    
    def get_exact_resfactored_average_arr_consider_lu_mask(self, arr: np.ndarray) -> np.ndarray:
            
        arr_2d = np.zeros_like(self.LUMAP_2D_FULLRES, dtype=np.float32)      # Create a 2D array of zeros with the same shape as the LUMAP_2D_FULLRES
        np.place(arr_2d, self.NLUM_MASK == 1, arr)                           # Place the values of arr in the 2D array where the LUMAP_2D_RESFACTORED is equal to idx_lu

        mask_arr_2d_resfactor = (self.LUMAP_2D_RESFACTORED != self.NODATA) & (self.LUMAP_2D_RESFACTORED != self.MASK_LU_CODE) 
        mask_arr_2d_fullres = (self.LUMAP_2D_FULLRES != self.NODATA) & (self.LUMAP_2D_FULLRES != self.MASK_LU_CODE)

        # Create a 2D array of IDs for the LUMAP_2D_RESFACTORED
        id_arr_2d_resfactored = np.arange(self.LUMAP_2D_RESFACTORED.size).reshape(self.LUMAP_2D_RESFACTORED.shape)
        id_arr_2d_fullres = upsample_array(self, id_arr_2d_resfactored, settings.RESFACTOR)

        # Calculate the average value for each cell in the resfactored array
        cell_count = np.bincount(id_arr_2d_fullres.flatten(), mask_arr_2d_fullres.flatten(), minlength=self.LUMAP_2D_RESFACTORED.size)
        cell_sum = np.bincount(id_arr_2d_fullres.flatten(), arr_2d.flatten(), minlength=self.LUMAP_2D_RESFACTORED.size)
        with np.errstate(divide='ignore', invalid='ignore'):                    # Ignore the division by zero warning
            cell_avg = cell_sum / cell_count
            cell_avg[~np.isfinite(cell_avg)] = 0                                # Set the NaN and Inf to 0
            
        # Reshape the 1D avg array to 2D array
        cell_avg_2d = cell_avg.reshape(self.LUMAP_2D_RESFACTORED.shape)
        return cell_avg_2d[mask_arr_2d_resfactor]
    
    
    def get_exact_resfactored_average_arr_without_lu_mask(self, arr: np.ndarray) -> np.ndarray:
        
        arr_2d = np.zeros_like(self.LUMAP_2D_FULLRES, dtype=np.float32)      # Create a 2D array of zeros with the same shape as the LUMAP_2D_FULLRES
        np.place(arr_2d, self.NLUM_MASK == 1, arr)                           # Place the values of arr in the 2D array where the LUMAP_2D_RESFACTORED is equal to idx_lu
        arr_2d = np.pad(arr_2d, ((0, settings.RESFACTOR), (0, settings.RESFACTOR)), mode='reflect')  

        arr_2d_xr = xr.DataArray(arr_2d, dims=['y', 'x'])
        arr_2d_xr_resfactored = arr_2d_xr.coarsen(x=settings.RESFACTOR, y=settings.RESFACTOR, boundary='trim').mean()
        arr_2d_xr_resfactored = arr_2d_xr_resfactored.values[0:self.LUMAP_2D_RESFACTORED.shape[0], 0:self.LUMAP_2D_RESFACTORED.shape[1]]  

        mask_arr_2d_resfactor = (self.LUMAP_2D_RESFACTORED != self.NODATA) & (self.LUMAP_2D_RESFACTORED != self.MASK_LU_CODE) 
        return arr_2d_xr_resfactored[mask_arr_2d_resfactor]
    

    
    def get_resfactored_lumap(self) -> np.ndarray:
        """
        Coarsens the LUMAP to the specified resolution factor.
        """

        lumap_resfactored = np.zeros(self.NCELLS, dtype=np.int8) - 1
        fill_mask = np.ones(self.NCELLS, dtype=bool)

        # Fill resfactored land-use map with the land-use codes given their resfactored size
        for _,(lu_code, res_size) in self.LU_RESFACTOR_CELLS.iterrows():
            
            lu_avg = self.AG_L_MRJ[:,:,lu_code].sum(0) * fill_mask
            res_size = min(res_size, (lu_avg > 0).sum())
            
            # Assign the n-largets cells with the land-use code
            lu_idx = np.argsort(lu_avg)[-res_size:]  
            lumap_resfactored[lu_idx] = lu_code
            fill_mask[lu_idx] = False
            
        # Fill -1 with nearest neighbour values
        nearst_ind = distance_transform_edt(
            (lumap_resfactored == -1),
            return_distances=False,
            return_indices=True
        )
      
        return lumap_resfactored[*nearst_ind]
    
    
    def get_watershed_yield_components(self, valid_watershed_id:list[int] = None):
        """
        Get the water yield components for the specified watersheds.
        """
        if settings.WATER_REGION_DEF == 'River Region':

            self.WATER_REGION_ID = pd.read_hdf(os.path.join(settings.INPUT_DIR, "rivreg_id.h5"), where=self.MASK).to_numpy()

            rr = pd.read_hdf(os.path.join(settings.INPUT_DIR, "rivreg_lut.h5"))
            self.WATER_REGION_NAMES = dict(zip(rr['HR_RIVREG_ID'], rr['HR_RIVREG_NAME']))  
            self.WATER_REGION_HIST_LEVEL = dict(zip(rr['HR_RIVREG_ID'], rr['WATER_YIELD_HIST_BASELINE_ML']))  
            
            rr_outside_luto = pd.read_hdf(os.path.join(settings.INPUT_DIR, 'water_yield_outside_LUTO_study_area_2010_2100_rr_ml.h5'))
            rr_outside_luto = rr_outside_luto.loc[:, pd.IndexSlice[:, settings.SSP]]
            rr_outside_luto.columns = rr_outside_luto.columns.droplevel('ssp')

            rr_natural_land = pd.read_hdf(os.path.join(settings.INPUT_DIR, 'water_yield_natural_land_2010_2100_rr_ml.h5'))
            rr_natural_land = rr_natural_land.loc[:, pd.IndexSlice[:, settings.SSP]]
            rr_natural_land.columns = rr_natural_land.columns.droplevel('ssp')
            rr_outside_luto = rr_outside_luto.reindex(columns=sorted(rr_outside_luto.columns))

            self.WATER_OUTSIDE_LUTO_BY_CCI = rr_outside_luto
            self.WATER_OUTSIDE_LUTO_HIST = self.WATER_YIELD_OUTSIDE_LUTO_HIST.query('Region_Type == "River Region"').set_index('Region_ID')['Water Yield (ML)'].to_dict()

        elif settings.WATER_REGION_DEF == 'Drainage Division':
            
            self.WATER_REGION_ID = pd.read_hdf(os.path.join(settings.INPUT_DIR, "draindiv_id.h5"), where=self.MASK).to_numpy()  # Drainage div ID mapped.

            dd = pd.read_hdf(os.path.join(settings.INPUT_DIR, "draindiv_lut.h5"))
            self.WATER_REGION_NAMES = dict(zip(dd['HR_DRAINDIV_ID'], dd['HR_DRAINDIV_NAME']))
            self.WATER_REGION_HIST_LEVEL = dict(zip(dd['HR_DRAINDIV_ID'], dd['WATER_YIELD_HIST_BASELINE_ML']))

            dd_outside_luto = pd.read_hdf(os.path.join(settings.INPUT_DIR, 'water_yield_outside_LUTO_study_area_2010_2100_dd_ml.h5'))
            dd_outside_luto = dd_outside_luto.loc[:, pd.IndexSlice[:, settings.SSP]]
            dd_outside_luto.columns = dd_outside_luto.columns.droplevel('ssp')

            dd_natural_land = pd.read_hdf(os.path.join(settings.INPUT_DIR, 'water_yield_natural_land_2010_2100_dd_ml.h5'))
            dd_natural_land = dd_natural_land.loc[:, pd.IndexSlice[:, settings.SSP]]
            dd_natural_land.columns = dd_natural_land.columns.droplevel('ssp')
            dd_natural_land = dd_natural_land.reindex(columns=sorted(dd_natural_land.columns))

            self.WATER_OUTSIDE_LUTO_BY_CCI = dd_outside_luto
            self.WATER_OUTSIDE_LUTO_HIST = self.WATER_YIELD_OUTSIDE_LUTO_HIST.query('Region_Type == "Drainage Division"').set_index('Region_ID')['Water Yield (ML)'].to_dict()
            
        else:
            raise ValueError(f"Unknown water region definition: {settings.WATER_REGION_DEF}. "
                        f"Must be either 'River Region' or 'Drainage Division'.")
            
            
        # Using high res factor will make some small river regions disappear; hence we update the data with validated river region ids
        if valid_watershed_id is None:
            valid_watershed_id = np.unique(self.WATER_REGION_ID)
        self.WATERSHED_DISAPPEARING = [self.WATER_REGION_NAMES[i] for i in set(self.WATER_REGION_NAMES.keys()) - set(valid_watershed_id)]
        
        if self.WATERSHED_DISAPPEARING:
            print(f"    WARNING! {len(self.WATERSHED_DISAPPEARING)} river regions are disappearing due to using high resolution factors.")
            [print(f"       - {list(i)}") for i in np.array_split(self.WATERSHED_DISAPPEARING, len(self.WATERSHED_DISAPPEARING)//3)]
            self.WATER_REGION_NAMES = {k: v for k, v in self.WATER_REGION_NAMES.items() if k in valid_watershed_id}
            self.WATER_REGION_HIST_LEVEL = {k: v for k, v in self.WATER_REGION_HIST_LEVEL.items() if k in valid_watershed_id}
            self.WATER_OUTSIDE_LUTO_BY_CCI = self.WATER_OUTSIDE_LUTO_BY_CCI.loc[:, self.WATER_OUTSIDE_LUTO_BY_CCI.columns.isin(valid_watershed_id)]
            self.WATER_OUTSIDE_LUTO_HIST = {k: v for k, v in self.WATER_OUTSIDE_LUTO_HIST.items() if k in valid_watershed_id}
            self.WATER_USE_DOMESTIC = {k: v for k, v in self.WATER_USE_DOMESTIC.items() if k in valid_watershed_id}

        return valid_watershed_id
    
    
    def get_GBF2_target_for_yr_cal(self, yr_cal:int) -> float:
        """
        Get the target score for priority degrade areas conservation.
        
        Parameters
        ----------
        yr_cal : int
            The year for which to get the habitat condition score.
            
        Returns
        -------
        float
            The priority degrade areas conservation target for the given year.
        """
 
        bio_habitat_score_baseline_sum = self.BIO_PRIORITY_DEGRADED_AREAS_R.sum()
        bio_habitat_score_base_yr_sum = self.BIO_PRIORITY_DEGRADED_CONTRIBUTION_WEIGHTED_AREAS_BASE_YR_R.sum()
        bio_habitat_score_base_yr_proportion = bio_habitat_score_base_yr_sum / bio_habitat_score_baseline_sum

        bio_habitat_target_proportion = [
            bio_habitat_score_base_yr_proportion + ((1 - bio_habitat_score_base_yr_proportion) * i)
            for i in settings.GBF2_TARGETS_DICT[settings.BIODIVERSITY_TARGET_GBF_2].values()
        ]

        targets_key_years = {
            self.YR_CAL_BASE: bio_habitat_score_base_yr_sum, 
            **dict(zip(settings.GBF2_TARGETS_DICT[settings.BIODIVERSITY_TARGET_GBF_2].keys(), bio_habitat_score_baseline_sum * np.array(bio_habitat_target_proportion)))
        }

        f = interp1d(
            list(targets_key_years.keys()),
            list(targets_key_years.values()),
            kind = "linear",
            fill_value = "extrapolate"
        )

        return f(yr_cal).item()  # Convert the interpolated value to a scalar
    
    
    def get_GBF3_limit_score_inside_LUTO_by_yr(self, yr:int) -> np.ndarray:
        '''
        Interpolate the user-defined targets to get target at the given year
        '''
        
        GBF3_target_percents = []
        for _,row in self.GBF3_BASELINE_AREA_AND_USERDEFINE_TARGETS.iterrows():
            f = interp1d(
                [2010, 2030, 2050, 2100],
                [min(row['BASE_YR_PERCENT'],row['USER_DEFINED_TARGET_PERCENT_2030']), 
                 row['USER_DEFINED_TARGET_PERCENT_2030'], 
                 row['USER_DEFINED_TARGET_PERCENT_2050'], 
                 row['USER_DEFINED_TARGET_PERCENT_2100']
                ],
                kind="linear",
                fill_value="extrapolate",
            )
            GBF3_target_percents.append(f(yr).item())
        
        limit_score_all_AUS = self.BIO_GBF3_BASELINE_SCORE_ALL_AUSTRALIA * (np.array(GBF3_target_percents) / 100)  # Convert the percentage to proportion
        limit_score_inside_LUTO = limit_score_all_AUS - self.BIO_GBF3_BASELINE_SCORE_OUTSIDE_LUTO
            
        return np.where(limit_score_inside_LUTO < 0, 0, limit_score_inside_LUTO)

    
    def get_GBF4_SNES_target_inside_LUTO_by_year(self, yr:int) -> np.ndarray:
        
        # Check the layer name
        snes_df_likely = self.BIO_GBF4_SNES_BASELINE_SCORE_TARGET_PERCENT_LIKELY
        snes_df_likely_maybe = self.BIO_GBF4_SNES_BASELINE_SCORE_TARGET_PERCENT_LIKELY_AND_MAYBE
        snes_df = pd.concat([snes_df_likely, snes_df_likely_maybe], ignore_index=True)

        targets = []
        for idx,row in snes_df.iterrows():
            layer = self.BIO_GBF4_PRESENCE_SNES_SEL[idx]
            f = interp1d(
                [2010, 2030, 2050, 2100],
                [row[f'HABITAT_SIGNIFICANCE_BASELINE_PERCENT_{layer}'], row[f'USER_DEFINED_TARGET_PERCENT_2030_{layer}'], row[f'USER_DEFINED_TARGET_PERCENT_2050_{layer}'], row[f'USER_DEFINED_TARGET_PERCENT_2100_{layer}']],
                kind = "linear",
                fill_value = "extrapolate",
            )
            
            score_all_aus = row[f'HABITAT_SIGNIFICANCE_BASELINE_ALL_AUSTRALIA_{layer}'] * f(yr) / 100  # Convert the percentage to proportion
            score_out_LUTO = row[f'HABITAT_SIGNIFICANCE_BASELINE_OUT_LUTO_NATURAL_{layer}'] 
            targets.append(score_all_aus - score_out_LUTO)

        return np.array(targets).astype(np.float32)

        
    def get_GBF4_ECNES_target_inside_LUTO_by_year(self, yr:int) -> np.ndarray:
        # Check the layer name
        ecnes_df_likely = self.BIO_GBF4_ECNES_BASELINE_SCORE_TARGET_PERCENT_LIKELY
        ecnes_df_likely_maybe = self.BIO_GBF4_ECNES_BASELINE_SCORE_TARGET_PERCENT_LIKELY_AND_MAYBE
        ecnes_df = pd.concat([ecnes_df_likely, ecnes_df_likely_maybe], ignore_index=True)

        targets = []
        for idx,row in ecnes_df.iterrows():
            layer = self.BIO_GBF4_PRESENCE_ECNES_SEL[idx]
            f = interp1d(
                [2010, 2030, 2050, 2100],
                [row[f'HABITAT_SIGNIFICANCE_BASELINE_PERCENT_{layer}'], row[f'USER_DEFINED_TARGET_PERCENT_2030_{layer}'], row[f'USER_DEFINED_TARGET_PERCENT_2050_{layer}'], row[f'USER_DEFINED_TARGET_PERCENT_2100_{layer}']],
                kind = "linear",
                fill_value = "extrapolate",
            )
            
            score_all_aus = row[f'HABITAT_SIGNIFICANCE_BASELINE_ALL_AUSTRALIA_{layer}'] * f(yr) / 100  # Convert the percentage to proportion
            score_out_LUTO = row[f'HABITAT_SIGNIFICANCE_BASELINE_OUT_LUTO_NATURAL_{layer}']
            targets.append(score_all_aus - score_out_LUTO)  
                      
        return np.array(targets).astype(np.float32)
    
    
    def get_GBF8_bio_layers_by_yr(self, yr: int, level:Literal['species', 'group']='species'):
        '''
        Get the biodiversity suitability score [hectare weighted] for each species at the given year.
        
        The raw biodiversity suitability score [2D (shape, 808*978), (dtype, uint8, 0-100)] represents the 
        suitability of each cell for each species/group.  Here it is LINEARLY interpolated to the given year,
        then LINEARLY interpolated to the given spatial coordinates.
        
        Because the coordinates are the controid of the `self.MASK` array, so the spatial interpolation is 
        simultaneously a masking process. 
        
        The suitability score is then weighted by the area (ha) of each cell. The area weighting is necessary 
        to ensure that the biodiversity suitability score will not be affected by different RESFACTOR (i.e., cell size) values.
        
        Parameters
        ----------
        yr : int
            The year for which to get the biodiversity suitability score.
        level : str, optional
            The level of the biodiversity suitability score, either 'species' or 'group'. The default is 'species'.
            
        Returns
        -------
        np.ndarray
            The biodiversity suitability score for each species at the given year.
        '''
        
        input_lr = self.BIO_GBF8_SPECIES_LAYER if level == 'species' else self.BIO_GBF8_GROUPS_LAYER
        
        current_species_val = input_lr.interp(                          # Here the year interpolation is done first                      
            year=yr,
            method='linear', 
            kwargs={'fill_value': 'extrapolate'}
        ).interp(                                                       # Then the spatial interpolation and masking is done
            x=xr.DataArray(self.COORD_LON_LAT[0], dims='cell'),
            y=xr.DataArray(self.COORD_LON_LAT[1], dims='cell'),
            method='linear'                                             # Use LINEAR interpolation
        ).drop_vars(['year']).values
        
        # Apply Savanna Burning penalties
        current_species_val = np.where(
            self.SAVBURN_ELIGIBLE,
            current_species_val * settings.BIO_CONTRIBUTION_LDS,
            current_species_val
        )
        
        return current_species_val.astype(np.float32)
    

    def get_GBF8_target_inside_LUTO_by_yr(self, yr: int) -> np.ndarray:
        '''
        Get the biodiversity suitability score (area weighted [ha]) for each species at the given year for the Inside LUTO natural land.
        '''
        target_scores = self.get_GBF8_score_all_Australia_by_yr(yr) - self.get_GBF8_score_outside_natural_LUTO_by_yr(yr)
        return target_scores
    

    
    def get_GBF8_score_all_Australia_by_yr(self, yr: int):
        '''
        Get the biodiversity suitability score (area weighted [ha]) for each species at the given year for all Australia.
        '''
        # Get the target percentage for each species at the given year
        target_pct = []
        for _,row in self.BIO_GBF8_BASELINE_SCORE_AND_TARGET_PERCENT_SPECIES.iterrows():
            f = interp1d(
                [2010, 2030, 2050, 2100],
                [row['HABITAT_SUITABILITY_BASELINE_PERCENT'], row[f'USER_DEFINED_TARGET_PERCENT_2030'], row[f'USER_DEFINED_TARGET_PERCENT_2050'], row[f'USER_DEFINED_TARGET_PERCENT_2100']],
                kind="linear",
                fill_value="extrapolate",
            )
            target_pct.append(f(yr).item()) 
            
        # Calculate the target biodiversity suitability score for each species at the given year for all Australia
        target_scores_all_AUS = self.BIO_GBF8_BASELINE_SCORE_AND_TARGET_PERCENT_SPECIES['HABITAT_SUITABILITY_BASELINE_SCORE_ALL_AUSTRALIA'] * (np.array(target_pct) / 100) # Convert the percentage to proportion
        return target_scores_all_AUS.values
    
    
    def get_GBF8_score_outside_natural_LUTO_by_yr(self, yr: int, level:Literal['species', 'group']='species'):
        '''
        Get the biodiversity suitability score (area weighted [ha]) for each species at the given year for the Outside LUTO natural land.
        '''
        
        if level == 'species':
            base_score = self.BIO_GBF8_BASELINE_SCORE_AND_TARGET_PERCENT_SPECIES['HABITAT_SUITABILITY_BASELINE_SCORE_OUTSIDE_LUTO']
            proj_score = self.BIO_GBF8_OUTSDIE_LUTO_SCORE_SPECIES.pivot(index='species', columns='year').reset_index()
        elif level == 'group':
            base_score = self.BIO_GBF8_BASELINE_SCORE_GROUPS['HABITAT_SUITABILITY_BASELINE_SCORE_OUTSIDE_LUTO']
            proj_score = self.BIO_GBF8_OUTSDIE_LUTO_SCORE_GROUPS.pivot(index='group', columns='year').reset_index()
        else:
            raise ValueError("Invalid level. Must be 'species' or 'group'")
        
        # Put the base score to the proj_score
        proj_score.columns = proj_score.columns.droplevel() 
        proj_score[1990] = base_score.values
        
        # Interpolate the suitability score for each species/group at the given year
        outside_natural_scores = []
        for _,row in proj_score.iterrows():
            f = interp1d(
                [1990, 2030, 2050, 2070, 2090],
                [row[1990], row[2030], row[2050], row[2070], row[2090]],
                kind="linear",
                fill_value="extrapolate",
            )
            outside_natural_scores.append(f(yr).item())
        
        return  outside_natural_scores


    
    def get_regional_adoption_percent_by_year(self, yr: int):
        """
        Get the regional adoption percentage for each region for the given year.
        
        Return a list of tuples where each tuple contains 
        - the region ID, 
        - landuse name, 
        - the adoption percentage.
        
        """
        if settings.REGIONAL_ADOPTION_CONSTRAINTS == "off":
            return ()
        
        reg_adop_limits = []
        for _,row in self.REGIONAL_ADOPTION_TARGETS.iterrows():
            f = interp1d(
                [2010, 2030, 2050, 2100],
                [row['BASE_LANDUSE_AREA_PERCENT'], row['ADOPTION_PERCENTAGE_2030'], row['ADOPTION_PERCENTAGE_2050'], row['ADOPTION_PERCENTAGE_2100']],
                kind="linear",
                fill_value="extrapolate",
            )
            reg_adop_limits.append((row[settings.REGIONAL_ADOPTION_ZONE], row['TARGET_LANDUSE'], f(yr).item()))
            
        return reg_adop_limits
    
    def get_regional_adoption_limit_ha_by_year(self, yr: int):
        """
        Get the regional adoption area for each region for the given year.
        
        Return a list of tuples where each tuple contains
        - the region ID,
        - landuse name,
        - the adoption area (ha).
        """
        if settings.REGIONAL_ADOPTION_CONSTRAINTS == "off":
            return ()
        
        reg_adop_limits = self.get_regional_adoption_percent_by_year(yr)
        reg_adop_limits_ha = []
        for reg, landuse, pct in reg_adop_limits:
            reg_total_area_ha = ((self.REGIONAL_ADOPTION_ZONES == reg) * self.REAL_AREA).sum()
            reg_adop_limits_ha.append((reg, landuse, reg_total_area_ha * pct / 100))
            
        return reg_adop_limits_ha
    
    
    def add_production_data(self, yr: int, data_type: str, prod_data: Any):
        """
        Safely save production data for a given year to the Data object.

        Parameters
        ----
        yr: int
            Year of production data being saved.
        data_type: str
            Type of production data being saved. Typically either 'Production', 'GHG Emissions' or 'Biodiversity'.
        prod_data: Any
            Actual production data to save.
        """
        if yr not in self.prod_data:
            self.prod_data[yr] = {}
        self.prod_data[yr][data_type] = prod_data

    def add_obj_vals(self, yr: int, obj_val: float):
        """
        Safely save objective value for a given year to the Data object
        """
        self.obj_vals[yr] = obj_val

    def get_production(self) -> np.ndarray:
        """
        Return total production of commodities for YR_CAL_BASE...
        """
        ag_X_mrj = self.AG_L_MRJ
        non_ag_X_rk = self.NON_AG_L_RK
        ag_man_X_mrj = self.AG_MAN_L_MRJ_DICT

        # The year index for the base year (2010) is 0.
        yr_idx = 0

        ag_q_mrp = ag_quantity.get_quantity_matrices(self, yr_idx)

        # Convert map of land-use in mrj format to mrp format using vectorization
        ag_X_mrp = np.einsum('mrj,pj->mrp', ag_X_mrj, self.LU2PR.astype(bool))

        # Sum quantities in product (PR/p) representation.
        ag_q_p = np.einsum('mrp,mrp->p', ag_q_mrp, ag_X_mrp)

        # Transform quantities to commodity (CM/c) representation.
        ag_q_c = np.einsum('cp,p->c', self.PR2CM.astype(bool), ag_q_p)

        # Get the quantity of each commodity produced by non-agricultural land uses
        q_crk = non_ag_quantity.get_quantity_matrix(self, ag_q_mrp, self.LUMAP)
        non_ag_q_c = np.einsum('crk,rk->c', q_crk, non_ag_X_rk)

        # Get quantities produced by agricultural management options
        ag_man_q_mrp = ag_quantity.get_agricultural_management_quantity_matrices(self, ag_q_mrp, yr_idx)
        ag_man_q_c = np.zeros(self.NCMS)
        for am, am_lus in settings.AG_MANAGEMENTS_TO_LAND_USES.items():
            if not settings.AG_MANAGEMENTS[am]:
                continue
            
            am_j_list = [self.DESC2AGLU[lu] for lu in am_lus]
            for j in am_j_list:
                for p in range(self.NPRS):
                    if self.LU2PR[p, j] ==0:
                        continue
                    dvar_mr = ag_man_X_mrj[am][:, :, j]
                    ag_q_mr = ag_man_q_mrp[am][:, :, p]
                    q_mr = dvar_mr * ag_q_mr
                    
                    for c in range(self.NCMS):
                        if self.PR2CM[c, p] == 0:
                            continue
                        ag_man_q_c[c] += q_mr.sum()
            
        return ag_q_c + non_ag_q_c + ag_man_q_c


    def get_carbon_price_by_yr_idx(self, yr_idx: int) -> float:
        """
        Return the price of carbon per tonne for a given year index (since 2010).
        The resulting year should be between 2010 - 2100
        """
        yr_cal = yr_idx + self.YR_CAL_BASE
        return self.get_carbon_price_by_year(yr_cal)

    def get_carbon_price_by_year(self, yr_cal: int) -> float:
        """
        Return the price of carbon per tonne for a given year.
        The resulting year should be between 2010 - 2100
        """
        if yr_cal not in self.CARBON_PRICES:
            raise ValueError(
                f"Carbon price data not given for the given year: {yr_cal}. "
                f"Year should be between {self.YR_CAL_BASE} and 2100."
            )
        return self.CARBON_PRICES[yr_cal]

    def get_water_nl_yield_for_yr_idx(
        self,
        yr_idx: int,
        water_dr_yield: Optional[np.ndarray] = None,
        water_sr_yield: Optional[np.ndarray] = None,
    ) -> np.ndarray:
        """
        Get the net land water yield array, ? inclusive of all cells that LUTO does not look at.?

        Returns
        -------
        np.ndarray: shape (NCELLS,)
        """
        water_dr_yield = (
            water_dr_yield if water_dr_yield is not None
            else self.WATER_YIELD_DR_FILE[yr_idx]
        )
        water_sr_yield = (
            water_sr_yield if water_sr_yield is not None
            else self.WATER_YIELD_SR_FILE[yr_idx]
        )
        dr_prop = self.DEEP_ROOTED_PROPORTION

        return (dr_prop * water_dr_yield + (1 - dr_prop) * water_sr_yield)
```

## luto/economics/agricultural/biodiversity.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

"""
Pure functions to calculate biodiversity by lm, lu.
"""


import itertools
import numpy as np

from luto import settings
from luto import tools
from luto.data import Data


def get_bio_overall_priority_score_matrices_mrj(data:Data):
    """
    Return b_mrj biodiversity score matrices by land management, cell, and land-use type.

    Parameters
    - data: The data object containing information about land management, cells, and land-use types.

    Returns
    - np.ndarray.
    """
    b_mrj = np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS), dtype=np.float32)

    for j in range(data.N_AG_LUS):
        b_mrj[:, :, j] = (
            data.BIO_CONNECTIVITY_LDS -                                                     # Biodiversity score after Late Dry Season (LDS) burning
            (data.BIO_CONNECTIVITY_RAW * (1 - data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[j]))    # Biodiversity degradation for land-use j
        ) * data.REAL_AREA    
    
    return b_mrj


def get_asparagopsis_effect_b_mrj(data:Data):
    """
    Gets biodiversity impacts of using Asparagopsis taxiformis (no effect)

    Parameters
    - data: The input data object containing NLMS and NCELLS attributes.

    Returns
    - An array of zeros with shape (data.NLMS, data.NCELLS, nlus).
    """
    nlus = len(settings.AG_MANAGEMENTS_TO_LAND_USES["Asparagopsis taxiformis"])
    return np.zeros((data.NLMS, data.NCELLS, nlus), dtype=np.float32)


def get_precision_agriculture_effect_b_mrj(data:Data):
    """
    Gets biodiversity impacts of using Precision Agriculture (no effect)

    Parameters
    - data: The input data object containing NLMS and NCELLS information

    Returns
    - An array of zeros with shape (data.NLMS, data.NCELLS, nlus)
    """
    nlus = len(settings.AG_MANAGEMENTS_TO_LAND_USES["Precision Agriculture"])
    return np.zeros((data.NLMS, data.NCELLS, nlus), dtype=np.float32)


def get_ecological_grazing_effect_b_mrj(data:Data):
    """
    Gets biodiversity impacts of using Ecological Grazing (no effect)

    Parameters
    - data: The input data object containing information about NLMS and NCELLS.

    Returns
    - An array of zeros with shape (NLMS, NCELLS, nlus)
    """
    nlus = len(settings.AG_MANAGEMENTS_TO_LAND_USES["Ecological Grazing"])
    return np.zeros((data.NLMS, data.NCELLS, nlus), dtype=np.float32)


def get_savanna_burning_effect_b_mrj(data:Data):
    """
    Gets biodiversity impacts of using Savanna Burning.

    Land that can perform Savanna Burning but does not is penalised for not doing so.
    Thus, add back in the penalised amount to get the positive effect of Savanna
    Burning on biodiversity.

    Parameters
    - data: The input data containing information about land management and biodiversity.

    Returns
    - new_b_mrj: A numpy array representing the biodiversity impacts of using Savanna Burning.
    """
    nlus = len(settings.AG_MANAGEMENTS_TO_LAND_USES["Savanna Burning"])
    new_b_mrj = np.zeros((data.NLMS, data.NCELLS, nlus), dtype=np.float32)

    eds_sav_burning_biodiv_benefits = np.where(
        data.SAVBURN_ELIGIBLE, 
        data.BIO_CONNECTIVITY_RAW * (1 - settings.BIO_CONTRIBUTION_LDS) * data.REAL_AREA, 
        0
    ).astype(np.float32)
    

    for m, j in itertools.product(range(data.NLMS), range(nlus)):
        new_b_mrj[m, :, j] = eds_sav_burning_biodiv_benefits

    return new_b_mrj


def get_agtech_ei_effect_b_mrj(data:Data):
    """
    Gets biodiversity impacts of using AgTech EI (no effect)

    Parameters
    - data: The input data object containing information about NLMS and NCELLS.

    Returns
    - An array of zeros with shape (NLMS, NCELLS, nlus)
    """
    nlus = len(settings.AG_MANAGEMENTS_TO_LAND_USES["AgTech EI"])
    return np.zeros((data.NLMS, data.NCELLS, nlus), dtype=np.float32)


def get_biochar_effect_b_mrj(data:Data, ag_b_mrj: np.ndarray, yr_idx):
    """
    Gets biodiversity impacts of using Biochar

    Parameters
    - data: The input data object containing information about NLMS and NCELLS.

    Returns
    - new_b_mrj: A numpy array representing the biodiversity impacts of using Biochar.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Biochar']
    lu_codes = np.array([data.DESC2AGLU[lu] for lu in land_uses])
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    b_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Biochar']:
        return b_mrj_effect

    for lu_idx, lu in enumerate(land_uses):
        biodiv_impact = data.BIOCHAR_DATA[lu].loc[yr_cal, 'Biodiversity_impact']

        if biodiv_impact != 1:
            j = lu_codes[lu_idx]
            b_mrj_effect[:, :, lu_idx] = ag_b_mrj[:, :, j] * (biodiv_impact - 1)

    return b_mrj_effect



def get_beef_hir_effect_b_mrj(data: Data, ag_b_mrj: np.ndarray) -> np.ndarray:
    """
    Gets biodiversity impacts of using HIR on beef.

    Parameters:
    - data: The input data object containing information about NLMS and NCELLS.

    Returns:
    - b_mrj_effect: A numpy array representing the biodiversity impacts of using Biochar.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['HIR - Beef']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    b_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    unallocated_j = tools.get_unallocated_natural_land_code(data)
    # HIR's biodiversity contribution is based on that of unallocated land 
    unallocated_b_mr = ag_b_mrj[:, :, unallocated_j]

    for idx, lu_code in enumerate(lu_codes):
        b_mrj_effect[:, :, idx] = unallocated_b_mr * (1 - data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[lu_code])

    return b_mrj_effect


def get_sheep_hir_effect_b_mrj(data: Data, ag_b_mrj: np.ndarray) -> np.ndarray:
    """
    Gets biodiversity impacts of using HIR on beef.

    Parameters:
    - data: The input data object containing information about NLMS and NCELLS.

    Returns:
    - b_mrj_effect: A numpy array representing the biodiversity impacts of using Biochar.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['HIR - Sheep']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    b_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    unallocated_j = tools.get_unallocated_natural_land_code(data)
    # HIR's biodiversity contribution is based on that of unallocated land 
    unallocated_b_mr = ag_b_mrj[:, :, unallocated_j]

    for idx, lu_code in enumerate(lu_codes):
        b_mrj_effect[:, :, idx] = unallocated_b_mr * (1 - data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[lu_code])

    return b_mrj_effect


def get_utility_solar_pv_effect_b_mrj(data:Data, ag_b_mrj: np.ndarray, yr_idx: int):
    """
    Gets biodiversity impacts of using Utility Solar PV

    Parameters
    - data: The input data object containing information about NLMS and NCELLS.

    Returns
    - new_b_mrj: A numpy array representing the biodiversity impacts of using Utility Solar PV.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Utility Solar PV']
    lu_codes = np.array([data.DESC2AGLU[lu] for lu in land_uses])
    yr_cal = data.YR_CAL_BASE + yr_idx
    # Set up the effects matrix
    b_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)   
    if not settings.AG_MANAGEMENTS['Utility Solar PV']:
        return b_mrj_effect
    for lu_idx, lu in enumerate(land_uses):
        biodiv_impact = data.UTILITY_SOLAR_PV_DATA[lu].loc[yr_cal, 'Biodiversity_compatability']
        if biodiv_impact != 1:
            j = lu_codes[lu_idx]
            b_mrj_effect[:, :, lu_idx] = ag_b_mrj[:, :, j] * (biodiv_impact - 1)
    return b_mrj_effect

def get_onshore_wind_effect_b_mrj(data:Data, ag_b_mrj: np.ndarray, yr_idx: int):
    """
    Gets biodiversity impacts of using Onshore Wind

    Parameters
    - data: The input data object containing information about NLMS and NCELLS.

    Returns
    - new_b_mrj: A numpy array representing the biodiversity impacts of using Onshore Wind.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Onshore Wind']
    lu_codes = np.array([data.DESC2AGLU[lu] for lu in land_uses])
    yr_cal = data.YR_CAL_BASE + yr_idx
    # Set up the effects matrix
    b_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)   
    if not settings.AG_MANAGEMENTS['Onshore Wind']:
        return b_mrj_effect
    for lu_idx, lu in enumerate(land_uses):
        biodiv_impact = data.ONSHORE_WIND_DATA[lu].loc[yr_cal, 'Biodiversity_compatability']
        if biodiv_impact != 1:
            j = lu_codes[lu_idx]
            b_mrj_effect[:, :, lu_idx] = ag_b_mrj[:, :, j] * (biodiv_impact - 1)
    return b_mrj_effect


def get_agricultural_management_biodiversity_matrices(data:Data, ag_b_mrj: np.ndarray, yr_idx: int):
    """
    Calculate the biodiversity matrices for different agricultural management practices.

    Parameters
    - data: The input data used for calculations.

    Returns
    A dictionary containing the biodiversity matrices for different agricultural management practices.
    The keys of the dictionary represent the management practices, and the values represent the corresponding biodiversity matrices.
    """

    asparagopsis_data = get_asparagopsis_effect_b_mrj(data)                       
    precision_agriculture_data = get_precision_agriculture_effect_b_mrj(data)     
    eco_grazing_data = get_ecological_grazing_effect_b_mrj(data)                   
    sav_burning_data = get_savanna_burning_effect_b_mrj(data)                       
    agtech_ei_data = get_agtech_ei_effect_b_mrj(data)                               
    biochar_data = get_biochar_effect_b_mrj(data, ag_b_mrj, yr_idx)                 
    beef_hir_data = get_beef_hir_effect_b_mrj(data, ag_b_mrj)                       
    sheep_hir_data = get_sheep_hir_effect_b_mrj(data, ag_b_mrj)
    solar_pv_data = get_utility_solar_pv_effect_b_mrj(data, ag_b_mrj, yr_idx)
    wind_data = get_onshore_wind_effect_b_mrj(data, ag_b_mrj, yr_idx)                  

    return {
        'Asparagopsis taxiformis': asparagopsis_data,
        'Precision Agriculture': precision_agriculture_data,
        'Ecological Grazing': eco_grazing_data,
        'Savanna Burning': sav_burning_data,
        'AgTech EI': agtech_ei_data,
        'Biochar': biochar_data,
        'HIR - Beef': beef_hir_data,
        'HIR - Sheep': sheep_hir_data,
        'Utility Solar PV': solar_pv_data,
        'Onshore Wind': wind_data,
    }


def get_GBF3_major_vegetation_matrices_vr(data:Data) -> np.ndarray:
    return data.NVIS_LAYERS_LDS * data.REAL_AREA


def get_GBF4_SNES_matrix_sr(data:Data) -> np.ndarray:
    """
    Gets the SNES contributions  matrix.
    
    Returns
    -------
    np.ndarray
        indexed (s, r) where s is species (independent of species conversation limits) and r is cell
    """
    return np.where(
        data.SAVBURN_ELIGIBLE,
        data.BIO_GBF4_SPECIES_LAYERS * data.REAL_AREA * settings.BIO_CONTRIBUTION_LDS,
        data.BIO_GBF4_SPECIES_LAYERS * data.REAL_AREA
    ).astype(np.float32)
    

def get_GBF4_ECNES_matrix_sr(data:Data) -> np.ndarray:
    """
    Gets the ECNES contributions  matrix.
    
    Returns
    -------
    np.ndarray
        indexed (s, r) where s is species (independent of species conversation limits) and r is cell
    """
    return np.where(
        data.SAVBURN_ELIGIBLE,
        data.BIO_GBF4_COMUNITY_LAYERS * data.REAL_AREA * settings.BIO_CONTRIBUTION_LDS,
        data.BIO_GBF4_COMUNITY_LAYERS * data.REAL_AREA
    ).astype(np.float32)
    


def get_GBF8_matrix_sr(data:Data, target_year: int):
    return np.where(
        data.SAVBURN_ELIGIBLE,
        data.get_GBF8_bio_layers_by_yr(target_year) * data.REAL_AREA * settings.BIO_CONTRIBUTION_LDS,
        data.get_GBF8_bio_layers_by_yr(target_year) * data.REAL_AREA
    )


def get_ag_biodiversity_contribution(data:Data) -> np.ndarray:
    """
    Return b_j biodiversity contribution matrices by land-use type.

    Parameters
    - data: The data object containing information about land management, cells, and land-use types.

    Returns
    - np.ndarray.
    """
    return np.array(list(data.BIO_HABITAT_CONTRIBUTION_LOOK_UP.values()))


def get_ag_management_biodiversity_contribution(
    data:Data,
    yr_cal: int,
) -> dict[str, dict[int, np.ndarray]]:
    
    am_contr_dict = {}
    
    if settings.AG_MANAGEMENTS['Asparagopsis taxiformis']:
        am_contr_dict['Asparagopsis taxiformis'] = {
            j_idx: np.zeros(data.NCELLS).astype(np.float32)
            for j_idx, lu in enumerate(settings.AG_MANAGEMENTS_TO_LAND_USES['Asparagopsis taxiformis'])
        }
    if settings.AG_MANAGEMENTS['Precision Agriculture']:
        am_contr_dict['Precision Agriculture'] = {
            j_idx: np.zeros(data.NCELLS).astype(np.float32)
            for j_idx, lu in enumerate(settings.AG_MANAGEMENTS_TO_LAND_USES['Precision Agriculture'])
        }
    if settings.AG_MANAGEMENTS['Ecological Grazing']:
        am_contr_dict['Ecological Grazing'] = {
            j_idx: np.zeros(data.NCELLS).astype(np.float32)
            for j_idx, lu in enumerate(settings.AG_MANAGEMENTS_TO_LAND_USES['Ecological Grazing'])
        }
    if settings.AG_MANAGEMENTS['Savanna Burning']:
        am_contr_dict['Savanna Burning'] = {
            j_idx: np.where(data.SAVBURN_ELIGIBLE, (1 - settings.BIO_CONTRIBUTION_LDS), 0).astype(np.float32)
            for j_idx, lu in enumerate(settings.AG_MANAGEMENTS_TO_LAND_USES['Savanna Burning'])
        }
    if settings.AG_MANAGEMENTS['AgTech EI']:
        am_contr_dict['AgTech EI'] = {
            j_idx: np.zeros(data.NCELLS).astype(np.float32)
            for j_idx, lu in enumerate(settings.AG_MANAGEMENTS_TO_LAND_USES['AgTech EI'])
        }
    if settings.AG_MANAGEMENTS['Biochar']:
        am_contr_dict['Biochar'] = {
            j_idx: (data.BIOCHAR_DATA[lu].loc[yr_cal, 'Biodiversity_impact'] - 1) * np.ones(data.NCELLS).astype(np.float32)
            for j_idx, lu in enumerate(settings.AG_MANAGEMENTS_TO_LAND_USES['Biochar'])
        }
    if settings.AG_MANAGEMENTS['HIR - Beef']:
        am_contr_dict['HIR - Beef'] = {
            j_idx: (
                np.ones(data.NCELLS).astype(np.float32) 
                * (1 - data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[tools.get_natural_beef_code(data)])    # The proportional gap of biodiversity between beef-natural to full-natural
            )
            for j_idx, lu in enumerate(settings.AG_MANAGEMENTS_TO_LAND_USES['HIR - Beef'])
        }
    if settings.AG_MANAGEMENTS['HIR - Sheep']:
        am_contr_dict['HIR - Sheep'] = {
            j_idx: (
                np.ones(data.NCELLS).astype(np.float32)
                * (1 - data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[tools.get_natural_sheep_code(data)])   # The proportional gap of biodiversity between sheep-natural to full-natural
            )
            for j_idx, lu in enumerate(settings.AG_MANAGEMENTS_TO_LAND_USES['HIR - Sheep'])
        }
    
    return am_contr_dict
```

## luto/economics/agricultural/cost.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.



"""
Pure functions to calculate costs of commodities and alt. land uses.
"""

import itertools
import numpy as np
import pandas as pd

from luto.data import Data
import luto.settings as settings
from luto.economics.agricultural.quantity import get_yield_pot, lvs_veg_types, get_quantity
from luto.settings import AG_MANAGEMENTS, AG_MANAGEMENTS_TO_LAND_USES
from luto.economics.agricultural.quantity import get_yield_pot, get_quantity, lvs_veg_types


def get_cost_crop(data:Data, lu, lm, yr_idx):
    """Return crop production cost <unit: $/cell> of `lu`+`lm` in `yr_idx` as np array.

    Args:
        data (object/module): Data object or module. Assumes fields like in `luto.data`.
        lu (str): Land use (e.g., 'Winter cereals' or 'Beef - natural land').
        lm (str): Land management (e.g., 'dry', 'irr').
        yr_idx (int): Number of years post base-year ('YR_CAL_BASE').

    Returns
        pandas.DataFrame: Costs of the crop as a numpy array, with columns representing different cost types.

    Raises:
        KeyError: If the passed `lm` is neither 'dry' nor 'irr'.

    Notes:
        - If the land-use does not exist in AGEC_CROPS, zeros are returned.

    """
    
    # Check if land-use exists in AGEC_CROPS (e.g., dryland Pears/Rice do not occur), if not return zeros
    if lu not in data.AGEC_CROPS['AC', lm].columns:
        costs_t = np.zeros((data.NCELLS))
        # The column name is irrelevant and only used to make the out df the same shape as the rest of crops.
        return pd.DataFrame(
            costs_t,
            columns=pd.MultiIndex.from_product([[lu], [lm], ['Area cost']])
        )

    else: # Calculate the total costs 
        yr_cal = data.YR_CAL_BASE + yr_idx
        
        # Quantity costs
        costs_q = (
            data.AGEC_CROPS['QC', lm, lu] 
            * data.QC_COST_MULTS.loc[yr_cal, lu]
            * get_quantity(data, lu.upper(), lm, yr_idx)
        )  # lu.upper() only for crops as needs to be in product format in get_quantity().  

        # Area costs.
        costs_a = data.AGEC_CROPS['AC', lm, lu] * data.AC_COST_MULTS.loc[yr_cal, lu]  # Area costs per hectare.

        # Fixed costs
        costs_flc = data.AGEC_CROPS['FLC', lm, lu] * data.FLC_COST_MULTS.loc[yr_cal, lu]  # Fixed labour costs.
        costs_foc = data.AGEC_CROPS['FOC', lm, lu] * data.FOC_COST_MULTS.loc[yr_cal, lu]  # Fixed operating costs.
        costs_fdc = data.AGEC_CROPS['FDC', lm, lu] * data.FDC_COST_MULTS.loc[yr_cal, lu]  # Fixed depreciation costs.

        # Water costs as water required in ML per hectare x delivery price per ML.
        if lm == 'irr':
            costs_w = (
            data.AGEC_CROPS['WR', lm, lu] 
            * data.AGEC_CROPS['WP', lm, lu] 
            * data.WP_COST_MULTS[yr_cal]
            )
        elif lm == 'dry':
            costs_w = 0
        else: # Passed lm is neither `dry` nor `irr`.
            raise KeyError(f"Unknown {lm} land management. Check `lm` key.")

        # Convert to $/cell including resfactor.
        # Quantity costs which has already been adjusted for REAL_AREA/resfactor via get_quantity
        costs_q *= 1
        costs_a *= data.REAL_AREA
        costs_flc *= data.REAL_AREA
        costs_foc *= data.REAL_AREA
        costs_fdc *= data.REAL_AREA
        costs_w *= data.REAL_AREA

        costs_t = np.stack([costs_q, costs_a, costs_flc, costs_foc, costs_fdc, costs_w]).T

        # Return costs as numpy array.
        return pd.DataFrame(
            costs_t,
            columns=pd.MultiIndex.from_product(
                [
                    [lu], 
                    [lm], 
                    ['Quantity cost', 'Area cost', 'Fixed labour cost', 'Fixed operating cost', 'Fixed depreciation cost', 'Water cost']
                ]
            )
        )



def get_cost_lvstk(data:Data, lu, lm, yr_idx):
    """Return lvstk prodution cost <unit: $/cell> of `lu`+`lm` in `yr_idx` as np array.

    Args:
        data (object/module): Data object or module.
        lu (str): Land use (e.g. 'Winter cereals' or 'Beef - natural land').
        lm (str): Land management (e.g. 'dry', 'irr').
        yr_idx (int): Number of years post base-year ('YR_CAL_BASE').

    Returns
        pandas.DataFrame: Costs as numpy array, with columns representing different cost types.

    Raises:
        KeyError: If the passed `lm` is neither 'dry' nor 'irr'.

    """
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Get livestock and vegetation type.
    lvstype, vegtype = lvs_veg_types(lu)
    lvstype_capital = lvstype.capitalize()

    # Get the yield potential, i.e. the total number of head per hectare.
    yield_pot = get_yield_pot(data, lvstype, vegtype, lm, yr_idx)

    # Variable costs - quantity-dependent costs as costs per head x heads per hectare.
    costs_q = data.AGEC_LVSTK['QC', lvstype] * yield_pot * data.QC_COST_MULTS.loc[yr_cal, lvstype_capital]

    # Variable costs - area-dependent costs per hectare.
    costs_a = data.AGEC_LVSTK['AC', lvstype] * data.AC_COST_MULTS.loc[yr_cal, lvstype_capital]

    # Fixed costs
    costs_flc = data.AGEC_LVSTK['FLC', lvstype] * data.FLC_COST_MULTS.loc[yr_cal, lvstype_capital]   # Fixed labour costs.
    costs_foc = data.AGEC_LVSTK['FOC', lvstype] * data.FOC_COST_MULTS.loc[yr_cal, lvstype_capital]   # Fixed operating costs.
    costs_fdc = data.AGEC_LVSTK['FDC', lvstype] * data.FDC_COST_MULTS.loc[yr_cal, lvstype_capital]   # Fixed depreciation costs.

    # Water costs in $/ha calculated as water requirements (ML/head) x heads per hectare x delivery price ($/ML)
    if lm == 'irr': # Irrigation water if required.
        WR_IRR = data.AGEC_LVSTK['WR_IRR', lvstype]
    elif lm == 'dry': # No irrigation water if not required.
        WR_IRR = 0
    else: # Passed lm is neither `dry` nor `irr`.
        raise KeyError(f"Unknown {lm} land management. Check `lm` key.")

    # Water delivery costs equal drinking water plus irrigation water req per head * yield (head/ha)
    costs_w = (data.AGEC_LVSTK['WR_DRN', lvstype] * settings.LIVESTOCK_DRINKING_WATER + WR_IRR) * yield_pot
    costs_w *= data.WATER_DELIVERY_PRICE * data.WP_COST_MULTS[yr_cal]  # $/ha

    # Convert costs to $ per cell including resfactor.
    costs_a *= data.REAL_AREA
    costs_flc *= data.REAL_AREA
    costs_foc *= data.REAL_AREA
    costs_fdc *= data.REAL_AREA
    costs_w *= data.REAL_AREA
    costs_q *= data.REAL_AREA

    costs = np.stack([costs_a, costs_flc, costs_foc, costs_fdc, costs_w, costs_q]).T

    # Return costs as numpy array.
    return pd.DataFrame(
        costs,
        columns=pd.MultiIndex.from_product(
            [
                [lu], 
                [lm], 
                ['Area cost', 'Fixed labour cost', 'Fixed operating cost', 'Fixed depreciation cost', 'Water cost', 'Quantity cost']
            ]
        )
    )


def get_cost(data:Data, lu, lm, yr_idx):
    """Return production cost <unit: $/cell> of `lu`+`lm` in `yr_idx` as np array.

    Args:
        data (object/module): Data object or module. Assumes fields like in `luto.data`.
        lu (str): Land use (e.g. 'Winter cereals').
        lm (str): Land management (e.g. 'dry', 'irr', 'org').
        yr_idx (int): Number of years post base-year ('YR_CAL_BASE').

    Returns
        np.array: Production cost <unit: $/cell> of `lu`+`lm` in `yr_idx`.

    Raises:
        KeyError: If land use `lu` is not found in `data.LANDUSES`.
    """
    # If it is a crop, it is known how to get the costs.
    if lu in data.LU_CROPS:
        return get_cost_crop(data, lu, lm, yr_idx)

    elif lu in data.LU_LVSTK:
        return get_cost_lvstk(data, lu, lm, yr_idx)

    elif lu in data.AGRICULTURAL_LANDUSES:
        return pd.DataFrame(
            np.zeros(data.NCELLS),
            columns=pd.MultiIndex.from_product([[lu], [lm], ['Area cost']])
        )

    else:
        raise KeyError(f"Land use '{lu}' not found in any LANDUSES")


def get_cost_matrix(data:Data, lm, yr_idx):
    """
    Return agricultural c_rj matrix <unit: $/cell> per lu under `lm` in `yr_idx`.
    
    Parameters
        data (DataFrame): The input data containing agricultural land use information.
        lm (str): The land use type.
        yr_idx (int): The index of the year.
    
    Returns
        DataFrame: The cost matrix representing the costs per cell for each land use under the given land use type and year index.
    """
    
    cost = pd.concat([get_cost(data, lu, lm, yr_idx) for lu in data.AGRICULTURAL_LANDUSES], axis=1)
        
    # Make sure all NaNs are replaced by zeroes.
    return cost.fillna(0)


def get_cost_matrices(data:Data, yr_idx, aggregate=True):
    """
    Return agricultural c_mrj matrix <unit: $/cell> as 3D Numpy array.

    Parameters
    - data: The input data containing information about land management.
    - yr_idx: The index of the year.
    - aggregate: A boolean value indicating whether to aggregate the cost matrices or not. Default is True.

    Returns
    - If aggregate is True, returns a 3D Numpy array representing the aggregated cost matrix.
    - If aggregate is False, returns a pandas DataFrame representing the cost matrix.

    Raises:
    - ValueError: If the value of aggregate is neither True nor False.
    """
    
    # Concatenate the revenue from each land management into a single Multiindex DataFrame.
    cost_rjms = pd.concat([get_cost_matrix(data, lm, yr_idx) for lm in data.LANDMANS], axis=1)
    
    if not aggregate:
        return cost_rjms

    df_jmr = cost_rjms.T.groupby(level=[0, 1]).sum()
    arr_jmr = df_jmr.values.reshape(*(list(df_jmr.index.levshape) + [-1]))
    return np.einsum('jmr->mrj', arr_jmr)



def get_asparagopsis_effect_c_mrj(data:Data, yr_idx):
    """
    Applies the effects of using asparagopsis to the cost data
    for all relevant agricultural land uses.

    Parameters
    - data: The data object containing relevant information.
    - yr_idx: The index of the year.

    Returns
    - new_c_mrj: The updated cost matrix <unit: $/cell>.

    This function calculates the cost per cell for each relevant agricultural land use
    when using asparagopsis. It takes into account the yield potential, annual cost per
    animal, and the real area of the cell. The function returns the updated cost matrix.
    """
    land_uses = AG_MANAGEMENTS_TO_LAND_USES["Asparagopsis taxiformis"]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_c_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not AG_MANAGEMENTS['Asparagopsis taxiformis']:
        return new_c_mrj

    # Update values in the new matrix
    for lm in data.LANDMANS:
        m = 0 if lm == 'dry' else 1
        for j_idx, lu in enumerate(land_uses):
            lvstype, vegtype = lvs_veg_types(lu)
            yield_pot = get_yield_pot(data, lvstype, vegtype, lm, yr_idx)
            cost_per_animal = data.ASPARAGOPSIS_DATA[lu].loc[yr_cal, 'Annual Cost Per Animal (A$2010/yr)']
            cost_per_cell = cost_per_animal * yield_pot * data.REAL_AREA

            new_c_mrj[m, :, j_idx] = cost_per_cell

    return new_c_mrj


def get_precision_agriculture_effect_c_mrj(data:Data, yr_idx):
    """
    Applies the effects of using precision agriculture to the cost data
    for all relevant agr. land uses.

    Parameters
    - data: The data object containing the necessary information.
    - yr_idx: The index of the year to calculate the effects for.

    Returns
    - new_c_mrj: The updated cost data matrix <unit: $/cell>.
    """
    land_uses = AG_MANAGEMENTS_TO_LAND_USES['Precision Agriculture']
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_c_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not AG_MANAGEMENTS['Precision Agriculture']:
        return new_c_mrj

    for m in range(data.NLMS):
        for j_idx, lu in enumerate(land_uses):
            cost_per_ha = data.PRECISION_AGRICULTURE_DATA[lu].loc[yr_cal, 'AnnCost_per_Ha']
            new_c_mrj[m, :, j_idx] = cost_per_ha * data.REAL_AREA

    return new_c_mrj


def get_ecological_grazing_effect_c_mrj(data:Data, yr_idx):
    """
    Applies the effects of using ecological grazing to the cost data
    for all relevant agr. land uses.

    Parameters
    - data: The data object containing the necessary input data.
    - yr_idx: The index of the year for which the effects are calculated.

    Returns
    - new_c_mrj: The matrix containing the updated cost <unit: $/cell>.
    """

    land_uses = AG_MANAGEMENTS_TO_LAND_USES['Ecological Grazing']
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_c_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)
    
    if not AG_MANAGEMENTS['Ecological Grazing']:
        return new_c_mrj

    for j_idx, lu in enumerate(land_uses):
        lvstype, _ = lvs_veg_types(lu)

        # Get effects on operating costs
        operating_mult = data.ECOLOGICAL_GRAZING_DATA[lu].loc[yr_cal, 'Operating_cost_multiplier']
        operating_c_effect = data.AGEC_LVSTK['FOC', lvstype] * (operating_mult - 1) * data.REAL_AREA

        # Get effects on labour costs
        labour_mult = data.ECOLOGICAL_GRAZING_DATA[lu].loc[yr_cal, 'Labour_cost_mulitiplier']
        labour_c_effect = data.AGEC_LVSTK['FLC', lvstype] * (labour_mult - 1) * data.REAL_AREA

        # Combine for total cost effect
        total_c_effect = operating_c_effect + labour_c_effect

        for m in range(data.NLMS):
            new_c_mrj[m, :, j_idx] = total_c_effect

    return new_c_mrj


def get_savanna_burning_effect_c_mrj(data:Data, yr_idx: int):
    """
    Applies the effects of using LDS Savanna Burning to the cost data
    for all relevant agr. land uses.

    Parameters
    - data: The input data containing relevant information for calculations.

    Returns
    - new_c_mrj: The modified cost data <unit: $/cell>.
    """
    nlus = len(AG_MANAGEMENTS_TO_LAND_USES["Savanna Burning"])
    new_c_mrj = np.zeros((data.NLMS, data.NCELLS, nlus))

    if not AG_MANAGEMENTS['Savanna Burning']:
        return new_c_mrj

    sav_burning_effect = (
        data.SAVBURN_COST_HA
        * data.SAVBURN_COST_MULTS[data.YR_CAL_BASE + yr_idx]
        * data.REAL_AREA
    )

    for m, j in itertools.product(range(data.NLMS), range(nlus)):
        new_c_mrj[m, :, j] = sav_burning_effect

    return new_c_mrj


def get_agtech_ei_effect_c_mrj(data:Data, yr_idx):
    """
    Applies the effects of using AgTech EI to the cost data
    for all relevant agr. land uses.

    Parameters
    - data: The data object containing the necessary information.
    - yr_idx: The index of the year.

    Returns
    - new_c_mrj: The updated cost data <unit: $/cell>.
    """
    land_uses = AG_MANAGEMENTS_TO_LAND_USES['AgTech EI']
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_c_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not AG_MANAGEMENTS['AgTech EI']:
        return new_c_mrj

    for m in range(data.NLMS):
        for j_idx, lu in enumerate(land_uses):
            cost_per_ha = data.AGTECH_EI_DATA[lu].loc[yr_cal, 'AnnCost_per_Ha']
            new_c_mrj[m, :, j_idx] = cost_per_ha * data.REAL_AREA

    return new_c_mrj


def get_biochar_effect_c_mrj(data:Data, yr_idx: int):
    """
    Applies the effects of using Biochar to the cost data
    for all relevant agr. land uses.

    Parameters
    - data: The data object containing the necessary information.
    - yr_idx: The index of the year.

    Returns
    - new_c_mrj: The updated cost data <unit: $/cell>.
    """
    land_uses = AG_MANAGEMENTS_TO_LAND_USES['Biochar']
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_c_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not AG_MANAGEMENTS['Biochar']:
        return new_c_mrj

    for m in range(data.NLMS):
        for j_idx, lu in enumerate(land_uses):
            cost_per_ha = data.BIOCHAR_DATA[lu].loc[yr_cal, 'AnnCost_per_Ha']
            new_c_mrj[m, :, j_idx] = cost_per_ha * data.REAL_AREA

    return new_c_mrj


def get_beef_hir_effect_c_mrj(data: Data, yr_idx: int):
    """
    Applies the effects of using HIR for beef to the cost data
    for all relevant agr. land uses.
    
    Parameters
    - data: The data object containing the necessary information.
    - yr_idx: The index of the year.
    
    Returns
    - c_mrj_effects: The updated cost data <unit: $/cell>.
    """
    yr_cal = data.YR_CAL_BASE + yr_idx
    land_uses = AG_MANAGEMENTS_TO_LAND_USES['HIR - Beef']
    c_mrj_effects = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    # Cost reduction due to reduced livestock density
    for m, lm in enumerate(data.LANDMANS):
        for j_idx, lu in enumerate(land_uses):
            # Quantity costs are reduced by `HIR_PRODUCTIVITY_CONTRIBUTION` under HIR
            lvstype, vegtype = lvs_veg_types(lu)
            lvstype_capital = lvstype.capitalize()
            yield_pot = get_yield_pot(data, lvstype, vegtype, lm, yr_idx)

            q_costs = data.AGEC_LVSTK['QC', lvstype] * yield_pot * data.QC_COST_MULTS.loc[yr_cal, lvstype_capital] * data.REAL_AREA
            c_mrj_effects[m, :, j_idx] += (settings.HIR_PRODUCTIVITY_CONTRIBUTION - 1) * q_costs

    return c_mrj_effects + (settings.BEEF_HIR_MAINTENANCE_COST_PER_HA_PER_YEAR * data.REAL_AREA)[:,None]


def get_sheep_hir_effect_c_mrj(data: Data, yr_idx: int):
    """
    Applies the effects of using HIR for sheep to the cost data
    for all relevant agr. land uses.
    
    Parameters
    - data: The data object containing the necessary information.
    - yr_idx: The index of the year.
    
    Returns
    - c_mrj_effects: The updated cost data <unit: $/cell>.
    """
    yr_cal = data.YR_CAL_BASE + yr_idx
    land_uses = AG_MANAGEMENTS_TO_LAND_USES['HIR - Sheep']
    c_mrj_effects = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    for m, lm in enumerate(data.LANDMANS):
        for j_idx, lu in enumerate(land_uses):
            # Quantity costs are reduced by 50% under HIR
            lvstype, vegtype = lvs_veg_types(lu)
            lvstype_capital = lvstype.capitalize()
            yield_pot = get_yield_pot(data, lvstype, vegtype, lm, yr_idx)

            q_costs = data.AGEC_LVSTK['QC', lvstype] * yield_pot * data.QC_COST_MULTS.loc[yr_cal, lvstype_capital] * data.REAL_AREA
            c_mrj_effects[m, :, j_idx] += (settings.HIR_PRODUCTIVITY_CONTRIBUTION - 1) * q_costs

    return c_mrj_effects + (settings.SHEEP_HIR_MAINTENANCE_COST_PER_HA_PER_YEAR * data.REAL_AREA)[:,None]

def get_utility_solar_pv_effect_c_mrj(data: Data, c_mrj, yr_idx):
    """
    Applies Utility Solar PV cost effects separately for establishment and O&M to the cost data.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Utility Solar PV']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Initialize new effects matrix
    new_c_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses)), dtype=np.float32)

    if not settings.AG_MANAGEMENTS['Utility Solar PV']:
        return new_c_mrj

    for j_idx, lu in enumerate(land_uses):
        # Retrieve multipliers (use 1.0 if missing)
        est_mult = data.UTILITY_SOLAR_PV_DATA[lu].loc[yr_cal, 'Establishment_Cost_Multiplier']
        est_mult = est_mult if not np.isnan(est_mult) else 1.0

        om_mult = data.UTILITY_SOLAR_PV_DATA[lu].loc[yr_cal, 'OM_Cost_Multiplier']
        om_mult = om_mult if not np.isnan(om_mult) else 1.0

        # Decompose original cost into establishment and O&M if possible
        # For illustration, assume access to base components:
        # c_mrj_est = establishment cost component
        # c_mrj_om = O&M cost component
        c_mrj_est = data.BASE_EST_COST[lu_codes[j_idx]]  # Shape: (NLMS, NCELLS)
        c_mrj_om = data.BASE_OM_COST[lu_codes[j_idx]]    # Shape: (NLMS, NCELLS)

        # Apply multipliers individually
        adj_est = c_mrj_est * est_mult
        adj_om = c_mrj_om * om_mult

        # Sum to get total adjusted cost
        new_c_mrj[:, :, j_idx] = adj_est + adj_om

    return new_c_mrj


def get_onshore_wind_effect_c_mrj(data: Data, c_mrj, yr_idx):
    """
    Applies Onshore Wind cost effects separately for establishment and O&M to the cost data.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Onshore Wind']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Initialize new effects matrix
    new_c_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses)), dtype=np.float32)

    if not settings.AG_MANAGEMENTS['Onshore Wind']:
        return new_c_mrj

    for j_idx, lu in enumerate(land_uses):
        # Retrieve multipliers (use 1.0 if missing)
        est_mult = data.ONSHORE_WIND_DATA[lu].loc[yr_cal, 'Establishment_Cost_Multiplier']
        est_mult = est_mult if not np.isnan(est_mult) else 1.0

        om_mult = data.ONSHORE_WIND_DATA[lu].loc[yr_cal, 'OM_Cost_Multiplier']
        om_mult = om_mult if not np.isnan(om_mult) else 1.0

        # Decompose original cost into establishment and O&M if possible
        # For illustration, assume access to base components:
        # c_mrj_est = establishment cost component
        # c_mrj_om = O&M cost component
        c_mrj_est = data.BASE_EST_COST[lu_codes[j_idx]]  # Shape: (NLMS, NCELLS)
        c_mrj_om = data.BASE_OM_COST[lu_codes[j_idx]]    # Shape: (NLMS, NCELLS)

        # Apply multipliers individually
        adj_est = c_mrj_est * est_mult
        adj_om = c_mrj_om * om_mult

        # Sum to get total adjusted cost
        new_c_mrj[:, :, j_idx] = adj_est + adj_om

    return new_c_mrj


def get_agricultural_management_cost_matrices(data: Data, c_mrj, yr_idx):
    """
    Calculate the cost matrices for different agricultural management practices.

    Args:
        data (dict): The input data for cost calculations.
        c_mrj (float): The cost of marginal reduction in emissions.
        yr_idx (int): The index of the year.

    Returns
        dict: A dictionary containing the cost matrices for different agricultural management practices.
            The keys are the names of the practices and the values are the corresponding cost matrices.
    """
    ag_mam_c_mrj = {}

    ag_mam_c_mrj['Asparagopsis taxiformis'] = get_asparagopsis_effect_c_mrj(data, yr_idx)           
    ag_mam_c_mrj['Precision Agriculture'] = get_precision_agriculture_effect_c_mrj(data, yr_idx)    
    ag_mam_c_mrj['Ecological Grazing'] = get_ecological_grazing_effect_c_mrj(data, yr_idx)          
    ag_mam_c_mrj['Savanna Burning'] = get_savanna_burning_effect_c_mrj(data, yr_idx)                
    ag_mam_c_mrj['AgTech EI'] = get_agtech_ei_effect_c_mrj(data, yr_idx)                            
    ag_mam_c_mrj['Biochar'] = get_biochar_effect_c_mrj(data, yr_idx)                                
    ag_mam_c_mrj['HIR - Beef'] = get_beef_hir_effect_c_mrj(data, yr_idx)                            
    ag_mam_c_mrj['HIR - Sheep'] = get_sheep_hir_effect_c_mrj(data, yr_idx)   
    ag_mam_c_mrj['Utility Solar PV'] = get_utility_solar_pv_effect_c_mrj(data, c_mrj, yr_idx)
    ag_mam_c_mrj['Onshore Wind'] = get_onshore_wind_effect_c_mrj(data, c_mrj, yr_idx)
                        

    return ag_mam_c_mrj
```

## luto/economics/agricultural/ghg.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.



"""
Pure functions to calculate greenhouse gas emissions by lm, lu.
"""

import itertools
import numpy as np
import pandas as pd

from luto.data import Data
import luto.tools as tools
from luto import settings
from luto.economics.agricultural.quantity import get_yield_pot
from luto.economics.agricultural.quantity import lvs_veg_types


def get_ghg_crop(data:Data, lu, lm, aggregate):
    """Return crop GHG emissions <unit: t/cell>  of `lu`+`lm` in `yr_idx` 
    as (np array|pd.DataFrame) depending on aggregate (True|False).

    Args:
        data (object/module): Data object or module. Assumes fields like in `luto.data`.
        lu (str): Land use (e.g. 'Winter cereals' or 'Beef - natural land').
        lm (str): Land management (e.g. 'dry', 'irr').
        aggregate (bool): True -> return GHG emission as np.array, False -> return GHG emission as pd.DataFrame.

    Returns
        np.array or pd.DataFrame: Crop GHG emissions <unit: t/cell>  of `lu`+`lm` in `yr_idx`.

    Crop GHG emissions include:
        - 'CO2E_KG_HA_CHEM_APPL'
        - 'CO2E_KG_HA_CROP_MGT'
        - 'CO2E_KG_HA_CULTIV'
        - 'CO2E_KG_HA_FERT_PROD'
        - 'CO2E_KG_HA_HARVEST'
        - 'CO2E_KG_HA_IRRIG'
        - 'CO2E_KG_HA_PEST_PROD'
        - 'CO2E_KG_HA_SOIL'
        - 'CO2E_KG_HA_SOWING'
    """
    
    # Process GHG_crop only if the land-use (lu) and land management (lm) combination exists (e.g., dryland Pears/Rice do not occur)
    if lu in data.AGGHG_CROPS['CO2E_KG_HA_CHEM_APPL', lm].columns:

        # Get the data column {ghg_rs: r -> each pixel,  s -> each GHG source}
        if settings.USE_GHG_SCOPE_1:
            ghg_rs = data.AGGHG_CROPS.loc[:, (data.AGGHG_CROPS.columns.get_level_values(0).isin(settings.CROP_GHG_SCOPE_1)) & 
                                             (data.AGGHG_CROPS.columns.get_level_values(1) == lm) & 
                                             (data.AGGHG_CROPS.columns.get_level_values(2) == lu)]
        else:
            ghg_rs = data.AGGHG_CROPS.loc[:, (slice(None), lm, lu)]

        # Convert kg CO2e per ha to tonnes. 
        ghg_rs /= 1000

        # Convert tonnes CO2 per ha to tonnes CO2 per cell including resfactor
        ghg_rs *= data.REAL_AREA[:, np.newaxis]

        # Convert to MultiIndex with levels [source, lm, lu]
        ghg_rs.columns = pd.MultiIndex.from_tuples([[col[0], lm, lu] for col in ghg_rs.columns])

        # Reset the dataframe index
        ghg_rs.reset_index(drop=True, inplace=True)

        # Return greenhouse gas emissions by individual source or summed over all sources (default)
        return ghg_rs if aggregate == False else ghg_rs.sum(axis=1).values



def get_ghg_lvstk( data:Data    # Data object.
                 , lu          # Land use.
                 , lm          # Land management.
                 , yr_idx      # Number of years post base-year ('YR_CAL_BASE').
                 , aggregate): # GHG calculated as a total (for the solver) or by individual source (for writing outputs)
    """Return livestock GHG emissions <unit: t/cell>  of `lu`+`lm` in `yr_idx`
            as (np array|pd.DataFrame) depending on aggregate (True|False).

    `data`: data object/module -- assumes fields like in `luto.data`.
    `lu`: land use (e.g. 'Winter cereals' or 'Beef - natural land').
    `lm`: land management (e.g. 'dry', 'irr').
    `yr_idx`: number of years from base year, counting from zero.
    `aggregate`: True -> return GHG emission as np.array 
                 False -> return GHG emission as pd.DataFrame.
    
    Livestock GHG emissions include:    
                  'CO2E_KG_HEAD_DUNG_URINE',
                  'CO2E_KG_HEAD_ELEC',
                  'CO2E_KG_HEAD_ENTERIC',
                  'CO2E_KG_HEAD_FODDER',
                  'CO2E_KG_HEAD_FUEL',
                  'CO2E_KG_HEAD_IND_LEACH_RUNOFF',
                  'CO2E_KG_HEAD_MANURE_MGT',
                  'CO2E_KG_HEAD_SEED',
    """
    
    lvstype, vegtype = lvs_veg_types(lu)

    # Get the yield potential, i.e. the total number of livestock head per hectare.
    yield_pot = get_yield_pot(data, lvstype, vegtype, lm, yr_idx)

    # Get GHG emissions by source in kg CO2e per head of livestock.  settings.LVSTK_GHG_SCOPE_1
    # Note: ghg_rs (r -> each cell, s -> each GHG source)
    if settings.USE_GHG_SCOPE_1:
        ghg_raw = data.AGGHG_LVSTK.loc[:, (data.AGGHG_LVSTK.columns.get_level_values(0) == lvstype) &
                                          (data.AGGHG_LVSTK.columns.get_level_values(1).isin(settings.LVSTK_GHG_SCOPE_1))]
    else:
        ghg_raw = data.AGGHG_LVSTK.loc[:, (lvstype, slice(None)) ]

    # Get the names for each GHG source
    ghg_name_s = [ i[1] for i in ghg_raw.columns ]

    # Calculate the GHG emissions (kgCO2/head * head/ha = kgCO/ha)
    ghg_rs = ghg_raw * yield_pot[:,np.newaxis]


    # Add pasture irrigation emissions.
    if lm == 'irr':
        ghg_lvstk_irr = data.AGGHG_IRRPAST
        ghg_lvstk_irr_cols = [i for i in ghg_lvstk_irr.columns if 'CO2E' in i]
        
        ghg_rs = pd.concat([ghg_rs, ghg_lvstk_irr[ghg_lvstk_irr_cols]], axis = 1)
        ghg_name_s += ghg_lvstk_irr_cols
        

    # Convert to tonnes of CO2e per ha. 
    ghg_rs = ghg_rs / 1000

    # Convert to tonnes CO2e per cell including resfactor
    ghg_rs *= data.REAL_AREA[:, np.newaxis]

    # Convert to MultiIndex with levels [source, lm, lu]
    ghg_rs = pd.DataFrame(ghg_rs)
    ghg_rs.columns = pd.MultiIndex.from_tuples( [(ghg, lm, lu) for ghg in ghg_name_s ])

    # Reset dataframe index
    ghg_rs.reset_index(drop = True, inplace = True)
    
    # Return the full dataframe if Aggregate == False otherwise return the sum over all GHG sources
    return ghg_rs if aggregate == False else ghg_rs.sum(axis = 1).values
       


def get_ghg(data:Data, lu, lm, yr_idx, aggregate):
    """Return GHG emissions [tCO2e/cell] of `lu`+`lm` in `yr_idx` 
    as (np array|pd.DataFrame) depending on aggregate (True|False).

    Args:
        data (object/module): Data object or module. Assumes fields like in `luto.data`.
        lu (str): Land use (e.g. 'Winter cereals').
        lm (str): Land management (e.g. 'dry', 'irr').
        yr_idx (int): Number of years from base year, counting from zero.
        aggregate (bool): True -> return GHG emission as np.array, False -> return GHG emission as pd.DataFrame.

    Returns
        np.array or pd.DataFrame: GHG emissions [tCO2e/cell] of `lu`+`lm` in `yr_idx`.

    Raises:
        KeyError: If land use `lu` is not found in `data.LANDUSES`.
    """

    # If it is a crop, it is known how to get GHG emissions.
    if lu in data.LU_CROPS:
        return get_ghg_crop(data, lu, lm, aggregate)
    elif lu in data.LU_LVSTK:
        return get_ghg_lvstk(data, lu, lm, yr_idx, aggregate)
    elif lu in data.AGRICULTURAL_LANDUSES:
        if aggregate:
            return np.zeros(data.NCELLS)
        else:
            return pd.DataFrame({('CO2E_KG_HA_CHEM_APPL', lm, lu): np.zeros(data.NCELLS)})
    else:
        raise KeyError(f"Land use '{lu}' not found in data.LANDUSES")



def get_ghg_matrix(data:Data, lm, yr_idx, aggregate):
    """
    Return g_rj matrix <unit: t/cell> per lu under `lm` in `yr_idx`.

    Parameters
    - data: The data object containing the necessary information.
    - lm: The land use model.
    - yr_idx: The index of the year.
    - aggregate: A boolean indicating whether to aggregate the results or not.

    Returns
    - If `aggregate` is True, returns a numpy array of shape (NCELLS, len(data.AGRICULTURAL_LANDUSES)).
    - If `aggregate` is False, returns a pandas DataFrame with columns corresponding to each agricultural land use.

    """
    if aggregate == True: 
        g_rj = np.zeros((data.NCELLS, len(data.AGRICULTURAL_LANDUSES)))
        for j, lu in enumerate(data.AGRICULTURAL_LANDUSES):
            g_rj[:, j] = get_ghg(data, lu, lm, yr_idx, aggregate)
            
        # Make sure all NaNs are replaced by zeroes.
        g_rj = np.nan_to_num(g_rj)
    
        return g_rj
    
    elif aggregate == False:     
        return pd.concat([get_ghg(data, lu, lm, yr_idx, aggregate) 
                          for lu in data.AGRICULTURAL_LANDUSES],axis=1)
        


def get_ghg_matrices(data:Data, yr_idx, aggregate=True):
    """
    Return g_mrj matrix <unit: t/cell> as 3D Numpy array.
    
    Parameters
        data (object): The data object containing the necessary information.
        yr_idx (int): The index of the year.
        aggregate (bool, optional): Whether to aggregate the results. Defaults to True.
    
    Returns
        numpy.ndarray or pandas.DataFrame: The GHG emissions matrix as a 3D Numpy array if aggregate is True,
        or as a pandas DataFrame if aggregate is False.
    """
    
    if aggregate == True:  
        return np.stack(
            tuple(
                get_ghg_matrix(data, lm, yr_idx, aggregate)
                for lm in data.LANDMANS
            )
        )
    elif aggregate == False:
        ghg_df = pd.concat([get_ghg_matrix(data, lu, yr_idx, aggregate) for lu in data.LANDMANS], axis=1).replace('CO2E_KG_HA','TCO2E')
        column_rename = [(i[0].replace('CO2E_KG_HA','TCO2E'),i[1],i[2]) for i in ghg_df.columns]
        column_rename = [(i[0].replace('CO2E_KG_HEAD','TCO2E'),i[1],i[2]) for i in column_rename]
        ghg_df.columns = pd.MultiIndex.from_tuples(column_rename)
        return ghg_df


def get_ghg_unall_natural_to_lvstk_natural(data:Data, lumap) -> np.ndarray:
    """
    Gets the one-off greenhouse gas penalties for transitioning unallocated natural land to livestock natural land.
    
    Parameters
        data (object): The data object containing relevant information.
        lumap (1D array): The lumap object containing land use mapping.

    Returns
        np.ndarray, <unit : t/cell>.
    """
    
    ncells, n_ag_lus = data.REAL_AREA.shape[0], len(data.AGRICULTURAL_LANDUSES)
    ghg_unall_natural_to_lvstk_natural_rj = np.zeros((ncells, n_ag_lus), dtype=np.float32)
    un_allow_code = data.DESC2AGLU["Unallocated - natural land"]

    for to_lu in data.LU_LVSTK_NATURAL:

        ghg_unall_natural_to_lvstk_natural_r = (
            data.CO2E_STOCK_UNALL_NATURAL[lumap == un_allow_code] 
            * (1 - data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[to_lu])
            * data.REAL_AREA[lumap == un_allow_code]
        ) 
        
        ghg_unall_natural_to_lvstk_natural_rj[lumap == un_allow_code, to_lu] = ghg_unall_natural_to_lvstk_natural_r
            
    return np.stack([ghg_unall_natural_to_lvstk_natural_rj] * 2)


def get_ghg_lvstk_natural_to_modified(data:Data, lumap) -> np.ndarray:
    """
    Gets the one-off greenhouse gas penalties for transitioning livestock natural land to modified land.
    
    Parameters
        data (object): The data object containing relevant information.
        lumap (1D array): The lumap object containing land use mapping.

    Returns
        np.ndarray, <unit : t/cell>.
    """
    
    ncells, n_ag_lus = data.REAL_AREA.shape[0], len(data.AGRICULTURAL_LANDUSES)
    ghg_lvstk_natural_to_modified_rj = np.zeros((ncells, n_ag_lus), dtype=np.float32)
    
    for from_lu in data.LU_LVSTK_NATURAL:
        for to_lu in data.LU_MODIFIED_LAND:
            # Get GHG penalties from current land use to future land use
            ghg_lvstk_natural_to_modified_r = (
                data.CO2E_STOCK_UNALL_NATURAL[lumap == from_lu] 
                * (1 - data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[to_lu])
                * data.REAL_AREA[lumap == from_lu]
            ) 
            
            # Assign the penalties to the transition matrices
            ghg_lvstk_natural_to_modified_rj[lumap == from_lu, to_lu] = ghg_lvstk_natural_to_modified_r
        
    return np.stack([ghg_lvstk_natural_to_modified_rj] * 2)


def get_ghg_unall_natural_to_modified(data:Data, lumap) -> np.ndarray:
    """
    Gets the one-off greenhouse gas penalties for transitioning unallocated natural land to modified land.

    Parameters
        data (object): The data object containing relevant information.
        lumap (1D array): The lumap object containing land use mapping.

    Returns
        np.ndarray, <unit : t/cell>.
    """
    ncells, n_ag_lus = data.REAL_AREA.shape[0], len(data.AGRICULTURAL_LANDUSES)
    ghg_unall_natural_to_modified_rj = np.zeros((ncells, n_ag_lus), dtype=np.float32)
    un_allow_code = data.DESC2AGLU["Unallocated - natural land"]

    for to_lu in data.LU_MODIFIED_LAND:
        # Get GHG penalties from current land use to future land use
        ghg_unall_natural_to_modified_r = (
            data.CO2E_STOCK_UNALL_NATURAL[lumap == un_allow_code] 
            * (1 - data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[to_lu])
            * data.REAL_AREA[lumap == un_allow_code]
        ) 
        
        # Assign the penalties to the transition matrices
        ghg_unall_natural_to_modified_rj[lumap == un_allow_code, to_lu] = ghg_unall_natural_to_modified_r

    return np.stack([ghg_unall_natural_to_modified_rj] * 2)


def get_ghg_transition_emissions(data:Data, lumap, separate=False) -> np.ndarray:
    """
    Get the one-off greenhouse gas penalties for transitioning between land uses.

    Parameters
    ----------
      data (object): The data object containing relevant information.
      lumap (np.ndarray): The lumap object containing land use mapping.
      separate (bool): Whether to return the penalties for each transition separately.

    Returns
    -------
      GHG penalties (dict[np.ndarray]|np.ndarray): The greenhouse gas transition penalties.
    """
   
    ghg_lvstck_natural_to_unall_natural = np.zeros_like(data.AG_L_MRJ)   # No land can transited to unall-natural, here use a full zero array for consistency
    ghg_lvstck_natural_to_modified = get_ghg_lvstk_natural_to_modified(data, lumap)
    ghg_unall_natural_to_lvstck_natural = get_ghg_unall_natural_to_lvstk_natural(data, lumap)
    ghg_unall_natural_to_modified = get_ghg_unall_natural_to_modified(data, lumap)
    
    if separate:
        ghg_trainsition_penalties = {
            'Livestock natural to unallocated natural': ghg_lvstck_natural_to_unall_natural,
            'Unallocated natural to livestock natural': ghg_unall_natural_to_lvstck_natural,
            'Livestock natural to modified': ghg_lvstck_natural_to_modified,
            'Unallocated natural to modified': ghg_unall_natural_to_modified
        }
    else:
        ghg_trainsition_penalties = ghg_lvstck_natural_to_unall_natural \
            + ghg_unall_natural_to_lvstck_natural \
            + ghg_lvstck_natural_to_modified \
            + ghg_unall_natural_to_modified \
    
    return ghg_trainsition_penalties
    
    


def get_asparagopsis_effect_g_mrj(data:Data, yr_idx):
    """
    Applies the effects of using asparagopsis to the GHG data
    for all relevant agricultural land uses.

    Parameters
    - data: The input data containing GHG and land use information.
    - yr_idx: The index of the year to calculate the effects for.

    Returns
    - new_g_mrj: The matrix <unit: t/cell> containing the updated GHG data with the effects of using asparagopsis.

    Note: This function relies on other helper functions such as lvs_veg_types and get_yield_pot to calculate
    the reduction amount for each land use and management type.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES["Asparagopsis taxiformis"]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_g_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Asparagopsis taxiformis']:
        return new_g_mrj

    # Update values in the new matrix, taking into account the CH4 reduction of asparagopsis
    for lu_idx, lu in enumerate(land_uses):
        ch4_reduction_perc = 1 - data.ASPARAGOPSIS_DATA[lu].loc[yr_cal, "CO2E_KG_HEAD_ENTERIC"]

        if ch4_reduction_perc != 0:
            for lm in data.LANDMANS:
                m = 0 if lm == 'irr' else 1
                # Subtract enteric fermentation emissions multiplied by reduction multiplier
                lvstype, vegtype = lvs_veg_types(lu)

                yield_pot = get_yield_pot(data, lvstype, vegtype, lm, yr_idx)

                reduction_amnt = (
                    data.AGGHG_LVSTK[lvstype, "CO2E_KG_HEAD_ENTERIC"].to_numpy()
                    * yield_pot
                    * ch4_reduction_perc
                    / 1000            # convert to tonnes
                    * data.REAL_AREA  # adjust for resfactor
                )
                new_g_mrj[m, :, lu_idx] = -reduction_amnt

    return new_g_mrj


def get_precision_agriculture_effect_g_mrj(data:Data, yr_idx):
    """
    Applies the effects of using precision agriculture to the GHG data
    for all relevant agr. land uses.

    Parameters
    - data: The input data containing the necessary information.
    - yr_idx: The index of the year to calculate the effects for.

    Returns
    - new_g_mrj: The matrix <unit: t/cell> containing the updated GHG data after applying the effects of precision agriculture.
    """

    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Precision Agriculture']
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_g_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Precision Agriculture']:
        return new_g_mrj

    # Update values in the new matrix
    for lu_idx, lu in enumerate(land_uses):
        lu_data = data.PRECISION_AGRICULTURE_DATA[lu]

        for lm in data.LANDMANS:
            m = 0 if lm == 'dry' else 1
            for co2e_type in [
                'CO2E_KG_HA_CHEM_APPL',
                'CO2E_KG_HA_CROP_MGT',
                'CO2E_KG_HA_PEST_PROD',
                'CO2E_KG_HA_SOIL'
            ]:
                # Check if land-use/land management combination exists (e.g., dryland Pears/Rice do not occur), if not use zeros
                if lu not in data.AGGHG_CROPS[data.AGGHG_CROPS.columns[0][0], lm].columns:
                    continue

                reduction_perc = 1 - lu_data.loc[yr_cal, co2e_type]

                if reduction_perc != 0:
                    reduction_amnt = (
                        np.nan_to_num(data.AGGHG_CROPS[co2e_type, lm, lu].to_numpy().copy(), 0)
                        * reduction_perc
                        / 1000            # convert to tonnes
                        * data.REAL_AREA  # adjust for resfactor
                    )
                    new_g_mrj[m, :, lu_idx] -= reduction_amnt

    if np.isnan(new_g_mrj).any():
        raise ValueError("Error in data: NaNs detected in agricultural management options' GHG effect matrix.")

    return new_g_mrj


def get_ecological_grazing_effect_g_mrj(data:Data, yr_idx):
    """
    Applies the effects of using ecological grazing to the GHG data
    for all relevant agricultural land uses.

    Parameters
    - data: The input data containing relevant information for calculations.
    - yr_idx: The index of the year for which the calculations are performed.

    Returns
    - new_g_mrj: The matrix <unit: t/cell> containing the updated GHG data after applying ecological grazing effects.
    """

    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Ecological Grazing']
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_g_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Ecological Grazing']:
        return new_g_mrj

    # Update values in the new matrix
    for lu_idx, lu in enumerate(land_uses):
        lu_data = data.ECOLOGICAL_GRAZING_DATA[lu]

        for lm in data.LANDMANS:
            m = 0 if lm == 'dry' else 1
            # Subtract leach runoff carbon benefit
            leach_reduction_perc = 1 - lu_data.loc[yr_cal, 'CO2E_KG_HEAD_IND_LEACH_RUNOFF']
            if leach_reduction_perc != 0:
                lvstype, vegtype = lvs_veg_types(lu)
                yield_pot = get_yield_pot(data, lvstype, vegtype, lm, yr_idx)

                leach_reduction_amnt = (
                    data.AGGHG_LVSTK[lvstype, 'CO2E_KG_HEAD_IND_LEACH_RUNOFF'].to_numpy()
                    * yield_pot       # convert to HAs
                    * leach_reduction_perc
                    / 1000            # convert to tonnes
                    * data.REAL_AREA  # adjust for resfactor
                )
                new_g_mrj[m, :, lu_idx] -= leach_reduction_amnt

            # Subtract soil carbon benefit
            soil_multiplier = lu_data.loc[yr_cal, 'IMPACTS_soil_carbon'] - 1
            if soil_multiplier != 0:
                soil_reduction_amnt = (
                    data.SOIL_CARBON_AVG_T_CO2_HA
                    * soil_multiplier
                    * data.REAL_AREA  # adjust for resfactor
                    / settings.SOC_AMORTISATION # annualise the soil carbon sequestration
                )
                new_g_mrj[m, :, lu_idx] -= soil_reduction_amnt

    return new_g_mrj


def get_savanna_burning_effect_g_mrj(data:Data):
    """
    Applies the effects of using savanna burning to the GHG data
    for all relevant agr. land uses.

    Parameters
    - data: The input data containing relevant information.
    - g_mrj: The savanna burning factor.

    Returns
    - sb_g_mrj: The GHG data <unit: t/cell> with the effects of savanna burning applied.
    """
    nlus = len(settings.AG_MANAGEMENTS_TO_LAND_USES["Savanna Burning"])
    sb_g_mrj = np.zeros((data.NLMS, data.NCELLS, nlus)).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Savanna Burning']:
        return sb_g_mrj

    for m, j in itertools.product(range(data.NLMS), range(nlus)):
        # sb_g_mrj[m, :, j] = -data.SAVBURN_TOTAL_TCO2E_HA * data.REAL_AREA
        sb_g_mrj[m, :, j] = np.where( data.SAVBURN_ELIGIBLE, 
                                     -data.SAVBURN_TOTAL_TCO2E_HA * data.REAL_AREA, 
                                      0
                                    )
    return sb_g_mrj


def get_agtech_ei_effect_g_mrj(data:Data, yr_idx):
    """
    Applies the effects of using AgTech EI to the GHG data
    for all relevant agr. land uses.

    Parameters
    - data: The input data containing the necessary information.
    - yr_idx: The index of the year to calculate the effects for.

    Returns
    - new_g_mrj: The matrix <unit: t/cell> containing the updated GHG data after applying the AgTech EI effects.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['AgTech EI']
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_g_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['AgTech EI']:
        return new_g_mrj

    # Update values in the new matrix
    for lu_idx, lu in enumerate(land_uses):
        lu_data = data.AGTECH_EI_DATA[lu]

        for lm in data.LANDMANS:
            m = 0 if lm == 'dry' else 1
            for co2e_type in [
                'CO2E_KG_HA_CHEM_APPL',
                'CO2E_KG_HA_CROP_MGT',
                'CO2E_KG_HA_PEST_PROD',
                'CO2E_KG_HA_SOIL'
            ]:    
                # Check if land-use/land management combination exists (e.g., dryland Pears/Rice do not occur), if not use zeros
                if lu not in data.AGGHG_CROPS[data.AGGHG_CROPS.columns[0][0], lm].columns:
                    continue

                reduction_perc = 1 - lu_data.loc[yr_cal, co2e_type]

                if reduction_perc != 0:
                    reduction_amnt = (
                        np.nan_to_num(data.AGGHG_CROPS[co2e_type, lm, lu].to_numpy().copy(), 0) 
                        * reduction_perc
                        / 1000            # convert to tonnes
                        * data.REAL_AREA  # adjust for resfactor
                    )
                    new_g_mrj[m, :, lu_idx] -= reduction_amnt

            # Subtract extra 'CO2e_KG_HA_IRRIG' carbon for irrigated land uses
            if m == 1:
                if lu not in data.AGGHG_CROPS[data.AGGHG_CROPS.columns[0][0], lm].columns:
                    continue

                # Columns names for irrig. CO2e are inconsistent across sheets
                irrig_co2e_col = 'CO2e_KG_HA_IRRIG'
                if 'CO2E_KG_HA_IRRIG' in lu_data.columns:
                    irrig_co2e_col = 'CO2E_KG_HA_IRRIG'

                reduction_perc = 1 - lu_data.loc[yr_cal, irrig_co2e_col]

                if reduction_perc != 0:
                    reduction_amnt = (
                        np.nan_to_num(data.AGGHG_CROPS['CO2E_KG_HA_IRRIG', lm, lu].copy().to_numpy(), 0) 
                        * reduction_perc
                        / 1000            # convert to tonnes
                        * data.REAL_AREA  # adjust for resfactor
                    )
                    new_g_mrj[m, :, lu_idx] -= reduction_amnt

    return new_g_mrj


def get_biochar_effect_g_mrj(data:Data, yr_idx):
    """
    Applies the effects of using Biochar to the GHG data
    for all relevant agr. land uses.

    Parameters
    - data: The input data containing the necessary information.
    - yr_idx: The index of the year to calculate the effects for.

    Returns
    - new_g_mrj: The matrix <unit: t/cell> containing the updated GHG data after applying the Biochar effects.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Biochar']
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_g_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Biochar']:
        return new_g_mrj

    # Update values in the new matrix
    for lu_idx, lu in enumerate(land_uses):
        lu_data = data.BIOCHAR_DATA[lu]

        for lm in data.LANDMANS:
            m = 0 if lm == 'dry' else 1
            for co2e_type in [
                'CO2E_KG_HA_CROP_MGT',
                'CO2E_KG_HA_SOIL',  # TODO: the column in the data refers to CO2E_KG_HA_SOIL_N_SURP
            ]:
                # Check if land-use/land management combination exists (e.g., dryland Pears/Rice do not occur), if not use zeros
                if lu not in data.AGGHG_CROPS[data.AGGHG_CROPS.columns[0][0], lm].columns:
                    continue
                
                if co2e_type == 'CO2E_KG_HA_SOIL':
                    reduction_perc = 1 - lu_data.loc[yr_cal, 'CO2E_KG_HA_SOIL_N_SURP']
                else:
                    reduction_perc = 1 - lu_data.loc[yr_cal, co2e_type]

                if reduction_perc != 0:
                    reduction_amnt = (
                        np.nan_to_num(data.AGGHG_CROPS[co2e_type, lm, lu].to_numpy().copy(), 0) 
                        * reduction_perc
                        / 1000            # convert to tonnes
                        * data.REAL_AREA  # adjust for resfactor
                    )
                    new_g_mrj[m, :, lu_idx] -= reduction_amnt

            # Subtract soil carbon benefit
            soil_multiplier = lu_data.loc[yr_cal, 'IMPACTS_soil_carbon'] - 1
            if soil_multiplier != 0:
                soil_reduction_amnt = (
                    data.SOIL_CARBON_AVG_T_CO2_HA
                    * soil_multiplier
                    * data.REAL_AREA  # adjust for resfactor
                    / settings.SOC_AMORTISATION # annualise the soil carbon sequestration 
                )
                new_g_mrj[m, :, lu_idx] -= soil_reduction_amnt

    return new_g_mrj


def get_beef_hir_effect_g_mrj(data: Data, yr_idx):
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['HIR - Beef']
    g_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses)))
    
    # GHG abatement from Land Use Change 
    for j_idx, lu in enumerate(land_uses):
        g_mrj_effect[:, :, j_idx] -= (
            data.CO2E_STOCK_UNALL_NATURAL      
            * (1 - data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[data.DESC2AGLU[lu]])
            * data.REAL_AREA
            / settings.HIR_EFFECT_YEARS    
        )

    # GHG abatement from livestock density reduction
    for lm_idx, lm in enumerate(data.LANDMANS):         
        for j_idx, lu in enumerate(land_uses):
            g_mrj_effect[lm_idx, :, j_idx] -= get_ghg_lvstk(data, lu, lm, yr_idx, True) * settings.HIR_PRODUCTIVITY_CONTRIBUTION

    return g_mrj_effect


def get_sheep_hir_effect_g_mrj(data: Data, yr_idx):
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['HIR - Sheep']
    g_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses)))
    
    # GHG abatement from Land Use Change
    for j_idx, lu in enumerate(land_uses):
        g_mrj_effect[:, :, j_idx] -= (
            data.CO2E_STOCK_UNALL_NATURAL      
            * (1 - data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[data.DESC2AGLU[lu]])
            * data.REAL_AREA
            / settings.HIR_EFFECT_YEARS    # Annualise carbon sequestration capacity to align the full growth span of a tree
        )
        
    # GHG abatement from livestock density reduction
    for lm_idx, lm in enumerate(data.LANDMANS):
        for j_idx, lu in enumerate(land_uses):
            g_mrj_effect[lm_idx, :, j_idx] -= get_ghg_lvstk(data, lu, lm, yr_idx, True) * settings.HIR_PRODUCTIVITY_CONTRIBUTION


    return g_mrj_effect

def get_utility_solar_pv_effect_g_mrj(data: Data) -> np.ndarray:
    """
    Applies the effects of using solar PV to the GHG data
    for all relevant agricultural land uses.
    
    Returns zero impact as solar PV installation has no direct 
    impact on farm emissions - displacement benefits are handled 
    by AusTIMES integration.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Utility Solar PV']
    
    # Set up the effects matrix - all zeros for no impact
    new_g_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)
    
    if not settings.AG_MANAGEMENTS['Utility Solar PV']:
        return new_g_mrj
    
    # Return zeros - no direct emissions impact from solar installation
    return new_g_mrj

def get_onshore_wind_effect_g_mrj(data:Data) -> np.ndarray:
    """
    Applies the effects of using onshore wind to the GHG data
    for all relevant agricultural land uses.
    
    Returns zero impact as onshore wind installation has no direct 
    impact on farm emissions - displacement benefits are handled 
    by AusTIMES integration.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Onshore Wind']
    
    # Set up the effects matrix - all zeros for no impact
    new_g_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)
    
    if not settings.AG_MANAGEMENTS['Onshore Wind']:
        return new_g_mrj
    
    # Return zeros - no direct emissions impact from wind installation
    return new_g_mrj

def get_agricultural_management_ghg_matrices(data:Data, yr_idx) -> dict[str, np.ndarray]:
    """
    Calculate the greenhouse gas (GHG) matrices for different agricultural management practices.

    Args:
        data: The input data for the calculations.
        yr_idx: The year index.

    Returns
        A dictionary containing the GHG matrices <unit: t/cell> for different agricultural management practices.
        The keys of the dictionary represent the management practices, and the values are numpy arrays.

    """
    asparagopsis_data = get_asparagopsis_effect_g_mrj(data, yr_idx)                         
    precision_agriculture_data = get_precision_agriculture_effect_g_mrj(data, yr_idx)       
    eco_grazing_data = get_ecological_grazing_effect_g_mrj(data, yr_idx)                    
    sav_burning_ghg_impact = get_savanna_burning_effect_g_mrj(data)                         
    agtech_ei_ghg_impact = get_agtech_ei_effect_g_mrj(data, yr_idx)                         
    biochar_ghg_impact = get_biochar_effect_g_mrj(data, yr_idx)                             
    beef_hir_ghg_impact = get_beef_hir_effect_g_mrj(data, yr_idx)                                   
    sheep_hir_ghg_impact = get_sheep_hir_effect_g_mrj(data, yr_idx)
    utility_solar_ghg_impact = get_utility_solar_pv_effect_g_mrj(data)
    onshore_wind_ghg_impact = get_onshore_wind_effect_g_mrj(data)                                 

    return {
        'Asparagopsis taxiformis': asparagopsis_data,
        'Precision Agriculture': precision_agriculture_data,
        'Ecological Grazing': eco_grazing_data,
        'Savanna Burning': sav_burning_ghg_impact,
        'AgTech EI': agtech_ei_ghg_impact,
        'Biochar': biochar_ghg_impact,
        'HIR - Beef': beef_hir_ghg_impact,
        'HIR - Sheep': sheep_hir_ghg_impact,
        'Utility Solar PV': utility_solar_ghg_impact,
        'Onshore Wind': onshore_wind_ghg_impact
    }
```

## luto/economics/agricultural/quantity.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

"""
Pure functions for calculating the production quantities of agricultural commodities.
"""
import numpy as np
import luto.settings as settings

from typing import Dict
from scipy.interpolate import interp1d

### Quantification of electricity yields from renewable energy land management strategies ###
from luto.data import load_capacity_factor_raster, load_dlf_raster

MGMT_TO_PRODUCT = {
    "Utility Solar PV": "UTILITY SOLAR PV - ELECTRICITY",
    "Onshore Wind": "ONSHORE WIND - ELECTRICITY"
}

MGMT_CONFIG = {
    "Utility Solar PV": {"gd": 150},  # in MW/km^2 as per data
    "Onshore Wind": {"gd": 7.2}
}

def compute_solar_yield_per_ha(cf_raster, dlf_raster, mw_per_ha):
    """
    Compute Utility Solar PV electricity yield per cell [MWh/ha/year].
    """
    hours = 8760
    return mw_per_ha * cf_raster * hours * (1 - dlf_raster)

def compute_wind_yield_per_ha(cf_raster, dlf_raster, mw_per_ha):
    """
    Compute Onshore Wind electricity yield per cell [MWh/ha/year].
    """
    hours = 8760
    return mw_per_ha * cf_raster * hours * (1 - dlf_raster)

def get_quantity_renewable(data, pr: str, lm: int, yr_idx: int):
    """
    Return electricity yield [MWh] for renewable product `pr` under management index `lm` for year index `yr_idx`.
    """
    if pr not in ["UTILITY SOLAR PV - ELECTRICITY", "ONSHORE WIND - ELECTRICITY"]:
        raise KeyError(f"Unknown renewable product '{pr}'")

    tech_name = data.LANDMANS[lm]
    if "solar" in tech_name.lower():
        lm_name = "Utility Solar PV"
    elif "wind" in tech_name.lower():
        lm_name = "Onshore Wind"
    else:
        raise KeyError(f"Unknown management type '{tech_name}' for renewable")

    cf = load_capacity_factor_raster(lm, data)
    dlf = load_dlf_raster(lm, data)

    mw_per_ha = MGMT_CONFIG[lm_name]["gd"] / 100  # Convert MW/km^2 to MW/ha

    if lm_name == "Utility Solar PV":
        yield_per_ha = compute_solar_yield_per_ha(cf, dlf, mw_per_ha)
    elif lm_name == "Onshore Wind":
        yield_per_ha = compute_wind_yield_per_ha(cf, dlf, mw_per_ha)
    else:
        raise KeyError(f"Unknown land management name '{lm_name}' for renewable yield")

    quantity = yield_per_ha * data.REAL_AREA
    return quantity.astype(np.float32)

#Main function to pull yield raster for a given management type
def lvs_veg_types(lu) -> tuple[str, str]:
    """Return livestock and vegetation types of the livestock land-use `lu`.

    Args:
        lu (str): The livestock land-use.

    Returns
        tuple: A tuple containing the livestock type and vegetation type.

    Raises:
        KeyError: If the livestock type or vegetation type cannot be identified.

    """

    # Determine type of livestock.
    if 'beef' in lu.lower():
        lvstype = 'BEEF'
    elif 'sheep' in lu.lower():
        lvstype = 'SHEEP'
    elif 'dairy' in lu.lower():
        lvstype = 'DAIRY'
    else:
        raise KeyError(f"Livestock type '{lu}' not identified.")

    # Determine type of vegetation.
    if 'natural' in lu.lower():
        vegtype = 'natural land'
    elif 'modified' in lu.lower():
        vegtype = 'modified land'
    else:
        raise KeyError(f"Vegetation type '{lu}' not identified.")

    return lvstype, vegtype


# Climate change impact function
def get_ccimpact(data, lu, lm, yr_idx):
    """
    Return climate change impact multiplier at (zero-based) year index.

    Parameters
    - data: The data object containing climate change impact data.
    - lu: The land-use for which the climate change impact is calculated.
    - lm: The land-management for which the climate change impact is calculated.
    - yr_idx: The zero-based index of the year for which the climate change impact is calculated.

    Returns
    - The climate change impact multiplier at the specified year index.
    """

    # Check if land-use exists in CLIMATE_CHANGE_IMPACT (e.g., dryland Pears/Rice do not occur), if not return ones
    if lu not in {t[0] for t in data.CLIMATE_CHANGE_IMPACT[lm].columns}:
        return np.ones((data.NCELLS))

    # Convert year index to calendar year to match the climate impact data which is by calendar year.
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Interpolate climate change damage for lu, lm, and year for each cell using a linear function.
    xs = {t[2] for t in data.CLIMATE_CHANGE_IMPACT.columns}  # Returns set {2020, 2050, 2080}
    xs.add(2010)                                             # Adds the year 2010 and returns set {2010, 2020, 2050, 2080}
    xs = sorted(xs)                                          # Returns list and ensures sorted lowest to highest [2010, 2020, 2050, 2080]
    yys = data.CLIMATE_CHANGE_IMPACT[lm, lu].fillna(1)       # Grabs the column and replaces NaNs with ones to avoid issues with calculating water use limits
    yys.insert(0, '2010', 1)                                 # Insert a new column for 2010 with value of 1 to ensure no climate change impact at 2010
    yys = yys.astype(np.float32)

    # Create linear function f and interpolate climate change impact
    f = interp1d(xs, yys, kind='linear', fill_value='extrapolate')
    return f(yr_cal)


def get_yield_pot(data, lvstype, vegtype, lm, yr_idx):
    """
    Return the yield potential <unit: head/ha> for livestock by land cover type.

    Parameters
    - data: Data object or module.
    - lvstype: Livestock type (one of 'BEEF', 'SHEEP' or 'DAIRY').
    - vegtype: Vegetation type (one of 'natural land' or 'modified land').
    - lm: Land-management type.
    - yr_idx: Number of years post 2010.

    Returns
    - yield_pot: The yield potential <unit: head/ha>.
    """

    # Factors varying as a function of `lvstype`.
    dse_per_head = {'BEEF': 8, 'SHEEP': 1.5, 'DAIRY': 17}
    grassfed_factor = {'BEEF': 0.85, 'SHEEP': 0.85, 'DAIRY': 0.65}
    denominator = (365 * dse_per_head[lvstype] * grassfed_factor[lvstype])

    # Base potential.
    yield_pot = data.FEED_REQ * data.PASTURE_KG_DM_HA / denominator

    # Multiply potential by appropriate SAFE_PUR (safe pasture utilisation rate).
    if vegtype == 'natural land':
        yield_pot *= data.SAFE_PUR_NATL
    elif vegtype == 'modified land':
        yield_pot *= data.SAFE_PUR_MODL
    else:
        raise KeyError(f"Land cover type '{vegtype}' not identified.")

    # Multiply livestock yield potential by appropriate irrigation factor (i.e., 2).
    if lm == 'irr':
        yield_pot *= 2

    # Apply climate change yield impact multiplier. Essentially changes the number of head per hectare by a multiplier i.e., 1.2 = a 20% increase.
    lu = f'{lvstype.capitalize()} - {vegtype}'
    yield_pot *= get_ccimpact(data, lu, lm, yr_idx)

    # Here we can add a productivity multiplier for sustainable intensification to increase pasture growth and yield potential (i.e., head/ha)
    # yield_pot *= yield_mult  ***Still to do***

    return yield_pot


def get_quantity_lvstk(data, pr, lm, yr_idx):
    """Return livestock yield of `pr`+`lm` in `yr_idx` as 1D Numpy array.

    Args:
        data (object/module): Data object or module.
        pr (str): Livestock + product like 'SHEEP - MODIFIED LAND WOOL'.
        lm (str): Land management.
        yr_idx (int): Number of years post base-year ('YR_CAL_BASE').

    Returns
        numpy.ndarray: Livestock yield of `pr`+`lm` in `yr_idx` as 1D Numpy array.

    Units:
        - <unit: t/cell> BEEF and SHEEP meat (1) and live exports (3).
        - <unit: t/cell> SHEEP wool (2).
        - <unit: kilolitres/cell> DAIRY (1).
    """

    # Get livestock and land cover type.
    lvstype, vegtype = lvs_veg_types(pr)

    # Get the yield potential.
    yield_pot = get_yield_pot(data, lvstype, vegtype, lm, yr_idx)

    # Determine base quantity case-by-case.

    # Beef yields just beef (1) and live exports (3) (both in tonnes of meat per ha).
    if lvstype == 'BEEF': # (F1 * Q1) or (F3 * Q3).
        if 'MEAT' in pr:
            quantity = ( data.AGEC_LVSTK['F1', lvstype]
                       * data.AGEC_LVSTK['Q1', lvstype] )
        elif 'LEXP' in pr:
            quantity = ( data.AGEC_LVSTK['F3', lvstype]
                       * data.AGEC_LVSTK['Q3', lvstype] )
        else:
            raise KeyError(f"Unknown {lvstype} product. Check `pr` key.")

    elif lvstype == 'SHEEP': # (F1 * Q1), (F2 * Q2), (F3 * Q3).
        if 'MEAT' in pr:
            quantity = ( data.AGEC_LVSTK['F1', lvstype]
                       * data.AGEC_LVSTK['Q1', lvstype] )
        elif 'WOOL' in pr:
            quantity = ( data.AGEC_LVSTK['F2', lvstype]
                       * data.AGEC_LVSTK['Q2', lvstype] )
        elif 'LEXP' in pr:
            quantity = ( data.AGEC_LVSTK['F3', lvstype]
                       * data.AGEC_LVSTK['Q3', lvstype] )
        else:
            raise KeyError(f"Unknown {lvstype} product. Check `pr` key.")

    elif lvstype == 'DAIRY': # (F1 * Q1).
        if 'DAIRY' in pr: 
            quantity = ( data.AGEC_LVSTK['F1', lvstype]
                       * data.AGEC_LVSTK['Q1', lvstype] 
                       / 1000 ) # Convert to KL
        else:
            raise KeyError(f"Unknown {lvstype} product. Check `pr` key.")

    else:
        raise KeyError(f"Livestock type '{lvstype}' not identified.")

    # Quantity is base quantity times the yield potential. yield_pot includes climate change impacts.
    quantity *= yield_pot

    # Convert quantities in tonnes/ha to tonnes/cell including real_area and resfactor.
    quantity *= data.REAL_AREA

    return quantity


def get_quantity_crop(data, pr, lm, yr_idx):
    """Return crop yield <unit: t/cell> of `pr`+`lm` in `yr_idx` as 1D Numpy array.

    Args:
        data (object/module): Data object or module.
        pr (str): Product -- equivalent to land use for crops.
        lm (str): Land management.
        yr_idx (int): Number of years post base-year ('YR_CAL_BASE').

    Returns
        numpy.ndarray: 1D Numpy array containing crop yield <unit: t/cell>.

    Raises:
        None.

    Notes:
        - `data` assumes fields like in `luto.data`.
        - `pr` is the product equivalent to land use for crops (e.g., 'winterCereals').
        - `lm` is the land management (e.g., 'dry', 'irr').
        - `yr_idx` is the number of years from the base year, counting from zero.
    """
    
    # Check if land-use exists in AGEC_CROPS (e.g., dryland Pears/Rice do not occur), if not return zeros
    if pr not in data.AGEC_CROPS['Yield', lm].columns:
        quantity = np.zeros((data.NCELLS)).astype(np.float32)
        
    else: # Calculate the quantities
        
        # Get the raw quantities in tonnes/ha from data.
        quantity = data.AGEC_CROPS['Yield', lm, pr].copy().to_numpy()
        
        # Apply climate change yield impact multiplier. Takes land use (lu) as input rather than product (pr) but lu == pr for crops
        quantity *= get_ccimpact(data, pr, lm, yr_idx)
    
        # Convert to tonnes per cell including real_area and resfactor.
        quantity *= data.REAL_AREA 

    return quantity

def get_quantity(data, pr, lm, yr_idx):
    """Return yield <unit: t/cell> of `pr`+`lm` in `yr_idx` as 1D Numpy array.

    Args:
        data (object/module): Data object or module.
        pr (str): Product produced.
        lm (str): Land management.
        yr_idx (int): Number of years post base-year ('YR_CAL_BASE').

    Returns
        numpy.ndarray: 1D Numpy array representing the yield <unit: t/cell>.

    Raises:
        KeyError: If the land use `pr` is not found in the data.

    Notes:
        - Assumes fields like in `luto.data`.
        - If it is a crop, it is known how to get the quantities.
        - Apply productivity increase multiplier by product. Essentially, this is a total factor productivity increase.
    """
    # If it is a crop, it is known how to get the quantities.
    if pr in data.PR_CROPS:
        q = get_quantity_crop(data, pr.capitalize(), lm, yr_idx)
    elif pr in data.PR_LVSTK:
        q = get_quantity_lvstk(data, pr, lm, yr_idx)
    elif pr in ["UTILITY SOLAR PV - ELECTRICITY", "ONSHORE WIND - ELECTRICITY"]:
        q = get_quantity_renewable(data, pr, lm, yr_idx)
    else:
        raise KeyError(f"Land use '{pr}' not found in data.")

    # Apply productivity increase multiplier by product. Essentially, this is a total factor productivity increase.
    q *= data.BAU_PROD_INCR[lm, pr][yr_idx]

    return q


def get_quantity_matrix(data, lm, yr_idx):
    """
    Return q_rp matrix of quantities per cell per product as 2D Numpy array.

    Parameters
    - data: The data object containing information about cells and products.
    - lm: The lm object representing the land management.
    - yr_idx: The index of the year.

    Returns
    - q_rp: A 2D Numpy array representing the quantities per cell per product.
    """

    q_rp = np.zeros((data.NCELLS, len(data.PRODUCTS))).astype(np.float32)
    for j, pr in enumerate(data.PRODUCTS):
        q_rp[:, j] = get_quantity(data, pr, lm, yr_idx)

    # Make sure all NaNs are replaced by zeroes.
    return np.nan_to_num(q_rp)


def get_quantity_matrices(data, yr_idx):
    """
    Return q_mrp matrix of quantities per cell as 3D Numpy array.

    Parameters
    - data: The input data containing information about quantities.
    - yr_idx: The index of the year.

    Returns
    - q_mrp: A 3D Numpy array representing the matrix of quantities per cell.
    """
    return np.stack(tuple( get_quantity_matrix(data, lm, yr_idx)
                           for lm in data.LANDMANS ))


def get_asparagopsis_effect_q_mrp(data, q_mrp, yr_idx):
    """
    Applies the effects of using asparagopsis to the quantity data
    for all relevant agr. land uses.

    Parameters
    - data: The data object containing relevant information.
    - q_mrp: The quantity data for all land uses and products.
    - yr_idx: The index of the year.

    Returns
    - new_q_mrp: The updated quantity data after applying the effects of using asparagopsis.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES["Asparagopsis taxiformis"]
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_q_mrp = np.zeros((data.NLMS, data.NCELLS, data.NPRS)).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Asparagopsis taxiformis']:
        return new_q_mrp

    # Update values in the new matrix using the correct multiplier for each LU
    for lu, j in zip(land_uses, lu_codes):
        multiplier = data.ASPARAGOPSIS_DATA[lu].loc[yr_cal, 'Productivity']
        if multiplier != 1:
            # Apply to all products associated with land use
            for p in range(data.NPRS):
                if data.LU2PR[p, j]:
                    # The effect is: effect value = old value * multiplier - old value
                    # E.g. a multiplier of .95 means a 5% reduction in quantity produced
                    new_q_mrp[:, :, p] = q_mrp[:, :, p] * (multiplier - 1)

    return new_q_mrp


def get_precision_agriculture_effect_q_mrp(data, q_mrp, yr_idx):
    """
    Applies the effects of using precision agriculture to the quantity data
    for all relevant agricultural land uses.

    Parameters
    - data: The data object containing relevant information.
    - q_mrp: The quantity data for all land uses.
    - yr_idx: The index of the year.

    Returns
    - new_q_mrp: The updated quantity data after applying precision agriculture effects.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Precision Agriculture']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_q_mrp = np.zeros((data.NLMS, data.NCELLS, data.NPRS)).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Precision Agriculture']:
        return new_q_mrp

    # Update values in the new matrix    
    for lu, j in zip(land_uses, lu_codes):
        multiplier = data.PRECISION_AGRICULTURE_DATA[lu].loc[yr_cal, 'Productivity']
        if multiplier != 1:
            # Apply to all products associated with land use
            for p in range(data.NPRS):
                if data.LU2PR[p, j]:
                    new_q_mrp[:, :, p] = q_mrp[:, :, p] * (multiplier - 1)

    return new_q_mrp


def get_ecological_grazing_effect_q_mrp(data, q_mrp, yr_idx):
    """
    Applies the effects of using ecological grazing to the quantity data
    for all relevant agricultural land uses.

    Parameters
    - data: The data object containing relevant information.
    - q_mrp: The quantity data to be updated.
    - yr_idx: The index of the year to be used for calculations.

    Returns
    - new_q_mrp: The updated quantity data after applying ecological grazing effects.
    """
    
    # Set up the effects matrix
    new_q_mrp = np.zeros((data.NLMS, data.NCELLS, data.NPRS)).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Ecological Grazing']:
        return new_q_mrp
    
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Ecological Grazing']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Update values in the new matrix    
    for lu, j in zip(land_uses, lu_codes):
        multiplier = data.ECOLOGICAL_GRAZING_DATA[lu].loc[yr_cal, 'Productivity']
        if multiplier != 1:
            # Apply to all products associated with land use
            for p in range(data.NPRS):
                if data.LU2PR[p, j]:
                    new_q_mrp[:, :, p] = q_mrp[:, :, p] * (multiplier - 1)

    return new_q_mrp


def get_savanna_burning_effect_q_mrp(data):
    """
    Applies the effects of using EDS savanna burning to the quantity data
    for all relevant agr. land uses.

    Since EDSSB has no effect on quantity produced, return an array of zeros.

    Parameters
    - data: The input data object containing information about the model

    Returns
    - An array of zeros with shape (NLMS, NCELLS, NPRS)
    """
    return np.zeros((data.NLMS, data.NCELLS, data.NPRS)).astype(np.float32)


def get_agtech_ei_effect_q_mrp(data, q_mrp, yr_idx):
    """
    Applies the effects of using AgTech EI to the quantity data
    for all relevant agr. land uses.

    Parameters
    - data: The data object containing relevant information.
    - q_mrp: The quantity data to be updated.
    - yr_idx: The index of the year.

    Returns
    - new_q_mrp: The updated quantity data
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['AgTech EI']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_q_mrp = np.zeros((data.NLMS, data.NCELLS, data.NPRS)).astype(np.float32)

    if not settings.AG_MANAGEMENTS['AgTech EI']:
        return new_q_mrp

    # Update values in the new matrix    
    for lu, j in zip(land_uses, lu_codes):
        multiplier = data.AGTECH_EI_DATA[lu].loc[yr_cal, 'Productivity']
        if multiplier != 1:
            # Apply to all products associated with land use
            for p in range(data.NPRS):
                if data.LU2PR[p, j]:
                    new_q_mrp[:, :, p] = q_mrp[:, :, p] * (multiplier - 1)

    return new_q_mrp


def get_biochar_effect_q_mrp(data, q_mrp, yr_idx):
    """
    Applies the effects of using Biochar to the quantity data
    for all relevant agricultural land uses.

    Parameters
    - data: The data object containing relevant information.
    - q_mrp: The quantity data to be updated.
    - yr_idx: The index of the year to be used for calculations.

    Returns
    - new_q_mrp: The updated quantity data after applying Biochar effects.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Biochar']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_q_mrp = np.zeros((data.NLMS, data.NCELLS, data.NPRS)).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Biochar']:
        return new_q_mrp

    # Update values in the new matrix    
    for lu, j in zip(land_uses, lu_codes):
        multiplier = data.BIOCHAR_DATA[lu].loc[yr_cal, 'Productivity']
        if multiplier != 1:
            # Apply to all products associated with land use
            for p in range(data.NPRS):
                if data.LU2PR[p, j]:
                    new_q_mrp[:, :, p] = q_mrp[:, :, p] * (multiplier - 1)

    return new_q_mrp


def get_beef_hir_effect_q_mrp(data, q_mrp):
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['HIR - Beef']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]

    # Set up the effects matrix
    q_mrp_effect = np.zeros((data.NLMS, data.NCELLS, data.NPRS)).astype(np.float32)

    if not settings.AG_MANAGEMENTS['HIR - Beef']:
        return q_mrp_effect
    
    # Update values in the new matrix    
    for lu, j in zip(land_uses, lu_codes):
        # Apply to all products associated with land use
        for p in range(data.NPRS):
            if data.LU2PR[p, j]:
                q_mrp_effect[:, :, p] = q_mrp[:, :, p] * (settings.HIR_PRODUCTIVITY_CONTRIBUTION - 1)

    return q_mrp_effect


def get_sheep_hir_effect_q_mrp(data, q_mrp):
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['HIR - Sheep']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]

    # Set up the effects matrix
    q_mrp_effect = np.zeros((data.NLMS, data.NCELLS, data.NPRS)).astype(np.float32)

    if not settings.AG_MANAGEMENTS['HIR - Sheep']:
        return q_mrp_effect
    
    # Update values in the new matrix    
    for lu, j in zip(land_uses, lu_codes):
        # Apply to all products associated with land use
        for p in range(data.NPRS):
            if data.LU2PR[p, j]:
                q_mrp_effect[:, :, p] = q_mrp[:, :, p] * (settings.HIR_PRODUCTIVITY_CONTRIBUTION - 1)

    return q_mrp_effect

def get_utility_solar_pv_effect_q_mrj(data, q_mrj, yr_idx):
    """
    Applies the effects of Utility Solar PV to the quantity data
    for all relevant agricultural land uses.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Utility Solar PV']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_q_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Utility Solar PV']:
        return new_q_mrj

    # Update values in the new matrix using the correct multiplier for each LU
    for lu_idx, lu in enumerate(land_uses):
        productivity_multiplier = data.UTILITY_SOLAR_PV_DATA[lu].loc[yr_cal, 'Productivity']
        if productivity_multiplier != 1:
            j = lu_codes[lu_idx]
            new_q_mrj[:, :, lu_idx] = q_mrj[:, :, j] * (productivity_multiplier - 1)

    return new_q_mrj


def get_onshore_wind_effect_q_mrj(data, q_mrj, yr_idx):
    """
    Applies the effects of Onshore Wind to the quantity data
    for all relevant agricultural land uses.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Onshore Wind']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_q_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Onshore Wind']:
        return new_q_mrj

    # Update values in the new matrix using the correct multiplier for each LU
    for lu_idx, lu in enumerate(land_uses):
        productivity_multiplier = data.ONSHORE_WIND_DATA[lu].loc[yr_cal, 'Productivity']
        if productivity_multiplier != 1:
            j = lu_codes[lu_idx]
            new_q_mrj[:, :, lu_idx] = q_mrj[:, :, j] * (productivity_multiplier - 1)

    return new_q_mrj

def get_agricultural_management_quantity_matrices(data, q_mrp, yr_idx) -> Dict[str, np.ndarray]:
    """
    Calculates the quantity matrices for different agricultural management practices.

    Args:
        data: The input data for the calculations.
        q_mrp: The 3D matix coresponding to water-supply, cell, and product.
        yr_idx: The 0-based year index.

    Returns
        A dictionary containing the quantity matrices for different agricultural management practices.
        The keys of the dictionary represent the names of the practices, and the values are the corresponding quantity matrices.
    """
    ag_mam_q_mrp = {}

    ag_mam_q_mrp['Asparagopsis taxiformis'] = get_asparagopsis_effect_q_mrp(data, q_mrp, yr_idx)            
    ag_mam_q_mrp['Precision Agriculture'] = get_precision_agriculture_effect_q_mrp(data, q_mrp, yr_idx)     
    ag_mam_q_mrp['Ecological Grazing'] = get_ecological_grazing_effect_q_mrp(data, q_mrp, yr_idx)           
    ag_mam_q_mrp['Savanna Burning'] = get_savanna_burning_effect_q_mrp(data)                                
    ag_mam_q_mrp['AgTech EI'] = get_agtech_ei_effect_q_mrp(data, q_mrp, yr_idx)                             
    ag_mam_q_mrp['Biochar'] = get_biochar_effect_q_mrp(data, q_mrp, yr_idx)                                 
    ag_mam_q_mrp['HIR - Beef'] = get_beef_hir_effect_q_mrp(data, q_mrp)                                     
    ag_mam_q_mrp['HIR - Sheep'] = get_sheep_hir_effect_q_mrp(data, q_mrp)     
    ag_mam_q_mrp['Utility Solar PV'] = get_utility_solar_pv_effect_q_mrj(data, q_mrp, yr_idx)
    ag_mam_q_mrp['Onshore Wind'] = get_onshore_wind_effect_q_mrj(data, q_mrp, yr_idx)                     

    return {am:ag_mam_q_mrp[am] for am in settings.AG_MANAGEMENTS if settings.AG_MANAGEMENTS[am]}
```

## luto/economics/agricultural/revenue.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

 

"""
Pure functions to calculate economic profit from land use.
"""

import numpy as np
import pandas as pd
from economics.agricultural import quantity
import luto.settings as settings 

from luto.data import Data
from luto.economics.agricultural.quantity import get_yield_pot, get_quantity, lvs_veg_types
from luto.economics.agricultural.ghg import get_savanna_burning_effect_g_mrj

def get_rev_crop( data:Data         # Data object.
                , lu           # Land use.
                , lm           # Land management.
                , yr_idx       # Number of years post base-year ('YR_CAL_BASE').
                ):
    """Return crop profit [AUD/cell] of `lu`+`lm` in `yr_idx` as np array.

    `data`: data object/module -- assumes fields like in `luto.data`.
    `lu`: land use (e.g. 'Winter cereals' or 'Beef - natural land').
    `lm`: land management (e.g. 'dry', 'irr').
    `yr_idx`: number of years from base year, counting from zero.
    """
    # Check if land-use exists in AGEC_CROPS (e.g., dryland Pears/Rice do not occur), if not return zeros
    if lu not in data.AGEC_CROPS['P1', lm].columns:
        rev_t = np.zeros((data.NCELLS)).astype(np.float32)
        
    else:
        rev_multiplier = 1
        if lu in data.CROP_PRICE_MULTIPLIERS.columns:
            rev_multiplier = data.CROP_PRICE_MULTIPLIERS.loc[data.YR_CAL_BASE + yr_idx, lu]
        else:
            print(f"WARNING: Multiplier for {lu} not found in 'ag_price_multipliers.xlsx'. Defaulting to 1.", flush=True)
            
        # Revenue in $ per cell (includes REAL_AREA via get_quantity)
        rev_t = ( data.AGEC_CROPS['P1', lm, lu] 
                * get_quantity( data, lu.upper(), lm, yr_idx )  # lu.upper() only for crops as needs to be in product format in get_quantity().
                * rev_multiplier
                ).values
    
    # Return revenue as MultiIndexed DataFrame.
    return pd.DataFrame(rev_t, columns=pd.MultiIndex.from_tuples([(lu, lm, 'Crop')]))

def get_rev_lvstk( data:Data   # Data object.
                 , lu           # Land use.
                 , lm           # Land management.
                 , yr_idx       # Number of years post base-year ('YR_CAL_BASE').
                 ):
    """Return livestock revenue [AUD/cell] of `lu`+`lm` in `yr_idx` as np array.

    `data`: data object/module -- assumes fields like in `luto.data`.
    `lu`: land use (e.g. 'Winter cereals' or 'Beef - natural land').
    `lm`: land management (e.g. 'dry', 'irr').
    `yr_idx`: number of years from base year, counting from zero."""
    
    yr_cal = data.YR_CAL_BASE + yr_idx
    # Get livestock and vegetation type.
    lvstype, vegtype = lvs_veg_types(lu)

    # Get the yield potential, i.e. the total number of heads per hectare.
    yield_pot = get_yield_pot(data, lvstype, vegtype, lm, yr_idx)

    # Revenue in $ per cell (includes RESMULT via get_quantity)
    if lvstype == 'BEEF':

        # Get the revenue from meat and live exports. Set to zero if not produced.
        rev_meat = yield_pot * (                               # Stocking density (head/ha)
                            ( data.AGEC_LVSTK['F1', lvstype]   # Fraction of herd producing (0 - 1)
                            * data.AGEC_LVSTK['Q1', lvstype]   # Quantity produced per head (meat tonnes/head)
                            * data.AGEC_LVSTK['P1', lvstype] ) # Price per unit quantity ($/tonne of meat)
                            * data.LVSTK_PRICE_MULTIPLIERS.loc[yr_cal, "BEEF P1"] # Multiplier for commodity price
                            )

        rev_lexp = yield_pot * (  
                            ( data.AGEC_LVSTK['F3', lvstype]   # Fraction of herd producing (0 - 1)
                            * data.AGEC_LVSTK['Q3', lvstype]   # Quantity produced per head (animal weight tonnes/head)
                            * data.AGEC_LVSTK['P3', lvstype] ) # Price per unit quantity ($/tonne of animal)
                            * data.LVSTK_PRICE_MULTIPLIERS.loc[yr_cal, "BEEF P3"] # Multiplier for commodity price
                            )  

        # Set Wool and Milk to zero as they are not produced by beef cattle
        rev_wool = rev_milk = np.zeros((data.NCELLS)).astype(np.float32)

    elif lvstype == 'SHEEP':    

        # Get the revenue from meat, wool and live exports. Set to zero if not produced.
        rev_meat = yield_pot * (  # Meat                           # Stocking density (head/ha)
                                ( data.AGEC_LVSTK['F1', lvstype]   # Fraction of herd producing (0 - 1)
                                * data.AGEC_LVSTK['Q1', lvstype]   # Quantity produced per head (meat tonnes/head)
                                * data.AGEC_LVSTK['P1', lvstype] ) # Price per unit quantity ($/tonne of meat)
                                * data.LVSTK_PRICE_MULTIPLIERS.loc[yr_cal, "SHEEP P1"] # Multiplier for commodity price
                                )
        rev_wool = yield_pot * (  # Wool                           # Stocking density (head/ha) 
                                ( data.AGEC_LVSTK['F2', lvstype]   # Fraction of herd producing (0 - 1) 
                                * data.AGEC_LVSTK['Q2', lvstype]   # Quantity produced per head (wool tonnes/head)
                                * data.AGEC_LVSTK['P2', lvstype] ) # Price per unit quantity ($/tonne wool)
                                * data.LVSTK_PRICE_MULTIPLIERS.loc[yr_cal, "SHEEP P2"] # Multiplier for commodity price
                                )   

        rev_lexp = yield_pot * (  # Live exports                   # Stocking density (head/ha)
                                ( data.AGEC_LVSTK['F3', lvstype]   # Fraction of herd producing (0 - 1) 
                                * data.AGEC_LVSTK['Q3', lvstype]   # Quantity produced per head (animal weight tonnes/head)
                                * data.AGEC_LVSTK['P3', lvstype] ) # Price per unit quantity ($/tonne of whole animal)
                                * data.LVSTK_PRICE_MULTIPLIERS.loc[yr_cal, "SHEEP P3"] # Multiplier for commodity price
                                )

        # Set Milk to zero as it is not produced by sheep
        rev_milk = np.zeros((data.NCELLS)).astype(np.float32) # Set Milk to zero as it is not produced by sheep


    elif lvstype == 'DAIRY':

        # Get the revenue from milk. Set to zero if not produced.
        rev_milk = yield_pot * (  # Milk                           # Stocking density (head/ha)
                                ( data.AGEC_LVSTK['F1', lvstype]   # Fraction of herd producing (0 - 1) 
                                * data.AGEC_LVSTK['Q1', lvstype]   # Quantity produced per head (milk litres/head)
                                * data.AGEC_LVSTK['P1', lvstype] ) # Price per unit quantity ($/litre milk)
                                * data.LVSTK_PRICE_MULTIPLIERS.loc[yr_cal, "DAIRY P1"] # Multiplier for commodity price
                                )

        # Set Meat, Wool and Live exports to zero
        rev_meat = rev_wool = rev_lexp = np.zeros((data.NCELLS)).astype(np.float32)

    else:  # Livestock type is unknown.
        raise KeyError(f"Unknown {lvstype} livestock type. Check `lvstype`.")   

    # Put the revenues into a MultiIndex DataFrame
    rev_seperate = pd.DataFrame(
        np.stack((rev_meat, rev_wool, rev_lexp, rev_milk), axis=1), 
        columns=pd.MultiIndex.from_product([[lu], [lm], ['Meat', 'Wool', 'Live Exports', 'Milk']])
    )

    # Revenue so far in AUD/ha. Now convert to AUD/cell including resfactor.
    rev_seperate = rev_seperate * data.REAL_AREA.reshape(-1, 1) # Convert to AUD/cell

    # Return revenue as numpy array.
    return rev_seperate

def get_rev_renewable(data: Data, lu: str, lm: int, yr_idx: int):
    """
    Return renewable revenue [AUD/cell] for given product and land management in year index.
    """
    lm_name = data.LANDMANS[lm]
    if "solar" in lm_name.lower():
        tech_key = "Utility Solar PV"
    elif "wind" in lm_name.lower():
        tech_key = "Onshore Wind"
    else:
        raise KeyError(f"Unknown land management type '{lm_name}' for renewable revenue.")

    try:
        price = data.ELECTRICITY_PRICE.loc[data.YR_CAL_BASE + yr_idx, tech_key]
    except (AttributeError, KeyError):
        price = 1.0
        print(f"Warning: Missing electricity price for {tech_key} at year {yr_idx}. Defaulting to 1.0")

    from luto.economics.agricultural.quantity import get_quantity_renewable
    quantity = get_quantity_renewable(data, lu, lm, yr_idx)

    revenue_val = quantity * price

    revenue_df = pd.DataFrame(
        revenue_val,
        columns=pd.MultiIndex.from_tuples([(lu, lm_name, "Electricity Revenue")])
    )
    return revenue_df

def get_rev( data:Data    # Data object.
            , lu           # Land use.
            , lm           # Land management.
            , yr_idx       # Number of years post base-year ('YR_CAL_BASE')
            ):
    """Return revenue from production [AUD/cell] of `lu`+`lm` in `yr_idx` as np array.

    `data`: data object/module -- assumes fields like in `luto.data`.
    `lu`: land use (e.g. 'Winter cereals').
    `lm`: land management (e.g. 'dry', 'irr').
    `yr_idx`: number of years from base year, counting from zero.
    """
    # If it is a crop, it is known how to get the revenue.
    if lu in data.LU_CROPS:
        return get_rev_crop(data, lu, lm, yr_idx)

    elif lu in data.LU_LVSTK:
        return get_rev_lvstk(data, lu, lm, yr_idx)

    elif lu in data.AGRICULTURAL_LANDUSES:
        return pd.DataFrame(
            np.zeros((data.NCELLS, 1)).astype(np.float32),
            columns=pd.MultiIndex.from_tuples([(lu, lm, 'Unallocated Land')])
        )
    else:
        raise KeyError(f"Land-use '{lu}' not found in data.LANDUSES")


def get_rev_matrix(data:Data, lm, yr_idx):
    """Return r_rj matrix of revenue/cell per lu under `lm` in `yr_idx`."""
    
    # Concatenate the revenue from each land use into a single Multiindex DataFrame.
    r_rjs = pd.concat(
        [get_rev(data, lu, lm, yr_idx) for lu in data.AGRICULTURAL_LANDUSES], 
        axis=1
    )
    r_rjs = r_rjs.fillna(0)
    return r_rjs


def get_rev_matrices(data:Data, yr_idx, aggregate:bool = True):
    """Return r_mrj matrix of revenue per cell as 3D Numpy array."""

    # Concatenate the revenue from each land management into a single Multiindex DataFrame.
    rev_rjms = pd.concat(
        [get_rev_matrix(data, lm, yr_idx) for lm in data.LANDMANS], 
        axis=1
    )

    if not aggregate:
        # Concatenate the revenue from each land management into a single Multiindex DataFrame.
        return rev_rjms
    
    df_jmr = rev_rjms.T.groupby(level=[0, 1]).sum()
    arr_jmr = df_jmr.values.reshape(*(list(df_jmr.index.levshape) + [-1]))
    return np.einsum('jmr->mrj', arr_jmr)


def get_commodity_prices(data: Data) -> np.ndarray:
    '''
    Get the prices of commodities in the base year. These prices will be used as multiplier
    to weight deviatios of commodity production from the target.
    '''
    
    commodity_lookup = {
        ('P1','BEEF'): 'beef meat',
        ('P3','BEEF'): 'beef lexp',
        ('P1','SHEEP'): 'sheep meat',
        ('P2','SHEEP'): 'sheep wool',
        ('P3','SHEEP'): 'sheep lexp',
        ('P1','DAIRY'): 'dairy',
    }

    commodity_prices = {}

    # Get the median price of each commodity
    for names, commodity in commodity_lookup.items():
        prices = np.nanpercentile(data.AGEC_LVSTK[names[0], names[1]], 50)
        prices = prices * 1000 if commodity == 'dairy' else prices # convert to per tonne for dairy
        commodity_prices[commodity] = prices

    # Get the median price of each crop; here need to use 'irr' because dry-Rice does exist in the data
    for name, col in data.AGEC_CROPS['P1','irr'].items():
        commodity_prices[name.lower()] = np.nanpercentile(col, 50)

    return np.array([commodity_prices[k] for k in data.COMMODITIES])


def get_asparagopsis_effect_r_mrj(data:Data, r_mrj, yr_idx):
    """
    Applies the effects of using asparagopsis to the revenue data
    for all relevant agr. land uses.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES["Asparagopsis taxiformis"]
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_r_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Asparagopsis taxiformis']:
        return new_r_mrj

    # Update values in the new matrix using the correct multiplier for each LU
    for lu_idx, lu in enumerate(land_uses):
        multiplier = data.ASPARAGOPSIS_DATA[lu].loc[yr_cal, 'Productivity']
        if multiplier != 1:
            j = lu_codes[lu_idx]
            # The effect is: new value = old value * multiplier - old value
            # E.g. a multiplier of .95 means a 5% reduction in quantity produced
            new_r_mrj[:, :, lu_idx] = r_mrj[:, :, j] * (multiplier - 1)

    return new_r_mrj


def get_precision_agriculture_effect_r_mrj(data:Data, r_mrj, yr_idx):
    """
    Applies the effects of using precision agriculture to the revenue data
    for all relevant agr. land uses.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Precision Agriculture']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_r_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Precision Agriculture']:
        return new_r_mrj

    # Update values in the new matrix using the correct multiplier for each LU
    for lu_idx, lu in enumerate(land_uses):
        multiplier = data.PRECISION_AGRICULTURE_DATA[lu].loc[yr_cal, 'Productivity']
        if multiplier != 1:
            j = lu_codes[lu_idx]
            new_r_mrj[:, :, lu_idx] = r_mrj[:, :, j] * (multiplier - 1)

    return new_r_mrj


def get_ecological_grazing_effect_r_mrj(data:Data, r_mrj, yr_idx):
    """
    Applies the effects of using ecologiacl grazing to the revenue data
    for all relevant agr. land uses.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Ecological Grazing']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_r_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Ecological Grazing']:
        return new_r_mrj

    # Update values in the new matrix using the correct multiplier for each LU
    for lu_idx, lu in enumerate(land_uses):
        multiplier = data.ECOLOGICAL_GRAZING_DATA[lu].loc[yr_cal, 'Productivity']
        if multiplier != 1:
            j = lu_codes[lu_idx]
            new_r_mrj[:, :, lu_idx] = r_mrj[:, :, j] * (multiplier - 1)

    return new_r_mrj


def get_savanna_burning_effect_r_mrj(data:Data, yr_idx: int):
    """
    Applies the effects of using EDS savanna burning to the revenue data
    for all relevant agr. land uses.

    Since EDSSB has no effect on revenue, return an array of zeros.
    """
    ghg_effect = get_savanna_burning_effect_g_mrj(data)
    return ghg_effect * data.get_carbon_price_by_yr_idx(yr_idx)


def get_agtech_ei_effect_r_mrj(data:Data, r_mrj, yr_idx):
    """
    Applies the effects of using AgTech EI to the revenue data
    for all relevant agr. land uses.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['AgTech EI']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_r_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['AgTech EI']:
        return new_r_mrj

    # Update values in the new matrix using the correct multiplier for each LU
    for lu_idx, lu in enumerate(land_uses):
        multiplier = data.AGTECH_EI_DATA[lu].loc[yr_cal, 'Productivity']
        if multiplier != 1:
            j = lu_codes[lu_idx]
            new_r_mrj[:, :, lu_idx] = r_mrj[:, :, j] * (multiplier - 1)

    return new_r_mrj


def get_biochar_effect_r_mrj(data:Data, r_mrj, yr_idx):
    """
    Applies the effects of using Biochar to the revenue data
    for all relevant agr. land uses.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Biochar']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_r_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Biochar']:
        return new_r_mrj

    # Update values in the new matrix using the correct multiplier for each LU
    for lu_idx, lu in enumerate(land_uses):
        multiplier = data.BIOCHAR_DATA[lu].loc[yr_cal, 'Productivity']
        if multiplier != 1:
            j = lu_codes[lu_idx]
            new_r_mrj[:, :, lu_idx] = r_mrj[:, :, j] * (multiplier - 1)

    return new_r_mrj



def get_beef_hir_effect_r_mrj(data: Data, r_mrj):
    """
    Applies the effects of using HIR to the beef revenue data
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['HIR - Beef']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]

    # Set up the effects matrix
    r_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['HIR - Beef']:
        return r_mrj_effect
    
    # Update values in the new matrix    
    for lu_idx in range(len(land_uses)):
        j = lu_codes[lu_idx]
        r_mrj_effect[:, :, lu_idx] = r_mrj[:, :, j] * (settings.HIR_PRODUCTIVITY_CONTRIBUTION - 1)

    return r_mrj_effect


def get_sheep_hir_effect_r_mrj(data: Data, r_mrj):
    """
    Applies the effects of using HIR to the sheep revenue data
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['HIR - Sheep']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]

    # Set up the effects matrix
    r_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['HIR - Sheep']:
        return r_mrj_effect
    
    # Update values in the new matrix    
    for lu_idx in range(len(land_uses)):
        j = lu_codes[lu_idx]
        r_mrj_effect[:, :, lu_idx] = r_mrj[:, :, j] * (settings.HIR_PRODUCTIVITY_CONTRIBUTION - 1)

    return r_mrj_effect

def get_utility_solar_pv_effect_r_mrj(data: Data, r_mrj, yr_idx):
    """
    Applies the effects of Utility Solar PV to the revenue data
    for all relevant agricultural land uses.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Utility Solar PV']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_r_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Utility Solar PV']:
        return new_r_mrj

    # Update values in the new matrix using the revenue multiplier for each LU
    for lu_idx, lu in enumerate(land_uses):
        revenue_multiplier = data.UTILITY_SOLAR_PV_DATA[lu].loc[yr_cal, 'Revenue']
        if revenue_multiplier != 1:
            j = lu_codes[lu_idx]
            new_r_mrj[:, :, lu_idx] = r_mrj[:, :, j] * (revenue_multiplier - 1)

    return new_r_mrj


def get_onshore_wind_effect_r_mrj(data: Data, r_mrj, yr_idx):
    """
    Applies the effects of Onshore Wind to the revenue data
    for all relevant agricultural land uses.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Onshore Wind']
    lu_codes = [data.DESC2AGLU[lu] for lu in land_uses]
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Set up the effects matrix
    new_r_mrj = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    if not settings.AG_MANAGEMENTS['Onshore Wind']:
        return new_r_mrj

    # Update values in the new matrix using the revenue multiplier for each LU
    for lu_idx, lu in enumerate(land_uses):
        revenue_multiplier = data.ONSHORE_WIND_DATA[lu].loc[yr_cal, 'Revenue']
        if revenue_multiplier != 1:
            j = lu_codes[lu_idx]
            new_r_mrj[:, :, lu_idx] = r_mrj[:, :, j] * (revenue_multiplier - 1)

    return new_r_mrj

def get_agricultural_management_revenue_matrices(data:Data, r_mrj, yr_idx) -> dict[str, np.ndarray]:
    """
    Calculate the revenue matrices for different agricultural management practices.

    Args:
        data: The input data for revenue calculation.
        r_mrj: The value of r_mrj parameter.
        yr_idx: The index of the year.

    Returns
        A dictionary containing revenue matrices for different agricultural management practices.
        The keys of the dictionary represent the management practices, and the values are numpy arrays.

    """
    ag_mam_r_mrj = {}

    ag_mam_r_mrj['Asparagopsis taxiformis'] = get_asparagopsis_effect_r_mrj(data, r_mrj, yr_idx)           
    ag_mam_r_mrj['Precision Agriculture'] = get_precision_agriculture_effect_r_mrj(data, r_mrj, yr_idx)  
    ag_mam_r_mrj['Ecological Grazing'] = get_ecological_grazing_effect_r_mrj(data, r_mrj, yr_idx)          
    ag_mam_r_mrj['Savanna Burning'] = get_savanna_burning_effect_r_mrj(data, yr_idx)                       
    ag_mam_r_mrj['AgTech EI'] = get_agtech_ei_effect_r_mrj(data, r_mrj, yr_idx)                            
    ag_mam_r_mrj['Biochar'] = get_biochar_effect_r_mrj(data, r_mrj, yr_idx)                                
    ag_mam_r_mrj['HIR - Beef'] = get_beef_hir_effect_r_mrj(data, r_mrj)                                    
    ag_mam_r_mrj['HIR - Sheep'] = get_sheep_hir_effect_r_mrj(data, r_mrj)
    ag_mam_r_mrj['Utility Solar PV'] = get_utility_solar_pv_effect_r_mrj(data, r_mrj, yr_idx)
    ag_mam_r_mrj['Onshore Wind'] = get_onshore_wind_effect_r_mrj(data, r_mrj, yr_idx)                                  

    return ag_mam_r_mrj
```

## luto/economics/agricultural/transitions.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.



"""
Data about transitions costs.
"""

import numpy as np
from typing import Dict

from luto.data import Data
from luto.settings import AG_MANAGEMENTS, AG_MANAGEMENTS_TO_LAND_USES
from luto.economics.agricultural.water import get_wreq_matrices
import luto.economics.agricultural.ghg as ag_ghg
from luto import settings
import luto.tools as tools
import luto.data as Data
from data import load_establishment_cost_raster

# Renewable energy eligibility criteria where establishment costs are non-zero
def eligibility_by_establishment_cost(data: Data, lm: int):
    """
    Returns a Boolean mask indicating eligibility for the renewable energy technology 
    corresponding to the given land management index.

    Eligibility is based on non-zero establishment costs in the corresponding raster.
    
    Parameters
    ----------
    data : Data
        The main data object containing land management descriptions.
    lm : int
        Land management index representing renewable technology.
    
    Returns
    -------
    np.ndarray (bool)
        Boolean mask raster of technological establishment eligibility.
    """
    tech_name = data.LANDMANS[lm]
    if 'solar' in tech_name.lower():
        tech_key = 'Utility Solar PV'
    elif 'wind' in tech_name.lower():
        tech_key = 'Onshore Wind'
    else:
        raise ValueError(f"Unknown renewable technology for land management '{tech_name}'")

    cost_raster = load_establishment_cost_raster(tech_key)
    eligible_mask = (cost_raster > 0) & (~np.isnan(cost_raster))

    return eligible_mask

def get_to_ag_exclude_matrices(data: Data, lumap: np.ndarray):
    """Return x_mrj exclude matrices.

    An exclude matrix indicates whether switching land-use for a certain cell r
    with land-use i to all other land-uses j under all land management types
    (i.e., dryland, irrigated) m is possible.

    Parameters
    ----------

    data: Data object.
    base_year: int
        Current base year of the solve.
    lumaps: dict[str, numpy.ndarray]
        All previously generated land-use maps (shape = ncells, dtype=int).


    Returns
    -------
    numpy.ndarray
        x_mrj exclude matrix. The m-slices correspond to the
        different land-management versions of the land-use `j` to switch _to_.
        With m==0 conventional dryland, m==1 conventional irrigated.
    """
    # Spatial exclusoin; if a land-use never exists in a SA2 region in 2010, it will be disallowed in this region forever
    x_mrj = data.EXCLUDE.copy().astype(np.int8)

    # Transition exclusion; Whether a landuse can be converted to another one (np.nan indicates NOT-ALLOW)
    t_ij = data.T_MAT.loc[:,data.AGRICULTURAL_LANDUSES].copy()                                          # Lexicographical transition matix (2D, all-lus to ag-lus).
    ag_cells, non_ag_cells = tools.get_ag_and_non_ag_cells(lumap)                                       # Get ag and non-ag index from base year lumap
    lumap2desc = np.vectorize(data.ALLLU2DESC.get, otypes=[str])
    
    t_rj = np.ones((data.NCELLS, len(data.AGRICULTURAL_LANDUSES))).astype(np.float32)       # Empty ones_rj array to be filled with transition flag (1 allow, 0 not allow)
    t_rj[ag_cells, :] = t_ij[lumap[ag_cells]]                                               # For ag cells in the base year lumap, get transition cost (np.nan is not-allow) for them
    t_rj[non_ag_cells, :] *= t_ij.sel(from_lu=lumap2desc(lumap[non_ag_cells]))              # For non-ag cells in the base year lumap, get transition cost (np.nan is not-allow) for them
    t_rj[non_ag_cells, :] *= t_ij.sel(from_lu=lumap2desc(data.LUMAP[non_ag_cells]))         # For non-ag cells, find its ag status in BASE_YR (2010), then get transition cost based on these 2010-ag status
    t_rj = np.where(np.isnan(t_rj), 0, 1).astype(np.int8)     

    # No-go exclusion; user-defined layer specifying which land-use are not disallowd at where
    no_go_x_mrj = np.ones_like(data.AG_L_MRJ)
    if settings.EXCLUDE_NO_GO_LU:
        for no_go_x_r, no_go_desc in zip(data.NO_GO_REGION_AG, data.NO_GO_LANDUSE_AG):
            no_go_j = data.DESC2AGLU[no_go_desc]
            no_go_x_mrj[:,:,no_go_j] = no_go_x_r

    return (x_mrj * t_rj * no_go_x_mrj).astype(np.int8)

def get_transition_matrices_ag2ag(data: Data, yr_idx: int, lumap: np.ndarray, lmmap: np.ndarray, separate=False):
    """
    Calculate the transition matrices for land-use and land management transitions.
    Args:
        data (Data object): The data object containing the necessary input data.
        yr_idx (int): The index of the current year.
        lumap (np.ndarray): Land use map of the base year for the transitions.
        lmmap (np.ndarray): Land management map of the base year for the transitions.
        separate (bool, optional): Whether to return separate cost matrices for each cost component.
                                   Defaults to False.
    Returns:
            numpy.ndarray or dict: The transition matrices for land-use and land management transitions.
                               If `separate` is False, returns a numpy array representing the total costs.
                               If `separate` is True, returns a dictionary with separate cost matrices for
                               establishment costs, Water license cost, and carbon releasing costs.
    """
    yr_cal = data.YR_CAL_BASE + yr_idx

    # Return l_mrj (Boolean) for current land-use and land management
    l_mrj = tools.lumap2ag_l_mrj(lumap, lmmap)
    l_mrj_not = np.logical_not(l_mrj)

    # Get the exclusion matrix
    x_mrj = get_to_ag_exclude_matrices(data, lumap)

    ag_cells, _ = tools.get_ag_and_non_ag_cells(lumap)

    n_ag_lms, ncells, n_ag_lus = data.AG_L_MRJ.shape

    # -------------------------------------------------------------- #
    # Transition costs (upfront, amortised to annual, per cell).  #
    # -------------------------------------------------------------- #

    # Raw transition-cost matrix is in $/ha and lexigraphically ordered (shape: land-use x land-use).
    t_ij = data.T_MAT.sel(from_lu=data.AGRICULTURAL_LANDUSES, to_lu=data.AGRICULTURAL_LANDUSES).values * data.TRANS_COST_MULTS[yr_cal]

    # Non-irrigation related transition costs for cell r to change to land-use j calculated based on lumap (in $/ha).
    # Only consider for cells currently being used for agriculture.
    e_rj = np.zeros((ncells, n_ag_lus)).astype(np.float32)
    e_rj[ag_cells, :] = t_ij[lumap[ag_cells]]

    # Amortise upfront costs to annualised costs and converted to $ per cell via REAL_AREA
    e_rj = tools.amortise(e_rj) * data.REAL_AREA[:, np.newaxis]

    # Repeat the transition costs into dryland and irrigated land management types
    e_mrj = np.stack([e_rj, e_rj], axis=0)

    # Update the cost matrix with exclude matrices; the transition cost for a cell that remain the same is 0.
    e_mrj = np.einsum('mrj,mrj,mrj->mrj', e_mrj, x_mrj, l_mrj_not).astype(np.float32)
    e_mrj = np.nan_to_num(e_mrj)

    # -------------------------------------------------------------- #
    # Water license cost (upfront, amortised to annual, per cell).   #
    # -------------------------------------------------------------- #

    w_mrj = get_wreq_matrices(data, yr_idx)                                     # <unit: ML/cell>
    w_delta_mrj = tools.get_ag_to_ag_water_delta_matrix(w_mrj, l_mrj, data, yr_idx)
    w_delta_mrj = np.einsum('mrj,mrj,mrj->mrj', w_delta_mrj, x_mrj, l_mrj_not).astype(np.float32)

    # -------------------------------------------------------------- #
    # Carbon costs of transitioning cells.                           #
    # -------------------------------------------------------------- #

    # Apply the cost of carbon released by transitioning natural land to modified land
    ghg_transition = ag_ghg.get_ghg_transition_emissions(data, lumap, separate=True)        # <unit: t/ha>
        
    ghg_transition = {
        k:np.einsum('mrj,mrj,mrj->mrj', v, x_mrj, l_mrj_not).astype(np.float32)             # No GHG penalty for cells that remain the same, or are prohibited from transitioning
        for k, v in ghg_transition.items()
    }
    
    ghg_transition = {
        k:tools.amortise(v * data.get_carbon_price_by_yr_idx(yr_idx))                       # Amortise the GHG penalties
        for k,v in ghg_transition.items()
    }
    
    ghg_t_types = ghg_transition.keys()
    ghg_t_smrj = np.stack([ghg_transition[t] for t in ghg_t_types], axis=0)                 # s: ghg_t_types, m: land management, r: cell, j: land use
    ghg_t_mrj = np.einsum('smrj->mrj', ghg_t_smrj)

    # -------------------------------------------------------------- #
    # Total costs.                                                   #
    # -------------------------------------------------------------- #

    if separate:
        return {'Establishment cost': e_mrj, 'Water license cost': w_delta_mrj, **ghg_transition}
    else:
        t_mrj = e_mrj + w_delta_mrj + ghg_t_mrj
        return t_mrj


def get_transition_matrices_ag2ag_from_base_year(data: Data, yr_idx, base_year, separate=False):
    """
    Calculate the transition matrices for land-use and land management transitions.
    Args:
        data (Data object): The data object containing the necessary input data.
        yr_idx (int): The index of the current year.
        base_year (int): The base year for the transition calculations.
        separate (bool, optional): Whether to return separate cost matrices for each cost component.
                                   Defaults to False.
    Returns:
        numpy.ndarray or dict: The transition matrices for land-use and land management transitions.
                               If `separate` is False, returns a numpy array representing the total costs.
                               If `separate` is True, returns a dictionary with separate cost matrices for
                               establishment costs, Water license cost, and carbon releasing costs.
    """
    lumap = data.lumaps[base_year]
    lmmap = data.lmmaps[base_year]
    return get_transition_matrices_ag2ag(data, yr_idx, lumap, lmmap, separate)
    

def get_asparagopsis_effect_t_mrj(data: Data):
    """
    Gets the transition costs of asparagopsis taxiformis, which are none.
    Transition/establishment costs are handled in the costs matrix.
    """
    land_uses = AG_MANAGEMENTS_TO_LAND_USES["Asparagopsis taxiformis"]
    return np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)


def get_precision_agriculture_effect_t_mrj(data: Data):
    """
    Gets the effects on transition costs of asparagopsis taxiformis, which are none.
    Transition/establishment costs are handled in the costs matrix.
    """
    land_uses = AG_MANAGEMENTS_TO_LAND_USES['Precision Agriculture']
    return np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)


def get_ecological_grazing_effect_t_mrj(data: Data):
    """
    Gets the effects on transition costs of ecological grazing, which are none.
    Transition/establishment costs are handled in the costs matrix.
    """
    land_uses = AG_MANAGEMENTS_TO_LAND_USES['Ecological Grazing']
    return np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)


def get_savanna_burning_effect_t_mrj(data):
    """
    Gets the effects on transition costs of savanna burning, which are none.
    Transition/establishment costs are handled in the costs matrix.
    """
    land_uses = AG_MANAGEMENTS_TO_LAND_USES['Savanna Burning']
    return np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)


def get_agtech_ei_effect_t_mrj(data):
    """
    Gets the effects on transition costs of AgTech EI, which are none.
    Transition/establishment costs are handled in the costs matrix.
    """
    land_uses = AG_MANAGEMENTS_TO_LAND_USES['AgTech EI']
    return np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)


def get_biochar_effect_t_mrj(data):
    """
    Gets the effects on transition costs of Biochar, which are none.
    Transition/establishment costs are handled in the costs matrix.
    """
    land_uses = AG_MANAGEMENTS_TO_LAND_USES['Biochar']
    return np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)


def get_beef_hir_effect_t_mrj(data):
    land_uses = AG_MANAGEMENTS_TO_LAND_USES['HIR - Beef']
    return np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

def get_sheep_hir_effect_t_mrj(data):
    land_uses = AG_MANAGEMENTS_TO_LAND_USES['HIR - Sheep']
    return np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

def get_utility_solar_pv_effect_t_mrj(data, yr_idx):
    """
    Calculate establishment-related transition costs for Utility Solar PV
    as a 3D array indexed by management (m), cell (r), and land use (j) for year yr_idx.
    """
    if not AG_MANAGEMENTS.get('Utility Solar PV', False):
        return np.zeros((data.NLMS, data.NCELLS, data.NPRS), dtype=np.float32)

    yr_cal = data.YR_BASE + yr_idx

    est_cost_raster = load_establishment_cost_raster('Utility PV')  # Spatial raster (e.g., $/ha)
    est_cost_per_cell = est_cost_raster * data.REAL_AREA  # Convert per ha to per cell

    est_cost_amortised = tools.amortise(est_cost_per_cell)  # Amortise over lifetime

    effect_array = np.zeros((data.NLMS, data.NCELLS, data.NPRS), dtype=np.float32)

    solar_lus = AG_MANAGEMENTS_TO_LAND_USES['Utility Solar PV']
    lu_indices = [data.DESC_TO_AGLU[lu] for lu in solar_lus]

    for m in range(data.NLMS):
        for j in lu_indices:
            effect_array[m, :, j] = est_cost_amortised

    return effect_array


def get_onshore_wind_effect_t_mrj(data, yr_idx):
    """
    Calculate establishment-related transition costs for Onshore Wind
    as a 3D array indexed by management (m), cell (r), and land use (j) for year yr_idx.
    """
    if not AG_MANAGEMENTS.get('Onshore Wind', False):
        return np.zeros((data.NLMS, data.NCELLS, data.NPRS), dtype=np.float32)

    yr_cal = data.YR_BASE + yr_idx

    est_cost_raster = load_establishment_cost_raster('Onshore Wind')
    est_cost_per_cell = est_cost_raster * data.REAL_AREA

    est_cost_amortised = tools.amortise(est_cost_per_cell)

    effect_array = np.zeros((data.NLMS, data.NCELLS, data.NPRS), dtype=np.float32)

    wind_lus = AG_MANAGEMENTS_TO_LAND_USES['Onshore Wind']
    lu_indices = [data.DESC_TO_AGLU[lu] for lu in wind_lus]

    for m in range(data.NLMS):
        for j in lu_indices:
            effect_array[m, :, j] = est_cost_amortised

    return effect_array


def get_agricultural_management_transition_matrices(data: Data, t_mrj, yr_idx) -> Dict[str, np.ndarray]:
    
    asparagopsis_data = get_asparagopsis_effect_t_mrj(data)                     
    precision_agriculture_data = get_precision_agriculture_effect_t_mrj(data)   
    eco_grazing_data = get_ecological_grazing_effect_t_mrj(data)                
    sav_burning_data = get_savanna_burning_effect_t_mrj(data)                   
    agtech_ei_data = get_agtech_ei_effect_t_mrj(data)                           
    biochar_data = get_biochar_effect_t_mrj(data)                               
    beef_hir_data = get_beef_hir_effect_t_mrj(data)                             
    sheep_hir_data = get_sheep_hir_effect_t_mrj(data)   
    utility_solar_data = get_utility_solar_pv_effect_t_mrj(data)
    onshore_wind_data = get_onshore_wind_effect_t_mrj(data)                      

    return {
        'Asparagopsis taxiformis': asparagopsis_data,
        'Precision Agriculture': precision_agriculture_data,
        'Ecological Grazing': eco_grazing_data,
        'Savanna Burning': sav_burning_data,
        'AgTech EI': agtech_ei_data,
        'Biochar': biochar_data,
        'HIR - Beef': beef_hir_data,
        'HIR - Sheep': sheep_hir_data,
        'Utility Solar PV': utility_solar_data,
        'Onshore Wind': onshore_wind_data
    }


def get_asparagopsis_adoption_limits(data: Data, yr_idx):
    """
    Gets the adoption limit of Asparagopsis taxiformis for each possible land use.
    """
    asparagopsis_limits = {}
    yr_cal = data.YR_CAL_BASE + yr_idx
    for lu in AG_MANAGEMENTS_TO_LAND_USES['Asparagopsis taxiformis']:
        j = data.DESC2AGLU[lu]
        asparagopsis_limits[j] = data.ASPARAGOPSIS_DATA[lu].loc[yr_cal, 'Technical_Adoption']

    return asparagopsis_limits


def get_precision_agriculture_adoption_limit(data: Data, yr_idx):
    """
    Gets the adoption limit of precision agriculture for each possible land use.
    """
    prec_agr_limits = {}
    yr_cal = data.YR_CAL_BASE + yr_idx
    for lu in AG_MANAGEMENTS_TO_LAND_USES['Precision Agriculture']:
        j = data.DESC2AGLU[lu]
        prec_agr_limits[j] = data.PRECISION_AGRICULTURE_DATA[lu].loc[yr_cal, 'Technical_Adoption']

    return prec_agr_limits


def get_ecological_grazing_adoption_limit(data: Data, yr_idx):
    """
    Gets the adoption limit of ecological grazing for each possible land use.
    """
    eco_grazing_limits = {}
    yr_cal = data.YR_CAL_BASE + yr_idx
    for lu in AG_MANAGEMENTS_TO_LAND_USES['Ecological Grazing']:
        j = data.DESC2AGLU[lu]
        eco_grazing_limits[j] = data.ECOLOGICAL_GRAZING_DATA[lu].loc[yr_cal, 'Feasible Adoption (%)']

    return eco_grazing_limits


def get_savanna_burning_adoption_limit(data):
    """
    Gets the adoption limit of Savanna Burning for each possible land use
    """
    sav_burning_limits = {}
    for lu in AG_MANAGEMENTS_TO_LAND_USES['Savanna Burning']:
        j = data.DESC2AGLU[lu]
        sav_burning_limits[j] = 1

    return sav_burning_limits


def get_agtech_ei_adoption_limit(data, yr_idx):
    """
    Gets the adoption limit of AgTech EI for each possible land use.
    """
    agtech_ei_limits = {}
    yr_cal = data.YR_CAL_BASE + yr_idx
    for lu in AG_MANAGEMENTS_TO_LAND_USES['AgTech EI']:
        j = data.DESC2AGLU[lu]
        agtech_ei_limits[j] = data.AGTECH_EI_DATA[lu].loc[yr_cal, 'Technical_Adoption']

    return agtech_ei_limits


def get_biochar_adoption_limit(data, yr_idx):
    """
    Gets the adoption limit of Biochar for each possible land use.
    """
    biochar_limits = {}
    yr_cal = data.YR_CAL_BASE + yr_idx
    for lu in AG_MANAGEMENTS_TO_LAND_USES['Biochar']:
        j = data.DESC2AGLU[lu]
        biochar_limits[j] = data.BIOCHAR_DATA[lu].loc[yr_cal, 'Technical_Adoption']

    return biochar_limits


def get_beef_hir_adoption_limit(data: Data):
    """
    Gets the adoption limit of HIR - Beef for each possible land use.
    """
    hir_limits = {}
    for lu in AG_MANAGEMENTS_TO_LAND_USES['HIR - Beef']:
        j = data.DESC2AGLU[lu]
        hir_limits[j] = 1

    return hir_limits


def get_sheep_hir_adoption_limit(data: Data):
    """
    Gets the adoption limit of HIR - Sheep for each possible land use.
    """
    hir_limits = {}
    for lu in AG_MANAGEMENTS_TO_LAND_USES['HIR - Sheep']:
        j = data.DESC2AGLU[lu]
        hir_limits[j] = 1

    return hir_limits

def get_utility_solar_pv_adoption_limit(data: Data, yr_idx):
    """
    Gets the adoption limit of Utility Solar PV for each possible land use.
    """
    solar_pv_limits = {}
    yr_cal = data.YR_CAL_BASE + yr_idx
    for lu in AG_MANAGEMENTS_TO_LAND_USES['Utility Solar PV']:
        j = data.DESC2AGLU[lu]
        solar_pv_limits[j] = data.UTILITY_SOLAR_PV_DATA[lu].loc[yr_cal, 'Technical_Adoption']

    return solar_pv_limits

def get_onshore_wind_adoption_limit(data: Data, yr_idx):
    """
    Gets the adoption limit of Onshore Wind for each possible land use.
    """
    wind_limits = {}
    yr_cal = data.YR_CAL_BASE + yr_idx
    for lu in AG_MANAGEMENTS_TO_LAND_USES['Onshore Wind']:
        j = data.DESC2AGLU[lu]
        wind_limits[j] = data.ONS_WIND_DATA[lu].loc[yr_cal, 'Technical_Adoption']

    return wind_limits

def get_agricultural_management_adoption_limits(data: Data, yr_idx) -> Dict[str, dict]:
    """
    An adoption limit represents the maximum percentage of cells (for each land use) that can utilise
    each agricultural management option.
    """
    ag_management_data = {}

    ag_management_data['Asparagopsis taxiformis'] = get_asparagopsis_adoption_limits(data, yr_idx)          if AG_MANAGEMENTS['Asparagopsis taxiformis'] else {data.DESC2AGLU[lu]: 0 for lu in AG_MANAGEMENTS_TO_LAND_USES['Asparagopsis taxiformis']}
    ag_management_data['Precision Agriculture'] = get_precision_agriculture_adoption_limit(data, yr_idx)    if AG_MANAGEMENTS['Precision Agriculture'] else {data.DESC2AGLU[lu]: 0 for lu in AG_MANAGEMENTS_TO_LAND_USES['Precision Agriculture']}
    ag_management_data['Ecological Grazing'] = get_ecological_grazing_adoption_limit(data, yr_idx)          if AG_MANAGEMENTS['Ecological Grazing'] else {data.DESC2AGLU[lu]: 0 for lu in AG_MANAGEMENTS_TO_LAND_USES['Ecological Grazing']}
    ag_management_data['Savanna Burning'] = get_savanna_burning_adoption_limit(data)                        if AG_MANAGEMENTS['Savanna Burning'] else {data.DESC2AGLU[lu]: 0 for lu in AG_MANAGEMENTS_TO_LAND_USES['Savanna Burning']}
    ag_management_data['AgTech EI'] = get_agtech_ei_adoption_limit(data, yr_idx)                            if AG_MANAGEMENTS['AgTech EI'] else {data.DESC2AGLU[lu]: 0 for lu in AG_MANAGEMENTS_TO_LAND_USES['AgTech EI']}
    ag_management_data['Biochar'] = get_biochar_adoption_limit(data, yr_idx)                                if AG_MANAGEMENTS['Biochar'] else {data.DESC2AGLU[lu]: 0 for lu in AG_MANAGEMENTS_TO_LAND_USES['Biochar']}
    ag_management_data['HIR - Beef'] = get_beef_hir_adoption_limit(data)                                    if AG_MANAGEMENTS['HIR - Beef'] else {data.DESC2AGLU[lu]: 0 for lu in AG_MANAGEMENTS_TO_LAND_USES['HIR - Beef']}
    ag_management_data['HIR - Sheep'] = get_sheep_hir_adoption_limit(data)                                  if AG_MANAGEMENTS['HIR - Sheep'] else {data.DESC2AGLU[lu]: 0 for lu in AG_MANAGEMENTS_TO_LAND_USES['HIR - Sheep']}
    ag_management_data['Utility Solar PV'] = get_utility_solar_pv_adoption_limit(data, yr_idx)              if AG_MANAGEMENTS['Utility Solar PV'] else {data.DESC2AGLU[lu]: 0 for lu in AG_MANAGEMENTS_TO_LAND_USES['Utility Solar PV']}
    ag_management_data['Onshore Wind'] = get_onshore_wind_adoption_limit(data, yr_idx)                      if AG_MANAGEMENTS['Onshore Wind'] else {data.DESC2AGLU[lu]: 0 for lu in AG_MANAGEMENTS_TO_LAND_USES['Onshore Wind']}

    return ag_management_data


def get_lower_bound_agricultural_management_matrices(data: Data, base_year) -> dict[str, dict]:
    """
    Gets the lower bound for the agricultural land use of the current years optimisation.
    """

    if base_year == data.YR_CAL_BASE or base_year not in data.non_ag_dvars:
        return {
            am: np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS), dtype=np.float32)
            for am in AG_MANAGEMENTS_TO_LAND_USES
            if AG_MANAGEMENTS[am]
        }

    return {
        am: np.divide(
            np.floor(data.ag_man_dvars[base_year][am].astype(np.float32) * 10 ** settings.ROUND_DECMIALS)
            , 10 ** settings.ROUND_DECMIALS
        )
        for am in AG_MANAGEMENTS_TO_LAND_USES
        if AG_MANAGEMENTS[am]
    }


def get_regional_adoption_limits(data: Data, yr_cal: int):
    if settings.REGIONAL_ADOPTION_CONSTRAINTS == "off":
        return None, None
    
    ag_reg_adoption_constrs = []
    non_ag_reg_adoption_constrs = []

    for reg_id, lu_name, area_limit_ha in data.get_regional_adoption_limit_ha_by_year(yr_cal):
        reg_ind = np.where(data.REGIONAL_ADOPTION_ZONES == reg_id)[0]

        if lu_name in data.DESC2AGLU:
            lu_code = data.DESC2AGLU[lu_name]
            ag_reg_adoption_constrs.append([reg_id, lu_code, lu_name, reg_ind, area_limit_ha])

        elif lu_name in data.DESC2NONAGLU:
            lu_code = data.DESC2NONAGLU[lu_name] - settings.NON_AGRICULTURAL_LU_BASE_CODE
            non_ag_reg_adoption_constrs.append([reg_id, lu_code, lu_name, reg_ind, area_limit_ha])

        else:
            raise ValueError(f"Regional adoption constraint exists for unrecognised land use: {lu_name}")

    return ag_reg_adoption_constrs, non_ag_reg_adoption_constrs
```

## luto/economics/agricultural/water.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.



"""
Pure functions to calculate water net yield by lm, lu and water limits.
"""

import numpy as np
import pandas as pd
import luto.settings as settings

from typing import Optional
from luto import tools
from luto.economics.agricultural.quantity import get_yield_pot, lvs_veg_types


def get_wreq_matrices(data, yr_idx):
    """
    Return water requirement (water use by irrigation and livestock drinking water) matrices
    by land management, cell, and land-use type.

    Parameters
        data (object): The data object containing the required data.
        yr_idx (int): The index of the year.

    Returns
        numpy.ndarray: The w_mrj <unit: ML/cell> water requirement matrices, indexed (m, r, j).
    """

    # Stack water requirements data
    w_req_mrj = np.stack((data.WREQ_DRY_RJ, data.WREQ_IRR_RJ))    # <unit: ML/head|ha>

    # Covert water requirements units from ML/head to ML/ha
    for j, lu in enumerate(data.AGRICULTURAL_LANDUSES):
        if lu in data.LU_LVSTK:
            lvs, veg = lvs_veg_types(lu)
            w_req_mrj[0, :, j] = w_req_mrj[0, :, j] * get_yield_pot(data, lvs, veg, 'dry', yr_idx)  # Water reqs depend on current stocking rate for drinking water
            w_req_mrj[1, :, j] = w_req_mrj[1, :, j] * get_yield_pot(data, lvs, veg, 'irr', 0)       # Water reqs depend on initial stocking rate for irrigation

    # Convert to ML per cell via REAL_AREA
    w_req_mrj *= data.REAL_AREA[:, np.newaxis]                      # <unit: ML/ha> * <unit: ha/cell> -> <unit: ML/cell>

    return w_req_mrj


def get_wyield_matrices(
    data, 
    yr_idx:int, 
    water_dr_yield: Optional[np.ndarray] = None,
    water_sr_yield: Optional[np.ndarray] = None
) -> np.ndarray:
    """
    Return water yield matrices for YR_CAL_BASE (2010) by land management, cell, and land-use type.

    Parameters
        data (object): The data object containing the required data.
        yr_idx (int): The index of the year.
        water_dr_yield (ndarray, <unit:ML/cell>): The water yield for deep-rooted vegetation.
        water_sr_yield (ndarray, <unit:ML/cell>): The water yield for shallow-rooted vegetation.

    Returns
        numpy.ndarray: The w_mrj <unit: ML/cell> water yield matrices, indexed (m, r, j).
    """
    w_yield_mrj = np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS)).astype(np.float32)

    w_yield_dr = data.WATER_YIELD_DR_FILE[yr_idx] if water_dr_yield is None else water_dr_yield
    w_yield_sr = data.WATER_YIELD_SR_FILE[yr_idx] if water_sr_yield is None else water_sr_yield
    w_yield_nl = data.get_water_nl_yield_for_yr_idx(yr_idx, w_yield_dr, w_yield_sr)


    for j in range(data.N_AG_LUS):
        if j in data.LU_SHALLOW_ROOTED:
            for m in range(data.NLMS):
                w_yield_mrj[m, :, j] = w_yield_sr * data.REAL_AREA

        elif j in data.LU_DEEP_ROOTED:
            for m in range(data.NLMS):
                w_yield_mrj[m, :, j] = w_yield_dr * data.REAL_AREA

        elif j in data.LU_NATURAL:
            for m in range(data.NLMS):
                w_yield_mrj[m, :, j] = w_yield_nl * data.REAL_AREA

        else:
            raise ValueError(
                f"Land use {j} ({data.AGLU2DESC[j]}) missing from all of "
                f"data.LU_SHALLOW_ROOTED, data.LU_DEEP_ROOTED, data.LU_NATURAL "
                f"(requires root definition)."
            )

    return w_yield_mrj


def get_water_net_yield_matrices(
    data, 
    yr_idx, 
    water_dr_yield: Optional[np.ndarray] = None,
    water_sr_yield: Optional[np.ndarray] = None
    ) -> np.ndarray:
    """
    Return water net yield matrices by land management, cell, and land-use type.
    The resulting array is used as the net yield w_mrj array in the input data of the solver.

    Parameters
        data (object): The data object containing the required data.
        yr_idx (int): The index of the year.
        water_dr_yield (ndarray, <unit:ML/cell>): The water yield for deep-rooted vegetation.
        water_sr_yield (ndarray, <unit:ML/cell>): The water yield for shallow-rooted vegetation.
        
    Notes:
        Provides the `water_dr_yield` or `water_sr_yield` will make the `yr_idx` useless because
        the water net yield will be calculated based on the provided water yield data regardless of the year.

    Returns
        numpy.ndarray: The w_mrj <unit: ML/cell> water net yield matrices, indexed (m, r, j).
    """
    return get_wyield_matrices(data, yr_idx, water_dr_yield, water_sr_yield) - get_wreq_matrices(data, yr_idx)


def get_asparagopsis_effect_w_mrj(data, yr_idx):
    """
    Applies the effects of using asparagopsis to the water net yield data
    for all relevant agr. land uses.

    Args:
        data (object): The data object containing relevant information.
        w_mrj (ndarray, <unit:ML/cell>): The water net yield data for all land uses.
        yr_idx (int): The index of the year.

    Returns
        ndarray <unit:ML/cell>: The updated water net yield data with the effects of using asparagopsis.

    Notes:
        Asparagopsis taxiformis has no effect on the water required.
    """

    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES["Asparagopsis taxiformis"]
    lu_codes = np.array([data.DESC2AGLU[lu] for lu in land_uses])
    yr_cal = data.YR_CAL_BASE + yr_idx

    wreq_mrj = get_wreq_matrices(data, yr_idx)

    # Set up the effects matrix
    w_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    # Update values in the new matrix using the correct multiplier for each LU
    for lu_idx, lu in enumerate(land_uses):
        multiplier = data.ASPARAGOPSIS_DATA[lu].loc[yr_cal, "Water_use"]
        if multiplier != 1:
            j = lu_codes[lu_idx]
            # The effect is: new value = old value * multiplier - old value
            # E.g. a multiplier of .95 means a 5% reduction in water used.
            # Since the effect applies to water use, it effects the net yield negatively.
            w_mrj_effect[:, :, lu_idx] = wreq_mrj[:, :, j] * (1 - multiplier)

    return w_mrj_effect


def get_precision_agriculture_effect_w_mrj(data, yr_idx):
    """
    Applies the effects of using precision agriculture to the water net yield data
    for all relevant agricultural land uses.

    Parameters
    - data: The data object containing relevant information for the calculation.
    - w_mrj <unit:ML/cell>: The original water net yield data for different land uses.
    - yr_idx: The index representing the year for which the calculation is performed.

    Returns
    - w_mrj_effect <unit:ML/cell>: The updated water net yield data after applying precision agriculture effects.
    """

    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Precision Agriculture']
    lu_codes = np.array([data.DESC2AGLU[lu] for lu in land_uses])
    yr_cal = data.YR_CAL_BASE + yr_idx

    wreq_mrj = get_wreq_matrices(data, yr_idx)

    # Set up the effects matrix
    w_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    # Update values in the new matrix using the correct multiplier for each land use
    for lu_idx, lu in enumerate(land_uses):
        multiplier = data.PRECISION_AGRICULTURE_DATA[lu].loc[yr_cal, "Water_use"]
        if multiplier != 1:
            j = lu_codes[lu_idx]
            # The effect is: new value = old value * multiplier - old value
            # E.g. a multiplier of .95 means a 5% reduction in water used.
            # Since the effect applies to water use, it effects the net yield negatively.
            w_mrj_effect[:, :, lu_idx] = wreq_mrj[:, :, j] * (1- multiplier)

    return w_mrj_effect


def get_ecological_grazing_effect_w_mrj(data, yr_idx):
    """
    Applies the effects of using ecological grazing to the water net yield data
    for all relevant agricultural land uses.

    Parameters
    - data: The data object containing relevant information.
    - w_mrj <unit:ML/cell>: The water net yield data for different land uses.
    - yr_idx: The index of the year.

    Returns
    - w_mrj_effect <unit:ML/cell>: The updated water net yield data after applying ecological grazing effects.
    """

    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Ecological Grazing']
    lu_codes = np.array([data.DESC2AGLU[lu] for lu in land_uses])
    yr_cal = data.YR_CAL_BASE + yr_idx

    wreq_mrj = get_wreq_matrices(data, yr_idx)

    # Set up the effects matrix
    w_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    # Update values in the new matrix using the correct multiplier for each land use
    for lu_idx, lu in enumerate(land_uses):
        multiplier = data.ECOLOGICAL_GRAZING_DATA[lu].loc[yr_cal, "INPUT-wrt_water-required"]
        if multiplier != 1:
            j = lu_codes[lu_idx]
            # The effect is: new value = old value * multiplier - old value
            # E.g. a multiplier of .95 means a 5% reduction in water used.
            # Since the effect applies to water use, it effects the net yield negatively.
            w_mrj_effect[:, :, lu_idx] = wreq_mrj[:, :, j] * (1- multiplier)

    return w_mrj_effect


def get_savanna_burning_effect_w_mrj(data):
    """
    Applies the effects of using savanna burning to the water net yield data
    for all relevant agr. land uses.

    Savanna burning does not affect water usage, so return an array of zeros.

    Parameters
    - data: The input data object containing information about land uses and water net yield.

    Returns
    - An array of zeros with dimensions (NLMS, NCELLS, nlus), where:
        - NLMS: Number of land management systems
        - NCELLS: Number of cells
        - nlus: Number of land uses affected by savanna burning
    """

    nlus = len(settings.AG_MANAGEMENTS_TO_LAND_USES['Savanna Burning'])
    return np.zeros((data.NLMS, data.NCELLS, nlus)).astype(np.float32)


def get_agtech_ei_effect_w_mrj(data, yr_idx):
    """
    Applies the effects of using AgTech EI to the water net yield data
    for all relevant agr. land uses.

    Parameters
    - data: The data object containing relevant information.
    - w_mrj <unit:ML/cell>: The water net yield data for all land uses.
    - yr_idx: The index of the year.

    Returns
    - w_mrj_effect <unit:ML/cell>: The updated water net yield data with AgTech EI effects applied.
    """

    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['AgTech EI']
    lu_codes = np.array([data.DESC2AGLU[lu] for lu in land_uses])
    yr_cal = data.YR_CAL_BASE + yr_idx

    wreq_mrj = get_wreq_matrices(data, yr_idx)

    # Set up the effects matrix
    w_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    # Update values in the new matrix using the correct multiplier for each LU
    for lu_idx, lu in enumerate(land_uses):
        multiplier = data.AGTECH_EI_DATA[lu].loc[yr_cal, "Water_use"]
        if multiplier != 1:
            j = lu_codes[lu_idx]
            # The effect is: new value = old value * multiplier - old value
            # E.g. a multiplier of .95 means a 5% reduction in water used.
            # Since the effect applies to water use, it effects the net yield negatively.
            w_mrj_effect[:, :, lu_idx] = wreq_mrj[:, :, j] * (1- multiplier)


    return w_mrj_effect


def get_biochar_effect_w_mrj(data, yr_idx):
    """
    Applies the effects of using Biochar to the water net yield data
    for all relevant agr. land uses.

    Parameters
    - data: The data object containing relevant information.
    - w_mrj <unit:ML/cell>: The water net yield data for all land uses.
    - yr_idx: The index of the year.

    Returns
    - w_mrj_effect <unit:ML/cell>: The updated water net yield data with Biochar applied.
    """

    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Biochar']
    lu_codes = np.array([data.DESC2AGLU[lu] for lu in land_uses])
    yr_cal = data.YR_CAL_BASE + yr_idx

    wreq_mrj = get_wreq_matrices(data, yr_idx)

    # Set up the effects matrix
    w_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    # Update values in the new matrix using the correct multiplier for each LU
    for lu_idx, lu in enumerate(land_uses):
        multiplier = data.BIOCHAR_DATA[lu].loc[yr_cal, "Water_use"]
        if multiplier != 1:
            j = lu_codes[lu_idx]
            w_mrj_effect[:, :, lu_idx] = wreq_mrj[:, :, j] * (1- multiplier)

    return w_mrj_effect


def get_beef_hir_effect_w_mrj(data, yr_idx):
    """
    Applies the effects of using HIR to the water net yield data
    for the natural beef land use.

    Parameters:
    - data: The data object containing relevant information.
    - w_mrj <unit:ML/cell>: The water net yield data for all land uses.
    - yr_idx: The index of the year.

    Returns:
    - w_mrj_effects <unit:ML/cell>: The updated water net yield data with Biochar applied.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['HIR - Beef']

    w_mrj_effects = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)
    base_w_req_mrj = np.stack(( data.WREQ_DRY_RJ, data.WREQ_IRR_RJ ))

    for lu_idx, lu in enumerate(land_uses):
        j = data.DESC2AGLU[lu]

        multiplier = 1 - settings.HIR_PRODUCTIVITY_CONTRIBUTION

        # Reduce water requirements due to drop in yield potential (increase in net yield)
        if lu in data.LU_LVSTK:
            lvs, veg = lvs_veg_types(lu)

            w_mrj_effects[0, :, lu_idx] = (
                (multiplier - 1) * base_w_req_mrj[0, :, j] * get_yield_pot(data, lvs, veg, 'dry', yr_idx)
            )
            w_mrj_effects[1, :, lu_idx] = (
                (multiplier - 1) * base_w_req_mrj[1, :, j] * get_yield_pot(data, lvs, veg, 'irr', 0)
            )

    return w_mrj_effects


def get_sheep_hir_effect_w_mrj(data, yr_idx):
    """
    Applies the effects of using HIR to the water net yield data
    for the natural sheep land use.

    Parameters:
    - data: The data object containing relevant information.
    - w_mrj <unit:ML/cell>: The water net yield data for all land uses.
    - yr_idx: The index of the year.

    Returns:
    - w_mrj_effects <unit:ML/cell>: The updated water net yield data with Biochar applied.
    """
    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['HIR - Sheep']

    w_mrj_effects = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)
    base_w_req_mrj = np.stack(( data.WREQ_DRY_RJ, data.WREQ_IRR_RJ ))

    for lu_idx, lu in enumerate(land_uses):
        j = data.DESC2AGLU[lu]

        multiplier = 1 - settings.HIR_PRODUCTIVITY_CONTRIBUTION

        # Reduce water requirements due to drop in yield potential (increase in net yield)
        if lu in data.LU_LVSTK:
            lvs, veg = lvs_veg_types(lu)

            w_mrj_effects[0, :, lu_idx] = (
                multiplier * base_w_req_mrj[0, :, j] * get_yield_pot(data, lvs, veg, 'dry', yr_idx)
            )
            w_mrj_effects[1, :, lu_idx] = (
                multiplier * base_w_req_mrj[1, :, j] * get_yield_pot(data, lvs, veg, 'irr', 0)
            )

        # TODO - potential effects of increased water yield of HIR areas?

    return w_mrj_effects

def get_utility_solar_pv_effect_w_mrj(data, yr_idx):
    """
    Applies the effects of using Utility Solar PV to the water net yield data
    for all relevant agr. land uses.

    Parameters
    - data: The data object containing relevant information.
    - w_mrj <unit:ML/cell>: The water net yield data for all land uses.
    - yr_idx: The index of the year.

    Returns
    - w_mrj_effect <unit:ML/cell>: The updated water net yield data with Utility Solar PV applied.
    """

    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Utility Solar PV']
    lu_codes = np.array([data.DESC2AGLU[lu] for lu in land_uses])
    yr_cal = data.YR_CAL_BASE + yr_idx

    wreq_mrj = get_wreq_matrices(data, yr_idx)

    # Set up the effects matrix
    w_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)

    # Update values in the new matrix using the correct multiplier for each LU
    for lu_idx, lu in enumerate(land_uses):
        multiplier = data.UTILITY_SOLAR_PV_DATA[lu].loc[yr_cal, "Water_use"]
        if multiplier != 1:
            j = lu_codes[lu_idx]
            # The effect is: new value = old value * multiplier - old value
            # E.g. a multiplier of .95 means a 5% reduction in water used.
            # Since the effect applies to water use, it effects the net yield negatively.
            w_mrj_effect[:, :, lu_idx] = wreq_mrj[:, :, j] * (1- multiplier)

    return w_mrj_effect

def get_onshore_wind_effect_w_mrj(data, yr_idx):
    """
    Applies the effects of using Onshore Wind to the water net yield data
    for all relevant agr. land uses.

    Parameters
    - data: The data object containing relevant information.
    - w_mrj <unit:ML/cell>: The water net yield data for all land uses.
    - yr_idx: The index of the year.

    Returns
    - w_mrj_effect <unit:ML/cell>: The updated water net yield data with Onshore Wind applied.
    """

    land_uses = settings.AG_MANAGEMENTS_TO_LAND_USES['Onshore Wind']
    lu_codes = np.array([data.DESC2AGLU[lu] for lu in land_uses])
    yr_cal = data.YR_CAL_BASE + yr_idx  
    wreq_mrj = get_wreq_matrices(data, yr_idx)
    # Set up the effects matrix
    w_mrj_effect = np.zeros((data.NLMS, data.NCELLS, len(land_uses))).astype(np.float32)   
    # Update values in the new matrix using the correct multiplier for each LU
    for lu_idx, lu in enumerate(land_uses):
        multiplier = data.ONS_WIND_DATA[lu].loc[yr_cal, "Water_use"]
        if multiplier != 1:
            j = lu_codes[lu_idx]
            # The effect is: new value = old value * multiplier - old value
            # E.g. a multiplier of .95 means a 5% reduction in water used.
            # Since the effect applies to water use, it effects the net yield negatively.
            w_mrj_effect[:, :, lu_idx] = wreq_mrj[:, :, j] * (1- multiplier)
    return w_mrj_effect


def get_agricultural_management_water_matrices(data, yr_idx) -> dict[str, np.ndarray]:
    
    ag_mam_w_mrj ={}
    
    ag_mam_w_mrj['Asparagopsis taxiformis'] = get_asparagopsis_effect_w_mrj(data, yr_idx)           
    ag_mam_w_mrj['Precision Agriculture'] = get_precision_agriculture_effect_w_mrj(data, yr_idx)    
    ag_mam_w_mrj['Ecological Grazing'] = get_ecological_grazing_effect_w_mrj(data, yr_idx)          
    ag_mam_w_mrj['Savanna Burning'] = get_savanna_burning_effect_w_mrj(data)                        
    ag_mam_w_mrj['AgTech EI'] = get_agtech_ei_effect_w_mrj(data, yr_idx)                            
    ag_mam_w_mrj['Biochar'] = get_biochar_effect_w_mrj(data, yr_idx)                                
    ag_mam_w_mrj['HIR - Beef'] = get_beef_hir_effect_w_mrj(data, yr_idx)                            
    ag_mam_w_mrj['HIR - Sheep'] = get_sheep_hir_effect_w_mrj(data, yr_idx)             
    ag_mam_w_mrj['Utility Solar PV'] = get_utility_solar_pv_effect_w_mrj(data, yr_idx)
    ag_mam_w_mrj['Onshore Wind'] = get_onshore_wind_effect_w_mrj(data, yr_idx)             

    return ag_mam_w_mrj




def get_climate_change_impact_whole_region(data, yr_cal):
    '''
    Calculate the climate change impact on water yield change for Ag-land and Outside-LUTO regions.

    Note, the climate change impact on water here is calculated assuming the land-use remains constant since the starting year.

    Parameters
    ----------
    data : object
        The data object containing the necessary input data.
    yr_cal : int
        The calendar year for which to calculate the climate change impact.

    Returns
    -------
    dict
        A dictionary containing the climate change impact on water yield change for each region.
    '''

    yr_idx = yr_cal - data.YR_CAL_BASE
    ag_dvar_mrj = tools.ag_mrj_to_xr(data, data.AG_L_MRJ).assign_coords(region_id=('cell', data.WATER_REGION_ID))

    # Get water yield change led by climate change
    ag_w_mrj_CCI = get_water_net_yield_matrices(data, yr_idx) -  get_water_net_yield_matrices(data, 0)
    wny_outside_luto_study_area_CCI = (
        np.array(list(data.WATER_OUTSIDE_LUTO_BY_CCI.loc[yr_cal].to_dict().values())) 
        - np.array(list(data.WATER_OUTSIDE_LUTO_BY_CCI.loc[data.YR_CAL_BASE].to_dict().values()))
    )

    CCI_impact = (
            (ag_w_mrj_CCI * ag_dvar_mrj).groupby('region_id').sum(['cell','lm', 'lu']) 
            + wny_outside_luto_study_area_CCI
        ).to_dataframe('Delta (ML)'
        ).reset_index(
        ).assign(name=lambda x: x['region_id'].map(data.WATER_REGION_NAMES), year=yr_cal)

    return CCI_impact


def get_water_delta_by_extreme_CCI_for_whole_region(data):
    """
    Get the extreme climate change impact on water yield change for the whole region.
    """
    water_delta_extreme_by_CCI = pd.DataFrame()
    for year in sorted(settings.SIM_YEARS):
        water_delta_extreme_by_CCI = pd.concat([
            water_delta_extreme_by_CCI,
            get_climate_change_impact_whole_region(data, year) 
        ])
        
    return water_delta_extreme_by_CCI.groupby('region_id')['Delta (ML)'].agg('min').to_dict()


def get_wny_inside_LUTO_by_CCI_for_base_yr(data):
    """
    Return water net yield for watershed regions at the BASE_YR.

    Parameters
        data (object): The data object containing the required data.

    Returns
        dict[int, float]: A dictionary with the following structure:
        - key: region ID
        - value: water net yield for this region (ML)
    """
    wny_inside_mrj = get_water_net_yield_matrices(data, 0)
    wny_base_yr_inside_r = np.einsum('mrj,mrj->r', wny_inside_mrj, data.AG_L_MRJ)
    wny_base_yr_inside_regions = {k:v for k,v in enumerate(np.bincount(data.WATER_REGION_ID, wny_base_yr_inside_r))}

    return wny_base_yr_inside_regions


def get_water_target_inside_LUTO_by_CCI(data):
    """
    Calculate the water net yield limit for each region based on historical levels.
    
    The limit is calculated as:
        - Water net yield limit for the whole region
        - Plus domestic water use
        - Minus water net yield from outside the LUTO study area
        
    Parameters
        data (object): The data object containing the required data.
        
    Returns
        dict[int, float]: A dictionary with the following structure:
        - key: region ID
        - value: water net yield limit for this region (ML)
    """

    wny_base_yr_outside_LUTO = data.WATER_OUTSIDE_LUTO_BY_CCI.loc[data.YR_CAL_BASE].to_dict()
    wny_base_yr_inside_LUTO = get_wny_inside_LUTO_by_CCI_for_base_yr(data)
    wny_extreme_delta = get_water_delta_by_extreme_CCI_for_whole_region(data)
    wreq_domestic = data.WATER_USE_DOMESTIC
    
    # Get inside LUTO targets based on historical level
    wny_inside_LUTO_targets = {}
    wny_relaxed_region_raw_targets = {}
    for reg_idx, hist_level in data.WATER_REGION_HIST_LEVEL.items():
        wny_inside_LUTO = wny_base_yr_inside_LUTO[reg_idx]
        wny_outside_LUTO = wny_base_yr_outside_LUTO[reg_idx]
        wreq_domestic = data.WATER_USE_DOMESTIC[reg_idx]    # positive values, indicating water requirements for domestic and industrial use
        CCI_extreme_stress = wny_extreme_delta[reg_idx]     # negative values, indicating water yield reductions by climate change
        
        wny_extreme_CCI = wny_inside_LUTO + wny_outside_LUTO - wreq_domestic + CCI_extreme_stress
        wny_hist_target = hist_level * settings.WATER_STRESS

        if wny_extreme_CCI < wny_hist_target:
            print(
                f"       target ({settings.WATER_REGION_DEF}) relaxed to ({wny_extreme_CCI:10,.0f} ML) from ({wny_hist_target:10,.0f} ML) for {data.WATER_REGION_NAMES[reg_idx]}."
            )
            wny_inside_LUTO_targets[reg_idx] = wny_extreme_CCI - wny_outside_LUTO
            wny_relaxed_region_raw_targets[reg_idx] = wny_hist_target
        else:
            wny_inside_LUTO_targets[reg_idx] = wny_hist_target - wny_outside_LUTO

    return wny_inside_LUTO_targets, wny_relaxed_region_raw_targets


"""
Water logic *** a little outdated but maybe still useful ***

The limits are related to the pre-European inflows into rivers. As a proxy
for these inflows are used the flows that would result if all cells had
deeply-rooted vegetation. The values from 1985 are used for this as these
do not incorporate climate change corrections on rainfall. So the limit is
a _lower_ limit, it is a bottom, not a cap.

Performance relative to the cap is then composed of two parts:
    1. Water used for irrigation or as livestock drinking water, and
    2. Water retained in the soil by vegetation.
The former (1) is calculated using the water requirements (WR) data. This
water use effectively raises the lower limit, i.e. is added to it. The latter
is computed from the water yields data. The water yield data state the
inflows from each cell based on which type of vegetation (deeply or shallowly
rooted) and which SSP projection.

The first approach is to try to limit water stress to below 40% of the
pre-European inflows. This means the limit is to have _at least_ 60% of
the 1985 inflows if all cells had deeply rooted vegetation. If these 1985
inflows are called L, then inflows need to be >= .6L. Inflows are computed
using the water yield data based on the vegetation the simulation wants to
plant -- i.e. deeply or shallowly rooted, corresponding to trees and crops,
roughly. Subtracted from this is then the water use for irrigation. Since
plants do not fully use the irrigated water, some of the irrigation actually
also adds to the inflows. This fraction is the _complement_ of the irrigation
efficiency. So either the irrigation efficiency corrected water use is added
to the lower limit, or the complement of it (the irrigation running off) is
added to the inflow.
"""
```

## luto/economics/land_use_culling.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import numpy as np
from luto import settings


def get_percentage_cost_mask(m, r, x_mrj_mask, costs_mrj):
    """
    Exclude the least profitable settings.LAND_USAGE_CULL_PERCENTAGE of land usage options for a given
    land management / cell.
    """
    # only consider costs that are relevant based on the exclusion matrix
    allowed_costs = costs_mrj[m, r, :][x_mrj_mask[m, r, :]]
    if len(allowed_costs) == 0:
        # this cell / land management pair has no valid land use options
        return None

    sorted_costs = np.sort(allowed_costs)
    include_percentage = 1 - settings.LAND_USAGE_CULL_PERCENTAGE
    max_land_use_options = max(
        round(include_percentage * len(allowed_costs)),
        1,  # there should always be at least one option
    )
    max_cost = sorted_costs[max_land_use_options - 1]

    # modify exclusion mask to only include costs that are below the threshold
    cost_include_mask = costs_mrj[m, r, :] <= max_cost
    return cost_include_mask


def get_absolute_cost_mask(m, r, x_mrj_mask, costs_mrj):
    """
    Include only the settings.MAX_LAND_USES_PER_CELL most profitable land usage options for a given
    land management / cell.
    """
    # only consider costs that are relevant based on the exclusion matrix
    allowed_costs = costs_mrj[m, r, :][x_mrj_mask[m, r, :]]
    if len(allowed_costs) < settings.MAX_LAND_USES_PER_CELL:
        # this cell / land management pair already has less than max_land_uses
        return None

    sorted_costs = np.sort(allowed_costs)
    max_cost = sorted_costs[settings.MAX_LAND_USES_PER_CELL - 1]

    # modify exclusion mask to only include costs that are below the threshold
    cost_include_mask = costs_mrj[m, r, :] <= max_cost
    return cost_include_mask


def apply_agricultural_land_use_culling(x_mrj, c_mrj, t_mrj, r_mrj):
    """
    Refine the exclude matrix to cull unprofitable land uses based on the settings.CULL_MODE setting.
    This function modifies the x_mrj matrix in-place.

    Args:
        x_mrj (np.ndarray): The 'exclude' matrix returned by `get_to_ag_exclude_matrices`. This will
            be modified in-place by this function.
        c_mrj (np.ndarray): The 'cost' matrix.
        t_mrj (np.ndarray): The 'transition' matrix.
        r_mrj (np.ndarray): The 'revenue' matrix.
    """

    if settings.CULL_MODE == "none":
        return

    x_mrj_mask = x_mrj.astype(bool)
    costs_mrj = (c_mrj + t_mrj) - r_mrj
    for r in range(costs_mrj.shape[1]):
        # Apply cost masks for every land management option
        for m in range(costs_mrj.shape[0]):
            if settings.CULL_MODE == "absolute":
                cost_include_mask = get_absolute_cost_mask(
                    m,
                    r,
                    x_mrj_mask,
                    costs_mrj,
                )
            elif settings.CULL_MODE == "percentage":
                cost_include_mask = get_percentage_cost_mask(
                    m, r, x_mrj_mask, costs_mrj
                )
            else:
                raise ValueError(f"Unknown settings.CULL_MODE={settings.CULL_MODE}")

            if cost_include_mask is None:
                continue

            x_mrj[m, r, :] = x_mrj[m, r, :] & cost_include_mask
```

## luto/economics/non_agricultural/biodiversity.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import numpy as np

from luto import settings
from luto.data import Data
from luto import tools
from luto.settings import (
    BIO_CONTRIBUTION_ENV_PLANTING, 
    BIO_CONTRIBUTION_CARBON_PLANTING_BLOCK, 
    BIO_CONTRIBUTION_CARBON_PLANTING_BELT, 
    BIO_CONTRIBUTION_RIPARIAN_PLANTING,
    BIO_CONTRIBUTION_AGROFORESTRY,
    BIO_CONTRIBUTION_BECCS,
    AF_PROPORTION,
    CP_BELT_PROPORTION,
)


def get_biodiv_environmental_plantings(data: Data) -> np.ndarray:
    return data.BIO_CONNECTIVITY_RAW * data.REAL_AREA * BIO_CONTRIBUTION_ENV_PLANTING


def get_biodiv_riparian_plantings(data: Data) -> np.ndarray:
    return data.BIO_CONNECTIVITY_RAW * data.REAL_AREA * BIO_CONTRIBUTION_RIPARIAN_PLANTING


def get_biodiv_agroforestry_base(data: Data) -> np.ndarray:
    return data.BIO_CONNECTIVITY_RAW * data.REAL_AREA * BIO_CONTRIBUTION_AGROFORESTRY


def get_biodiv_sheep_agroforestry(
    data: Data, 
    ag_b_mrj: np.ndarray, 
    agroforestry_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    ag_b_mrj: agricultural biodiversity matrix.
    agroforestry_x_r: Agroforestry exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    sheep_j = tools.get_sheep_code(data)

    # Only use the dryland version of sheep
    sheep_biodiv = ag_b_mrj[0, :, sheep_j]
    base_agroforestry_biodiv = get_biodiv_agroforestry_base(data)

    # Calculate contributions and return the sum
    agroforestry_contr = base_agroforestry_biodiv * agroforestry_x_r
    sheep_contr = sheep_biodiv * (1 - agroforestry_x_r)
    return agroforestry_contr + sheep_contr


def get_biodiv_beef_agroforestry(
    data: Data, 
    ag_b_mrj: np.ndarray, 
    agroforestry_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    ag_b_mrj: agricultural biodiversity matrix.
    agroforestry_x_r: Agroforestry exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    beef_j = tools.get_beef_code(data)

    # Only use the dryland version of beef
    beef_biodiv = ag_b_mrj[0, :, beef_j]
    base_agroforestry_biodiv = get_biodiv_agroforestry_base(data)

    # Calculate contributions and return the sum
    agroforestry_contr = base_agroforestry_biodiv * agroforestry_x_r
    beef_contr = beef_biodiv * (1 - agroforestry_x_r)
    return agroforestry_contr + beef_contr


def get_biodiv_carbon_plantings_block(data: Data) -> np.ndarray:
    return data.BIO_CONNECTIVITY_RAW * data.REAL_AREA * BIO_CONTRIBUTION_CARBON_PLANTING_BLOCK


def get_biodiv_carbon_plantings_belt_base(data: Data) -> np.ndarray:
    return data.BIO_CONNECTIVITY_RAW * data.REAL_AREA * BIO_CONTRIBUTION_CARBON_PLANTING_BELT


def get_biodiv_sheep_carbon_plantings_belt(
    data: Data, 
    ag_b_mrj: np.ndarray, 
    cp_belt_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    ag_b_mrj: agricultural biodiversity matrix.
    cp_belt_x_r: Carbon plantings belt exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    sheep_j = tools.get_sheep_code(data)

    # Only use the dryland version of sheep
    sheep_biodiv = ag_b_mrj[0, :, sheep_j]
    base_cp_biodiv = get_biodiv_carbon_plantings_belt_base(data)

    # Calculate contributions and return the sum
    cp_contr = base_cp_biodiv * cp_belt_x_r
    sheep_contr = sheep_biodiv * (1 - cp_belt_x_r)
    return cp_contr + sheep_contr


def get_biodiv_beef_carbon_plantings_belt(
    data: Data, 
    ag_b_mrj: np.ndarray, 
    cp_belt_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    ag_b_mrj: agricultural biodiversity matrix.
    cp_belt_x_r: Carbon plantings belt exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    beef_j = tools.get_beef_code(data)

    # Only use the dryland version of beef
    beef_biodiv = ag_b_mrj[0, :, beef_j]
    base_cp_biodiv = get_biodiv_carbon_plantings_belt_base(data)

    # Calculate contributions and return the sum
    cp_contr = base_cp_biodiv * cp_belt_x_r
    beef_contr = beef_biodiv * (1 - cp_belt_x_r)
    return cp_contr + beef_contr


def get_biodiv_beccs(data: Data):
    """
    Parameters
    ------
    data: Data object.

    Returns
    ------
    Numpy array indexed by r
    """
    return data.BIO_CONNECTIVITY_RAW * data.REAL_AREA * BIO_CONTRIBUTION_BECCS


def get_biodiv_destocked_land(data: Data, lumap: np.ndarray):
    """
    Parameters
    ------
    data: Data object.
    ag_b_mrj: agricultural biodiversity matrix.
    lumap: Land use map of the previous year.

    Returns
    ------
    Numpy array indexed by r
    """
    destock_b_contr = np.zeros(data.NCELLS)
    to_lu = data.DESC2AGLU['Unallocated - natural land']

    for from_lu in data.LU_LVSTK_NATURAL:
        destock_b_contr[lumap == from_lu] = (
            data.BIO_CONNECTIVITY_RAW[lumap == from_lu] 
            * (data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[to_lu] - data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[from_lu])
            * data.REAL_AREA[lumap == from_lu]
        )
        
    return destock_b_contr


def get_breq_matrix(data: Data, ag_b_mrj: np.ndarray, lumap: np.ndarray):
    """
    Returns non-agricultural c_rk matrix of costs per cell and land use.

    Parameters
    - data: The input data object containing necessary information.
    - ag_b_mrj: Agricultural biodiversity matrix.
    - lumap: Land use map of the previous year.

    Returns
    - numpy.ndarray: The non-agricultural c_rk matrix of costs per cell and land use.
    """
    agroforestry_x_r = tools.get_exclusions_agroforestry_base(data, lumap)
    cp_belt_x_r = tools.get_exclusions_carbon_plantings_belt_base(data, lumap)

    # reshape each non-agricultural matrix to be indexed (r, k) and concatenate on the k indexing
    non_agr_b_matrices = [
        get_biodiv_environmental_plantings(data),
        get_biodiv_riparian_plantings(data),
        get_biodiv_sheep_agroforestry(data, ag_b_mrj, agroforestry_x_r),
        get_biodiv_beef_agroforestry(data, ag_b_mrj, agroforestry_x_r),
        get_biodiv_carbon_plantings_block(data),
        get_biodiv_sheep_carbon_plantings_belt(data, ag_b_mrj, cp_belt_x_r),
        get_biodiv_beef_carbon_plantings_belt(data, ag_b_mrj, cp_belt_x_r),
        get_biodiv_beccs(data),                                               
        get_biodiv_destocked_land(data, lumap)
    ]

    return np.concatenate([
        arr.reshape((data.NCELLS, 1)) for arr in non_agr_b_matrices], 
        axis=1
    )



def get_non_ag_lu_biodiv_contribution(data: Data) -> dict[int, float]:
    return {
        # Environmental plantings
        0: BIO_CONTRIBUTION_ENV_PLANTING,
        # Riparian plantings
        1: BIO_CONTRIBUTION_RIPARIAN_PLANTING,
        # Sheep agroforestry
        2: (
            AF_PROPORTION * BIO_CONTRIBUTION_AGROFORESTRY
            + (1 - AF_PROPORTION) * (data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[tools.get_sheep_code(data)])
        ),
        # Beef agroforestry
        3: (
            AF_PROPORTION * BIO_CONTRIBUTION_AGROFORESTRY
            + (1 - AF_PROPORTION) * (data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[tools.get_beef_code(data)])
        ),
        # Carbon plantings (block)
        4: BIO_CONTRIBUTION_CARBON_PLANTING_BLOCK,
        # Sheep carbon plantings (belt)
        5: (
            CP_BELT_PROPORTION * BIO_CONTRIBUTION_AGROFORESTRY
            + (1 - CP_BELT_PROPORTION) * (data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[tools.get_sheep_code(data)])
        ),
        # Beef carbon plantings (belt)
        6: (
            CP_BELT_PROPORTION * BIO_CONTRIBUTION_AGROFORESTRY
            + (1 - CP_BELT_PROPORTION) * (data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[tools.get_beef_code(data)])
        ),
        # BECCS
        7: BIO_CONTRIBUTION_BECCS,
        # Destocked land
        8: data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[tools.get_unallocated_natural_land_code(data)],
    }
```

## luto/economics/non_agricultural/cost.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import numpy as np

from luto.data import Data
import luto.settings as settings
from luto.settings import NON_AG_LAND_USES
from luto import tools


def get_cost_env_plantings(data: Data, yr_cal: int) -> np.ndarray:
    """
    Parameters
    ----------
    data: Data object.

    Returns
    -------
    np.ndarray
        Cost of environmental plantings for each cell. 1-D array Indexed by cell.
    """
    cost_per_ha_per_year = (
        settings.EP_ANNUAL_MAINTENANCE_COST_PER_HA_PER_YEAR * data.MAINT_COST_MULTS[yr_cal]
        - settings.EP_ANNUAL_ECOSYSTEM_SERVICES_BENEFIT_PER_HA_PER_YEAR
    )
    return cost_per_ha_per_year * data.REAL_AREA


def get_cost_rip_plantings(data: Data, yr_cal: int) -> np.ndarray:
    """
    Parameters
    ----------
    data: Data object.

    Returns
    -------
    np.ndarray
        Cost of riparian plantings for each cell. 1-D array Indexed by cell.
    """
    cost_per_ha_per_year = (
        settings.RP_ANNUAL_MAINTENANCE_COST_PER_HA_PER_YEAR * data.MAINT_COST_MULTS[yr_cal]
        - settings.RP_ANNUAL_ECOSYSTEM_SERVICES_BENEFIT_PER_HA_PER_YEAR
    )
    return cost_per_ha_per_year * data.REAL_AREA 


def get_cost_agroforestry_base(data: Data, yr_cal: int) -> np.ndarray:
    """
    Parameters
    ----------
    data: Data object.

    Returns
    -------
    np.ndarray
        Cost of agroforestry for each cell. 1-D array Indexed by cell.
    """
    cost_per_ha_per_year = (
        settings.AF_ANNUAL_MAINTENANCE_COST_PER_HA_PER_YEAR * data.MAINT_COST_MULTS[yr_cal]
        - settings.AF_ANNUAL_ECOSYSTEM_SERVICES_BENEFIT_PER_HA_PER_YEAR
    )
    return cost_per_ha_per_year * data.REAL_AREA


def get_cost_sheep_agroforestry(
    data: Data,
    yr_cal: int,
    ag_c_mrj: np.ndarray, 
    agroforestry_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    ag_c_mrj: agricultural cost matrix.
    agroforestry_x_r: Agroforestry exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    sheep_j = tools.get_sheep_code(data)

    # Only use the dryland version of sheep
    sheep_cost = ag_c_mrj[0, :, sheep_j]
    base_agroforestry_cost = get_cost_agroforestry_base(data, yr_cal)

    # Calculate contributions and return the sum
    agroforestry_contr = base_agroforestry_cost * agroforestry_x_r
    sheep_contr = sheep_cost * (1 - agroforestry_x_r)
    return agroforestry_contr + sheep_contr


def get_cost_beef_agroforestry(
    data: Data,
    yr_cal: int,
    ag_c_mrj: np.ndarray, 
    agroforestry_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    ag_c_mrj: agricultural cost matrix.
    agroforestry_x_r: Agroforestry exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    beef_j = tools.get_beef_code(data)

    # Only use the dryland version of beef
    beef_cost = ag_c_mrj[0, :, beef_j]
    base_agroforestry_cost = get_cost_agroforestry_base(data, yr_cal)

    # Calculate contributions and return the sum
    agroforestry_contr = base_agroforestry_cost * agroforestry_x_r
    beef_contr = beef_cost * (1 - agroforestry_x_r)
    return agroforestry_contr + beef_contr


def get_cost_carbon_plantings_block(data: Data, yr_cal: int) -> np.ndarray:
    """
    Parameters
    ----------
    data: object/module
        Data object or module with fields like in `luto.data`.

    Returns
    -------
    np.ndarray
        Cost of carbon plantings (block arrangement) for each cell. 1-D array Indexed by cell.
    """
    cost_per_ha_per_year = (
        settings.CP_BLOCK_ANNUAL_MAINTENANCE_COST_PER_HA_PER_YEAR * data.MAINT_COST_MULTS[yr_cal]
        - settings.CP_BLOCK_ANNUAL_ECOSYSTEM_SERVICES_BENEFIT_PER_HA_PER_YEAR
    )
    return cost_per_ha_per_year * data.REAL_AREA


def get_cost_carbon_plantings_belt_base(data: Data, yr_cal) -> np.ndarray:
    """
    Parameters
    ----------
    data: Data object.

    Returns
    -------
    np.ndarray
        Cost of carbon plantings (belt arrangement) for each cell. 1-D array Indexed by cell.
    """
    cost_per_ha_per_year = (
        settings.CP_BELT_ANNUAL_MAINTENANCE_COST_PER_HA_PER_YEAR * data.MAINT_COST_MULTS[yr_cal]
        - settings.CP_BELT_ANNUAL_ECOSYSTEM_SERVICES_BENEFIT_PER_HA_PER_YEAR
    )
    return cost_per_ha_per_year * data.REAL_AREA


def get_cost_sheep_carbon_plantings_belt(
    data: Data,
    yr_cal: int,
    ag_c_mrj: np.ndarray, 
    cp_belt_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    ag_c_mrj: agricultural cost matrix.
    cp_belt_x_r: Carbon plantings belt exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    sheep_j = tools.get_sheep_code(data)

    # Only use the dryland version of sheep
    sheep_cost = ag_c_mrj[0, :, sheep_j]
    base_cp_cost = get_cost_carbon_plantings_belt_base(data, yr_cal)

    # Calculate contributions and return the sum
    cp_contr = base_cp_cost * cp_belt_x_r
    sheep_contr = sheep_cost * (1 - cp_belt_x_r)
    return cp_contr + sheep_contr


def get_cost_beef_carbon_plantings_belt(
    data: Data,
    yr_cal: int,
    ag_c_mrj: np.ndarray, 
    cp_belt_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    ag_c_mrj: agricultural cost matrix.
    cp_belt_x_r: Carbon plantings belt exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    beef_j = tools.get_beef_code(data)

    # Only use the dryland version of beef
    beef_cost = ag_c_mrj[0, :, beef_j]
    base_cp_cost = get_cost_carbon_plantings_belt_base(data, yr_cal)

    # Calculate contributions and return the sum
    cp_contr = base_cp_cost * cp_belt_x_r
    beef_contr = beef_cost * (1 - cp_belt_x_r)
    return cp_contr + beef_contr


def get_cost_beccs(data: Data, yr_cal: int) -> np.ndarray:
    """
    Parameters
    ----------
    data: Data object.

    Returns
    -------
    np.ndarray
        Cost of BECCS for each cell. 1-D array Indexed by cell.
    """
    return np.nan_to_num(data.BECCS_COSTS_AUD_HA_YR) * data.BECCS_COST_MULTS[yr_cal] * data.REAL_AREA


def get_cost_destocked(data: Data, yr_cal: int) -> np.ndarray:
    """
    Parameters
    ----------
    data: Data object.

    Returns
    -------
    np.ndarray
        Cost of maintaining destocked land for each cell. Equivalent to maintaining environmental plantings.
    Returns
        1-D array Indexed by cell.
    """
    return settings.EP_ANNUAL_MAINTENANCE_COST_PER_HA_PER_YEAR * data.MAINT_COST_MULTS[yr_cal] * data.REAL_AREA


def get_cost_matrix(data:Data, ag_c_mrj:np.ndarray, lumap:np.ndarray, yr_cal:int) -> np.ndarray:
    """
    Returns non-agricultural c_rk matrix of costs per cell and land use.

    Parameters
    - data: The input data containing information about the cells and land use.

    Returns
    - cost_matrix: A 2D numpy array of costs per cell and land use.
    """
    agroforestry_x_r = tools.get_exclusions_agroforestry_base(data, lumap)
    cp_belt_x_r = tools.get_exclusions_carbon_plantings_belt_base(data, lumap)

    # reshape each non-agricultural matrix to be indexed (r, k) and concatenate on the k indexing
    non_agr_c_matrices = [
        get_cost_env_plantings(data, yr_cal),
        get_cost_rip_plantings(data, yr_cal),
        get_cost_sheep_agroforestry(data, yr_cal, ag_c_mrj, agroforestry_x_r),
        get_cost_beef_agroforestry(data, yr_cal, ag_c_mrj, agroforestry_x_r),
        get_cost_carbon_plantings_block(data, yr_cal),
        get_cost_sheep_carbon_plantings_belt(data, yr_cal, ag_c_mrj, cp_belt_x_r),
        get_cost_beef_carbon_plantings_belt(data, yr_cal, ag_c_mrj, cp_belt_x_r),
        get_cost_beccs(data, yr_cal),                                               
        get_cost_destocked(data, yr_cal)
    ]

    return np.concatenate(
        [arr.reshape((data.NCELLS, 1)) for arr in non_agr_c_matrices],
        axis=1
    )
```

## luto/economics/non_agricultural/ghg.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import numpy as np
import pandas as pd
import luto.settings as settings

from luto.data import Data
from luto import tools



def get_ghg_env_plantings(data: Data, aggregate) -> np.ndarray|pd.DataFrame:
    """
    Parameters
    ----------
    data: Data object.

    Returns
    -------
    if aggregate == True (default)  -> np.ndarray
       aggregate == False           -> pd.DataFrame
    
    Greenhouse gas emissions of environmental plantings for each cell.
    Since environmental plantings reduces carbon in the air, each value will be <= 0.
    """
    
    # Tonnes of CO2e per ha, adjusted for resfactor
    if aggregate==True:
        return -data.EP_BLOCK_AVG_T_CO2_HA * data.REAL_AREA
    elif aggregate==False:
        return pd.DataFrame(-data.EP_BLOCK_AVG_T_CO2_HA * data.REAL_AREA, columns=['ENV_PLANTINGS'])
    else:
        # If the aggregate arguments is not in [True,False]. That must be someting wrong
        raise KeyError(f"Aggregate '{aggregate} can be only specified as [True,False]" )


def get_ghg_rip_plantings(data: Data, aggregate) -> np.ndarray|pd.DataFrame:
    """
    Parameters
    ----------
    data: Data object.

    Returns
    -------
    if aggregate == True (default)  -> np.ndarray
       aggregate == False           -> pd.DataFrame
    
    Greenhouse gas emissions of Riparian Plantings for each cell. Same as environmental plantings.
    Since riparian plantings reduces carbon in the air, each value will be <= 0.
    """

    # Tonnes of CO2e per ha, adjusted for resfactor
    if aggregate==True:
        return -data.EP_RIP_AVG_T_CO2_HA * data.REAL_AREA
    elif aggregate==False:
        return pd.DataFrame(-data.EP_RIP_AVG_T_CO2_HA * data.REAL_AREA, columns=['RIP_PLANTINGS'])
    else:
        raise KeyError(f"Aggregate '{aggregate} can be only specified as [True,False]" )


def get_ghg_agroforestry_base(data: Data) -> np.ndarray:
    """
    Parameters
    ----------
    data: Data object.

    Returns
    -------
    np.ndarray
    
    Greenhouse gas emissions of agroforestry for each cell.
    Since agroforestry reduces carbon in the air, each value will be <= 0.
    """
    
    # Tonnes of CO2e per ha, adjusted for resfactor
    return -data.EP_BELT_AVG_T_CO2_HA * data.REAL_AREA
    

def get_ghg_sheep_agroforestry(
    data: Data,
    ag_g_mrj: np.ndarray, 
    agroforestry_x_r: np.ndarray,
    aggregate: bool,
) -> np.ndarray|pd.DataFrame:
    """
    Parameters
    ------
    data: Data object.
    aggregate: boolean governing whether to aggregate data or not.
    ag_g_mrj: agricultural GHG matrix.
    agroforestry_x_r: Agroforestry exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    sheep_j = tools.get_sheep_code(data)

    # Only use the dryland version of sheep
    sheep_cost = ag_g_mrj[0, :, sheep_j]
    base_agroforestry_cost = get_ghg_agroforestry_base(data)

    # Calculate contributions and return the sum
    agroforestry_contr = base_agroforestry_cost * agroforestry_x_r
    sheep_contr = sheep_cost * (1 - agroforestry_x_r)
    ghg_total = agroforestry_contr + sheep_contr

    if aggregate==True:
        return ghg_total
    elif aggregate==False:
        return pd.DataFrame(ghg_total, columns=['SHEEP_AGROFORESTRY'])
    else:
        raise KeyError(f"Aggregate '{aggregate} can be only specified as [True,False]" )
    

def get_ghg_beef_agroforestry(
    data: Data,
    ag_g_mrj: np.ndarray, 
    agroforestry_x_r: np.ndarray,
    aggregate: bool,
) -> np.ndarray|pd.DataFrame:
    """
    Parameters
    ------
    data: Data object.
    aggregate: boolean governing whether to aggregate data or not.
    ag_g_mrj: agricultural GHG matrix.
    agroforestry_x_r: Agroforestry exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    beef_j = tools.get_beef_code(data)

    # Only use the dryland version of beef
    beef_cost = ag_g_mrj[0, :, beef_j]
    base_agroforestry_cost = get_ghg_agroforestry_base(data)

    # Calculate contributions and return the sum
    agroforestry_contr = base_agroforestry_cost * agroforestry_x_r
    beef_contr = beef_cost * (1 - agroforestry_x_r)
    ghg_total = agroforestry_contr + beef_contr

    if aggregate==True:
        return ghg_total
    elif aggregate==False:
        return pd.DataFrame(ghg_total, columns=['BEEF_AGROFORESTRY'])
    else:
        raise KeyError(f"Aggregate '{aggregate} can be only specified as [True,False]" )


def get_ghg_carbon_plantings_block(data, aggregate) -> np.ndarray|pd.DataFrame:
    """
    Parameters
    ----------
    data: object/module
        Data object or module with fields like in `luto.data`.

    Returns
    -------
    if aggregate == True (default)  -> np.ndarray
       aggregate == False           -> pd.DataFrame
    
    Greenhouse gas emissions of carbon plantings (block) for each cell.
    Since carbon plantings reduces carbon in the air, each value will be <= 0.
    """
    
    # Tonnes of CO2e per ha, adjusted for resfactor
    if aggregate==True:
        return -data.CP_BLOCK_AVG_T_CO2_HA * data.REAL_AREA
    elif aggregate==False:
        return pd.DataFrame(-data.CP_BLOCK_AVG_T_CO2_HA * data.REAL_AREA,columns=['CARBON_PLANTINGS_BLOCK'])
    else:
        raise KeyError(f"Aggregate '{aggregate} can be only specified as [True,False]" )
    

def get_ghg_carbon_plantings_belt_base(data) -> np.ndarray:
    """
    Parameters
    ----------
    data: object/module
        Data object or module with fields like in `luto.data`.

    Returns
    -------
    np.ndarray
    
    Greenhouse gas emissions of carbon plantings (belt) for each cell.
    Since carbon plantings reduces carbon in the air, each value will be <= 0.
    """
    # Tonnes of CO2e per ha, adjusted for resfactor
    return -data.CP_BELT_AVG_T_CO2_HA * data.REAL_AREA
    

def get_ghg_sheep_carbon_plantings_belt(
    data: Data,
    ag_g_mrj: np.ndarray, 
    cp_belt_x_r: np.ndarray,
    aggregate: bool,
) -> np.ndarray|pd.DataFrame:
    """
    Parameters
    ------
    data: Data object.
    aggregate: boolean governing whether to aggregate data or not.
    ag_g_mrj: agricultural GHG matrix.
    cp_belt_x_r: Carbon plantings belt exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    sheep_j = tools.get_sheep_code(data)

    # Only use the dryland version of sheep
    sheep_cost = ag_g_mrj[0, :, sheep_j]
    base_cp_cost = get_ghg_carbon_plantings_belt_base(data)

    # Calculate contributions and return the sum
    cp_contr = base_cp_cost * cp_belt_x_r
    sheep_contr = sheep_cost * (1 - cp_belt_x_r)
    ghg_total = cp_contr + sheep_contr

    if aggregate==True:
        return ghg_total
    elif aggregate==False:
        return pd.DataFrame(ghg_total,columns=['SHEEP_CARBON_PLANTINGS_BELT'])
    else:
        raise KeyError(f"Aggregate '{aggregate} can be only specified as [True,False]" )


def get_ghg_beef_carbon_plantings_belt(
    data: Data,
    ag_g_mrj: np.ndarray, 
    cp_belt_x_r: np.ndarray,
    aggregate: bool,
) -> np.ndarray|pd.DataFrame:
    """
    Parameters
    ------
    data: Data object.
    aggregate: boolean governing whether to aggregate data or not.
    ag_g_mrj: agricultural GHG matrix.
    cp_belt_x_r: Carbon plantings belt exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    beef_j = tools.get_beef_code(data)

    # Only use the dryland version of beef
    beef_cost = ag_g_mrj[0, :, beef_j]
    base_cp_cost = get_ghg_carbon_plantings_belt_base(data)

    # Calculate contributions and return the sum
    cp_contr = base_cp_cost * cp_belt_x_r
    beef_contr = beef_cost * (1 - cp_belt_x_r)
    ghg_total = cp_contr + beef_contr

    if aggregate==True:
        return ghg_total
    elif aggregate==False:
        return pd.DataFrame(ghg_total,columns=['SHEEP_CARBON_PLANTINGS_BELT'])
    else:
        raise KeyError(f"Aggregate '{aggregate} can be only specified as [True,False]" )


def get_ghg_beccs(data, aggregate) -> np.ndarray|pd.DataFrame:
    """
    Calculate the greenhouse gas emissions of BECCS for each cell.
    
    Parameters
    ----------
    data: object/module
        Data object or module with fields like in `luto.data`.

    Returns
    -------
    if aggregate == True (default)  -> np.ndarray
       aggregate == False           -> pd.DataFrame
    """

    # Tonnes of CO2e per ha, adjusted for resfactor
    if aggregate==True:
        return -np.nan_to_num(data.BECCS_TCO2E_HA_YR) * data.REAL_AREA
    elif aggregate==False:
        return pd.DataFrame(-np.nan_to_num(data.BECCS_TCO2E_HA_YR) * data.REAL_AREA, columns=['BECCS'])
    else:
        raise KeyError(f"Aggregate '{aggregate} can be only specified as [True,False]" )
    

def get_ghg_destocked_land(
    data: Data,
    lumap: np.ndarray,
    aggregate: bool = True,
) -> np.ndarray:
    """
    Calculate the greenhouse gas emissions of Destocked land for each cell. Note, only cells that are 
    livestock - natural land in the BASE_YR (2010) and then converted into unallowcated - natural land 
    in the target year are 'destocked'.
    
    Parameters
    ----------
    data: object/module
        Data object or module with fields like in `luto.data`.

    Returns
    -------
    if aggregate == True (default)  -> np.ndarray
       aggregate == False           -> pd.DataFrame
    """
    # Only cells that are livestock - natural land in the BASE_YR (2010) and then converted into unallowcated - natural land in the target year are 'destocked'.
    lumap_BASE_YR = data.lumaps[data.YR_CAL_BASE]
    penalty_ghg_r = np.zeros(data.NCELLS)
    
    for from_lu in data.LU_LVSTK_NATURAL:
        penalty_ghg_r[lumap_BASE_YR == from_lu] = (
            data.CO2E_STOCK_UNALL_NATURAL[lumap_BASE_YR == from_lu]
            * (data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[from_lu] - 1)
            * data.REAL_AREA[lumap_BASE_YR == from_lu]
            / settings.HIR_EFFECT_YEARS    # Annualise carbon sequestration capacity to align the full grwoth span of a tree
        )

    if aggregate==True:
        return penalty_ghg_r
    elif aggregate==False:
        return pd.DataFrame(penalty_ghg_r, columns=['DESTOCKED_LAND'])
    else:
        # If the aggregate arguments is not in [True,False]. That must be someting wrong
        raise KeyError(f"Aggregate '{aggregate} can be only specified as [True,False]" )



def get_ghg_matrix(data: Data, ag_g_mrj, lumap, aggregate=True) -> np.ndarray:
    """
    Get the g_rk matrix containing non-agricultural greenhouse gas emissions.

    Parameters
    - data: The input data for calculating greenhouse gas emissions.
    - aggregate: A boolean flag indicating whether to aggregate the matrices or not. Default is True.

    Returns
    - If aggregate is True, returns a numpy ndarray representing the aggregated g_rk matrix.
    - If aggregate is False, returns a pandas DataFrame representing the g_rk matrix.

    Raises:
    - KeyError: If the aggregate argument is not a boolean value.

    Note:
    - The function internally calls several other functions to calculate different components of the g_rk matrix.
    """

    agroforestry_x_r = tools.get_exclusions_agroforestry_base(data, lumap)
    cp_belt_x_r = tools.get_exclusions_carbon_plantings_belt_base(data, lumap)

    non_agr_ghg_matrices = {}

    # reshape each non-agricultural matrix to be indexed (r, k) and concatenate on the k indexing
    non_agr_ghg_matrices['Environmental Plantings'] = get_ghg_env_plantings(data, aggregate)                                                
    non_agr_ghg_matrices['Riparian Plantings'] = get_ghg_rip_plantings(data, aggregate)                                                     
    non_agr_ghg_matrices['Sheep Agroforestry'] = get_ghg_sheep_agroforestry(data, ag_g_mrj, agroforestry_x_r, aggregate)                    
    non_agr_ghg_matrices['Beef Agroforestry'] = get_ghg_beef_agroforestry(data, ag_g_mrj, agroforestry_x_r, aggregate)                      
    non_agr_ghg_matrices['Carbon Plantings (Block)'] = get_ghg_carbon_plantings_block(data, aggregate)                                      
    non_agr_ghg_matrices['Sheep Carbon Plantings (Belt)'] = get_ghg_sheep_carbon_plantings_belt(data, ag_g_mrj, cp_belt_x_r, aggregate) 
    non_agr_ghg_matrices['Beef Carbon Plantings (Belt)'] = get_ghg_beef_carbon_plantings_belt(data, ag_g_mrj, cp_belt_x_r, aggregate)       
    non_agr_ghg_matrices['BECCS'] = get_ghg_beccs(data, aggregate)                                                                          
    non_agr_ghg_matrices['Destocked - natural land'] = get_ghg_destocked_land(data, lumap, aggregate)                                       
      
    if aggregate==True:
        # reshape each non-agricultural matrix to be indexed (r, k) and concatenate on the k indexing
        non_agr_ghg_matrices = [
            non_agr_ghg_matrix.reshape((data.NCELLS, 1)) for non_agr_ghg_matrix in non_agr_ghg_matrices.values()
        ]
        return np.concatenate(non_agr_ghg_matrices, axis=1)
    
    elif aggregate==False:
        return pd.concat(list(non_agr_ghg_matrices.values()), axis=1)
    else:
        # If the aggregate arguments is not in [True,False]. That must be someting wrong
        raise KeyError(f"Aggregate '{aggregate} can be only specified as [True,False]" )
```

## luto/economics/non_agricultural/quantity.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import numpy as np

from luto import tools
from copy import deepcopy
from luto import settings


def get_sheep_q_cr(data, ag_q_mrp: np.ndarray) -> np.ndarray:
    """
    Gets the matrix containing the commodities produced by sheep (modified land) 
    """
    sheep_j = tools.get_sheep_code(data)

    sheep_p = []
    for p in range(data.NPRS):
        if data.LU2PR[p, sheep_j]:
            sheep_p.append(p)

    sheep_q_cr = np.zeros((data.NCMS, data.NCELLS)).astype(np.float32)
    for c in range(data.NCMS):
        for p in sheep_p:
            if data.PR2CM[c, p]:
                sheep_q_cr[c, :] += ag_q_mrp[0, :, p]

    return sheep_q_cr
        

def get_beef_q_cr(data, ag_q_mrp: np.ndarray) -> np.ndarray:
    """
    Gets the matrix containing the commodities produced by beef (modified land) 
    """
    beef_j = tools.get_beef_code(data)

    beef_p = []
    for p in range(data.NPRS):
        if data.LU2PR[p, beef_j]:
            beef_p.append(p)

    beef_q_cr = np.zeros((data.NCMS, data.NCELLS)).astype(np.float32)
    for p in beef_p:
        for c in range(data.NCMS):
            if data.PR2CM[c, p]:
                beef_q_cr[c, :] += ag_q_mrp[0, :, p]

    return beef_q_cr


def get_quantity_env_plantings(data) -> np.ndarray:
    """
    Parameters
    ----------
    data: Data object.

    Returns
    -------
    np.ndarray
        Indexed by (c, r): represents the quantity commodity c produced by cell r
        if used for environmental plantings.
        A matrix of zeros because environmental plantings doesn't produce anything.
    """
    return np.zeros((data.NCMS, data.NCELLS)).astype(np.float32)


def get_quantity_rip_plantings(data) -> np.ndarray:
    """
    Parameters
    ----------
    data: Data object.

    Returns
    -------
    np.ndarray
        Indexed by (c, r): represents the quantity commodity c produced by cell r
        if used for riparian plantings.
        A matrix of zeros because Riparian Plantings doesn't produce anything.
    """

    return np.zeros((data.NCMS, data.NCELLS)).astype(np.float32)


def get_quantity_agroforestry_base(data) -> np.ndarray:
    """
    Parameters
    ----------
    data: Data object.

    Returns
    -------
    np.ndarray
        Indexed by (c, r): represents the quantity commodity c produced by cell r
        if used for agroforestry.
        A matrix of zeros because agroforestry doesn't produce anything.
    """

    return np.zeros((data.NCMS, data.NCELLS)).astype(np.float32)


def get_quantity_sheep_agroforestry(
    data,
    ag_q_mrp: np.ndarray, 
    agroforestry_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    ag_c_mrj: agricultural cost matrix.
    agroforestry_x_r: Agroforestry exclude matrix.

    Returns
    ------
    Numpy array indexed by (c, r)
    """
    sheep_quantity_cr = get_sheep_q_cr(data, ag_q_mrp)    
    base_agroforestry_quantity_cr = get_quantity_agroforestry_base(data)

    # Calculate contributions and return the sum
    agroforestry_contr = deepcopy(base_agroforestry_quantity_cr)
    for c in range(data.NCMS):
        agroforestry_contr[c, :] *= agroforestry_x_r

    sheep_contr = deepcopy(sheep_quantity_cr)
    for c in range(data.NCMS):
        sheep_contr[c, :] *= (1 - agroforestry_x_r)

    return agroforestry_contr + sheep_contr


def get_quantity_beef_agroforestry(
    data, 
    ag_q_mrp: np.ndarray, 
    agroforestry_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    ag_c_mrj: agricultural cost matrix.
    agroforestry_x_r: Agroforestry exclude matrix.

    Returns
    ------
    Numpy array indexed by (c, r)
    """
    beef_quantity_cr = get_beef_q_cr(data, ag_q_mrp)    
    base_agroforestry_quantity_cr = get_quantity_agroforestry_base(data)

    # Calculate contributions and return the sum
    agroforestry_contr = deepcopy(base_agroforestry_quantity_cr)
    for c in range(data.NCMS):
        agroforestry_contr[c, :] *= agroforestry_x_r

    beef_contr = deepcopy(beef_quantity_cr)
    for c in range(data.NCMS):
        beef_contr[c, :] *= (1 - agroforestry_x_r)

    return agroforestry_contr + beef_contr


def get_quantity_carbon_plantings_block(data) -> np.ndarray:
    """
    Parameters
    ----------
    data: object/module
        Data object or module with fields like in `luto.data`.

    Returns
    -------
    np.ndarray
        Indexed by (c, r): represents the quantity commodity c produced by cell r
        if used for carbon plantings (block).
        A matrix of zeros because carbon plantings doesn't produce anything.
    """
    return np.zeros((data.NCMS, data.NCELLS)).astype(np.float32)


def get_quantity_carbon_plantings_belt_base(data) -> np.ndarray:
    """
    Parameters
    ----------
    data: object/module
        Data object or module with fields like in `luto.data`.

    Returns
    -------
    np.ndarray
        Indexed by (c, r): represents the quantity commodity c produced by cell r
        if used for carbon plantings (belt).
        A matrix of zeros because carbon plantings doesn't produce anything.
    """
    return np.zeros((data.NCMS, data.NCELLS)).astype(np.float32)


def get_quantity_sheep_carbon_plantings_belt(
    data, 
    ag_q_mrp: np.ndarray, 
    cp_belt_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    ag_c_mrj: agricultural cost matrix.
    cp_belt_x_r: Carbon plantings belt exclude matrix.

    Returns
    ------
    Numpy array indexed by (c, r)
    """
    sheep_quantity_cr = get_sheep_q_cr(data, ag_q_mrp)    
    base_cp_quantity_cr = get_quantity_carbon_plantings_belt_base(data)

    # Calculate contributions and return the sum
    cp_contr = deepcopy(base_cp_quantity_cr)
    for c in range(data.NCMS):
        cp_contr[c, :] *= cp_belt_x_r

    sheep_contr = deepcopy(sheep_quantity_cr)
    for c in range(data.NCMS):
        sheep_contr[c, :] *= (1 - cp_belt_x_r)

    return cp_contr + sheep_contr


def get_quantity_beef_carbon_plantings_belt(
    data, 
    ag_q_mrp: np.ndarray, 
    cp_belt_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    ag_c_mrj: agricultural cost matrix.
    cp_belt_x_r: Carbon plantings belt exclude matrix.

    Returns
    ------
    Numpy array indexed by (c, r)
    """
    beef_quantity_cr = get_beef_q_cr(data, ag_q_mrp)    
    base_cp_quantity_cr = get_quantity_carbon_plantings_belt_base(data)

    # Calculate contributions and return the sum
    cp_contr = deepcopy(base_cp_quantity_cr)
    for c in range(data.NCMS):
        cp_contr[c, :] *= cp_belt_x_r

    beef_contr = deepcopy(beef_quantity_cr)
    for c in range(data.NCMS):
        beef_contr[c, :] *= (1 - cp_belt_x_r)

    return cp_contr + beef_contr


def get_quantity_beccs(data) -> np.ndarray:
    """
    Parameters
    ----------
    data: object/module
        Data object or module with fields like in `luto.data`.

    Returns
    -------
    np.ndarray
        Indexed by (c, r): represents the quantity commodity c produced by cell r
        if used for BECCS.
        A matrix of zeros because BECCS doesn't produce anything.
    """
    return np.zeros((data.NCMS, data.NCELLS)).astype(np.float32)


def get_quantity_destocked(data) -> np.ndarray:
    """
    Parameters
    ----------
    data: object/module
        Data object or module with fields like in `luto.data`.

    Returns
    -------
    np.ndarray
        Indexed by (c, r): represents the quantity commodity c produced by cell r
        if used for Destocked land.
        A matrix of zeros because destocked land doesn't produce anything.
    """
    return np.zeros((data.NCMS, data.NCELLS)).astype(np.float32)


def get_quantity_matrix(data, ag_q_mrp: np.ndarray, lumap: np.ndarray) -> np.ndarray:
    """
    Get the non-agricultural quantity matrix q_crk.
    Values represent the yield of each commodity c from the cell r when using
    the non-agricultural land use k.

    Parameters
    - data: The input data containing information about the land use and commodities.

    Returns
    - np.ndarray: The non-agricultural quantity matrix q_crk.
    """
    agroforestry_x_r = tools.get_exclusions_agroforestry_base(data, lumap)
    cp_belt_x_r = tools.get_exclusions_carbon_plantings_belt_base(data, lumap)
    
    # reshape each non-agricultural quantity matrix to be indexed (c, r, 1) and concatenate on the k indexing
    non_agr_quantity_matrices = [
        get_quantity_env_plantings(data),
        get_quantity_rip_plantings(data),
        get_quantity_sheep_agroforestry(data, ag_q_mrp, agroforestry_x_r),
        get_quantity_beef_agroforestry(data, ag_q_mrp, agroforestry_x_r),
        get_quantity_carbon_plantings_block(data),
        get_quantity_sheep_carbon_plantings_belt(data, ag_q_mrp, cp_belt_x_r),
        get_quantity_beef_carbon_plantings_belt(data, ag_q_mrp, cp_belt_x_r),
        get_quantity_beccs(data),
        get_quantity_destocked(data),
    ]

    return np.concatenate(
        [arr.reshape((data.NCMS, data.NCELLS, 1)) for arr in non_agr_quantity_matrices], 
        axis=2
    )
```

## luto/economics/non_agricultural/revenue.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import numpy as np
from luto.settings import NON_AG_LAND_USES
import luto.settings as settings
from luto.data import Data
from luto import tools


def get_rev_env_plantings(data: Data, yr_cal: int) -> np.ndarray:
    """
    Parameters
    ----------
    data: Data object.

    Returns
    -------
    np.ndarray
        The revenue produced by environmental plantings for each cell. A 1-D array indexed by cell.
    """
    # Multiply carbon reduction by carbon price for each cell and adjust for resfactor.
    return data.EP_BLOCK_AVG_T_CO2_HA * data.REAL_AREA * data.get_carbon_price_by_year(yr_cal)


def get_rev_rip_plantings(data: Data, yr_cal: int) -> np.ndarray:
    """
    Parameters
    ----------
    data: Data object.

    Note: this is the same as for environmental plantings.

    Returns
    -------
    np.ndarray
        The revenue produced by riparian plantings for each cell. A 1-D array indexed by cell.
    """
    return data.EP_RIP_AVG_T_CO2_HA * data.REAL_AREA * data.get_carbon_price_by_year(yr_cal)


def get_rev_agroforestry_base(data: Data, yr_cal: int) -> np.ndarray:
    """
    Parameters
    ----------
    data: Data object.

    Note: this is the same as for environmental plantings.

    Returns
    -------
    np.ndarray
        The revenue produced by agroforestry for each cell. A 1-D array indexed by cell.
    """
    return data.EP_BELT_AVG_T_CO2_HA * data.REAL_AREA * data.get_carbon_price_by_year(yr_cal)


def get_rev_sheep_agroforestry(
    data: Data, 
    yr_cal: int,
    ag_r_mrj: np.ndarray, 
    agroforestry_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    ag_r_mrj: agricultural revenue matrix.
    agroforestry_x_r: Agroforestry exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    sheep_j = tools.get_sheep_code(data)

    # Only use the dryland version of sheep
    sheep_rev = ag_r_mrj[0, :, sheep_j]
    base_agroforestry_rev = get_rev_agroforestry_base(data, yr_cal)

    # Calculate contributions and return the sum
    agroforestry_contr = base_agroforestry_rev * agroforestry_x_r
    sheep_contr = sheep_rev * (1 - agroforestry_x_r)
    return agroforestry_contr + sheep_contr


def get_rev_beef_agroforestry(
    data: Data, 
    yr_cal: int,
    ag_r_mrj: np.ndarray, 
    agroforestry_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    ag_r_mrj: agricultural revenue matrix.
    agroforestry_x_r: Agroforestry exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    beef_j = tools.get_beef_code(data)

    # Only use the dryland version of beef
    beef_rev = ag_r_mrj[0, :, beef_j]
    base_agroforestry_rev = get_rev_agroforestry_base(data, yr_cal)

    # Calculate contributions and return the sum
    agroforestry_contr = base_agroforestry_rev * agroforestry_x_r
    beef_contr = beef_rev * (1 - agroforestry_x_r)
    return agroforestry_contr + beef_contr


def get_rev_carbon_plantings_block(data: Data, yr_cal: int) -> np.ndarray:
    """
    Parameters
    ----------
    data: object/module
        Data object or module with fields like in `luto.data`.

    Returns
    -------
    np.ndarray
        The cost of carbon plantings (block) for each cell. A 1-D array indexed by cell.
    """
    # Multiply carbon reduction by carbon price for each cell and adjust for resfactor.
    return data.CP_BLOCK_AVG_T_CO2_HA * data.REAL_AREA * data.get_carbon_price_by_year(yr_cal)


def get_rev_carbon_plantings_belt_base(data: Data, yr_cal: int) -> np.ndarray:
    """
    Parameters
    ----------
    data: object/module
        Data object or module with fields like in `luto.data`.

    Returns
    -------
    np.ndarray
        The cost of carbon plantings (belt) for each cell. A 1-D array indexed by cell.
    """
    # Multiply carbon reduction by carbon price for each cell and adjust for resfactor.
    return data.CP_BELT_AVG_T_CO2_HA * data.REAL_AREA * data.get_carbon_price_by_year(yr_cal)


def get_rev_sheep_carbon_plantings_belt(
    data: Data, 
    yr_cal: int,
    ag_r_mrj: np.ndarray, 
    cp_belt_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    yr_cal: year being examined.
    ag_r_mrj: agricultural revenue matrix.
    cp_belt_x_r: Carbon plantings belt exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    sheep_j = tools.get_sheep_code(data)

    # Only use the dryland version of sheep
    sheep_rev = ag_r_mrj[0, :, sheep_j]
    base_cp_rev = get_rev_carbon_plantings_belt_base(data, yr_cal)

    # Calculate contributions and return the sum
    cp_contr = base_cp_rev * cp_belt_x_r
    sheep_contr = sheep_rev * (1 - cp_belt_x_r)
    return cp_contr + sheep_contr


def get_rev_beef_carbon_plantings_belt(
    data: Data, 
    yr_cal: int,
    ag_r_mrj: np.ndarray, 
    cp_belt_x_r: np.ndarray
) -> np.ndarray:
    """
    Parameters
    ------
    data: Data object.
    ag_r_mrj: agricultural revenue matrix.
    cp_belt_x_r: Carbon plantings belt exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    beef_j = tools.get_beef_code(data)

    # Only use the dryland version of beef
    beef_rev = ag_r_mrj[0, :, beef_j]
    base_cp_rev = get_rev_carbon_plantings_belt_base(data, yr_cal)

    # Calculate contributions and return the sum
    cp_contr = base_cp_rev * cp_belt_x_r
    beef_contr = beef_rev * (1 - cp_belt_x_r)
    return cp_contr + beef_contr


def get_rev_beccs(data: Data, yr_cal: int) -> np.ndarray:
    """
    Parameters
    ----------
    data: object/module
        Data object or module with fields like in `luto.data`.

    Returns
    -------
    np.ndarray
    """
    base_rev = np.nan_to_num(data.BECCS_REV_AUD_HA_YR) * data.BECCS_REV_MULTS[yr_cal] * data.REAL_AREA
    return base_rev + np.nan_to_num(data.BECCS_TCO2E_HA_YR) * data.REAL_AREA * data.get_carbon_price_by_year(yr_cal)


def get_rev_destocked(data: Data, ag_r_mrj: np.ndarray) -> np.ndarray:
    """
    Parameters
    ----------
    data: object/module
        Data object or module with fields like in `luto.data`.
    ag_r_mrj: np.ndarray
        Agricultural revenue matrix.

    Returns
    -------
    np.ndarray
    """
    unallocated_j = tools.get_unallocated_natural_land_code(data)
    return ag_r_mrj[0, :, unallocated_j]


def get_rev_matrix(data: Data, yr_cal: int, ag_r_mrj, lumap) -> np.ndarray:
    """
    Gets the matrix containing the revenue produced by each non-agricultural land use for each cell.

    Parameters
        data (Data): The data object containing the necessary information.

    Returns
        np.ndarray.
    """
    agroforestry_x_r = tools.get_exclusions_agroforestry_base(data, lumap)
    cp_belt_x_r = tools.get_exclusions_carbon_plantings_belt_base(data, lumap)

    # reshape each non-agricultural matrix to be indexed (r, k) and concatenate on the k indexing
    non_agr_rev_matrices = [
        get_rev_env_plantings(data, yr_cal),
        get_rev_rip_plantings(data, yr_cal),
        get_rev_sheep_agroforestry(data, yr_cal, ag_r_mrj, agroforestry_x_r),
        get_rev_beef_agroforestry(data, yr_cal, ag_r_mrj, agroforestry_x_r),
        get_rev_carbon_plantings_block(data, yr_cal),
        get_rev_sheep_carbon_plantings_belt(data, yr_cal, ag_r_mrj, cp_belt_x_r),
        get_rev_beef_carbon_plantings_belt(data, yr_cal, ag_r_mrj, cp_belt_x_r),
        get_rev_beccs(data, yr_cal),
        get_rev_destocked(data, ag_r_mrj),
    ]

    return np.concatenate(
        [arr.reshape((data.NCELLS, 1)) for arr in non_agr_rev_matrices],
        axis=1
    )
```

## luto/economics/non_agricultural/transitions.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import numpy as np

from luto import settings
from luto.data import Data
import luto.tools as tools
import luto.economics.agricultural.water as ag_water
import luto.economics.agricultural.ghg as ag_ghg
import luto.economics.agricultural.transitions as ag_transitions


def get_env_plant_transitions_from_ag(data: Data, yr_idx, lumap, lmmap, separate=False) -> np.ndarray|dict:
    """
    Calculate the transition costs for transitioning from agricultural land to environmental plantings.

    Args:
        data (object): The data object containing relevant information.
        yr_idx (int): The index of the year.
        lumap (np.ndarray): The land use map.
        lmmap (np.ndarray): The water supply map.
        separate (bool, optional): Whether to return separate costs or the total cost. Defaults to False.

    Returns
        np.ndarray|dict: The transition costs as either a numpy array or a dictionary, depending on the value of `separate`.
    """
    yr_cal = data.YR_CAL_BASE + yr_idx
    cells = np.isin(lumap, np.array(list(data.AGLU2DESC.keys())))

    # Establishment costs
    est_costs_r = tools.amortise(data.EP_EST_COST_HA * data.REAL_AREA * data.EST_COST_MULTS[yr_cal]).astype(np.float32)
    est_costs_r[~cells] = 0.0
    
    # Transition costs
    ag_to_ep_j = data.T_MAT.sel(from_lu=data.AGRICULTURAL_LANDUSES, to_lu='Environmental Plantings').values
    ag_to_ep_t_r = np.vectorize(dict(enumerate(ag_to_ep_j)).get, otypes=['float32'])(lumap)
    ag_to_ep_t_r = np.nan_to_num(ag_to_ep_t_r)
    ag_to_ep_t_r = tools.amortise(ag_to_ep_t_r * data.REAL_AREA)
    ag_to_ep_t_r[~cells] = 0.0
    
    # Water costs; Assume EP is dryland
    w_rm_irrig_cost_r = np.where(lmmap == 1, settings.REMOVE_IRRIG_COST * data.IRRIG_COST_MULTS[yr_cal], 0) * data.REAL_AREA
    w_rm_irrig_cost_r[~cells] = 0.0

    if separate:
        return {'Establishment cost (Ag2Non-Ag)': est_costs_r,
                'Transition cost (Ag2Non-Ag)': ag_to_ep_t_r, 
                'Remove irrigation cost (Ag2Non-Ag)': w_rm_irrig_cost_r}
    else:   
        return est_costs_r + ag_to_ep_t_r + w_rm_irrig_cost_r


def get_rip_plant_transitions_from_ag(data: Data, yr_idx, lumap, lmmap, separate=False) -> np.ndarray|dict:
    """
    Get transition costs from agricultural land uses to riparian plantings for each cell.

    Returns
    -------
    np.ndarray
        1-D array, indexed by cell.
    """
    yr_cal = data.YR_CAL_BASE + yr_idx
    cells = np.isin(lumap, np.array(list(data.AGLU2DESC.keys())))

    # Establishment costs
    est_costs_r = tools.amortise(data.RP_EST_COST_HA * data.REAL_AREA * data.EST_COST_MULTS[yr_cal]).astype(np.float32)
    est_costs_r[~cells] = 0.0
    # est_costs_r *= data.RP_PROPORTION
    
    # Transition costs
    ag_to_ep_j = data.T_MAT.sel(from_lu=data.AGRICULTURAL_LANDUSES, to_lu='Riparian Plantings').values
    ag_to_ep_t_r = np.vectorize(dict(enumerate(ag_to_ep_j)).get, otypes=['float32'])(lumap)
    ag_to_ep_t_r = np.nan_to_num(ag_to_ep_t_r)
    ag_to_ep_t_r = tools.amortise(ag_to_ep_t_r * data.REAL_AREA)
    ag_to_ep_t_r[~cells] = 0.0
    # ag_to_ep_t_r *= data.RP_PROPORTION
    
    
    # Water costs; Assume riparian plantings are dryland
    w_rm_irrig_cost_r = np.where(lmmap == 1, settings.REMOVE_IRRIG_COST * data.IRRIG_COST_MULTS[yr_cal], 0) * data.REAL_AREA
    w_rm_irrig_cost_r[~cells] = 0.0

    # Fencing costs
    fencing_cost_r = (
        data.RP_FENCING_LENGTH 
        * settings.FENCING_COST_PER_M
        * data.FENCE_COST_MULTS[yr_cal]
        * data.REAL_AREA
    ).astype(np.float32)
    fencing_cost_r[~cells] = 0.0
    # fencing_cost_r *= data.RP_PROPORTION
    
    
    if separate:
        return {
            'Establishment cost (Ag2Non-Ag)': est_costs_r,
            'Transition cost (Ag2Non-Ag)': ag_to_ep_t_r,
            'Remove irrigation cost (Ag2Non-Ag)': w_rm_irrig_cost_r,
            'Fencing cost (Ag2Non-Ag)': fencing_cost_r
        }
    else:
        return est_costs_r + ag_to_ep_t_r + w_rm_irrig_cost_r + fencing_cost_r


def get_sheep_agroforestry_transitions_from_ag(
    data: Data, yr_idx, lumap, lmmap, separate=False
):
    """
    Get the base transition costs from agricultural land uses to Sheep Agroforestry for each cell.

    Returns
    -------
    np.ndarray
        (separate = False) 1-D array, indexed by cell. 
    dict
        (separate = True) Dict of separated transition costs.
    """
    
    yr_cal = data.YR_CAL_BASE + yr_idx
    cells = np.isin(lumap, np.array(list(data.AGLU2DESC.keys())))

    # Establishment costs
    est_costs_r = tools.amortise(data.AF_EST_COST_HA * data.REAL_AREA * data.EST_COST_MULTS[yr_cal]).astype(np.float32)
    est_costs_r[~cells] = 0.0
    est_costs_r *= settings.AF_PROPORTION  
    
    # Transition costs
    ag_to_agroforestry_j = data.T_MAT.sel(from_lu=data.AGRICULTURAL_LANDUSES, to_lu='Sheep Agroforestry').values
    ag_to_agroforestry_t_r = np.vectorize(dict(enumerate(ag_to_agroforestry_j)).get, otypes=['float32'])(lumap)
    ag_to_agroforestry_t_r = np.nan_to_num(ag_to_agroforestry_t_r)
    ag_to_agroforestry_t_r = tools.amortise(ag_to_agroforestry_t_r * data.REAL_AREA)
    ag_to_agroforestry_t_r[~cells] = 0.0
    ag_to_agroforestry_t_r *= settings.AF_PROPORTION
    
    ag_to_sheep_j = data.T_MAT.sel(from_lu=data.AGRICULTURAL_LANDUSES, to_lu='Sheep - modified land').values    # Only consider ag to sheep-modified land here; Ag to sheep-natural is handled in the destocked-natural module
    ag_to_sheep_t_r = np.vectorize(dict(enumerate(ag_to_sheep_j)).get, otypes=['float32'])(lumap)
    ag_to_sheep_t_r = np.nan_to_num(ag_to_sheep_t_r)
    ag_to_sheep_t_r = tools.amortise(ag_to_sheep_t_r * data.REAL_AREA)
    ag_to_sheep_t_r[~cells] = 0.0
    ag_to_sheep_t_r *= (1 - settings.AF_PROPORTION)
    
    # Water costs; Assume AF is dryland so no need to multiply by AF_PROPORTION here
    w_rm_irrig_cost_r = np.where(lmmap == 1, settings.REMOVE_IRRIG_COST * data.IRRIG_COST_MULTS[yr_cal], 0) * data.REAL_AREA
    w_rm_irrig_cost_r[~cells] = 0.0

    # Fencing costs
    fencing_cost_r = (
        settings.AF_FENCING_LENGTH_HA
        * settings.FENCING_COST_PER_M
        * data.FENCE_COST_MULTS[yr_cal]
        * data.REAL_AREA 
    ).astype(np.float32)
    fencing_cost_r[~cells] = 0.0
    
    if separate:
        return {
            'Establishment cost (Ag2Non-Ag)': est_costs_r,
            'Transition cost (Ag2Non-Ag)': ag_to_agroforestry_t_r,
            'Transition cost (Ag2AF-Sheep)': ag_to_sheep_t_r,
            'Remove irrigation cost (Ag2Non-Ag)': w_rm_irrig_cost_r,
            'Fencing cost (Ag2Non-Ag)': fencing_cost_r
        }
    else:
        return est_costs_r + ag_to_agroforestry_t_r + ag_to_sheep_t_r + w_rm_irrig_cost_r + fencing_cost_r
    

def get_beef_agroforestry_transitions_from_ag(
    data: Data, yr_idx, lumap, lmmap, separate=False
):
    """
    Get the base transition costs from agricultural land uses to Beef Agroforestry for each cell.

    Returns
    -------
    np.ndarray
        (separate = False) 1-D array, indexed by cell. 
    dict
        (separate = True) Dict of separated transition costs.
    """
    
    yr_cal = data.YR_CAL_BASE + yr_idx
    cells = np.isin(lumap, np.array(list(data.AGLU2DESC.keys())))

    # Establishment costs
    est_costs_r = tools.amortise(data.AF_EST_COST_HA * data.REAL_AREA * data.EST_COST_MULTS[yr_cal]).astype(np.float32)
    est_costs_r[~cells] = 0.0
    est_costs_r *= settings.AF_PROPORTION  
    
    # Transition costs
    ag_to_agroforestry_j = data.T_MAT.sel(from_lu=data.AGRICULTURAL_LANDUSES, to_lu='Beef Agroforestry').values
    ag_to_agroforestry_t_r = np.vectorize(dict(enumerate(ag_to_agroforestry_j)).get, otypes=['float32'])(lumap)
    ag_to_agroforestry_t_r = np.nan_to_num(ag_to_agroforestry_t_r)
    ag_to_agroforestry_t_r = tools.amortise(ag_to_agroforestry_t_r * data.REAL_AREA)
    ag_to_agroforestry_t_r[~cells] = 0.0
    ag_to_agroforestry_t_r *= settings.AF_PROPORTION
    
    ag_to_beef_j = data.T_MAT.sel(from_lu=data.AGRICULTURAL_LANDUSES, to_lu='Beef - modified land').values    # Only consider ag to beef-modified land here; Ag to beef-natural is handled in the destocked-natural module
    ag_to_beef_t_r = np.vectorize(dict(enumerate(ag_to_beef_j)).get, otypes=['float32'])(lumap)
    ag_to_beef_t_r = np.nan_to_num(ag_to_beef_t_r)
    ag_to_beef_t_r = tools.amortise(ag_to_beef_t_r * data.REAL_AREA)
    ag_to_beef_t_r[~cells] = 0.0
    ag_to_beef_t_r *= (1 - settings.AF_PROPORTION)
    
    # Water costs; Assume AF is dryland so no need to multiply by AF_PROPORTION here
    w_rm_irrig_cost_r = np.where(lmmap == 1, settings.REMOVE_IRRIG_COST * data.IRRIG_COST_MULTS[yr_cal], 0) * data.REAL_AREA
    w_rm_irrig_cost_r[~cells] = 0.0
    
    # Fencing costs
    fencing_cost_r = (
        settings.AF_FENCING_LENGTH_HA
        * settings.FENCING_COST_PER_M
        * data.FENCE_COST_MULTS[data.YR_CAL_BASE + yr_idx]
        * data.REAL_AREA
    ).astype(np.float32)
    fencing_cost_r[~cells] = 0.0
    
    if separate:
        return {
            'Establishment cost (Ag2Non-Ag)': est_costs_r,
            'Transition cost (Ag2Non-Ag)': ag_to_agroforestry_t_r,
            'Transition cost (Ag2AF-Beef)': ag_to_beef_t_r,
            'Remove irrigation cost (Ag2Non-Ag)': w_rm_irrig_cost_r,
            'Fencing cost (Ag2Non-Ag)': fencing_cost_r
        }
    else:
        return est_costs_r + ag_to_agroforestry_t_r + ag_to_beef_t_r + w_rm_irrig_cost_r + fencing_cost_r


def get_carbon_plantings_block_from_ag(data: Data, yr_idx, lumap, lmmap, separate=False) -> np.ndarray|dict:
    """
    Get transition costs from agricultural land uses to carbon plantings (block) for each cell.

    Returns
    -------
    np.ndarray
        1-D array, indexed by cell.
    """
    yr_cal = data.YR_CAL_BASE + yr_idx
    cells = np.isin(lumap, np.array(list(data.AGLU2DESC.keys())))

    # Establishment costs
    est_costs_CP_r = tools.amortise(data.CP_EST_COST_HA * data.REAL_AREA * data.EST_COST_MULTS[yr_cal]).astype(np.float32)
    est_costs_CP_r[~cells] = 0.0

    # Transition costs
    ag_to_cp_j = data.T_MAT.sel(from_lu=data.AGRICULTURAL_LANDUSES, to_lu='Carbon Plantings (Block)').values
    ag_to_cp_t_r = np.vectorize(dict(enumerate(ag_to_cp_j)).get, otypes=['float32'])(lumap)
    ag_to_cp_t_r = np.nan_to_num(ag_to_cp_t_r)
    ag_to_cp_t_r = tools.amortise(ag_to_cp_t_r * data.REAL_AREA)
    ag_to_cp_t_r[~cells] = 0.0

    # Water costs; Assume CP is dryland
    w_rm_irrig_cost_r = np.where(lmmap == 1, settings.REMOVE_IRRIG_COST * data.IRRIG_COST_MULTS[yr_cal], 0) * data.REAL_AREA
    w_rm_irrig_cost_r[~cells] = 0.0

    if separate:
        return {
            'Establishment cost (Ag2Non-Ag)': est_costs_CP_r,
            'Transition cost (Ag2Non-Ag)': ag_to_cp_t_r,
            'Remove irrigation cost (Ag2Non-Ag)': w_rm_irrig_cost_r
        }
    else:
        return est_costs_CP_r + ag_to_cp_t_r + w_rm_irrig_cost_r


def get_sheep_carbon_plantings_belt_from_ag(
    data: Data, yr_idx, lumap, lmmap, separate=False
):
    """
    Get the transition costs from agricultural land uses to Sheep Carbon Plantings (belt) for each cell.

    Returns
    -------
    np.ndarray
        (separate = False) 1-D array, indexed by cell. 
    dict
        (separate = True) Dict of separated transition costs.
    """
    
    yr_cal = data.YR_CAL_BASE + yr_idx
    cells = np.isin(lumap, np.array(list(data.AGLU2DESC.keys())))

    # Establishment costs
    est_costs_CP_r = tools.amortise(data.CP_EST_COST_HA * data.REAL_AREA * data.EST_COST_MULTS[yr_cal]).astype(np.float32)
    est_costs_CP_r[~cells] = 0.0
    est_costs_CP_r *= settings.CP_BELT_PROPORTION

    # Transition costs
    ag_to_cp_j = data.T_MAT.sel(from_lu=data.AGRICULTURAL_LANDUSES, to_lu='Sheep Carbon Plantings (Belt)').values
    ag_to_cp_t_r = np.vectorize(dict(enumerate(ag_to_cp_j)).get, otypes=['float32'])(lumap)
    ag_to_cp_t_r = np.nan_to_num(ag_to_cp_t_r)
    ag_to_cp_t_r = tools.amortise(ag_to_cp_t_r * data.REAL_AREA)
    ag_to_cp_t_r[~cells] = 0.0
    ag_to_cp_t_r *= settings.CP_BELT_PROPORTION
    
    ag_to_sheep_j = data.T_MAT.sel(from_lu=data.AGRICULTURAL_LANDUSES, to_lu='Sheep - modified land').values    # Only consider sheep-modified land here; Ag to sheep-natural is handled in the destocked-natural module
    ag_to_sheep_t_r = np.vectorize(dict(enumerate(ag_to_sheep_j)).get, otypes=['float32'])(lumap)
    ag_to_sheep_t_r = np.nan_to_num(ag_to_sheep_t_r)
    ag_to_sheep_t_r = tools.amortise(ag_to_sheep_t_r * data.REAL_AREA)
    ag_to_sheep_t_r[~cells] = 0.0
    ag_to_sheep_t_r *= (1 - settings.CP_BELT_PROPORTION)  
    
    # Water costs; Assume CP is dryland
    w_rm_irrig_cost_r = np.where(lmmap == 1, settings.REMOVE_IRRIG_COST * data.IRRIG_COST_MULTS[yr_cal], 0) * data.REAL_AREA
    w_rm_irrig_cost_r[~cells] = 0.0

    fencing_cost_r = (
        settings.CP_BELT_FENCING_LENGTH
        * settings.FENCING_COST_PER_M
        * data.FENCE_COST_MULTS[data.YR_CAL_BASE + yr_idx]
        * data.REAL_AREA
    ).astype(np.float32)
    fencing_cost_r[~cells] = 0.0

    if separate:
        return {
            'Establishment cost (Ag2Non-Ag)': est_costs_CP_r,
            'Transition cost (Ag2Non-Ag)': ag_to_cp_t_r,
            'Transition cost (Ag2CP-Sheep)': ag_to_sheep_t_r,
            'Remove irrigation cost (Ag2Non-Ag)': w_rm_irrig_cost_r,
            'Fencing cost (Ag2Non-Ag)': fencing_cost_r
        }
    else:
        return est_costs_CP_r + ag_to_cp_t_r + ag_to_sheep_t_r + w_rm_irrig_cost_r + fencing_cost_r


def get_beef_carbon_plantings_belt_from_ag(
    data: Data,  yr_idx, lumap, lmmap, separate=False
):
    """
    Get the base transition costs from agricultural land uses to Beef Carbon Plantings (belt) for each cell.

    Returns
    -------
    np.ndarray
        (separate = False) 1-D array, indexed by cell. 
    dict
        (separate = True) Dict of separated transition costs.
    """
    
    yr_cal = data.YR_CAL_BASE + yr_idx
    cells = np.isin(lumap, np.array(list(data.AGLU2DESC.keys())))

    # Establishment costs
    est_costs_CP_r = tools.amortise(data.CP_EST_COST_HA * data.REAL_AREA * data.EST_COST_MULTS[yr_cal]).astype(np.float32)
    est_costs_CP_r[~cells] = 0.0
    est_costs_CP_r *= settings.CP_BELT_PROPORTION

    # Transition costs
    ag_to_cp_j = data.T_MAT.sel(from_lu=data.AGRICULTURAL_LANDUSES, to_lu='Beef Carbon Plantings (Belt)').values
    ag_to_cp_t_r = np.vectorize(dict(enumerate(ag_to_cp_j)).get, otypes=['float32'])(lumap)
    ag_to_cp_t_r = np.nan_to_num(ag_to_cp_t_r)
    ag_to_cp_t_r = tools.amortise(ag_to_cp_t_r * data.REAL_AREA)
    ag_to_cp_t_r[~cells] = 0.0
    ag_to_cp_t_r *= settings.CP_BELT_PROPORTION
    
    ag_to_sheep_j = data.T_MAT.sel(from_lu=data.AGRICULTURAL_LANDUSES, to_lu='Beef - modified land').values    # Only consider beef-modified land here; Ag to beef-natural is handled in the destocked-natural module
    ag_to_sheep_t_r = np.vectorize(dict(enumerate(ag_to_sheep_j)).get, otypes=['float32'])(lumap)
    ag_to_sheep_t_r = np.nan_to_num(ag_to_sheep_t_r)
    ag_to_sheep_t_r = tools.amortise(ag_to_sheep_t_r * data.REAL_AREA)
    ag_to_sheep_t_r[~cells] = 0.0
    ag_to_sheep_t_r *= (1 - settings.CP_BELT_PROPORTION)  
    
    # Water costs; Assume CP is dryland
    w_rm_irrig_cost_r = np.where(lmmap == 1, settings.REMOVE_IRRIG_COST * data.IRRIG_COST_MULTS[yr_cal], 0) * data.REAL_AREA
    w_rm_irrig_cost_r[~cells] = 0.0

    fencing_cost_r = (
        settings.CP_BELT_FENCING_LENGTH
        * settings.FENCING_COST_PER_M
        * data.FENCE_COST_MULTS[data.YR_CAL_BASE + yr_idx]
        * data.REAL_AREA
    ).astype(np.float32)
    fencing_cost_r[~cells] = 0.0

    if separate:
        return {
            'Establishment cost (Ag2Non-Ag)': est_costs_CP_r,
            'Transition cost (Ag2Non-Ag)': ag_to_cp_t_r,
            'Transition cost (Ag2CP-Beef)': ag_to_sheep_t_r,
            'Remove irrigation cost (Ag2Non-Ag)': w_rm_irrig_cost_r,
            'Fencing cost (Ag2Non-Ag)': fencing_cost_r
        }
    else:
        return est_costs_CP_r + ag_to_cp_t_r + ag_to_sheep_t_r + w_rm_irrig_cost_r + fencing_cost_r


def get_beccs_from_ag(data, yr_idx, lumap, lmmap, separate=False) -> np.ndarray|dict:
    """
    Get transition costs from agricultural land uses to BECCS for each cell.

    Returns
    -------
    np.ndarray
        1-D array, indexed by cell.
    """

    return get_env_plant_transitions_from_ag(data, yr_idx, lumap, lmmap, separate)



def get_destocked_from_ag(
    data: Data, yr_idx, lumap, lmmap, separate=False
) -> np.ndarray | dict:
    """
    Get transition costs from agricultural land uses to destocked land for each cell.

    Returns
    -------
    if separate == False:
        np.ndarray
            1-D array, indexed by cell.
    if separate == True:
        dict
            Separated dictionary of transition cost arrays.
    """
    yr_cal = data.YR_CAL_BASE + yr_idx
    cells = np.isin(lumap, data.LU_LVSTK_NATURAL)
    
    # Establishment costs; If destocking brings 30% of bio/GHG benefits, then it takes 30% of establishment costs as Environmental Plantings
    HCAS_benefit_mult = {lu:1 - data.BIO_HABITAT_CONTRIBUTION_LOOK_UP[lu] for lu in data.LU_LVSTK_NATURAL}
    est_costs_r = np.vectorize(HCAS_benefit_mult.get, otypes=[np.float32])(lumap) * data.EP_EST_COST_HA
    est_costs_r = np.nan_to_num(est_costs_r)
    est_costs_r = tools.amortise(est_costs_r * data.REAL_AREA)
    
    # # Transition costs
    # ag2destock_j = data.T_MAT.sel(from_lu=data.AGRICULTURAL_LANDUSES, to_lu='Destocked - natural land').values
    # ag_to_destock_t_r = np.vectorize(dict(enumerate(ag2destock_j)).get, otypes=['float32'])(lumap)
    # ag_to_destock_t_r = np.nan_to_num(ag_to_destock_t_r)
    # ag_to_destock_t_r = tools.amortise(ag_to_destock_t_r * data.REAL_AREA)
    # ag_to_destock_t_r[~cells] = 0.0
    
    # Water costs; Assume destocked land is dryland
    w_rm_irrig_cost_r = np.where(lmmap == 1, settings.REMOVE_IRRIG_COST * data.IRRIG_COST_MULTS[yr_cal], 0) * data.REAL_AREA
    w_rm_irrig_cost_r[~cells] = 0.0
    
    if separate:
        return {
            'Establishment cost (Ag2Non-Ag)': est_costs_r,
            'Remove irrigation cost (Ag2Non-Ag)': w_rm_irrig_cost_r
        }
    else:
        return est_costs_r + w_rm_irrig_cost_r


def get_transition_matrix_ag2nonag(
    data: Data,
    yr_idx: int,
    lumap: np.ndarray,
    lmmap: np.ndarray,
    separate: bool = False
) -> np.ndarray|dict:
    """
    Get the matrix containing transition costs from agricultural land uses to non-agricultural land uses.

    Parameters
    ----------
    data : object
        The data object containing information about the model.
    yr_idx : int
        The index of the year.
    lumap : dict
        The land use map.
    lmmap : dict
        The land management map.
    separate : bool, optional
        If True, return a dictionary containing the transition costs for each non-agricultural land use.
        If False, return a 2-D array indexed by (r, k) where r is cell and k is non-agricultural land usage.

    Returns
    -------
    np.ndarray or dict
        If separate is False, returns a 2-D array indexed by (r, k) where r is cell and k is non-agricultural land usage.
        If separate is True, returns a dictionary containing the transition costs for each non-agricultural land use.
    """

    env_plant_transitions_from_ag = get_env_plant_transitions_from_ag(data, yr_idx, lumap, lmmap, separate) 
    rip_plant_transitions_from_ag = get_rip_plant_transitions_from_ag(data, yr_idx, lumap, lmmap, separate) 
    sheep_agroforestry_transitions_from_ag = get_sheep_agroforestry_transitions_from_ag(data, yr_idx, lumap, lmmap, separate) 
    beef_agroforestry_transitions_from_ag = get_beef_agroforestry_transitions_from_ag(data, yr_idx, lumap, lmmap, separate)
    carbon_plantings_block_transitions_from_ag = get_carbon_plantings_block_from_ag(data, yr_idx, lumap, lmmap, separate)            
    sheep_carbon_plantings_belt_transitions_from_ag = get_sheep_carbon_plantings_belt_from_ag(data, yr_idx, lumap, lmmap, separate)        
    beef_carbon_plantings_belt_transitions_from_ag = get_beef_carbon_plantings_belt_from_ag(data, yr_idx, lumap, lmmap, separate)         
    beccs_transitions_from_ag = get_beccs_from_ag(data, yr_idx, lumap, lmmap, separate)
    destocked_from_ag = get_destocked_from_ag(data, yr_idx, lumap, lmmap, separate)

    if separate:
        # IMPORTANT: The order of the keys in the dictionary must match the order of the non-agricultural land uses
        return {
            'Environmental Plantings': env_plant_transitions_from_ag,
            'Riparian Plantings': rip_plant_transitions_from_ag,
            'Sheep Agroforestry': sheep_agroforestry_transitions_from_ag,
            'Beef Agroforestry': beef_agroforestry_transitions_from_ag,
            'Carbon Plantings (Block)': carbon_plantings_block_transitions_from_ag,
            'Sheep Carbon Plantings (Belt)': sheep_carbon_plantings_belt_transitions_from_ag,
            'Beef Carbon Plantings (Belt)': beef_carbon_plantings_belt_transitions_from_ag,
            'BECCS': beccs_transitions_from_ag,
            'Destocked - natural land': destocked_from_ag,
        }
        
    else:
        return np.array([
            env_plant_transitions_from_ag,
            rip_plant_transitions_from_ag,
            sheep_agroforestry_transitions_from_ag,
            beef_agroforestry_transitions_from_ag,
            carbon_plantings_block_transitions_from_ag,
            sheep_carbon_plantings_belt_transitions_from_ag,
            beef_carbon_plantings_belt_transitions_from_ag,
            beccs_transitions_from_ag,
            destocked_from_ag,
        ]).T.astype(np.float32)


# TODO: Need to check the logic of transition cost, espcially the water cost.
def get_env_plantings_to_ag(data: Data, yr_idx, lumap, lmmap, separate=False) -> np.ndarray|dict:
    """
    Get transition costs from environmental plantings to agricultural land uses for each cell.

    Returns
    -------
    np.ndarray
        3-D array, indexed by (m, r, j).
    """
    yr_cal = data.YR_CAL_BASE + yr_idx
    l_mrj = tools.lumap2ag_l_mrj(lumap, lmmap)
    l_mrj_not = np.logical_not(l_mrj)           # This ensures the lu remains the same has 0 cost
    ag_cells, _ = tools.get_ag_and_non_ag_cells(lumap)

    # Get base transition costs: add cost of installing irrigation
    base_ep_to_ag_t = data.EP2AG_TRANSITION_COSTS_HA * data.TRANS_COST_MULTS[yr_cal]
    base_ep_to_ag_t_mrj = np.broadcast_to(base_ep_to_ag_t, (data.NLMS, data.NCELLS, base_ep_to_ag_t.shape[0]))
    base_ep_to_ag_t_mrj = tools.amortise(base_ep_to_ag_t_mrj).copy()
    base_ep_to_ag_t_mrj[:, ag_cells, :] = 0

    # Get water license price and costs of installing/removing irrigation where appropriate
    w_mrj = ag_water.get_wreq_matrices(data, yr_idx)
    w_delta_mrj = tools.get_ag_to_ag_water_delta_matrix(w_mrj, l_mrj, data, yr_idx)
    w_delta_mrj[:, ag_cells, :] = 0
    

    if separate:
        return {'Transition cost (Non-Ag2Ag)':np.nan_to_num(np.einsum('mrj,mrj,r->mrj', base_ep_to_ag_t_mrj, l_mrj_not, data.REAL_AREA)), 
                'Water license cost (Non-Ag2Ag)': np.nan_to_num(np.einsum('mrj,mrj,r->mrj', w_delta_mrj, l_mrj_not, data.REAL_AREA))}
        
    # Add cost of water license and cost of installing/removing irrigation where relevant (pre-amortised)
    ep_to_ag_t_mrj = (base_ep_to_ag_t_mrj + w_delta_mrj) * l_mrj_not * data.REAL_AREA[np.newaxis, :, np.newaxis]
    return np.nan_to_num(ep_to_ag_t_mrj) 


def get_rip_plantings_to_ag(data: Data, yr_idx, lumap, lmmap, separate=False) -> np.ndarray|dict:
    """
    Get transition costs from riparian plantings to agricultural land uses for each cell.
    
    Note: this is the same as for environmental plantings.

    Returns
    -------
    np.ndarray
        3-D array, indexed by (m, r, j).
    """
    if separate:
        return get_env_plantings_to_ag(data, yr_idx, lumap, lmmap, separate)
    else:
        return get_env_plantings_to_ag(data, yr_idx, lumap, lmmap)


def get_agroforestry_to_ag_base(data: Data, yr_idx, lumap, lmmap, separate) -> np.ndarray|dict:
    """
    Get transition costs from agroforestry to agricultural land uses for each cell.
    
    Note: this is the same as for environmental plantings.

    Returns
    -------
    np.ndarray
        3-D array, indexed by (m, r, j).
    """
    if separate:
        return get_env_plantings_to_ag(data, yr_idx, lumap, lmmap, separate)
    else:
        return get_env_plantings_to_ag(data, yr_idx, lumap, lmmap)


def get_sheep_to_ag_base(data: Data, yr_idx: int, lumap, separate=False) -> np.ndarray|dict:
    """
    Get sheep contribution to transition costs to agricultural land uses.
    Used for getting transition costs for Sheep Agroforestry and CP (Belt).

    Returns
    -------
    np.ndarray separate = False
        3-D array, indexed by (m, r, j).
    dict (separate = True)
        Dictionary of separated out transition costs.
    ------
    """
    yr_cal = data.YR_CAL_BASE + yr_idx
    sheep_j = tools.get_sheep_code(data)

    all_sheep_lumap = (np.ones(data.NCELLS) * sheep_j).astype(np.int8)
    all_dry_lmmap = np.zeros(data.NCELLS).astype(np.float32)
    l_mrj = tools.lumap2ag_l_mrj(all_sheep_lumap, all_dry_lmmap)
    l_mrj_not = np.logical_not(l_mrj)

    t_ij = data.AG_TMATRIX * data.TRANS_COST_MULTS[yr_cal]
    x_mrj = ag_transitions.get_to_ag_exclude_matrices(data, all_sheep_lumap)

    # Calculate sheep contribution to transition costs
    # Establishment costs
    ag_cells = tools.get_ag_cells(lumap)

    e_rj = np.zeros((data.NCELLS, data.N_AG_LUS)).astype(np.float32)
    e_rj[ag_cells, :] = t_ij[all_sheep_lumap[ag_cells]]

    e_rj = tools.amortise(e_rj) * data.REAL_AREA[:, np.newaxis]
    e_rj_dry = np.einsum('rj,r->rj', e_rj, all_sheep_lumap == 0)
    e_rj_irr = np.einsum('rj,r->rj', e_rj, all_dry_lmmap == 1)
    e_mrj = np.stack([e_rj_dry, e_rj_irr], axis=0)
    e_mrj = np.einsum('mrj,mrj,mrj->mrj', e_mrj, x_mrj, l_mrj_not)

    # Water license cost
    w_mrj = ag_water.get_wreq_matrices(data, yr_idx)
    w_delta_mrj = tools.get_ag_to_ag_water_delta_matrix(w_mrj, l_mrj, data, yr_idx)
    w_delta_mrj = np.einsum('mrj,mrj,mrj->mrj', w_delta_mrj, x_mrj, l_mrj_not)

    # Carbon costs
    ghg_t_mrj = ag_ghg.get_ghg_transition_emissions(data, all_sheep_lumap)               # <unit: t/ha>      
    ghg_t_mrj_cost = tools.amortise(ghg_t_mrj * data.get_carbon_price_by_yr_idx(yr_idx))     
    ghg_t_mrj_cost = np.einsum('mrj,mrj,mrj->mrj', ghg_t_mrj_cost, x_mrj, l_mrj_not)

    # Ensure transition costs are zero for all agricultural cells 
    e_mrj[:, ag_cells, :] = np.zeros((data.NLMS, ag_cells.shape[0], data.N_AG_LUS)).astype(np.float32)
    w_delta_mrj[:, ag_cells, :] = np.zeros((data.NLMS, ag_cells.shape[0], data.N_AG_LUS)).astype(np.float32)
    ghg_t_mrj_cost[:, ag_cells, :] = np.zeros((data.NLMS, ag_cells.shape[0], data.N_AG_LUS)).astype(np.float32)

    if separate:
        return {
            'Establishment cost (Non-Ag2Ag)': np.nan_to_num(e_mrj), 
            'Water license cost (Non-Ag2Ag)': np.nan_to_num(w_delta_mrj), 
            'GHG emissions cost (Non-Ag2Ag)': np.nan_to_num(ghg_t_mrj_cost)
        }
    
    else:
        return np.nan_to_num(e_mrj + w_delta_mrj + ghg_t_mrj_cost)


def get_beef_to_ag_base(data: Data, yr_idx, lumap, separate) -> np.ndarray|dict:
    """
    Get beef contribution to transition costs to agricultural land uses.
    Used for getting transition costs for Beef Agroforestry and CP (Belt).

    Returns
    -------
    np.ndarray separate = False
        3-D array, indexed by (m, r, j).
    dict (separate = True)
        Dictionary of separated out transition costs.
    """
    yr_cal = data.YR_CAL_BASE + yr_idx
    beef_j = tools.get_beef_code(data)

    all_beef_lumap = (np.ones(data.NCELLS) * beef_j).astype(np.int8)
    all_dry_lmmap = np.zeros(data.NCELLS).astype(np.float32)
    l_mrj = tools.lumap2ag_l_mrj(all_beef_lumap, all_dry_lmmap)
    l_mrj_not = np.logical_not(l_mrj)

    t_ij = data.AG_TMATRIX * data.TRANS_COST_MULTS[yr_cal]
    x_mrj = ag_transitions.get_to_ag_exclude_matrices(data, all_beef_lumap)

    # Establishment costs
    ag_cells = tools.get_ag_cells(lumap)

    e_rj = np.zeros((data.NCELLS, data.N_AG_LUS)).astype(np.float32)
    e_rj[ag_cells, :] = t_ij[all_beef_lumap[ag_cells]]

    e_rj = tools.amortise(e_rj) * data.REAL_AREA[:, np.newaxis]
    e_mrj = np.stack([e_rj] * data.NLMS, axis=0)
    e_mrj = np.einsum('mrj,mrj,mrj->mrj', e_mrj, x_mrj, l_mrj_not)

    # Water license cost
    w_mrj = ag_water.get_wreq_matrices(data, yr_idx)
    w_delta_mrj = tools.get_ag_to_ag_water_delta_matrix(w_mrj, l_mrj, data, yr_idx)
    w_delta_mrj = np.einsum('mrj,mrj,mrj->mrj', w_delta_mrj, x_mrj, l_mrj_not)

    # Carbon costs
    ghg_t_mrj = ag_ghg.get_ghg_transition_emissions(data, all_beef_lumap)               # <unit: t/ha>      
    ghg_t_mrj_cost = tools.amortise(ghg_t_mrj * data.get_carbon_price_by_yr_idx(yr_idx))     
    ghg_t_mrj_cost = np.einsum('mrj,mrj,mrj->mrj', ghg_t_mrj_cost, x_mrj, l_mrj_not)

    beef_af_cells = tools.get_beef_agroforestry_cells(lumap)
    non_beef_af_cells = np.array([r for r in range(data.NCELLS) if r not in beef_af_cells])

    # Ensure transition costs are zero for all agricultural cells 
    e_mrj[:, ag_cells, :] = np.zeros((data.NLMS, ag_cells.shape[0], data.N_AG_LUS)).astype(np.float32)
    w_delta_mrj[:, ag_cells, :] = np.zeros((data.NLMS, ag_cells.shape[0], data.N_AG_LUS)).astype(np.float32)
    ghg_t_mrj_cost[:, ag_cells, :] = np.zeros((data.NLMS, ag_cells.shape[0], data.N_AG_LUS)).astype(np.float32)

    if separate:
        return {
            'Establishment cost (Non-Ag2Ag)': np.nan_to_num(e_mrj), 
            'Water license cost (Non-Ag2Ag)': np.nan_to_num(w_delta_mrj), 
            'GHG emissions cost (Non-Ag2Ag)': np.nan_to_num(ghg_t_mrj_cost)
        }
    
    else:
        t_mrj = e_mrj + w_delta_mrj + ghg_t_mrj_cost
        # Set all costs for non-beef-agroforestry cells to zero
        t_mrj[:, non_beef_af_cells, :] = 0
        return np.nan_to_num(t_mrj)


def get_sheep_agroforestry_to_ag(
    data: Data, yr_idx, lumap, lmmap, agroforestry_x_r, separate=False
) -> np.ndarray|dict:
    """
    Get transition costs of Sheep Agroforestry to all agricultural land uses.

    Returns
    -------
    np.ndarray separate = False
        3-D array, indexed by (m, r, j).
    dict (separate = True)
        Dictionary of separated out transition costs.
    """
    sheep_tcosts = get_sheep_to_ag_base(data, yr_idx, lumap, separate)
    agroforestry_tcosts = get_agroforestry_to_ag_base(data, yr_idx, lumap, lmmap, separate)

    if separate:
        # Combine and return separated costs
        combined_costs = {}
        for key, array in agroforestry_tcosts.items():
            combined_costs[key] = np.zeros(array.shape).astype(np.float32)
            for m in range(data.NLMS):
                for j in range(data.N_AG_LUS):
                    combined_costs[key][m, :, j] = array[m, :, j] * agroforestry_x_r

        for key, array in sheep_tcosts.items():
            if key not in combined_costs:
                combined_costs[key] = np.zeros(array.shape).astype(np.float32)
            for m in range(data.NLMS):
                for j in range(data.N_AG_LUS):
                    combined_costs[key][m, :, j] += array[m, :, j] * (1 - agroforestry_x_r)

        return combined_costs
    
    else:
        sheep_contr = np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS)).astype(np.float32)
        for m in range(data.NLMS):
            for j in range(data.N_AG_LUS):
                sheep_contr[m, :, j] = (1 - agroforestry_x_r) * sheep_tcosts[m, :, j]

        agroforestry_contr = np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS)).astype(np.float32)
        for m in range(data.NLMS):
            for j in range(data.N_AG_LUS):
                agroforestry_contr[m, :, j] = agroforestry_x_r * agroforestry_tcosts[m, :, j]

        return sheep_contr + agroforestry_contr


def get_beef_agroforestry_to_ag(
    data: Data, yr_idx, lumap, lmmap, agroforestry_x_r, separate=False
) -> np.ndarray|dict:
    """
    Get transition costs of Beef Agroforestry to all agricultural land uses.
    
    Returns
    -------
    np.ndarray separate = False
        3-D array, indexed by (m, r, j).
    dict (separate = True)
        Dictionary of separated out transition costs.
    """
    beef_tcosts = get_beef_to_ag_base(data, yr_idx, lumap, separate)
    agroforestry_tcosts = get_agroforestry_to_ag_base(data, yr_idx, lumap, lmmap, separate)

    if separate:
        # Combine and return separated costs
        combined_costs = {}
        for key, array in agroforestry_tcosts.items():
            combined_costs[key] = np.zeros(array.shape).astype(np.float32)
            for m in range(data.NLMS):
                for j in range(data.N_AG_LUS):
                    combined_costs[key][m, :, j] = array[m, :, j] * agroforestry_x_r

        for key, array in beef_tcosts.items():
            if key not in combined_costs:
                combined_costs[key] = np.zeros(array.shape).astype(np.float32)
            for m in range(data.NLMS):
                for j in range(data.N_AG_LUS):
                    combined_costs[key][m, :, j] += array[m, :, j] * (1 - agroforestry_x_r)

        return combined_costs
    
    else:
        beef_contr = np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS)).astype(np.float32)
        for m in range(data.NLMS):
            for j in range(data.N_AG_LUS):
                beef_contr[m, :, j] = (1 - agroforestry_x_r) * beef_tcosts[m, :, j]

        agroforestry_contr = np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS)).astype(np.float32)
        for m in range(data.NLMS):
            for j in range(data.N_AG_LUS):
                agroforestry_contr[m, :, j] = agroforestry_x_r * agroforestry_tcosts[m, :, j]

        return beef_contr + agroforestry_contr


def get_carbon_plantings_block_to_ag(data: Data, yr_idx, lumap, lmmap, separate=False):
    """
    Get transition costs from carbon plantings (block) to agricultural land uses for each cell.
    
    Note: this is the same as for environmental plantings.

    Returns
    -------
    np.ndarray
        3-D array, indexed by (m, r, j).
    """
    return get_env_plantings_to_ag(data, yr_idx, lumap, lmmap, separate)


def get_carbon_plantings_belt_to_ag_base(data, yr_idx, lumap, lmmap, separate=False) -> np.ndarray|dict:
    """
    Get transition costs from carbon plantings (belt) to agricultural land uses for each cell.
    
    Note: this is the same as for environmental plantings.

    Returns
    -------
    np.ndarray
        3-D array, indexed by (m, r, j).
    """
    return get_env_plantings_to_ag(data, yr_idx, lumap, lmmap, separate)


def get_sheep_carbon_plantings_belt_to_ag(
    data: Data, yr_idx, lumap, lmmap, cp_belt_x_r, separate
) -> np.ndarray|dict:
    """
    Get transition costs of Sheep Carbon Plantings (Belt) to all agricultural land uses.
    
    Returns
    -------
    np.ndarray separate = False
        3-D array, indexed by (m, r, j).
    dict (separate = True)
        Dictionary of separated out transition costs.
    """
    sheep_tcosts = get_sheep_to_ag_base(data, yr_idx, lumap, separate)
    cp_belt_tcosts = get_carbon_plantings_belt_to_ag_base(data, yr_idx, lumap, lmmap, separate)

    if separate:
        # Combine and return separated costs
        combined_costs = {}
        for key, array in cp_belt_tcosts.items():
            combined_costs[key] = np.zeros(array.shape).astype(np.float32)
            for m in range(data.NLMS):
                for j in range(data.N_AG_LUS):
                    combined_costs[key][m, :, j] = array[m, :, j] * cp_belt_x_r

        for key, array in sheep_tcosts.items():
            if key not in combined_costs:
                combined_costs[key] = np.zeros(array.shape).astype(np.float32)
            for m in range(data.NLMS):
                for j in range(data.N_AG_LUS):
                    combined_costs[key][m, :, j] += array[m, :, j] * (1 - cp_belt_x_r)

        return combined_costs
    
    else:
        sheep_contr = np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS)).astype(np.float32)
        for m in range(data.NLMS):
            for j in range(data.N_AG_LUS):
                sheep_contr[m, :, j] = (1 - cp_belt_x_r) * sheep_tcosts[m, :, j]

        cp_belt_contr = np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS)).astype(np.float32)
        for m in range(data.NLMS):
            for j in range(data.N_AG_LUS):
                cp_belt_contr[m, :, j] = cp_belt_x_r * cp_belt_tcosts[m, :, j]

        return sheep_contr + cp_belt_contr
    

def get_beef_carbon_plantings_belt_to_ag(
    data: Data, yr_idx, lumap, lmmap, cp_belt_x_r, separate
) -> np.ndarray|dict:
    """
    Get transition costs of Beef Carbon Plantings (Belt) to all agricultural land uses.
    
    Returns
    -------
    np.ndarray separate = False
        3-D array, indexed by (m, r, j).
    dict (separate = True)
        Dictionary of separated out transition costs.
    """
    beef_tcosts = get_beef_to_ag_base(data, yr_idx, lumap, separate)
    cp_belt_tcosts = get_carbon_plantings_belt_to_ag_base(data, yr_idx, lumap, lmmap, separate)

    if separate:
        # Combine and return separated costs
        combined_costs = {}
        for key, array in cp_belt_tcosts.items():
            combined_costs[key] = np.zeros(array.shape).astype(np.float32)
            for m in range(data.NLMS):
                for j in range(data.N_AG_LUS):
                    combined_costs[key][m, :, j] = array[m, :, j] * cp_belt_x_r

        for key, array in beef_tcosts.items():
            if key not in combined_costs:
                combined_costs[key] = np.zeros(array.shape).astype(np.float32)
            for m in range(data.NLMS):
                for j in range(data.N_AG_LUS):
                    combined_costs[key][m, :, j] += array[m, :, j] * (1 - cp_belt_x_r)

        return combined_costs
    
    else:
        beef_contr = np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS)).astype(np.float32)
        for m in range(data.NLMS):
            for j in range(data.N_AG_LUS):
                beef_contr[m, :, j] = (1 - cp_belt_x_r) * beef_tcosts[m, :, j]

        cp_belt_contr = np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS)).astype(np.float32)
        for m in range(data.NLMS):
            for j in range(data.N_AG_LUS):
                cp_belt_contr[m, :, j] = cp_belt_x_r * cp_belt_tcosts[m, :, j]

        return beef_contr + cp_belt_contr


def get_beccs_to_ag(data: Data, yr_idx, lumap, lmmap, separate=False) -> np.ndarray|dict:
    """
    Get transition costs from BECCS to agricultural land uses for each cell.
    
    Note: this is the same as for environmental plantings.

    Returns
    -------
    np.ndarray
        3-D array, indexed by (m, r, j).
    """
    if separate:
        return get_env_plantings_to_ag(data, yr_idx, lumap, lmmap, separate)
    else:
        return get_env_plantings_to_ag(data, yr_idx, lumap, lmmap)
    

def get_destocked_to_ag(data: Data, yr_idx: int, lumap: np.ndarray, lmmap: np.ndarray, separate: bool = False) -> np.ndarray:
    """
    Get transition costs from destocked land to agricultural land uses for each cell.
    Transition costs are based on the transition costs of unallocated natural land to agricultural land.
    
    Returns
    -------
    np.ndarray
        3-D array, indexed by (m, r, j).
    """
    unallocated_j = tools.get_unallocated_natural_land_code(data)
    all_unallocated_lumap = (np.ones(data.NCELLS) * unallocated_j).astype(np.int8)
    all_dry_lmmap = (np.zeros(data.NCELLS)).astype(np.int8)

    destocked_cells = tools.get_destocked_land_cells(lumap)
    if destocked_cells.size == 0 and separate == False:
        return np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS))
    
    # Get transition costs from destocked cells by using transition costs from unallocated land
    unallocated_t_mrj = ag_transitions.get_transition_matrices_ag2ag(
        data, yr_idx, all_unallocated_lumap, all_dry_lmmap, separate=separate
    )

    if separate == False:
        destocked_t_mrj = np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS))
        destocked_t_mrj[:, destocked_cells, :] = unallocated_t_mrj[:, destocked_cells, :]
        return destocked_t_mrj
    
    elif separate == True:
        sep_destocked_trans = {k: np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS)) for k in unallocated_t_mrj}
        if destocked_cells.size == 0:
            return sep_destocked_trans

        for k, v in unallocated_t_mrj.items():
            sep_destocked_trans[k][:, destocked_cells, :] = v[:, destocked_cells, :]
        return sep_destocked_trans

    raise ValueError(
        f"Incorrect value for 'separate' when calling get_destocked_from_ag: {separate}. "
        f"should be either True or False."
    )


def get_transition_matrix_nonag2ag(data: Data, yr_idx, lumap, lmmap, separate=False) -> np.ndarray|dict:
    """
    Get the matrix containing transition costs from non-agricultural land uses to agricultural land uses.

    Parameters
    ----------
    data : np.ndarray
        The input data array.
    yr_idx : int
        The index of the year.
    lumap : dict
        The land use mapping dictionary.
    lmmap : dict
        The land management mapping dictionary.
    separate : bool, optional
        If True, returns a dictionary of transition matrices for each land use category.
        If False, returns a single aggregated transition matrix.

    Returns
    -------
    np.ndarray or dict
        If `separate` is True, returns a dictionary of transition matrices, where the keys are the land use categories.
        If `separate` is False, returns a single aggregated transition matrix.

    """
    
    non_ag_to_agr_t_matrices = {lu: np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS)).astype(np.float32) for lu in settings.NON_AG_LAND_USES}

    agroforestry_x_r = tools.get_exclusions_agroforestry_base(data, lumap)
    cp_belt_x_r = tools.get_exclusions_carbon_plantings_belt_base(data, lumap)

    # reshape each non-agricultural matrix to be indexed (r, k) and concatenate on the k indexing
    non_ag_to_agr_t_matrices['Environmental Plantings'] = get_env_plantings_to_ag(data, yr_idx, lumap, lmmap, separate)
    non_ag_to_agr_t_matrices['Riparian Plantings'] = get_rip_plantings_to_ag(data, yr_idx, lumap, lmmap, separate)
    non_ag_to_agr_t_matrices['Sheep Agroforestry'] = get_sheep_agroforestry_to_ag(data, yr_idx, lumap, lmmap, agroforestry_x_r, separate)
    non_ag_to_agr_t_matrices['Beef Agroforestry'] = get_beef_agroforestry_to_ag(data, yr_idx, lumap, lmmap, agroforestry_x_r, separate)
    non_ag_to_agr_t_matrices['Carbon Plantings (Block)'] = get_carbon_plantings_block_to_ag(data, yr_idx, lumap, lmmap, separate)
    non_ag_to_agr_t_matrices['Sheep Carbon Plantings (Belt)'] = get_sheep_carbon_plantings_belt_to_ag(data, yr_idx, lumap, lmmap, cp_belt_x_r, separate)
    non_ag_to_agr_t_matrices['Beef Carbon Plantings (Belt)'] = get_beef_carbon_plantings_belt_to_ag(data, yr_idx, lumap, lmmap, cp_belt_x_r, separate)
    non_ag_to_agr_t_matrices['BECCS'] = get_beccs_to_ag(data, yr_idx, lumap, lmmap, separate)
    non_ag_to_agr_t_matrices['Destocked - natural land'] = get_destocked_to_ag(data, yr_idx, lumap, lmmap, separate)

    if separate:
        # Note: The order of the keys in the dictionary must match the order of the non-agricultural land uses
        return non_ag_to_agr_t_matrices
            
    non_ag_to_agr_t_matrices = list(non_ag_to_agr_t_matrices.values())
    return np.add.reduce(non_ag_to_agr_t_matrices)


def get_non_ag_transition_matrix(data: Data) -> np.ndarray:
    """
    Get the matrix that contains transition costs for non-agricultural land uses. 
    There are no transition costs for non-agricultural land uses, therefore the matrix is filled with zeros.
    
    Parameters
        data (object): The data object containing information about the model.
    
    Returns
        np.ndarray: The transition cost matrix, filled with zeros.
    """
    return np.zeros((data.NCELLS, data.N_NON_AG_LUS)).astype(np.float32)



def get_to_non_ag_exclude_matrices(data: Data, lumap) -> np.ndarray:
    """
    Get the non-agricultural exclusions matrix.

    Parameters
    ----------
    data : object
        The data object containing information about the model.
    lumap : object
        The lumap object containing land usage mapping information.

    Returns
    -------
    np.ndarray
        A 2-D array indexed by (r, k) where r is the cell and k is the non-agricultural land usage.

    Notes
    -----
    This function calculates the non-agricultural exclusions matrix by combining several exclusion matrices
    related to different non-agricultural land uses. The resulting matrix is a concatenation of these matrices
    along the k indexing.
    """

    # Get transition costs for to_non_ag 2D array (r, k)
    t_ik = data.T_MAT.sel(to_lu=data.NON_AGRICULTURAL_LANDUSES).copy()
    lumap2desc = np.vectorize(data.ALLLU2DESC.get, otypes=[str])
    ag_cells, non_ag_cells = tools.get_ag_and_non_ag_cells(lumap)                            
    
    t_rk = np.ones((data.NCELLS, len(data.NON_AGRICULTURAL_LANDUSES))).astype(np.float32)    # Empty ones_rj array to be filled with transition flag (1 allow, 0 not allow)
    t_rk[ag_cells, :] = t_ik[lumap[ag_cells]]                                                # For ag cells in the base year lumap, get transition cost (np.nan is not-allow) for them
    t_rk[non_ag_cells, :] *= t_ik.sel(from_lu=lumap2desc(lumap[non_ag_cells]))               # For non-ag cells in the base year lumap, get transition cost (np.nan is not-allow) for them
    t_rk[non_ag_cells, :] *= t_ik.sel(from_lu=lumap2desc(data.LUMAP[non_ag_cells]))          # For non-ag cells, find its ag status in BASE_YR (2010), then get transition cost based on these 2010-ag status
    t_rk = np.where(np.isnan(t_rk), 0, 1).astype(np.int8)  

    # No-go exclusion; user-defined layer specifying which land-use are not disallowd at where
    no_go_x_rk = np.ones((data.NCELLS, data.N_NON_AG_LUS))  
    if settings.EXCLUDE_NO_GO_LU:
        for no_go_x_r, no_go_desc in zip(data.NO_GO_REGION_NON_AG, data.NO_GO_LANDUSE_NON_AG):
            no_go_j = data.NON_AGRICULTURAL_LANDUSES.index(no_go_desc)   # Get the index of the non-agricultural land use
            no_go_x_rk[:, no_go_j] = no_go_x_r
            
    # Assign non-ag maximum land-use proportions
    no_go_x_rk = (t_rk * no_go_x_rk).astype(np.float32)
    
    # Riparian Plantings can not exceed its proportion to the cell
    RP_j = data.NON_AGRICULTURAL_LANDUSES.index('Riparian Plantings')
    no_go_x_rk[:, RP_j] *= data.RP_PROPORTION                  

    return no_go_x_rk


def get_lower_bound_non_agricultural_matrices(data: Data, base_year) -> np.ndarray:
    """
    Get the non-agricultural lower bound matrix.

    Returns
    -------
    2-D array, indexed by (r,k) where r is the cell and k is the non-agricultural land usage.
    """

    if base_year == data.YR_CAL_BASE or base_year not in data.non_ag_dvars:
        return np.zeros((data.NCELLS, len(settings.NON_AG_LAND_USES))).astype(np.float32)
        
    # return np.divide(
    #     np.floor(data.non_ag_dvars[base_year].astype(np.float32) * 10 ** settings.ROUND_DECMIALS),
    #     10 ** settings.ROUND_DECMIALS,
    # )
    
    return data.non_ag_dvars[base_year].astype(np.float32)
```

## luto/economics/non_agricultural/water.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import numpy as np
import luto.data as Data

from typing import Optional
from luto import tools


def get_w_net_yield_env_planting(
    data: Data, 
    yr_idx: int, 
    water_dr_yield: Optional[np.ndarray] = None,
    water_sr_yield: Optional[np.ndarray] = None
    ) -> np.ndarray:
    """
    Get water yields vector of environmental plantings.

    Environmental plantings refer to restoring land to its pre-European vegetation state. 
    So we need to use the `get_water_nl_yield_for_yr_idx` to consider both deep-rooted and 
    shallow-rooted water yields under the pre-European vegetation state.

    Returns
    -------
    1-D array, indexed by cell.
    
    Notes
    -----
    If `water_dr_yield` and `water_sr_yield` are provided, the function will calculate
    the water yields regardless of the `yr_idx`.
    """
    w_yield_dr = data.WATER_YIELD_DR_FILE[yr_idx] if water_dr_yield is None else water_dr_yield
    w_yield_sr = data.WATER_YIELD_SR_FILE[yr_idx] if water_sr_yield is None else water_sr_yield
    w_yield_nl = data.get_water_nl_yield_for_yr_idx(yr_idx, w_yield_dr, w_yield_sr)
    wyield = w_yield_nl * data.REAL_AREA
    return wyield


def get_w_net_yield_carbon_plantings_block(
    data: Data, 
    yr_idx: int, 
    water_dr_yield: Optional[np.ndarray] = None
    ) -> np.ndarray:
    """
    Get water yields vector of carbon plantings (block arrangement).

    Carbon plantings are pure deep-rooted systems.

    Returns
    -------
    1-D array, indexed by cell.
    """
    w_yield_dr = data.WATER_YIELD_DR_FILE[yr_idx] if water_dr_yield is None else water_dr_yield
    wyield = w_yield_dr * data.REAL_AREA
    return wyield


def get_w_net_yield_rip_planting(
    data: Data, 
    yr_idx: int, 
    water_dr_yield: Optional[np.ndarray] = None
    ) -> np.ndarray:
    """
    Get water yields vector of riparian plantings.

    Note: this is the same as for environmental plantings.

    Returns
    -------
    1-D array, indexed by cell.
    """
    return get_w_net_yield_env_planting(data, yr_idx, water_dr_yield)


def get_w_net_yield_agroforestry_base(
    data: Data, 
    yr_idx: int, 
    water_dr_yield: Optional[np.ndarray] = None,
    water_sr_yield: Optional[np.ndarray] = None
    ) -> np.ndarray:
    """
    Get water yields vector of agroforestry.

    Note: this is the same as for environmental plantings.

    Returns
    -------
    1-D array, indexed by cell.
    """
    return get_w_net_yield_env_planting(data, yr_idx, water_dr_yield, water_sr_yield)


def get_w_net_yield_sheep_agroforestry(
    data: Data, 
    ag_w_mrj: np.ndarray, 
    agroforestry_x_r: np.ndarray,
    yr_idx: int,
    water_dr_yield: Optional[np.ndarray] = None,
    water_sr_yield: Optional[np.ndarray] = None
) -> np.ndarray:
    """
    Parameters
    ------
    data object.
    ag_w_mrj: agricultural water requirements matrix.
    agroforestry_x_r: Agroforestry exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    sheep_j = tools.get_sheep_code(data)

    # Only use the dryland version of sheep
    sheep_w_net_yield = ag_w_mrj[0, :, sheep_j]
    base_agroforestry_w_net_yield = get_w_net_yield_agroforestry_base(data, yr_idx, water_dr_yield, water_sr_yield)

    # Calculate contributions and return the sum
    agroforestry_contr = base_agroforestry_w_net_yield * agroforestry_x_r
    sheep_contr = sheep_w_net_yield * (1 - agroforestry_x_r)
    return agroforestry_contr + sheep_contr


def get_w_net_yield_beef_agroforestry(
    data: Data, 
    ag_w_mrj: np.ndarray, 
    agroforestry_x_r: np.ndarray,
    yr_idx: int,
    water_dr_yield: Optional[np.ndarray] = None,
    water_sr_yield: Optional[np.ndarray] = None
) -> np.ndarray:
    """
    Parameters
    ------
    data object.
    ag_w_mrj: agricultural water yield matrix.
    agroforestry_x_r: Agroforestry exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    beef_j = tools.get_beef_code(data)

    # Only use the dryland version of beef
    beef_w_net_yield = ag_w_mrj[0, :, beef_j]
    base_agroforestry_w_net_yield = get_w_net_yield_agroforestry_base(data, yr_idx, water_dr_yield, water_sr_yield)

    # Calculate contributions and return the sum
    agroforestry_contr = base_agroforestry_w_net_yield * agroforestry_x_r
    beef_contr = beef_w_net_yield * (1 - agroforestry_x_r)
    return agroforestry_contr + beef_contr


def get_w_net_yield_carbon_plantings_belt_base(data, yr_idx: int, water_dr_yield: Optional[np.ndarray] = None) -> np.ndarray:
    """
    Get water requirments vector of carbon plantings (belt arrangement).

    Note: this is the same as for carbon plantings.

    Returns
    -------
    1-D array, indexed by cell.
    """
    return get_w_net_yield_carbon_plantings_block(data, yr_idx, water_dr_yield)


def get_w_net_yield_sheep_carbon_plantings_belt(
    data: Data, 
    ag_w_mrj: np.ndarray, 
    cp_belt_x_r: np.ndarray,
    yr_idx: int,
    water_dr_yield: Optional[np.ndarray] = None
) -> np.ndarray:
    """
    Parameters
    ------
    data object.
    ag_w_mrj: agricultural water requirements matrix.
    cp_belt_x_r: Carbon plantings belt exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    sheep_j = tools.get_sheep_code(data)

    # Only use the dryland version of sheep
    sheep_w_net_yield = ag_w_mrj[0, :, sheep_j]
    base_cp_w_net_yield = get_w_net_yield_carbon_plantings_belt_base(data, yr_idx, water_dr_yield)

    # Calculate contributions and return the sum
    cp_contr = base_cp_w_net_yield * cp_belt_x_r
    sheep_contr = sheep_w_net_yield * (1 - cp_belt_x_r)
    return cp_contr + sheep_contr


def get_w_net_yield_beef_carbon_plantings_belt(
    data: Data, 
    ag_w_mrj: np.ndarray, 
    cp_belt_x_r: np.ndarray,
    yr_idx: int,
    water_dr_yield: Optional[np.ndarray] = None
) -> np.ndarray:
    """
    Parameters
    ------
    data object.
    ag_w_mrj: agricultural water requirements matrix.
    cp_belt_x_r: Carbon plantings belt exclude matrix.

    Returns
    ------
    Numpy array indexed by r
    """
    beef_j = tools.get_beef_code(data)

    # Only use the dryland version of beef
    beef_w_net_yield = ag_w_mrj[0, :, beef_j]
    base_cp_w_net_yield = get_w_net_yield_carbon_plantings_belt_base(data, yr_idx, water_dr_yield)

    # Calculate contributions and return the sum
    cp_contr = base_cp_w_net_yield * cp_belt_x_r
    beef_contr = beef_w_net_yield * (1 - cp_belt_x_r)
    return cp_contr + beef_contr


def get_w_net_yield_beccs(data, yr_idx: int, water_dr_yield: Optional[np.ndarray] = None) -> np.ndarray:
    """
    Get water requirments vector of BECCS.

    Note: this is the same as for carbon plantings.

    Returns
    -------
    1-D array, indexed by cell.
    """
    return get_w_net_yield_carbon_plantings_block(data, yr_idx, water_dr_yield)


def get_w_net_yield_destocked(data, ag_w_mrj):
    unallocated_j = tools.get_unallocated_natural_land_code(data)
    return ag_w_mrj[0, :, unallocated_j]


def get_w_net_yield_matrix(
    data: Data,
    ag_w_mrj: np.ndarray,
    lumap: np.ndarray,
    yr_idx: int,
    water_dr_yield: Optional[np.ndarray] = None,
    water_sr_yield: Optional[np.ndarray] = None
) -> np.ndarray:
    """
    Get the water yields matrix for all non-agricultural land uses.

    Parameters
    ----------
    data : object
        The data object containing necessary information for calculating the water yields.

    Returns
    -------
    np.ndarray
        The water yields matrix for all non-agricultural land uses.
        Indexed by (r, k) where r is the cell index and k is the non-agricultural land usage index.
    """
    agroforestry_x_r = tools.get_exclusions_agroforestry_base(data, lumap)
    cp_belt_x_r = tools.get_exclusions_carbon_plantings_belt_base(data, lumap)

    non_agr_yield_matrices = [
        get_w_net_yield_env_planting(data, yr_idx, water_dr_yield, water_sr_yield)                     ,
        get_w_net_yield_rip_planting(data, yr_idx, water_dr_yield)                                     ,
        get_w_net_yield_sheep_agroforestry(data, ag_w_mrj, agroforestry_x_r, yr_idx, water_dr_yield, water_sr_yield) ,
        get_w_net_yield_beef_agroforestry(data, ag_w_mrj, agroforestry_x_r, yr_idx, water_dr_yield, water_sr_yield)  ,
        get_w_net_yield_carbon_plantings_block(data, yr_idx, water_dr_yield)                           ,
        get_w_net_yield_sheep_carbon_plantings_belt(data, ag_w_mrj, cp_belt_x_r, yr_idx, water_dr_yield)             ,
        get_w_net_yield_beef_carbon_plantings_belt(data, ag_w_mrj, cp_belt_x_r, yr_idx, water_dr_yield)              ,
        get_w_net_yield_beccs(data, yr_idx, water_dr_yield)                                                   ,
        get_w_net_yield_destocked(data, ag_w_mrj)                                                             
    ]

    # reshape each non-agricultural matrix to be indexed (r, k) and concatenate on the k indexing
    return np.concatenate([
        arr.reshape((data.NCELLS, 1)) for arr in non_agr_yield_matrices
    ], axis=1)
```

## luto/economics/off_land_commodity/__init__.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import pandas as pd

# import luto settings
from luto.settings import (
    INPUT_DIR, 
    SCENARIO, 
    DIET_DOM, 
    DIET_GLOB,
    CONVERGENCE, 
    IMPORT_TREND, 
    WASTE, 
    FEED_EFFICIENCY,
    EGGS_AVG_WEIGHT
)


def get_demand_df(egg_weight=EGGS_AVG_WEIGHT) -> pd.DataFrame:
    """
    Get the demand dataframe for off-land commodities.

    Args:
        egg_weight (int, optional): The weight of each egg in grams. Defaults to settings.EGGS_AVG_WEIGHT.

    Returns
        pd.DataFrame: The demand dataframe for off-land commodities.
    """

    # Read the demand data
    dd = pd.read_hdf(f'{INPUT_DIR}/demand_projections.h5')

    # Select the demand data under the running scenario
    DEMAND_DATA = dd.loc[(
        SCENARIO, DIET_DOM, DIET_GLOB, CONVERGENCE, IMPORT_TREND, WASTE, FEED_EFFICIENCY)].copy()

    # Convert eggs from count to tonnes
    DEMAND_DATA.loc['eggs'] = DEMAND_DATA.loc['eggs'] * egg_weight / 1000 / 1000

    # Filter the demand data to only include years up to the target year
    DEMAND_DATA_long = DEMAND_DATA.melt(
        ignore_index=False,
        value_name='Quantity (tonnes, KL)'
    ).reset_index()

    DEMAND_DATA_long.columns = ['Commodity', 'Type', 'Year', 'Quantity (tonnes, KL)']

    # Rename the columns, so that they are the same with LUTO naming convention
    DEMAND_DATA_long['Type'] = DEMAND_DATA_long['Type'].str.title()
    DEMAND_DATA_long['Commodity'] = DEMAND_DATA_long['Commodity'] \
        .apply(lambda x: x[0].upper() + x[1:].lower())

    return DEMAND_DATA_long
```

## luto/helpers.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.



"""
LUTO 2.0 temporary helper code.
"""

# Protect against accidental running of entire script and deleting input data
import sys
import datetime
sys.exit()

# # To run LUTO, execute steps 1-4 below...

# 1. Refresh input data (if required)
from luto.dataprep import create_new_dataset
create_new_dataset()

# 2. Run the simulation and profile memory use
%load_ext memory_profiler
import luto.simulation as sim
data = sim.load_data()
%memit sim.run(data=data, base=2010, target=2050)

# 3. Write the ouputs to file
from luto.tools.write import write_outputs
write_outputs(data)


#############################################################
# Minimalist run code
#############################################################
from luto.dataprep import create_new_dataset
create_new_dataset()

import luto.simulation as sim
data = sim.load_data()
sim.run(data=data, base=2010, target=2050)


#############################################################
# Save data object to disk
#############################################################
import luto.simulation as sim
data = sim.load_data()
sim.save_data_to_disk(data, f'F:/jinzhu/TMP/Data_object/Data_{settings.RESFACTOR}_without_output_{datetime.date.today().isoformat()}.pkl')


#############################################################
# Faster data loading (6min -> 10s)
#############################################################
import luto.simulation as sim
data = sim.load_data_from_disk('F:/jinzhu/TMP/Data_object/Data_RES10_without_output_2024-11-10.pkl') 
sim.run(data=data, base=2010, target=2050)





#################################################### Pixel-level data testing code

import pandas as pd
import numpy as np
import luto.simulation as sim
import luto.economics.agricultural.transitions as ag_transition
import luto.economics.agricultural.cost as ag_cost
import luto.economics.agricultural.revenue as ag_revenue
from luto.economics.agricultural.ghg import get_ghg_transition_emissions
from luto import settings
import random as rand
  
# Load data object into memory
data = sim.Data(sim.bdata, 2030)

# Read in the lmap dataframe which contains land-use and land management mapping from 2010, mask and reset index
lmap = pd.read_hdf('../raw_data/cell_LU_mapping.h5')[data.MASK].reset_index()

# Load cropping and irrigation exclusion factors and mask them
prec_over_175mm = pd.read_hdf('../raw_data/cell_biophysical_df.h5')['AVG_GROW_SEAS_PREC_GE_175_MM_YR'].to_numpy()[data.MASK]
pot_irr_areas = pd.read_hdf('../raw_data/cell_zones_df.h5')['POTENTIAL_IRRIGATION_AREAS'].to_numpy()[data.MASK]

# Get array containing cell index values where potential irrigation == 1
irr_idx = np.nonzero(pot_irr_areas)[0]

# Load land use and land management maps
lumap = data.LUMAP
lmmap = data.LMMAP
lumaps = {2010:lumap}
lmmaps = {2010:lmmap}
d = {0:'Dryland', 1:'Irrigated'}

# Calculate the exclude, transistions costs, and cost of production matrices
x_mrj = ag_transition.get_to_ag_exclude_matrices(data, 2010, lumaps)
t_mrj = ag_transition.get_transition_matrices_ag2ag_from_base_year(data, 20, 2010)
gct_mrj = get_ghg_transition_emissions(data, lumap) * data.get_carbon_price_by_yr_idx(0)
c_mrj = ag_cost.get_cost_matrices(data, 0, lumap) - gct_mrj
r_mrj = ag_revenue.get_rev_matrices(data, 0)

# Load ag_X_mrj file from a run with the same resfactor
ag_X_mrj = np.load('output/2023_09_02__14_02_41/ag_X_mrj_2030.npy')

# Get cells which are Sheep - modified land in 2030
sheep_mod_2030 = ag_X_mrj[..., data.AGRICULTURAL_LANDUSES.index('Sheep - modified land')]

# Get cells which are Unallocated - natural land in 2010
uall_nat_2010 = lumap == data.AGRICULTURAL_LANDUSES.index('Unallocated - natural land')

# Get cells which change from Unall - nat to Sheep - mod
xind = np.nonzero( (sheep_mod_2030 * uall_nat_2010)[0] )[0]

def spot_check(r):
    
    # Get SA2_ID
    sa2 = lmap.loc[r, 'SA2_ID'].item()
    
    print('\nCELL_ID', r, data.AGRICULTURAL_LANDUSES[lumap[r]], ',', d[lmmap[r]], ', SA2', sa2, ', RF excl', str(prec_over_175mm[r]) + ', IRR excl', str(pot_irr_areas[r]), '\n')
    
    # Print unique land-use and land management types in the SA2
    df = lmap.query('SA2_ID == @sa2')[['IRRIGATION', 'LU_DESC']].drop_duplicates()
    df = df.sort_values(['IRRIGATION', 'LU_DESC'])
    print(df)
    
    print('\n' + f'{"Dryland land-uses" : <48}{"Irrigated land-uses" : <0}')
    
    print(f'{"X" : <4}{"TransCosts" : <12}{"GHG_Costs" : <12}{"Costs" : <10}{"Rev" : <10}{"X" : <4}{"TransCosts" : <12}{"GHG_Costs" : <12}{"Costs" : <10}{"Rev" : <10}')
            
    for i in range(len(data.AGRICULTURAL_LANDUSES)):
        print(f'{x_mrj[0, r, i] : <4}{t_mrj[0, r, i] : <12,.0f}{gct_mrj[0, r, i] : <12,.0f}{c_mrj[0, r, i] : <10,.0f}{r_mrj[0, r, i] : <10,.0f}{x_mrj[1, r, i] : <4}{t_mrj[1, r, i] : <12,.0f}{gct_mrj[1, r, i] : <12,.0f}{c_mrj[1, r, i] : <10,.0f}{r_mrj[1, r, i] : <10,.0f}{data.AGRICULTURAL_LANDUSES[i] : <10}')

r = rand.randint(0, data.NCELLS)
r = rand.choice(irr_idx)
r = rand.choice(xind)
spot_check(r)

####################################################





write_files(sim, path)
write_production(sim, 2030, d_c, path)
write_water(sim, 2030, path)
write_ghg(sim, 2030, path)

data = sim.data
df_2010 = get_water_totals(data, sim.lumaps[2010], sim.lmmaps[2010])
df_2030 = get_water_totals(data, sim.lumaps[2030], sim.lmmaps[2030])



# Example of code to inspect things 
sim.bdata.WREQ_CROPS_DRY_RJ

import sys
sys.getsizeof(sim.data.WREQ_LVSTK_DRY_RJ)

import luto.simulation as sim
t_mrj, c_mrj, q_mrp, l_mrj = temp(2010, 2030, sim.d_c, 1000)

#Check compare output maps
import numpy as np
new = np.load('N:/LUF-Modelling/LUTO2_BB/LUTO2/output/2022_11_20__09_23_06/lumap2030.npy')
old = np.load('N:/LUF-Modelling/LUTO2_BB/LUTO2/output/2022_11_20__09_24_47/lumap2030.npy')
ind = np.flatnonzero(old != new)
ind.shape
for row in ind:
    print(old[row], new[row])

# Get commodity production totals when no resfactor used and check against raw data
x = get_production()
for i, j in enumerate(sim.data.COMMODITIES):
    print(j, x[i])

import pandas as pd
raw_econ = pd.read_hdf('N:/Data-Master/Profit_map/cell_ag_data.h5')
raw_yield = raw_econ.groupby(['SPREAD_DESC'], observed = True, as_index = False).agg(CROPS_TONNES = ('CROPS_TONNES', 'sum'),
                                                                                     MEAT_EXCL_LEXP_TONNES = ('MEAT_EXCL_LEXP_TONNES', 'sum'),
                                                                                     MEAT_INCL_LEXP_TONNES = ('MEAT_INCL_LEXP_TONNES', 'sum'),
                                                                                     LIVE_EXP_HEAD = ('LIVE_EXP_HEAD', 'sum'),
                                                                                     LIVE_EXP_MEAT_TONNES = ('LIVE_EXP_MEAT_TONNES', 'sum'),
                                                                                     MILK_KL = ('MILK_KL', 'sum'),
                                                                                     WOOL_TONNES = ('WOOL_TONNES', 'sum'))
         



dem_SSP2 = np.load('N:/LUF-Modelling/fdh-archive/data/neoluto-data/new-data-and-domain/demands-ssp2-2010-2100.npy')


agec_crops_fdh_neo = pd.read_hdf('N:/LUF-Modelling/fdh-archive/dev/neoluto/input/agec-crops-c9.hdf5')

agec_crops_fdh = pd.read_hdf('N:/LUF-Modelling/fdh-archive/data/neoluto-data/new-data-and-domain/agec-crops-c9.hdf5')

agec_crops_fdh_neo.equals(agec_crops_fdh)


AGEC_CROPS.columns.get_level_values(2).unique()

AGGHG_CROPS.columns.levels

AGGHG_CROPS.loc[0:10, (slice(None), 'dry', 'Winter cereals')]


for lu in sim.bdata.AGRICULTURAL_LANDUSES:
    if lu in x_dry.columns:
        print(lu, 'True')
    else:
        print(lu, 'False')
        
def i(array):
    print('Size in memory {:.2f} MB'.format(array.itemsize * array.size / 2**20))
    print('Shape %s' % str(array.shape))
    print('Datatype %s' % str(array.dtype))

def temp( base    # Base year from which the data is taken.
        , target  # Year to be solved for.
        , demands # Demands in the form of a d_c array.
        , penalty # Penalty level.
        # , limits  # (Environmental) limits as additional soft/hard constraints.
        ):
    """Solve the linear programme using the `base` lumap for `target` year."""

    # Synchronise base and target years across module so matrix-getters know.
    sync_years(base, target)

    return get_t_mrj(), get_c_mrj(), get_q_mrp(), get_x_mrj()
```

## luto/memory_test.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import sys
sys.path.append('.')

from memory_profiler import profile
import luto.simulation as sim  
from luto.tools import write

data = sim.load_data()
sim.run(data)
write.write_outputs(sim)
```

## luto/settings.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.



""" LUTO model settings. """

import os
import pandas as pd


# ---------------------------------------------------------------------------- #
# LUTO model version.                                                                 #
# ---------------------------------------------------------------------------- #

VERSION = '2.3'


# ---------------------------------------------------------------------------- #
# Spyder options                                                            #
# ---------------------------------------------------------------------------- #

pd.set_option('display.width', 470)
pd.set_option('display.max_columns', 100)
pd.set_option('display.max_rows', 100)
pd.set_option('display.float_format', '{:,.4f}'.format)


# ---------------------------------------------------------------------------- #
# Directories.                                                                 #
# ---------------------------------------------------------------------------- #

INPUT_DIR = 'input'
OUTPUT_DIR = 'output'
RAW_DATA = '../raw_data'


# ---------------------------------------------------------------------------- #
# Scenario parameters.                                                                  #
# ---------------------------------------------------------------------------- #

# Climate change assumptions. Options include '126', '245', '370', '585'
SSP = '245'
RCP = 'rcp' + SSP[1] + 'p' + SSP[2] # Representative Concentration Pathway string identifier e.g., 'rcp4p5'.

# Set demand parameters which define requirements for Australian production of agricultural commodities
SCENARIO = 'SSP' + SSP[0] # SSP1, SSP2, SSP3, SSP4, SSP5
DIET_DOM = 'BAU'                    # 'BAU', 'FLX', 'VEG', 'VGN' - domestic diets in Australia
DIET_GLOB = 'BAU'                   # 'BAU', 'FLX', 'VEG', 'VGN' - global diets
CONVERGENCE = 2050                  # 2050 or 2100 - date at which dietary transformation is completed (velocity of transformation)
IMPORT_TREND = 'Static'             # 'Static' (assumes 2010 shares of imports for each commodity) or 'Trend' (follows historical rate of change in shares of imports for each commodity)
WASTE = 1                           # 1 for full waste, 0.5 for half waste
FEED_EFFICIENCY = 'BAU'             # 'BAU' or 'High'

# Add CO2 fertilisation effects on agricultural production from GAEZ v4
CO2_FERT = 'off'   # or 'off'

# Fire impacts on carbon sequestration
RISK_OF_REVERSAL = 0.05  # Risk of reversal buffer under ERF (reasonable values range from 0.05 [100 years] to 0.25 [25 years]) https://www.cleanenergyregulator.gov.au/ERF/Choosing-a-project-type/Opportunities-for-the-land-sector/Risk-of-reversal-buffer
FIRE_RISK = 'med'   # Options are 'low', 'med', 'high'. Determines whether to take the 5th, 50th, or 95th percentile of modelled fire impacts.
""" Mean FIRE_RISK cell values (%)
    FD_RISK_PERC_5TH    80.3967
    FD_RISK_MEDIAN      89.2485
    FD_RISK_PERC_95TH   93.2735 """


# ---------------------------------------------------------------------------- #
# Economic parameters
# ---------------------------------------------------------------------------- #

# Amortise upfront (i.e., establishment and transitions) costs
AMORTISE_UPFRONT_COSTS = False

# Discount rate for amortisation
DISCOUNT_RATE = 0.07     # 0.05 = 5% pa.

# Set amortisation period
AMORTISATION_PERIOD = 30 # years



# ---------------------------------------------------------------------------- #
# Model parameters
# ---------------------------------------------------------------------------- #

# Optionally coarse-grain spatial domain (faster runs useful for testing). E.g. RESFACTOR 5 selects the middle cell in every 5 x 5 cell block
RESFACTOR = 13      # set to 1 to run at full spatial resolution, > 1 to run at reduced resolution.

# The step size for the temporal domain (years)
SIM_YEARS = list(range(2020,2051,5)) # range(2020,2050)


# Define the objective function
OBJECTIVE = 'maxprofit'   # maximise profit (revenue - costs)  **** Requires soft demand constraints otherwise agriculture over-produces
# OBJECTIVE = 'mincost'  # minimise cost (transitions costs + annual production costs)



"""
If any of the targets are set to 'soft':
    Then they will have a deviation from target (normalised to near 1
    by dividing their BASE_YR (2010) sum) in the objective function.

    Here the weights determine the relative importance of each target 
    in the objective function.E.g., if SOLVER_WEIGHT_GHG = 2 and the 
    rest are 1, then reducing GHG deviation from target will be twice 
    as important as the other targets in the objective function.

If the target is set to 'hard' or 'off': 
    Then the deviation from target will be 0 and the weight will not be used.
"""
SOLVER_WEIGHT_DEMAND = 1
SOLVER_WEIGHT_GHG = 1
SOLVER_WEIGHT_WATER = 1

RESCALE_FACTOR = 1e3
'''
All input data before feeding into the solver is rescaled in the range between 0 and this factor.
This is to avoid numerical issues with the solver when dealing with very small/large numbers. 
E.g., the water yield for some cells is 10t but the Biodiversity-score is 1e-7, making the 
the model sensitive to variations in input data. 
'''



# ---------------------------------------------------------------------------- #
# Geographical raster writing parameters
# ---------------------------------------------------------------------------- #
PARALLEL_WRITE = True                       # If to use parallel processing to write GeoTiffs: True or False
WRITE_THREADS = min(10, os.cpu_count())     # The Threads to use for map making, only work with PARALLEL_WRITE = True

# ---------------------------------------------------------------------------- #
# Gurobi parameters
# ---------------------------------------------------------------------------- #

# Select Gurobi algorithm used to solve continuous models or the initial root relaxation of a MIP model. Default is automatic.
SOLVE_METHOD = 2  # 'automatic: -1, primal simplex: 0, dual simplex: 0, barrier: 2, concurrent: 3, deterministic concurrent: 4, deterministic concurrent simplex: 5

# Presolve parameters (switching both to 0 solves numerical problems)
PRESOLVE = 0     # automatic (-1), off (0), conservative (1), or aggressive (2)
AGGREGATE = 0    # Controls the aggregation level in presolve. The options are off (0), moderate (1), or aggressive (2). In rare instances, aggregation can lead to an accumulation of numerical errors. Turning it off can sometimes improve solution accuracy (it did not fix sub-optimal termination issue)

# Print detailed output to screen
VERBOSE = 1

# Relax the tolerances for feasibility and optimality
FEASIBILITY_TOLERANCE = 1e-2              # Primal feasility tolerance - Default: 1e-6, Min: 1e-9, Max: 1e-2
OPTIMALITY_TOLERANCE = 1e-2               # Dual feasility tolerance - Default: 1e-6, Min: 1e-9, Max: 1e-2
BARRIER_CONVERGENCE_TOLERANCE = 1e-5      # Range from 1e-2 to 1e-8 (default), that larger the number the faster but the less exact the solve. 1e-5 is a good compromise between optimality and speed.

# Whether to use crossover in barrier solve. 0 = off, -1 = automatic. Auto cleans up sub-optimal termination errors without much additional compute time (apart from 2050 when it sometimes never finishes).
CROSSOVER = 0

# Parameters for dealing with numerical issues. NUMERIC_FOCUS = 2 fixes most things but roughly doubles solve time.
SCALE_FLAG = -1     # Scales the rows and columns of the model to improve the numerical properties of the constraint matrix. -1: Auto, 0: No scaling, 1: equilibrium scaling (First scale each row to make its largest nonzero entry to be magnitude one, then scale each column to max-norm 1), 2: geometric scaling, 3: multi-pass equilibrium scaling. Testing revealed that 1 tripled solve time, 3 led to numerical problems.
NUMERIC_FOCUS = 0   # Controls the degree to which the code attempts to detect and manage numerical issues. Default (0) makes an automatic choice, with a slight preference for speed. Settings 1-3 increasingly shift the focus towards being more careful in numerical computations. NUMERIC_FOCUS = 1 is ok, but 2 increases solve time by ~4x
BARHOMOGENOUS = 1   # Useful for recognizing infeasibility or unboundedness. At the default setting (-1), it is only used when barrier solves a node relaxation for a MIP model. 0 = off, 1 = on. It is a bit slower than the default algorithm (3x slower in testing).

# Number of threads to use in parallel algorithms (e.g., barrier)
THREADS = min(32, os.cpu_count())



# ---------------------------------------------------------------------------- #
# No-Go areas; Regional adoption constraints
# ---------------------------------------------------------------------------- #

EXCLUDE_NO_GO_LU = False
NO_GO_VECTORS = {
    'Winter cereals':           os.path.join(os.path.abspath(INPUT_DIR), 'no_go_areas', 'no_go_Winter_cereals.shp'),
    'Environmental Plantings':  os.path.join(os.path.abspath(INPUT_DIR), 'no_go_areas', 'no_go_Enviornmental_Plantings.shp')
}
'''
Land-use and vector file pairs to exclude land-use from being utilised in that area. 
 - The key is the land-use name. 
 - The value is the path to the ESRI shapefile.
'''

REGIONAL_ADOPTION_CONSTRAINTS = 'NON_AG_UNIFORM'    # 'off', 'on', 'NON_AG_UNIFORM'
REGIONAL_ADOPTION_NON_AG_UNIFORM = 15                # None or numbers between 0-100 (both inclusive); Only work under 'NON_AG_UNIFORM'!
                                                    #   E.g., 5 means each non-ag land can not exceed 5% adoption in every region
REGIONAL_ADOPTION_ZONE = 'NRM_CODE'                 # 'ABARES_AAGIS', 'LGA_CODE', 'NRM_CODE', 'IBRA_ID', 'SLA_5DIGIT'
'''
The regional adoption zone is the spatial unit used to enforce regional adoption constraints.
The options are:
  - 'ABARES_AAGIS': Australian Bureau of Agricultural and Resource Economics and Sciences (ABARES) Agricultural and Agribusiness Geographic Information System (AAGIS) regions.
  - 'LGA_CODE': Local Government Area code.
  - 'NRM_CODE': Natural Resource Management code.
  - 'IBRA_ID': Interim Biogeographic Regionalisation of Australia (IBRA) region code.
  - 'SLA_5DIGIT': Statistical Local Area (SLA) 5-digit code.
'''



# ---------------------------------------------------------------------------- #
# Non-agricultural land usage parameters
# ---------------------------------------------------------------------------- #

NON_AG_LAND_USES = {
    'Environmental Plantings': True,
    'Riparian Plantings': True,
    'Sheep Agroforestry': True,
    'Beef Agroforestry': True,
    'Carbon Plantings (Block)': True,
    'Sheep Carbon Plantings (Belt)': True,
    'Beef Carbon Plantings (Belt)': True,
    'BECCS': False,
    'Destocked - natural land': True,
}
"""
The dictionary here is the master list of all of the non agricultural land uses
and whether they are currently enabled in the solver (True/False).

To disable a non-agricultural land use, change the correpsonding value of the
NON_AG_LAND_USES dictionary to false.
"""


NON_AG_LAND_USES_REVERSIBLE = {
    'Environmental Plantings': False,
    'Riparian Plantings': False,
    'Sheep Agroforestry': False,
    'Beef Agroforestry': False,
    'Carbon Plantings (Block)': False,
    'Sheep Carbon Plantings (Belt)': False,
    'Beef Carbon Plantings (Belt)': False,
    'BECCS': False,
    'Destocked - natural land': True,
}
"""
The values of the below dictionary determine whether the model is allowed to abandon non-agr.
land uses on cells in the years after it chooses to utilise them. For example, if a cell has is using 'Environmental Plantings'
and the corresponding value in this dictionary is False, all cells using EP must also utilise this land use in all subsequent
years.

CAUTION: Setting reversibility == True can cause infeasibility issues in timeseries runs due to not being able to meet the water constraints.
With the net water yield limit set to say 80%, some catchments could be close to that yield then they experience some land use change to meet
GHG and biodiversity targets. This pushes the catchment close to the net yield constraint. Over time, climate change may reduce the amount of
water yield and if non-ag land uses are not reversible then a catchment may not be able to meet the net yield constraint.
This is expected behaviour and the user must choose how to deal with it.
"""

# Cost of fencing per linear metre
FENCING_COST_PER_M = 2

# Environmental Plantings Parameters
EP_ANNUAL_MAINTENANCE_COST_PER_HA_PER_YEAR = 100
EP_ANNUAL_ECOSYSTEM_SERVICES_BENEFIT_PER_HA_PER_YEAR = 0

# Carbon Plantings Block Parameters
CP_BLOCK_ANNUAL_MAINTENANCE_COST_PER_HA_PER_YEAR = 100
CP_BLOCK_ANNUAL_ECOSYSTEM_SERVICES_BENEFIT_PER_HA_PER_YEAR = 0

# Carbon Plantings Belt Parameters
CP_BELT_ANNUAL_MAINTENANCE_COST_PER_HA_PER_YEAR = 100
CP_BELT_ANNUAL_ECOSYSTEM_SERVICES_BENEFIT_PER_HA_PER_YEAR = 0

CP_BELT_ROW_WIDTH = 20
CP_BELT_ROW_SPACING = 40
CP_BELT_PROPORTION = CP_BELT_ROW_WIDTH / (CP_BELT_ROW_WIDTH + CP_BELT_ROW_SPACING)
cp_no_alleys_per_ha = 100 / (CP_BELT_ROW_WIDTH + CP_BELT_ROW_SPACING)
CP_BELT_FENCING_LENGTH = 100 * cp_no_alleys_per_ha * 2     # Length (average) of fencing required per ha in metres

# Riparian Planting Parameters
RP_ANNUAL_MAINTENANCE_COST_PER_HA_PER_YEAR = 100
RP_ANNUAL_ECOSYSTEM_SERVICES_BENEFIT_PER_HA_PER_YEAR = 0

RIPARIAN_PLANTING_BUFFER_WIDTH = 30
RIPARIAN_PLANTING_TORTUOSITY_FACTOR = 0.5

# Agroforestry Parameters
AF_ANNUAL_MAINTENANCE_COST_PER_HA_PER_YEAR = 100
AF_ANNUAL_ECOSYSTEM_SERVICES_BENEFIT_PER_HA_PER_YEAR = 0

AGROFORESTRY_ROW_WIDTH = 20
AGROFORESTRY_ROW_SPACING = 40
AF_PROPORTION = AGROFORESTRY_ROW_WIDTH / (AGROFORESTRY_ROW_WIDTH + AGROFORESTRY_ROW_SPACING)
no_belts_per_ha = 100 / (AGROFORESTRY_ROW_WIDTH + AGROFORESTRY_ROW_SPACING)
AF_FENCING_LENGTH_HA = 100 * no_belts_per_ha * 2 # Length of fencing required per ha in metres


# ---------------------------------------------------------------------------- #
# Agricultural Management parameters
# ---------------------------------------------------------------------------- #


AG_MANAGEMENTS_TO_LAND_USES = {
    'Asparagopsis taxiformis':  ['Beef - modified land', 'Sheep - modified land', 'Dairy - natural land', 'Dairy - modified land'],
    
    'Precision Agriculture':    [# Cropping:
                                'Hay', 'Summer cereals', 'Summer legumes', 'Summer oilseeds', 'Winter cereals', 'Winter legumes', 'Winter oilseeds',
                                # Intensive Cropping:
                                'Cotton', 'Other non-cereal crops', 'Rice', 'Sugar', 'Vegetables',
                                # Horticulture:
                                'Apples', 'Citrus', 'Grapes', 'Nuts', 'Pears', 'Plantation fruit', 'Stone fruit', 'Tropical stone fruit'],
    
    'Ecological Grazing':       ['Beef - modified land', 'Sheep - modified land', 'Dairy - modified land'],
    
    'Savanna Burning': [        'Beef - natural land', 'Dairy - natural land', 'Sheep - natural land', 'Unallocated - natural land'],
    
    'AgTech EI': [              # Cropping:
                                'Hay', 'Summer cereals', 'Summer legumes', 'Summer oilseeds', 'Winter cereals', 'Winter legumes', 'Winter oilseeds',
                                # Intensive Cropping:
                                'Cotton', 'Other non-cereal crops', 'Rice', 'Sugar', 'Vegetables',
                                # Horticulture:
                                'Apples', 'Citrus', 'Grapes', 'Nuts', 'Pears', 'Plantation fruit', 'Stone fruit', 'Tropical stone fruit'],
    
    'Biochar':                  [# Cropping
                                'Hay', 'Summer cereals', 'Summer legumes', 'Summer oilseeds', 'Winter cereals', 'Winter legumes', 'Winter oilseeds',
                                # Horticulture:
                                'Apples', 'Citrus', 'Grapes', 'Nuts', 'Pears', 'Plantation fruit', 'Stone fruit', 'Tropical stone fruit'],

    'HIR - Beef':               ['Beef - natural land'],
    'HIR - Sheep':              ['Sheep - natural land'],
    'Utility Solar PV':         ['Unallocated - modified land','Beef - modified land', 'Sheep - modified land', 'Dairy - modified land'
                                # Cropping:
                                'Hay', 'Summer cereals', 'Summer legumes', 'Summer oilseeds', 'Winter cereals', 'Winter legumes', 'Winter oilseeds',], 
    'Onshore Wind':             ['Unallocated - modified land','Beef - modified land', 'Sheep - modified land', 'Dairy - modified land',
                                # Cropping:
                                'Hay', 'Summer cereals', 'Summer legumes', 'Summer oilseeds', 'Winter cereals', 'Winter legumes', 'Winter oilseeds',
                                # Intensive Cropping:
                                'Cotton', 'Other non-cereal crops', 'Rice', 'Sugar', 'Vegetables']
                                }                                


AG_MANAGEMENTS = {
    'Asparagopsis taxiformis': True,
    'Precision Agriculture': True,
    'Ecological Grazing': False,
    'Savanna Burning': True,
    'AgTech EI': True,
    'Biochar': True,
    'HIR - Beef': True,
    'HIR - Sheep': True,
    'Utility Solar PV': True,
    'Onshore Wind': True,
}
"""
The dictionary below contains a master list of all agricultural management options and
which land uses they correspond to.

To disable an ag-mangement option, change the corresponding value in the AG_MANAGEMENTS dictionary to False.
"""

AG_MANAGEMENTS_REVERSIBLE = {
    'Asparagopsis taxiformis': True,
    'Precision Agriculture': True,
    'Ecological Grazing': True,
    'Savanna Burning': True,
    'AgTech EI': True,
    'Biochar': True,
    'HIR - Beef': True,
    'HIR - Sheep': True,
    'Utility Solar PV': False,
    'Onshore Wind': False,
}
"""
The values of the below dictionary determine whether the model is allowed to abandon agricultural
management options on cells in the years after it chooses to utilise them. For example, if a cell has is using 'Asparagopsis taxiformis',
and the corresponding value in this dictionary is False, all cells using Asparagopsis taxiformis must also utilise this land use
and agricultural management combination in all subsequent years.

WARNING: changing to False will result in 'locking in' land uses on cells that utilise the agricultural management option for
the rest of the simulation. This may be an unintended side effect.
"""


# The cost for removing and establishing irrigation infrastructure ($ per hectare)
REMOVE_IRRIG_COST = 5000
NEW_IRRIG_COST = 10000

# Savanna burning cost per hectare per year ($/ha/yr)
SAVBURN_COST_HA_YR = 10

# The minimum value an agricultural management variable must take for the write_output function to consider it being used on a cell
AGRICULTURAL_MANAGEMENT_USE_THRESHOLD = 0.1

# Productivity contribution of HIR compared to not implementing HIR
HIR_PRODUCTIVITY_CONTRIBUTION = 0.5

# Maintainace cost for HIR
BEEF_HIR_MAINTENANCE_COST_PER_HA_PER_YEAR = 0
SHEEP_HIR_MAINTENANCE_COST_PER_HA_PER_YEAR = 0

# HIR effecting years
HIR_EFFECT_YEARS = 91

# -------------- Renewable energy parameters ------------------------
# Renewable Energy Generation Density (MW/km²) keyed by normalized technology strings
GENERATION_DENSITY = {
    'Utility Solar PV': 150,    # MW/km²
    'Onshore Wind': 7.2,  # MW/km²
}

def get_generation_density(lm_name: str) -> float:
    """
    Return the generation density (MW/km²) for the given land management name.
    
    Parameters
    ----------
    lm_name : str
        Normalized management type e.g., 'Utility Solar PV' or 'Onshore Wind'
    
    Returns
    -------
    float
        Generation density in MW/km²
    
    Raises
    ------
    ValueError
        If management type is unknown.
    """
    try:
        return GENERATION_DENSITY[lm_name]
    except KeyError:
        raise ValueError(f"Unknown land management name: {lm_name}")

# --------------Renewable energy target parameters ---------------------------- #  
# User selects the renewable energy target aggregation level: 'state' or 'NRM'
RE_TARGET_LEVEL = "state"  # options: "state", "NRM"

# If 'NRM', optionally specify which NRMs to include; None means all
SELECTED_NRM = None  # e.g., ["Mallee", "Corangamite"]

def get_target_level():
    return RE_TARGET_LEVEL

def get_selected_nrm():
    if RE_TARGET_LEVEL.lower() == "nrm":
        return SELECTED_NRM
    return None

# ---------------------------------------------------------------------------- #
# Off-land commodity parameters
# ---------------------------------------------------------------------------- #

OFF_LAND_COMMODITIES = ['pork', 'chicken', 'eggs', 'aquaculture']
EGGS_AVG_WEIGHT = 60  # Average weight of an egg in grams


# ---------------------------------------------------------------------------- #
# Environmental parameters
# ---------------------------------------------------------------------------- #

# Take data from 'GHG_targets.xlsx', 
GHG_TARGETS_DICT = {
    'off':      None,
    'low':      '1.8C (67%) excl. avoided emis SCOPE1',
    'medium':   '1.5C (50%) excl. avoided emis SCOPE1',
    'high':     '1.5C (67%) excl. avoided emis SCOPE1',
}

# Greenhouse gas emissions limits and parameters *******************************
GHG_EMISSIONS_LIMITS = 'high'        # 'off', 'low', 'medium', or 'high'
'''
`GHG_EMISSIONS_LIMITS` options include: 
- Assuming agriculture is responsible to sequester 100% of the carbon emissions
    - '1.5C (67%)', '1.5C (50%)', or '1.8C (67%)' 
- Assuming agriculture is responsible to sequester carbon emissions not including electricity emissions and  off-land emissions 
    - '1.5C (67%) excl. avoided emis', '1.5C (50%) excl. avoided emis', or '1.8C (67%) excl. avoided emis'
- Assuming agriculture is responsible to sequester carbon emissions only in the scope 1 emissions (i.e., direct emissions from land-use and livestock types)
    - '1.5C (67%) excl. avoided emis SCOPE1', '1.5C (50%) excl. avoided emis SCOPE1', or '1.8C (67%) excl. avoided emis SCOPE1'
'''
  	  	  



# Carbon price scenario: either 'AS_GHG', 'Default', '100', or 'CONSTANT', or NONE.
# Setting to None falls back to the 'Default' scenario.
CARBON_PRICES_FIELD = 'CONSTANT'

# Automatically update the carbon price field if it is set to 'AS_GHG'
if CARBON_PRICES_FIELD == 'AS_GHG':
    CARBON_PRICES_FIELD = GHG_TARGETS_DICT[GHG_EMISSIONS_LIMITS][:9].replace('(','')  # '1.5C (67%) excl. avoided emis' -> '1.5C 67%'

if CARBON_PRICES_FIELD == 'CONSTANT':
    CARBON_PRICE_COSTANT = 0.0  # The constant value to add to the carbon price (e.g., $10/tonne CO2e).
'''
Only works when CARBON_PRICES_FIELD is set to 'CONSTANT'.
'''


USE_GHG_SCOPE_1 = True  # If True, only considers the basic GHG types (i.e., CO2E_KG_HA_SOIL, CO2E_KG_HEAD_DUNG_URINE, CO2E_KG_HEAD_ENTERIC, CO2E_KG_HEAD_FODDER, CO2E_KG_HEAD_IND_LEACH_RUNOFF, CO2E_KG_HEAD_SEED).
'''
Basic GHG types are the direct emissions from the land-use and livestock types, excluding
indirect emissions such as fertiliser, irrigation, land management, etc.
'''

CROP_GHG_SCOPE_1 = ['CO2E_KG_HA_SOIL']
LVSTK_GHG_SCOPE_1 = ['CO2E_KG_HEAD_DUNG_URINE', 'CO2E_KG_HEAD_ENTERIC', 'CO2E_KG_HEAD_IND_LEACH_RUNOFF', 'CO2E_KG_HEAD_MANURE_MGT']


# Number of years over which to spread (average) soil carbon accumulation (from Mosnier et al. 2022 and Johnson et al. 2021)
SOC_AMORTISATION = 91   # (2025/05/05) Change from 15 -> 91; This makes sure BIO_CHAR has the same GHG effect span as HIR

GHG_CONSTRAINT_TYPE = 'hard'  # Adds GHG limits as a constraint in the solver (linear programming approach)
# GHG_CONSTRAINT_TYPE = 'soft'  # Adds GHG usage as a type of slack variable in the solver (goal programming approach)

# Weight for the GHG/Demand deviation in the objective function
SOLVE_WEIGHT_ALPHA = 1  
''' 
Range from 0 to 1 that balances the relative important between economic values and biodiversity scores.
 - if approaching 0, the model will focus on maximising biodiversity scores.
 - if approaching 1, the model will focus on maximising prifit (or minimising cost).
'''

SOLVE_WEIGHT_BETA = 0.5
'''
The weight of the deviations from target in the objective function.
 - if approaching 0, the model will ignore the deviations from target.
 - if approaching 1, the model will try harder to meet the target.
'''


# Water use yield and parameters *******************************
WATER_LIMITS = 'on'                     # 'on' or 'off'. 'off' will turn off water net yield limit constraints in the solver.
WATER_CLIMATE_CHANGE_IMPACT = 'on'      # 'on' or 'off'. 'off' will turn off climate change impact on water yields.

WATER_CONSTRAINT_TYPE = 'hard'  # Adds water limits as a constraint in the solver (linear programming approach)
# WATER_CONSTRAINT_TYPE = 'soft'  # Adds water usage as a type of slack variable in the solver (goal programming approach)


# Regionalisation to enforce water use limits by
WATER_REGION_DEF = 'Drainage Division'         # 'River Region' or 'Drainage Division' Bureau of Meteorology GeoFabric definition
"""
    Water net yield targets: the value represents the proportion of the historical water yields
    that the net yield must exceed in a given year. Base year (2010) uses base year net yields as targets.
    Everything past the latest year specified uses the target figure for the latest year.
    
    Safe and just Earth system boundaries suggests a water stress of 0.2 (yield of 0.8). This is inclusive of
    domestic/industrial: https://www.nature.com/articles/s41586-023-06083-8, Approximately 70% of the total water use
    is used for agricultural purposes. This includes water used for irrigation, livestock, and domestic purposes on farms,
    with the rest used for domestic/industrial  https://soe.dcceew.gov.au/inland-water/pressures/population
    Hence, assuming that this proportion is uniform over all catchments and remains constant over time then if water
    stress is 0.2 then agriculture can use up 70% of this, leaving 30% for domestic/industrial. The water yield target for ag
    should then be historical net yield * (1 - water stress * agricultural share)
    
    Aqueduct water stress levels:
    Low stress < 10% of the water available is withdrawn annually
    Low to medium stress 10-20% of the water available is withdrawn annually
    Medium to high stress 20-40% 10% of the water available is withdrawn annually
    High stress 40-80% of the water available is withdrawn annually
    Extremely high stress > 80% of the water available is withdrawn annually
    
    https://chinawaterrisk.org/resources/analysis-reviews/aqueduct-global-water-stress-rankings/ 
"""

WATER_STRESS = 0.6                                      # Aqueduct limit catchments, 0.6 means the water yield in a region must be >= 60% of the historical water yield

# Consider livestock drinking water (0 [off] or 1 [on]) ***** Livestock drinking water can cause infeasibility issues with water constraint in Pilbara
LIVESTOCK_DRINKING_WATER = 1

# Consider water license costs (0 [off] or 1 [on]) of land-use transition ***** If on then there is a noticeable water sell-off by irrigators in the MDB when maximising profit
INCLUDE_WATER_LICENSE_COSTS = 1



# Biodiversity limits and parameters *******************************


# ------------------- Agricultural biodiversity parameters -------------------

GBF2_CONSTRAINT_TYPE = 'hard' # Adds biodiversity limits as a constraint in the solver (linear programming approach)
# GBF2_CONSTRAINT_TYPE = 'soft'  # Adds biodiversity usage as a type of slack variable in the solver (goal programming approach)
'''
The constraint type for the biodiversity target.
- 'hard' adds biodiversity limits as a constraint in the solver (linear programming approach)
- 'soft' adds biodiversity usage as a type of slack variable in the solver (goal programming approach)
'''

# Set biodiversity target (0 - 1 e.g., 0.3 = 30% of total achievable Zonation biodiversity benefit)
GBF2_TARGETS_DICT = {
    'off':     None,
    'low':    {2030: 0,    2050: 0,    2100: 0},
    'medium': {2030: 0.30, 2050: 0.30, 2100: 0.30},
    'high':   {2030: 0.30, 2050: 0.50, 2100: 0.50},
}

# Global Biodiversity Framework Target 2: Restore 30% of all Degraded Ecosystems
BIODIVERSITY_TARGET_GBF_2 = 'high'            # 'off', 'low', 'medium', or 'high'
'''
Kunming-Montreal Global Biodiversity Framework Target 2: Restore 30% of all Degraded Ecosystems
Ensure that by 2030 at least 30 per cent of areas of degraded terrestrial, inland water, and coastal and marine ecosystems are under effective restoration,
in order to enhance biodiversity and ecosystem functions and services, ecological integrity and connectivity.
 - 'off' will turn off the GBF-3 target. 
 - 'low' is the low level of biodiversity target (i.e., restore 0% of degreaded biodiversity socore in the 'priority degraded land').
 - 'medium' is the medium level of biodiversity target (i.e., restore 15% of degreaded biodiversity socore in the 'priority degraded land').
 - 'high' is the high level of biodiversity target (i.e., restore 25% of degreaded biodiversity socore in the 'priority degraded land').
'''


GBF2_PRIORITY_DEGRADED_AREAS_PERCENTAGE_CUT = 20
'''
Based on Zonation alogrithm, the biodiversity feature coverage (an indicator of overall biodiversity benifits) is 
more attached to high rank cells (rank is an indicator of importance/priority in biodiversity conservation). 
For example, cells with rank between 0.9-1.0 only cover 20% of the areas but contribute to 40% of the biodiversity benefits.

By sorting the rank values from high to low and plot the cumulative area and cumulative biodiversity benefits,
we can get the a curve that shows the relationship between the area and the biodiversity benefits. In LUTO, we normalise
the area and biodiversity benefits between 0-100, and use the `GBF2_PRIORITY_DEGRADED_AREAS_PERCENTAGE_CUT` as the threshold
to identify the priority degraded areas that should be conserved to achieve the biodiversity target.

If set to 0, no cells will be considered as priority degraded areas, equal to not setting any GBF2 target.
If set to 100, all cells will be considered as priority degraded areas, equal to setting the GBF2 to the LUTO study area.
'''


# Connectivity source source
CONNECTIVITY_SOURCE = 'NCI'                 # 'DCCEEW_NCI', 'NATURAL_AREA_CONNECTIVITY' or 'NONE'
'''
The connectivity source is the source of the connectivity score used to weigh the raw biodiversity priority score.
This score is normalised between 0 (fartherst) and 1 (closest).
Can be either 'NCI' or 'DWI'.
- if 'NCI' is selected, the connectivity score is sourced from the DCCEEW's National Connectivity Index (v3.0).
- if 'DWI' is selected, the connectivity score is calculated as distance to the nearest area of natural land as mapped
        by the National Land Use Map of Australia.
- if 'NONE' is selected, the connectivity score is not used in the biodiversity calculation.
'''

# Connectivity score importance
CONNECTIVITY_LB = 0.7                       # Avaliable values are [0.5, 0.6, 0.7, 0.8, 0.9]
'''
The relative importance of the connectivity score in the biodiversity calculation. Used to scale the raw biodiversity score.
I.e., the lower bound of the connectivity score for weighting the raw biodiversity priority score is CONNECTIVITY_LB.
'''


# Habitat condition data source
HABITAT_CONDITION = 'USER_DEFINED'                  # One of [10, 25, 50, 75, 90], or 'USER_DEFINED'
'''
Different land-use types have different biodiversity degradation impacts. We calculated the percentiles values of HCAS (indicating the
suitability for wild animals ranging between 0-1) for each land-use type.Avaliable percentiles is one of [10, 25, 50, 75, 90].

For example, the 50th percentile for 'Beef - Modified land' is 0.22, meaning this land retains 22% biodiversity score compared
to undisturbed natural land.
'''


# Biodiversity value under default late dry season savanna fire regime
BIO_CONTRIBUTION_LDS = 0.8
''' For example, 0.8 means that all areas in the area eligible for savanna burning have a biodiversity value of 0.8 * the raw biodiv value
    (due to hot fires etc). When EDS sav burning is implemented the area is attributed the full biodiversity value (i.e., 1.0).
'''

# Non-agricultural biodiversity parameters 
BIO_CONTRIBUTION_ENV_PLANTING = 0.8
BIO_CONTRIBUTION_CARBON_PLANTING_BLOCK = 0.1
BIO_CONTRIBUTION_CARBON_PLANTING_BELT = 0.1
BIO_CONTRIBUTION_RIPARIAN_PLANTING = 1.2
BIO_CONTRIBUTION_AGROFORESTRY = 0.75       
BIO_CONTRIBUTION_BECCS = 0
''' 
The benefit of each non-agricultural land use to biodiversity is set as a proportion to the raw biodiversity priority value.
For example, if the raw biodiversity priority value is 0.6 and the benefit is 0.8, then the biodiversity value
will be 0.6 * 0.8 = 0.48.
'''




# ---------------------- Vegetation parameters ----------------------

GBF3_TARGET_CLASS  = 'MVS'                  # 'MVG', 'MVS', 'MVG_IBRA', 'MVS_IBRA'
'''
The National Vegetation Information System (NVIS) provides the 100m resolution information on
the distribution of vegetation (~30 primary group layers, or ~90 subgroup layers) across Australia.

- If 'MVG/MVS' is selected, use need to define conservation target for each NVIS group across the whole study area.
- If 'MVS_IBRA/MVG_IBRA' is selected, use need to define conservation target for each NVIS group for selected the IBRA region.
'''

GBF3_TARGETS_DICT = {
    'off':     None,
    'medium':  30,
    'high':    50,
    'USER_DEFINED': None
}

BIODIVERSITY_TARGET_GBF_3  = 'off'           # 'off', 'medium', 'high', or 'USER_DEFINED'
'''
Target 3 of the Kunming-Montreal Global Biodiversity Framework:
protect and manage 30% of the world's land, water, and coastal areas by 2030.

- if 'off' is selected, turn off the GBF-3 target for biodiversity.
- if 'medium' is selected, the conservation target is set to 30% for each NVIS group at 2050.
- if 'high' is selected, the conservation target is set to 50% for each NVIS group at 2050.
- if 'USER_DEFINED' is selected, the conservation target is reading from `input.BIODIVERSITY_GBF3_SCORES_AND_TARGETS.xlsx`.
'''



# ------------------------------- Species parameters -------------------------------
BIODIVERSITY_TARGET_GBF_4_SNES =  'off'           # 'on' or 'off'.
BIODIVERSITY_TARGET_GBF_4_ECNES = 'off'           # 'on' or 'off'.

'''
Target 4 of the Kunming-Montreal Global Biodiversity Framework (GBF) aims to 
halt the extinction of known threatened species, protect genetic diversity, 
and manage human-wildlife interactions
'''



# -------------------------------- Climate change impacts on biodiversity -------------------------------
BIODIVERSITY_TARGET_GBF_8 = 'off'           # 'on' or 'off'.
'''
Target 8 of the Kunming-Montreal Global Biodiversity Framework (GBF) aims to 
reduce the impacts of climate change on biodiversity and ecosystems.
'''




# ---------------------------------------------------------------------------- #
# Other parameters
# ---------------------------------------------------------------------------- #

# Cell culling
CULL_MODE = 'absolute'      # cull to include at most MAX_LAND_USES_PER_CELL
# CULL_MODE = 'percentage'    # cull the LAND_USAGE_THRESHOLD_PERCENTAGE % most expensive options
# CULL_MODE = 'none'          # do no culling

MAX_LAND_USES_PER_CELL = 12         if CULL_MODE == 'absolute' else 'Not used'
LAND_USAGE_CULL_PERCENTAGE = 0.15   if CULL_MODE == 'percentage' else 'Not used'

# Non-ag output coding. Non-agricultural land uses will appear on the land use map offset by this amount (e.g. land use 0 will appear as 100)
NON_AGRICULTURAL_LU_BASE_CODE = 100

# Number of decimals to round the lower bound matrices to for non-agricultural land uses and agricultural management options.
ROUND_DECMIALS = 6


""" NON-AGRICULTURAL LAND USES (indexed by k)
0: 'Environmental Plantings'
1: 'Riparian Plantings'
2: 'Sheep Agroforestry'
3: 'Beef Agroforestry'
4: 'Carbon Plantings (Block)'
5: 'Sheep Carbon Plantings (Belt)'
6: 'Beef Carbon Plantings (Belt)'
7: 'BECCS'
8: 'Destocked - natural land'


DRAINAGE DIVISIONS
 1: 'Tanami-Timor Sea Coast',
 2: 'South Western Plateau',
 3: 'South West Coast',
 4: 'Tasmania',
 5: 'South East Coast (Victoria)',
 6: 'South Australian Gulf',
 7: 'Murray-Darling Basin',
 8: 'Pilbara-Gascoyne',
 9: 'North Western Plateau',
 10: 'South East Coast (NSW)',
 11: 'Carpentaria Coast',
 12: 'Lake Eyre Basin',
 13: 'North East Coast'


RIVER REGIONS
 1: 'ADELAIDE RIVER',
 2: 'ALBANY COAST',
 3: 'ARCHER-WATSON RIVERS',
 4: 'ARTHUR RIVER',
 5: 'ASHBURTON RIVER',
 6: 'AVOCA RIVER',
 7: 'AVON RIVER-TYRELL LAKE',
 8: 'BAFFLE CREEK',
 9: 'BARRON RIVER',
 10: 'BARWON RIVER-LAKE CORANGAMITE',
 11: 'BATHURST-MELVILLE ISLANDS',
 12: 'BEGA RIVER',
 13: 'BELLINGER RIVER',
 14: 'BENANEE-WILLANDRA CREEK',
 15: 'BILLABONG-YANCO CREEKS',
 16: 'BLACK RIVER',
 17: 'BLACKWOOD RIVER',
 18: 'BLYTH RIVER',
 19: 'BORDER RIVERS',
 20: 'BOYNE RIVER',
 21: 'BRISBANE RIVER',
 22: 'BROKEN RIVER',
 23: 'BROUGHTON RIVER',
 24: 'BRUNSWICK RIVER',
 25: 'BUCKINGHAM RIVER',
 26: 'BULLO RIVER-LAKE BANCANNIA',
 27: 'BUNYIP RIVER',
 28: 'BURDEKIN RIVER',
 29: 'BURNETT RIVER',
 30: 'BURRUM RIVER',
 31: 'BUSSELTON COAST',
 32: 'CALLIOPE RIVER',
 33: 'CALVERT RIVER',
 34: 'CAMPASPE RIVER',
 35: 'CAPE LEVEQUE COAST',
 36: 'CARDWELL COAST',
 37: 'CASTLEREAGH RIVER',
 38: 'CLARENCE RIVER',
 39: 'CLYDE RIVER-JERVIS BAY',
 40: 'COAL RIVER',
 41: 'COLLIE-PRESTON RIVERS',
 42: 'CONDAMINE-CULGOA RIVERS',
 43: 'COOPER CREEK',
 44: 'CURTIS ISLAND',
 45: 'DAINTREE RIVER',
 46: 'DALY RIVER',
 47: 'DARLING RIVER',
 48: 'DE GREY RIVER',
 49: 'DENMARK RIVER',
 50: 'DERWENT RIVER',
 51: 'DIAMANTINA-GEORGINA RIVERS',
 52: 'DON RIVER',
 53: 'DONNELLY RIVER',
 54: 'DRYSDALE RIVER',
 55: 'DUCIE RIVER',
 56: 'EAST ALLIGATOR RIVER',
 57: 'EAST COAST',
 58: 'EAST GIPPSLAND',
 59: 'EMBLEY RIVER',
 60: 'ENDEAVOUR RIVER',
 61: 'ESPERANCE COAST',
 62: 'EYRE PENINSULA',
 63: 'FINNISS RIVER',
 64: 'FITZMAURICE RIVER',
 65: 'FITZROY RIVER (QLD)',
 66: 'FITZROY RIVER (WA)',
 67: 'FLEURIEU PENINSULA',
 68: 'FLINDERS-CAPE BARREN ISLANDS',
 69: 'FLINDERS-NORMAN RIVERS',
 70: 'FORTESCUE RIVER',
 71: 'FORTH RIVER',
 72: 'FRANKLAND-DEEP RIVERS',
 73: 'FRASER ISLAND',
 74: 'GAIRDNER',
 75: 'GASCOYNE RIVER',
 76: 'GAWLER RIVER',
 77: 'GLENELG RIVER',
 78: 'GOOMADEER RIVER',
 79: 'GORDON RIVER',
 80: 'GOULBURN RIVER',
 81: 'GOYDER RIVER',
 82: 'GREENOUGH RIVER',
 83: 'GROOTE EYLANDT',
 84: 'GWYDIR RIVER',
 85: 'HASTINGS RIVER',
 86: 'HAUGHTON RIVER',
 87: 'HAWKESBURY RIVER',
 88: 'HERBERT RIVER',
 89: 'HINCHINBROOK ISLAND',
 90: 'HOLROYD RIVER',
 91: 'HOPKINS RIVER',
 92: 'HUNTER RIVER',
 93: 'HUON RIVER',
 94: 'ISDELL RIVER',
 95: 'JARDINE RIVER',
 96: 'JEANNIE RIVER',
 97: 'JOHNSTONE RIVER',
 98: 'KANGAROO ISLAND',
 99: 'KARUAH RIVER',
 100: 'KEEP RIVER',
 101: 'KENT RIVER',
 102: 'KIEWA RIVER',
 103: 'KING EDWARD RIVER',
 104: 'KING ISAND',
 105: 'KING-HENTY RIVERS',
 106: 'KINGSTON COAST',
 107: 'KOLAN RIVER',
 108: 'KOOLATONG RIVER',
 109: 'LACHLAN RIVER',
 110: 'LAKE EYRE',
 111: 'LAKE TORRENS-MAMBRAY COAST',
 112: 'LENNARD RIVER',
 113: 'LIMMEN BIGHT RIVER',
 114: 'LITTLE RIVER',
 115: 'LIVERPOOL RIVER',
 116: 'LOCKHART RIVER',
 117: 'LODDON RIVER',
 118: 'LOGAN-ALBERT RIVERS',
 119: 'LOWER MALLEE',
 120: 'LOWER MURRAY RIVER',
 121: 'MACLEAY RIVER',
 122: 'MACQUARIE-BOGAN RIVERS',
 123: 'MACQUARIE-TUGGERAH LAKES',
 124: 'MANNING RIVER',
 125: 'MAROOCHY RIVER',
 126: 'MARY RIVER (NT)',
 127: 'MARY RIVER (QLD)',
 128: 'MERSEY RIVER',
 129: 'MILLICENT COAST',
 130: 'MITCHELL-COLEMAN RIVERS (QLD)',
 131: 'MITCHELL-THOMSON RIVERS',
 132: 'MOONIE RIVER',
 133: 'MOORE-HILL RIVERS',
 134: 'MORNING INLET',
 135: 'MORNINGTON ISLAND',
 136: 'MORUYA RIVER',
 137: 'MOSSMAN RIVER',
 138: 'MOYLE RIVER',
 139: 'MULGRAVE-RUSSELL RIVERS',
 140: 'MURCHISON RIVER',
 141: 'MURRAY RIVER (WA)',
 142: 'MURRAY RIVERINA',
 143: 'MURRUMBIDGEE RIVER',
 144: 'MYPONGA RIVER',
 145: 'McARTHUR RIVER',
 146: 'NAMOI RIVER',
 147: 'NICHOLSON-LEICHHARDT RIVERS',
 148: 'NOOSA RIVER',
 149: 'NORMANBY RIVER',
 150: 'NULLARBOR',
 151: "O'CONNELL RIVER",
 152: 'OLIVE-PASCOE RIVERS',
 153: 'ONKAPARINGA RIVER',
 154: 'ONSLOW COAST',
 155: 'ORD-PENTECOST RIVERS',
 156: 'OTWAY COAST',
 157: 'OVENS RIVER',
 158: 'PAROO RIVER',
 159: 'PIEMAN RIVER',
 160: 'PINE RIVER',
 161: 'PIONEER RIVER',
 162: 'PIPER-RINGAROOMA RIVERS',
 163: 'PLANE CREEK',
 164: 'PORT HEDLAND COAST',
 165: 'PORTLAND COAST',
 166: 'PRINCE REGENT RIVER',
 167: 'PROSERPINE RIVER',
 168: 'RICHMOND RIVER',
 169: 'ROBINSON RIVER',
 170: 'ROPER RIVER',
 171: 'ROSIE RIVER',
 172: 'ROSS RIVER',
 173: 'RUBICON RIVER',
 174: 'SALT LAKE',
 175: 'SANDY CAPE COAST',
 176: 'SANDY DESERT',
 177: 'SETTLEMENT CREEK',
 178: 'SHANNON RIVER',
 179: 'SHOALHAVEN RIVER',
 180: 'SHOALWATER CREEK',
 181: 'SMITHTON-BURNIE COAST',
 182: 'SNOWY RIVER',
 183: 'SOUTH ALLIGATOR RIVER',
 184: 'SOUTH COAST',
 185: 'SOUTH GIPPSLAND',
 186: 'SOUTH-WEST COAST',
 187: 'SPENCER GULF',
 188: 'STEWART RIVER',
 189: 'STRADBROKE ISLAND',
 190: 'STYX RIVER',
 191: 'SWAN COAST-AVON RIVER',
 192: 'SYDNEY COAST-GEORGES RIVER',
 193: 'TAMAR RIVER',
 194: 'TORRENS RIVER',
 195: 'TORRES STRAIT ISLANDS',
 196: 'TOWAMBA RIVER',
 197: 'TOWNS RIVER',
 198: 'TULLY-MURRAY RIVERS',
 199: 'TUROSS RIVER',
 200: 'TWEED RIVER',
 201: 'UPPER MALLEE',
 202: 'UPPER MURRAY RIVER',
 203: 'VICTORIA RIVER-WISO',
 204: 'WAKEFIELD RIVER',
 205: 'WALKER RIVER',
 206: 'WARD RIVER',
 207: 'WARREGO RIVER',
 208: 'WARREN RIVER',
 209: 'WATER PARK CREEK',
 210: 'WENLOCK RIVER',
 211: 'WERRIBEE RIVER',
 212: 'WHITSUNDAY ISLANDS',
 213: 'WILDMAN RIVER',
 214: 'WIMMERA RIVER',
 215: 'WOLLONGONG COAST',
 216: 'WOORAMEL RIVER',
 217: 'YANNARIE RIVER',
 218: 'YARRA RIVER'}
"""
```

## luto/simulation.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.



"""
To maintain state and handle iteration and data-view changes. This module
functions as a singleton class. It is intended to be the _only_ part of the
model that has 'global' varying state.
"""

import os
import time
import dill
import gzip
import pickle
import threading

from gurobipy import GRB
from luto import settings
from luto.data import Data
from luto.solvers.input_data import get_input_data
from luto.solvers.solver import LutoSolver
from luto.tools.write import write_outputs
from luto.tools import (
    LogToFile,
    log_memory_usage,
    set_path,
    write_timestamp,
    read_timestamp
)




def load_data() -> Data:
    """
    Load the Data object containing all required data to run a LUTO simulation.
    """
    
    # Generate new timestamp each time and apply decorator dynamically
    current_timestamp = write_timestamp()
    save_dir = f"{settings.OUTPUT_DIR}/{current_timestamp}_RF{settings.RESFACTOR}_{settings.SIM_YEARS[0]}-{settings.SIM_YEARS[-1]}"
    log_path = f"{save_dir}/LUTO_RUN_"
    set_path()
    
    # Apply the LogToFile decorator dynamically
    @LogToFile(log_path)
    def _load_data():
        # Thread to log memory usage
        stop_event = threading.Event()
        memory_thread = threading.Thread(target=log_memory_usage, args=(save_dir, 'w', 1, stop_event))
        memory_thread.start()
        
        try:
            data = Data()
            data.timestamp = read_timestamp()
            data.path = save_dir
        except Exception as e:
            print(f"An error occurred while loading data: {e}")
            raise e
        finally:
            # Ensure the memory logging thread is stopped
            stop_event.set()
            memory_thread.join()

        return data
    
    return _load_data()


def run(
    data: Data, 
) -> None:
    """
    Run the simulation.
    """
    
    # Generate new timestamp each time and apply decorator dynamically
    current_timestamp = read_timestamp()
    save_dir = f"{settings.OUTPUT_DIR}/{current_timestamp}_RF{settings.RESFACTOR}_{settings.SIM_YEARS[0]}-{settings.SIM_YEARS[-1]}"
    log_path = f"{save_dir}/LUTO_RUN_"
    
    # Apply the LogToFile decorator dynamically
    @LogToFile(log_path)
    def _run():
        # Get the years to run
        years = sorted(settings.SIM_YEARS).copy()
        
        # Start recording memory usage
        stop_event = threading.Event()
        memory_thread = threading.Thread(target=log_memory_usage, args=(save_dir, 'a', 1, stop_event))
        memory_thread.start()
        
        try:
            print('\n')
            print(f"Running LUTO {settings.VERSION} between {years[0]} - {years[-1]} at RES-{settings.RESFACTOR}, total {len(years)} runs!\n", flush=True)
            # Insert the base year at the beginning of the years list if not already present
            if data.YR_CAL_BASE not in years: 
                years.insert(0, data.YR_CAL_BASE)
            # Solve and write outputs
            solve_timeseries(data, years)
            save_data_to_disk(data, f"{save_dir}/Data_RES{settings.RESFACTOR}.gz")
            write_outputs(data)
        except Exception as e:
            print(f"An error occurred during the simulation: {e}")
            raise e
        finally:
            # Ensure the memory logging thread is stopped
            stop_event.set()
            memory_thread.join()
    
    return _run()


def solve_timeseries(data: Data, years_to_run: list[int]) -> None:

    for step in range(len(years_to_run) - 1):
        base_year = years_to_run[step]
        target_year = years_to_run[step + 1]

        print( "-------------------------------------------------")
        print( f"Running for year {target_year}"   )
        print( "-------------------------------------------------\n")
        
        start_time = time.time()
        input_data = get_input_data(data, base_year, target_year)

        # if step == 0:
        #     luto_solver = LutoSolver(input_data, d_c)
        #     luto_solver.formulate()

        # if step > 0:
        #     prev_base_year = years_to_run[step - 1]

        #     old_ag_x_mrj = luto_solver._input_data.ag_x_mrj.copy()
        #     old_ag_man_lb_mrj = luto_solver._input_data.ag_man_lb_mrj.copy()
        #     old_non_ag_x_rk = luto_solver._input_data.non_ag_x_rk.copy()
        #     old_non_ag_lb_rk = luto_solver._input_data.non_ag_lb_rk.copy()

        #     luto_solver.update_formulation(
        #         input_data=input_data,
        #         d_c=d_c,
        #         old_ag_x_mrj=old_ag_x_mrj,
        #         old_ag_man_lb_mrj=old_ag_man_lb_mrj,
        #         old_non_ag_x_rk=old_non_ag_x_rk,
        #         old_non_ag_lb_rk=old_non_ag_lb_rk,
        #         old_lumap=data.lumaps[prev_base_year],
        #         current_lumap=data.lumaps[base_year],
        #         old_lmmap=data.lmmaps[prev_base_year],
        #         current_lmmap=data.lmmaps[base_year],
        #     )

        luto_solver = LutoSolver(input_data)
        luto_solver.formulate()
        solution = luto_solver.solve()
        
        data.last_year = target_year 

        data.add_lumap(target_year, solution.lumap)
        data.add_lmmap(target_year, solution.lmmap)
        data.add_ammaps(target_year, solution.ammaps)
        data.add_ag_dvars(target_year, solution.ag_X_mrj)
        data.add_non_ag_dvars(target_year, solution.non_ag_X_rk)
        data.add_ag_man_dvars(target_year, solution.ag_man_X_mrj)
        data.add_obj_vals(target_year, solution.obj_val)

        for data_type, prod_data in solution.prod_data.items():
            data.add_production_data(target_year, data_type, prod_data)
            

        print(f'Processing for {target_year} completed in {round(time.time() - start_time)} seconds\n\n' )
        
        if luto_solver.gurobi_model.Status not in [GRB.OPTIMAL, GRB.SUBOPTIMAL]:
            print('!' * 100)
            print(f"Warning: Gurobi solver did not find an optimal/suboptimal solution for year {target_year}. Status: {luto_solver.gurobi_model.Status}")
            print(f'Warning: The results are still written to disk, but will not be optimal.')
            print('!' * 100)
            print('\n')
            
            break



def save_data_to_disk(data: Data, path: str, compress_level=6) -> None:
    """Save the Data object to disk with gzip compression.
    Arguments:
        data: `Data` object.
        path: Path to save the Data object.
        compress_level: Compression level for gzip compression.
    """
    print(f'Saving data to {path}...')

    # Save with gzip compression
    with gzip.open(path, 'wb', compresslevel=compress_level) as f:
        dill.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)
    
    
def load_data_from_disk(path: str) -> Data:
    """Load the Data object from disk.
    
    Arguments:
        path: Path to the Data object.

    Raises:
        ValueError: if the resolution factor from the data object does not match the settings.RESFACTOR.

    Returns
        Data: `Data` object.
    """
    
    # Generate new timestamp each time and apply decorator dynamically
    current_timestamp = write_timestamp()
    save_dir = f"{settings.OUTPUT_DIR}/{current_timestamp}_RF{settings.RESFACTOR}_{settings.SIM_YEARS[0]}-{settings.SIM_YEARS[-1]}"
    log_path = f"{save_dir}/LUTO_RUN_"
    
    set_path()
    
    # Apply the LogToFile decorator dynamically
    @LogToFile(log_path, 'w')
    def _load_data():
        print(f"Loading data from {path}...\n")
        
        # Load the data object with gzip compression
        with gzip.open(path, 'rb') as f:
            data = dill.load(f)
            data.timestamp = read_timestamp()
            data.path = save_dir

        # Check if the resolution factor from the data object matches the settings.RESFACTOR
        if int(data.RESMULT ** 0.5) != settings.RESFACTOR:
            raise ValueError(f'Resolution factor from data loading ({int(data.RESMULT ** 0.5)}) does not match it of settings ({settings.RESFACTOR})!')
        
        return data
    
    return _load_data()
```

## luto/solvers/input_data.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.



import numpy as np

from collections import defaultdict
from dataclasses import dataclass
from functools import cached_property
from typing import Any, Optional

from luto.data import Data
from luto import settings
from luto.economics import land_use_culling

import luto.economics.agricultural.cost as ag_cost
import luto.economics.agricultural.ghg as ag_ghg
import luto.economics.agricultural.quantity as ag_quantity
import luto.economics.agricultural.revenue as ag_revenue
import luto.economics.agricultural.transitions as ag_transition
import luto.economics.agricultural.water as ag_water
import luto.economics.agricultural.biodiversity as ag_biodiversity

import luto.economics.non_agricultural.water as non_ag_water
import luto.economics.non_agricultural.biodiversity as non_ag_biodiversity
import luto.economics.non_agricultural.cost as non_ag_cost
import luto.economics.non_agricultural.ghg as non_ag_ghg
import luto.economics.non_agricultural.quantity as non_ag_quantity
import luto.economics.non_agricultural.transitions as non_ag_transition
import luto.economics.non_agricultural.revenue as non_ag_revenue


@dataclass
class SolverInputData:
    """
    An object that collects and stores all relevant data for solver.py.
    """   
    base_year: int                                                      # The base year of this solving process
    target_year: int                                                    # The target year of this solving process

    ag_g_mrj: np.ndarray                                                # Agricultural greenhouse gas emissions matrices.
    ag_w_mrj: np.ndarray                                                # Agricultural water yields matrices.
    ag_b_mrj: np.ndarray                                                # Agricultural biodiversity matrices.
    ag_x_mrj: np.ndarray                                                # Agricultural exclude matrices.
    ag_q_mrp: np.ndarray                                                # Agricultural yield matrices -- note the `p` (product) index instead of `j` (land-use).
    ag_ghg_t_mrj: np.ndarray                                            # GHG emissions released during transitions between agricultural land uses.

    non_ag_g_rk: np.ndarray                                             # Non-agricultural greenhouse gas emissions matrix.
    non_ag_w_rk: np.ndarray                                             # Non-agricultural water yields matrix.
    non_ag_b_rk: np.ndarray                                             # Non-agricultural biodiversity matrix.
    non_ag_x_rk: np.ndarray                                             # Non-agricultural exclude matrices.
    non_ag_q_crk: np.ndarray                                            # Non-agricultural yield matrix.
    non_ag_lb_rk: np.ndarray                                            # Non-agricultural lower bound matrices.

    ag_man_g_mrj: dict                                                  # Agricultural Management options' GHG emission effects.
    ag_man_w_mrj: dict                                                  # Agricultural Management options' water yield effects.
    ag_man_b_mrj: dict                                                  # Agricultural Management options' biodiversity effects.
    ag_man_q_mrp: dict                                                  # Agricultural Management options' quantity effects.
    ag_man_limits: dict                                                 # Agricultural Management options' adoption limits.
    ag_man_lb_mrj: dict                                                 # Agricultural Management options' lower bounds.

    water_region_indices: dict[int, np.ndarray]                         # Water region indices -> dict. Key: region.
    water_region_names: dict[int, str]                                  # Water yield for the BASE_YR based on historical water yield layers.
      
    biodiv_contr_ag_j: np.ndarray                                       # Biodiversity contribution scale from agricultural land uses.
    biodiv_contr_non_ag_k: dict[int, float]                             # Biodiversity contribution scale from non-agricultural land uses.
    biodiv_contr_ag_man: dict[str, dict[int, np.ndarray]]               # Biodiversity contribution scale from agricultural management options.
    
    GBF2_raw_priority_degraded_area_r: np.ndarray                       # Raw areas (GBF2) from priority degrade areas - indexed by cell (r).
    GBF3_raw_MVG_area_vr: np.ndarray                                    # Raw areas (GBF3) from Major vegetation group - indexed by veg. group (v) and cell (r)
    GBF3_names: dict[int, str]                                          # Major vegetation groups names - indexed by major vegetation group (v).
    GBF3_ind: dict[str, int]                                            # Major vegetation groups indices - indexed by major vegetation group (v).
    GBF4_SNES_xr: np.ndarray                                            # Raw areas (GBF4) Species NES contribution data - indexed by species/ecological community (x) and cell (r).
    GBF4_SNES_names: dict[int, str]                                     # Species NES names - indexed by species/ecological community (x).
    GBF4_ECNES_xr: np.ndarray                                           # Raw areas (GBF4) Ecological community NES contribution data - indexed by species/ecological community (x) and cell (r).
    GBF4_ECNES_names: dict[int, str]                                    # Ecological community NES names - indexed by species/ecological community (x).
    GBF8_raw_species_area_sr: np.ndarray                                # Raw areas (GBF8) Species data - indexed by species (s) and cell (r).
    GBF8_species_names: dict[int, str]                                  # Species names - indexed by species (s).
    GBF8_species_indices: dict[int, float]                              # Species indices - indexed by species (s).

    savanna_eligible_r: np.ndarray                                      # Cells that are eligible for savanna burnining land use.
    priority_degraded_mask_idx: np.ndarray                              # Mask of priority degraded areas - indexed by cell (r).

    base_yr_prod: dict[str, tuple]                                      # Base year production of each commodity.
    scale_factors: dict[float]                                          # Scale factors for each input layer.

    economic_contr_mrj: float                                           # base year economic contribution matrix.
    economic_BASE_YR_prices: np.ndarray                                 # base year commodity prices.
    economic_target_yr_carbon_price: float                              # target year carbon price.
    
    offland_ghg: np.ndarray                                             # GHG emissions from off-land commodities.

    lu2pr_pj: np.ndarray                                                # Conversion matrix: land-use to product(s).
    pr2cm_cp: np.ndarray                                                # Conversion matrix: product(s) to commodity.
    limits: dict                                                        # Targets to use.
    desc2aglu: dict                                                     # Map of agricultural land use descriptions to codes.
    real_area: np.ndarray                                               # Area of each cell, indexed by cell (r)
                
    @property
    def ncms(self):
        # Number of commodities
        return self.pr2cm_cp.shape[0]           
    
    @property
    def n_ag_lms(self):
        # Number of agricultural landmans
        return self.ag_g_mrj.shape[0]

    @property
    def ncells(self):
        # Number of cells
        return self.ag_g_mrj.shape[1]

    @property
    def n_ag_lus(self):
        # Number of agricultural landuses
        return self.ag_g_mrj.shape[2]

    @property
    def n_non_ag_lus(self):
        # Number of non-agricultural landuses
        return self.non_ag_g_rk.shape[1]

    @property
    def nprs(self):
        # Number of products
        return self.ag_q_mrp.shape[2]

    @cached_property
    def am2j(self):
        # Map of agricultural management options to land use codes
        return {
            am: [self.desc2aglu[lu] for lu in am_lus]
            for am, am_lus in settings.AG_MANAGEMENTS_TO_LAND_USES.items()
            if settings.AG_MANAGEMENTS[am]
        }

    @cached_property
    def j2am(self):
        _j2am = defaultdict(list)
        for am, am_j_list in self.am2j.items():
            for j in am_j_list:
                _j2am[j].append(am)

        return _j2am

    @cached_property
    def j2p(self):
        return {
            j: [p for p in range(self.nprs) if self.lu2pr_pj[p, j]]
            for j in range(self.n_ag_lus)
        }

    @cached_property
    def ag_lu2cells(self):
        # Make an index of each cell permitted to transform to each land use / land management combination
        return {
            (m, j): np.where(self.ag_x_mrj[m, :, j])[0]
            for j in range(self.n_ag_lus)
            for m in range(self.n_ag_lms)
        }

    @cached_property
    def cells2ag_lu(self) -> dict[int, list[tuple[int, int]]]:
        ag_lu2cells = self.ag_lu2cells
        cells2ag_lu = defaultdict(list)
        for (m, j), j_cells in ag_lu2cells.items():
            for r in j_cells:
                cells2ag_lu[r].append((m,j))

        return dict(cells2ag_lu)

    @cached_property
    def non_ag_lu2cells(self) -> dict[int, np.ndarray]:
        return {k: np.where(self.non_ag_x_rk[:, k])[0] for k in range(self.n_non_ag_lus)}

    @cached_property
    def cells2non_ag_lu(self) -> dict[int, list[int]]:
        non_ag_lu2cells = self.non_ag_lu2cells
        cells2non_ag_lu = defaultdict(list)
        for k, k_cells in non_ag_lu2cells.items():
            for r in k_cells:
                cells2non_ag_lu[r].append(k)

        return dict(cells2non_ag_lu) 
    

def get_ag_c_mrj(data: Data, target_index):
    print('Getting agricultural cost matrices...', flush = True)
    output = ag_cost.get_cost_matrices(data, target_index)
    return output.astype(np.float32)


def get_non_ag_c_rk(data: Data, ag_c_mrj: np.ndarray, lumap: np.ndarray, target_year):
    print('Getting non-agricultural cost matrices...', flush = True)
    output = non_ag_cost.get_cost_matrix(data, ag_c_mrj, lumap, target_year)
    return output.astype(np.float32)


def get_ag_r_mrj(data: Data, target_index):
    print('Getting agricultural revenue matrices...', flush = True)
    output = ag_revenue.get_rev_matrices(data, target_index)
    return output.astype(np.float32)


def get_non_ag_r_rk(data: Data, ag_r_mrj: np.ndarray, base_year: int, target_year: int):
    print('Getting non-agricultural revenue matrices...', flush = True)
    output = non_ag_revenue.get_rev_matrix(data, target_year, ag_r_mrj, data.lumaps[base_year])
    return output.astype(np.float32)


def get_ag_g_mrj(data: Data, target_index):
    print('Getting agricultural GHG emissions matrices...', flush = True)
    output = ag_ghg.get_ghg_matrices(data, target_index)
    return output.astype(np.float32)


def get_non_ag_g_rk(data: Data, ag_g_mrj, base_year):
    print('Getting non-agricultural GHG emissions matrices...', flush = True)
    output = non_ag_ghg.get_ghg_matrix(data, ag_g_mrj, data.lumaps[base_year])
    return output.astype(np.float32)


def get_ag_w_mrj(data: Data, target_index, water_dr_yield: Optional[np.ndarray] = None, water_sr_yield: Optional[np.ndarray] = None):
    print('Getting agricultural water net yield matrices based on historical water yield layers ...', flush = True)
    output = ag_water.get_water_net_yield_matrices(data, target_index, water_dr_yield, water_sr_yield)
    return output.astype(np.float32)

def get_w_region_indices(data: Data):
    if settings.WATER_LIMITS == 'off':
        return {}
    print('Getting water region indices...', flush = True)
    return data.WATER_REGION_INDEX_R

def get_w_region_names(data: Data):
    if settings.WATER_LIMITS == 'off':
        return {}
    print('Getting water region names...', flush = True)
    return data.WATER_REGION_NAMES


def get_ag_b_mrj(data: Data):
    print('Getting agricultural biodiversity requirement matrices...', flush = True)
    output = ag_biodiversity.get_bio_overall_priority_score_matrices_mrj(data)
    return output.astype(np.float32)


def get_ag_biodiv_contr_j(data: Data) -> dict[int, float]:
    print('Getting biodiversity degredation data for agricultural land uses...', flush = True)
    return ag_biodiversity.get_ag_biodiversity_contribution(data)


def get_non_ag_biodiv_impact_k(data: Data) -> dict[int, float]:
    print('Getting biodiversity benefits data for non-agricultural land uses...', flush = True)
    return non_ag_biodiversity.get_non_ag_lu_biodiv_contribution(data)


def get_ag_man_biodiv_impacts(data: Data, target_year: int) -> dict[str, dict[str, float]]:
    print('Getting biodiversity benefits data for agricultural management options...', flush = True)
    return ag_biodiversity.get_ag_management_biodiversity_contribution(data, target_year)

def get_GBF2_priority_degrade_area_r(data: Data) -> np.ndarray:
    if settings.BIODIVERSITY_TARGET_GBF_2 == "off":
        return np.empty(0)
    print('Getting priority degrade area matrices...', flush = True)
    # Need to copy if the return value is a direct reference to the data
    output = data.BIO_PRIORITY_DEGRADED_AREAS_R.copy()
    return output

def get_GBF3_MVG_area_vr(data: Data):
    if settings.BIODIVERSITY_TARGET_GBF_3 == "off":
        return np.empty(0)
    print('Getting agricultural major vegetation groups matrices...', flush = True)
    output = ag_biodiversity.get_GBF3_major_vegetation_matrices_vr(data)
    return output

def get_GBF3_major_vegetation_names(data: Data) -> dict[int,str]:
    if settings.BIODIVERSITY_TARGET_GBF_3 == "off":
        return np.empty(0)
    print('Getting agricultural major vegetation groups names...', flush = True)
    return data.BIO_GBF3_ID2DESC

def get_GBF3_major_indices(data: Data) -> dict[str, int]:
    if settings.BIODIVERSITY_TARGET_GBF_3 == "off":
        return np.empty(0)
    print('Getting agricultural major vegetation groups indices...', flush = True)
    return data.MAJOR_VEG_INDECES

def get_GBF4_SNES_xr(data: Data) -> np.ndarray:
    if settings.BIODIVERSITY_TARGET_GBF_4_SNES != "on":
        return np.empty(0)
    return ag_biodiversity.get_GBF4_SNES_matrix_sr(data)

def get_GBF4_SNES_names(data: Data) -> dict[int,str]:
    if settings.BIODIVERSITY_TARGET_GBF_4_SNES != "on":
        return np.empty(0)
    print('Getting agricultural species NES names...', flush = True)
    return {x: name for x, name in enumerate(data.BIO_GBF4_SNES_SEL_ALL)}

def get_GBF4_ECNES_xr(data: Data) -> np.ndarray:
    if settings.BIODIVERSITY_TARGET_GBF_4_ECNES != "on":
        return np.empty(0)
    return ag_biodiversity.get_GBF4_ECNES_matrix_sr(data)

def get_GBF4_ECNES_names(data: Data) -> dict[int,str]:
    if settings.BIODIVERSITY_TARGET_GBF_4_ECNES != "on":
        return np.empty(0)
    print('Getting agricultural ecological community NES names...', flush = True)
    return {x: name for x, name in enumerate(data.BIO_GBF4_ECNES_SEL_ALL)}

def get_GBF8_species_area_sr(data: Data, target_year: int) -> np.ndarray:
    if settings.BIODIVERSITY_TARGET_GBF_8 != "on":
        return np.empty(0)
    print('Getting species conservation cell data...', flush = True)
    return ag_biodiversity.get_GBF8_matrix_sr(data, target_year)

def get_GBF8_species_names(data: Data) -> dict[int,str]:
    if settings.BIODIVERSITY_TARGET_GBF_8 != "on":
        return np.empty(0)
    print('Getting species conservation names...', flush = True)
    return {s: spec_name for s, spec_name in enumerate(data.BIO_GBF8_SEL_SPECIES)}

def get_GBF8_indices(data: Data, yr_cal) -> dict[int, float]:
    if settings.BIODIVERSITY_TARGET_GBF_8 != "on":
        return np.empty(0)
    print('Getting species conservation indices...', flush = True)
    species_matrix = data.get_GBF8_bio_layers_by_yr(yr_cal)
    return {s: np.where(species_matrix[s] > 0)[0] for s in range(data.N_GBF8_SPECIES)}


def get_non_ag_w_rk(
    data: Data, 
    ag_w_mrj: np.ndarray, 
    base_year, 
    target_year, 
    water_dr_yield: Optional[np.ndarray] = None, 
    water_sr_yield: Optional[np.ndarray] = None
    ):
    print('Getting non-agricultural water yield matrices...', flush = True)
    yr_idx = target_year - data.YR_CAL_BASE
    output = non_ag_water.get_w_net_yield_matrix(data, ag_w_mrj, data.lumaps[base_year], yr_idx, water_dr_yield, water_sr_yield)
    return output.astype(np.float32)


def get_non_ag_b_rk(data: Data, ag_b_mrj: np.ndarray, base_year):
    print('Getting non-agricultural biodiversity requirement matrices...', flush = True)
    output = non_ag_biodiversity.get_breq_matrix(data, ag_b_mrj, data.lumaps[base_year])
    return output.astype(np.float32)


def get_ag_q_mrp(data: Data, target_index):
    print('Getting agricultural production quantity matrices...', flush = True)
    output = ag_quantity.get_quantity_matrices(data, target_index)
    return output.astype(np.float32)


def get_non_ag_q_crk(data: Data, ag_q_mrp: np.ndarray, base_year: int):
    print('Getting non-agricultural production quantity matrices...', flush = True)
    output = non_ag_quantity.get_quantity_matrix(data, ag_q_mrp, data.lumaps[base_year])
    return output.astype(np.float32)


def get_ag_ghg_t_mrj(data: Data, base_year):
    print('Getting agricultural transitions GHG emissions...', flush = True)
    output = ag_ghg.get_ghg_transition_emissions(data, data.lumaps[base_year])
    return output.astype(np.float32)


def get_ag_t_mrj(data: Data, target_index, base_year):
    print('Getting agricultural transition cost matrices...', flush = True)
    
    ag_t_mrj = ag_transition.get_transition_matrices_ag2ag_from_base_year(
        data, 
        target_index, 
        base_year
    ).astype(np.float32)
    
    # Transition costs occures if the base year is not the target year
    return ag_t_mrj if (base_year - data.YR_CAL_BASE != target_index) else np.zeros_like(ag_t_mrj).astype(np.float32)


def get_ag_to_non_ag_t_rk(data: Data, target_index, base_year, ag_t_mrj):
    print('Getting agricultural to non-agricultural transition cost matrices...', flush = True)
    non_ag_t_mrj = non_ag_transition.get_transition_matrix_ag2nonag( 
        data, 
        target_index, 
        data.lumaps[base_year], 
        data.lmmaps[base_year]
    ).astype(np.float32)
    # Transition costs occures if the base year is not the target year
    return non_ag_t_mrj if (base_year - data.YR_CAL_BASE != target_index) else np.zeros_like(non_ag_t_mrj).astype(np.float32)


def get_non_ag_to_ag_t_mrj(data: Data, base_year:int, target_index: int):
    print('Getting non-agricultural to agricultural transition cost matrices...', flush = True)
    
    non_ag_to_ag_mrj = non_ag_transition.get_transition_matrix_nonag2ag(
        data, 
        target_index, 
        data.lumaps[base_year], 
        data.lmmaps[base_year],
    ).astype(np.float32)
    # Transition costs occures if the base year is not the target year
    return non_ag_to_ag_mrj if (base_year - data.YR_CAL_BASE != target_index) else np.zeros_like(non_ag_to_ag_mrj).astype(np.float32)


def get_non_ag_t_rk(data: Data, base_year):
    print('Getting non-agricultural transition cost matrices...', flush = True)
    output = non_ag_transition.get_non_ag_transition_matrix(data)
    return output.astype(np.float32)


def get_ag_x_mrj(data: Data, base_year):
    print('Getting agricultural exclude matrices...', flush = True)
    output = ag_transition.get_to_ag_exclude_matrices(data, data.lumaps[base_year])
    return output


def get_non_ag_x_rk(data: Data, base_year):
    print('Getting non-agricultural exclude matrices...', flush = True)
    output = non_ag_transition.get_to_non_ag_exclude_matrices(data, data.lumaps[base_year])
    return output


def get_ag_man_lb_mrj(data: Data, base_year):
    print('Getting agricultural lower bound matrices...', flush = True)
    output = ag_transition.get_lower_bound_agricultural_management_matrices(data, base_year)
    return output


def get_non_ag_lb_rk(data: Data, base_year):
    print('Getting non-agricultural lower bound matrices...', flush = True)
    output = non_ag_transition.get_lower_bound_non_agricultural_matrices(data, base_year)
    return output


def get_ag_man_c_mrj(data: Data, target_index, ag_c_mrj: np.ndarray):
    print('Getting agricultural management options\' cost effects...', flush = True)
    output = ag_cost.get_agricultural_management_cost_matrices(data, ag_c_mrj, target_index)
    return output


def get_ag_man_g_mrj(data: Data, target_index):
    print('Getting agricultural management options\' GHG emission effects...', flush = True)
    output = ag_ghg.get_agricultural_management_ghg_matrices(data, target_index)
    return output


def get_ag_man_q_mrj(data: Data, target_index, ag_q_mrp: np.ndarray):
    print('Getting agricultural management options\' quantity effects...', flush = True)
    output = ag_quantity.get_agricultural_management_quantity_matrices(data, ag_q_mrp, target_index)
    return output


def get_ag_man_r_mrj(data: Data, target_index, ag_r_mrj: np.ndarray):
    print('Getting agricultural management options\' revenue effects...', flush = True)
    output = ag_revenue.get_agricultural_management_revenue_matrices(data, ag_r_mrj, target_index)
    return output


def get_ag_man_t_mrj(data: Data, target_index, ag_t_mrj: np.ndarray):
    print('Getting agricultural management options\' transition cost effects...', flush = True)
    output = ag_transition.get_agricultural_management_transition_matrices(data, ag_t_mrj, target_index)
    return output


def get_ag_man_w_mrj(data: Data, target_index):
    print('Getting agricultural management options\' water yield effects...', flush = True)
    output = ag_water.get_agricultural_management_water_matrices(data, target_index)
    return output


def get_ag_man_b_mrj(data: Data, target_index, ag_b_mrj: np.ndarray):
    print('Getting agricultural management options\' biodiversity effects...', flush = True)
    output = ag_biodiversity.get_agricultural_management_biodiversity_matrices(data, ag_b_mrj, target_index)
    return output


def get_ag_man_limits(data: Data, target_index):
    print('Getting agricultural management options\' adoption limits...', flush = True)
    output = ag_transition.get_agricultural_management_adoption_limits(data, target_index)
    return output


def get_economic_mrj(
    ag_c_mrj: np.ndarray,
    ag_r_mrj: np.ndarray,
    ag_t_mrj: np.ndarray,
    ag_to_non_ag_t_rk: np.ndarray,
    non_ag_c_rk: np.ndarray,
    non_ag_r_rk: np.ndarray,
    non_ag_t_rk: np.ndarray,
    non_ag_to_ag_t_mrj: np.ndarray,
    ag_man_c_mrj: dict[str, np.ndarray],
    ag_man_r_mrj: dict[str, np.ndarray],
    ag_man_t_mrj: dict[str, np.ndarray],
    ) -> dict[str, np.ndarray|dict[str, np.ndarray]]:
    
    print('Getting base year economic matrix...', flush = True)
    
    if settings.OBJECTIVE == "maxprofit":
        # Pre-calculate profit (revenue minus cost) for each land use
        ag_obj_mrj = ag_r_mrj - (ag_c_mrj + ag_t_mrj + non_ag_to_ag_t_mrj)
        non_ag_obj_rk = non_ag_r_rk - (non_ag_c_rk + non_ag_t_rk + ag_to_non_ag_t_rk)

        # Get effects of alternative agr. management options (stored in a dict)
        ag_man_objs = {
            am: ag_man_r_mrj[am] - (ag_man_c_mrj[am] + ag_man_t_mrj[am]) 
            for am in settings.AG_MANAGEMENTS_TO_LAND_USES
        }

    elif settings.OBJECTIVE == "mincost":
        # Pre-calculate sum of production and transition costs
        ag_obj_mrj = ag_c_mrj + ag_t_mrj + non_ag_to_ag_t_mrj
        non_ag_obj_rk = non_ag_c_rk + non_ag_t_rk + ag_to_non_ag_t_rk

        # Store calculations for each agricultural management option in a dict
        ag_man_objs = {
            am: (ag_man_c_mrj[am] + ag_man_t_mrj[am])      
            for am in settings.AG_MANAGEMENTS_TO_LAND_USES
        }

    else:
        raise ValueError("Unknown objective!")

    ag_obj_mrj = np.nan_to_num(ag_obj_mrj)
    non_ag_obj_rk = np.nan_to_num(non_ag_obj_rk)
    ag_man_objs = {am: np.nan_to_num(arr) for am, arr in ag_man_objs.items()}

    return [ag_obj_mrj, non_ag_obj_rk, ag_man_objs]


def get_commodity_prices_BASE_YR(data: Data) -> np.ndarray:
    """
    Get the commodity prices for the target year.
    """
    print('Getting commodity prices...', flush = True)
    return ag_revenue.get_commodity_prices(data)


def get_target_yr_carbon_price(data: Data, target_year: int) -> float:
    return data.CARBON_PRICES[target_year]


def get_BASE_YR_economic_value(data: Data):
    """
    Calculate the economic value of the agricultural sector.
    """
    if data.BASE_YR_economic_value is not None:
        return data.BASE_YR_economic_value
    
    # Get the revenue and cost matrices
    r_mrj = ag_revenue.get_rev_matrices(data, 0)
    c_mrj = ag_cost.get_cost_matrices(data, 0)
    # Calculate the economic value
    if settings.OBJECTIVE == 'maxprofit':
        e_mrj = (r_mrj - c_mrj)
    elif settings.OBJECTIVE == 'mincost':
        e_mrj = c_mrj
    else:
        raise ValueError("Invalid `settings.OBJECTIVE`. Use 'maxprofit' or 'maxcost'.")
    
    data.BASE_YR_economic_value = np.einsum('mrj,mrj->', e_mrj, data.AG_L_MRJ)
    return data.BASE_YR_economic_value

def get_BASE_YR_production_t(data: Data):
    """
    Calculate the production of each commodity in the base year.
    """
    # Get the revenue and cost matrices
    return data.BASE_YR_production_t

def get_BASE_YR_GHG_t(data: Data):
    """
    Calculate the GHG emissions of the agricultural sector.
    """
    if data.BASE_YR_GHG_t is not None:
        return data.BASE_YR_GHG_t
    # Get the GHG matrices
    ag_g_mrj = get_ag_g_mrj(data, 0)
    data.BASE_YR_GHG_t = np.einsum('mrj,mrj->', ag_g_mrj, data.AG_L_MRJ)
    return data.BASE_YR_GHG_t
    
def get_BASE_YR_overall_bio_value(data: Data):
    """
    Calculate the economic value of the agricultural sector.
    """
    if data.BASE_YR_overall_bio_value is not None:
        return data.BASE_YR_overall_bio_value
    # Get the revenue and cost matrices
    ag_b_mrj = ag_biodiversity.get_bio_overall_priority_score_matrices_mrj(data)
    data.BASE_YR_overall_bio_value = np.einsum('mrj,mrj->', ag_b_mrj, data.AG_L_MRJ)
    return data.BASE_YR_overall_bio_value

def get_BASE_YR_GBF2_score(data: Data) -> np.ndarray:
    if settings.BIODIVERSITY_TARGET_GBF_2 == "off":
        return np.empty(0)
    if data.BASE_YR_GBF2_score is not None:
        return data.BASE_YR_GBF2_score
    print('Getting priority degrade area base year score...', flush = True)
    GBF2_ly_r = get_GBF2_priority_degrade_area_r(data)
    GBF2_contr_j = get_ag_biodiv_contr_j(data)
    base_yr_dvar_mrj = data.AG_L_MRJ
    data.BASE_YR_GBF2_score = np.einsum('r,j,mrj->', GBF2_ly_r, GBF2_contr_j, base_yr_dvar_mrj)
    return data.BASE_YR_GBF2_score

def get_BASE_YR_water_ML(data: Data) -> np.ndarray:
    """
    Calculate the water net yield of the agricultural sector.
    """
    if data.BASE_YR_water_ML is not None:
        return data.BASE_YR_water_ML
    # Get the water matrices
    ag_w_mrj = get_ag_w_mrj(data, 0)
    ag_w_index = get_w_region_indices(data)
    
    water_ML = []
    for _,idx in ag_w_index.items():
        water_ML.append(
            np.einsum('mrj, mrj->', ag_w_mrj[:, idx, :], data.AG_L_MRJ[:, idx, :])
        )
    data.BASE_YR_water_ML = np.array(water_ML)
    return data.BASE_YR_water_ML
    

def get_savanna_eligible_r(data: Data) -> np.ndarray:
    return np.where(data.SAVBURN_ELIGIBLE == 1)[0]


def get_priority_degraded_mask_idx(data: Data) -> np.ndarray:
    if settings.BIODIVERSITY_TARGET_GBF_2 == "off":
        return np.empty(0)
    return np.where(data.BIO_PRIORITY_DEGRADED_AREAS_R)[0]


def get_limits(data: Data, yr_cal: int, resale_factors) -> dict[str, Any]:
    """
    Gets the following limits for the solve:
    - Water net yield limits
    - GHG limits
    - Biodiversity limits
    - Regional adoption limits
    """
    print('Getting environmental limits...', flush = True)
    
    limits = {
        'demand': None,
        'water': None,
        'ghg': None,
        'GBF2': None,
        'GBF3': None,
        'GBF4_SNES': None,
        'GBF4_ECNES': None,
        'GBF8': None,
        'ag_regional_adoption': None,
        'non_ag_regional_adoption': None,
    }
    
    if True:    # Always set demand limits
        limits['demand'] = data.D_CY[yr_cal - data.YR_CAL_BASE]
        limits['demand_rescale'] = limits['demand'] / resale_factors['Demand']
    
    if settings.WATER_LIMITS == 'on':
        limits['water'] = data.WATER_YIELD_TARGETS
        limits['water_rescale'] = {k: v / resale_factors['Water'] for k, v in limits['water'].items()}
        
    if settings.GHG_EMISSIONS_LIMITS != 'off':
        limits['ghg'] = data.GHG_TARGETS[yr_cal]
        limits['ghg_rescale'] = limits['ghg'] / resale_factors['GHG']

    if settings.BIODIVERSITY_TARGET_GBF_2 != 'off':
        limits["GBF2"] = data.get_GBF2_target_for_yr_cal(yr_cal)
        limits["GBF2_rescale"] = limits["GBF2"] / resale_factors['GBF2']

    if settings.BIODIVERSITY_TARGET_GBF_3 != 'off':
        limits["GBF3"] = data.get_GBF3_limit_score_inside_LUTO_by_yr(yr_cal)
        limits["GBF3_rescale"] = limits["GBF3"] / resale_factors['GBF3']
        
    if settings.BIODIVERSITY_TARGET_GBF_4_SNES == "on":
        limits["GBF4_SNES"] = data.get_GBF4_SNES_target_inside_LUTO_by_year(yr_cal)
        limits["GBF4_SNES_rescale"] = limits["GBF4_SNES"] / resale_factors['GBF4_SNES']
        
    if settings.BIODIVERSITY_TARGET_GBF_4_ECNES == "on":
        limits["GBF4_ECNES"] = data.get_GBF4_ECNES_target_inside_LUTO_by_year(yr_cal)
        limits["GBF4_ECNES_rescale"] = limits["GBF4_ECNES"] / resale_factors['GBF4_ECNES']

    if settings.BIODIVERSITY_TARGET_GBF_8 == "on":
        limits["GBF8"] = data.get_GBF8_target_inside_LUTO_by_yr(yr_cal)
        limits["GBF8_rescale"] = limits["GBF8"] / resale_factors['GBF8']

    if settings.REGIONAL_ADOPTION_CONSTRAINTS != 'off':
        ag_reg_adoption, non_ag_reg_adoption = ag_transition.get_regional_adoption_limits(data, yr_cal)
        limits["ag_regional_adoption"] = ag_reg_adoption
        limits["non_ag_regional_adoption"] = non_ag_reg_adoption

    return limits


def rescale_solver_input_data(arries:list) -> None:
    """
    Rescale the solver input data based on `settings.RESCALE_FACTOR`.
    To resume the data, just multiply the arrays by the returned scale factor.
    
    After rescaling, the arrays will be rescaled to the magnitude (regardless of signs) between 0 and 1e3.
    """

    max_vals = []
    for arr in arries:
        if isinstance(arr, np.ndarray):
            arr = arr.astype(np.float32)
            max_vals.append(max(arr.max(), abs(arr.min())))
        elif isinstance(arr, dict):
            # Assume all dictionaries are {str: np.ndarray}
            max_vals.extend([max(v.max(), abs(v.min())) for v in arr.values()])
    
    scale = (np.max(max_vals) / settings.RESCALE_FACTOR).astype(np.float32)
    
    for arr in arries:
        if isinstance(arr, dict):
            # Update dictionary values in-place
            for k in arr:
                arr[k] /= scale
        elif isinstance(arr, np.ndarray):
            # Arrays are already updated in-place
            arr /= scale

    return scale


def get_input_data(data: Data, base_year: int, target_year: int) -> SolverInputData:
    """
    Using the given Data object, prepare a SolverInputData object for the solver.
    """

    target_index = target_year - data.YR_CAL_BASE
    
    ag_c_mrj = get_ag_c_mrj(data, target_index)
    ag_r_mrj = get_ag_r_mrj(data, target_index)
    ag_t_mrj = get_ag_t_mrj(data, target_index, base_year)
    ag_to_non_ag_t_rk = get_ag_to_non_ag_t_rk(data, target_index, base_year, ag_t_mrj)
    
    non_ag_c_rk = get_non_ag_c_rk(data, ag_c_mrj, data.lumaps[base_year], target_year)
    non_ag_r_rk = get_non_ag_r_rk(data, ag_r_mrj, base_year, target_year)
    non_ag_t_rk = get_non_ag_t_rk(data, base_year)
    non_ag_to_ag_t_mrj = get_non_ag_to_ag_t_mrj(data, base_year, target_index)
    
    ag_man_c_mrj = get_ag_man_c_mrj(data, target_index, ag_c_mrj)
    ag_man_r_mrj = get_ag_man_r_mrj(data, target_index, ag_r_mrj)
    ag_man_t_mrj = get_ag_man_t_mrj(data, target_index, ag_t_mrj)
    
    ag_obj_mrj, non_ag_obj_rk,  ag_man_objs=get_economic_mrj(
        ag_c_mrj,
        ag_r_mrj,
        ag_t_mrj,
        ag_to_non_ag_t_rk,
        non_ag_c_rk,
        non_ag_r_rk,
        non_ag_t_rk,
        non_ag_to_ag_t_mrj,
        ag_man_c_mrj,
        ag_man_r_mrj,
        ag_man_t_mrj
    )
    

    ag_g_mrj = get_ag_g_mrj(data, target_index)
    ag_w_mrj = (
        get_ag_w_mrj(data, target_index) if settings.WATER_CLIMATE_CHANGE_IMPACT == 'on' 
        else get_ag_w_mrj(data, target_index, data.WATER_YIELD_HIST_DR, data.WATER_YIELD_HIST_SR)
    )
    ag_b_mrj = get_ag_b_mrj(data)
    ag_x_mrj = get_ag_x_mrj(data, base_year)
    ag_q_mrp = get_ag_q_mrp(data, target_index)
    ag_ghg_t_mrj = get_ag_ghg_t_mrj(data, base_year)

    non_ag_g_rk = get_non_ag_g_rk(data, ag_g_mrj, base_year)
    non_ag_w_rk = (
        get_non_ag_w_rk(data, ag_w_mrj, base_year, target_year)   
        if settings.WATER_CLIMATE_CHANGE_IMPACT == 'on' 
        else get_non_ag_w_rk(data, ag_w_mrj, base_year, target_year, data.WATER_YIELD_HIST_DR, data.WATER_YIELD_HIST_SR)
    )
    non_ag_b_rk = get_non_ag_b_rk(data, ag_b_mrj, base_year)
    non_ag_x_rk = get_non_ag_x_rk(data, base_year)
    non_ag_q_crk = get_non_ag_q_crk(data, ag_q_mrp, base_year)
    non_ag_lb_rk = get_non_ag_lb_rk(data, base_year)
    
    ag_man_g_mrj=get_ag_man_g_mrj(data, target_index)
    ag_man_w_mrj=get_ag_man_w_mrj(data, target_index)
    ag_man_b_mrj=get_ag_man_b_mrj(data, target_index, ag_b_mrj)
    ag_man_q_mrp=get_ag_man_q_mrj(data, target_index, ag_q_mrp)
    ag_man_limits=get_ag_man_limits(data, target_index)                            
    ag_man_lb_mrj=get_ag_man_lb_mrj(data, base_year)
    
    water_region_indices=get_w_region_indices(data)
    water_region_names=get_w_region_names(data)
    
    biodiv_contr_ag_j=get_ag_biodiv_contr_j(data)
    biodiv_contr_non_ag_k=get_non_ag_biodiv_impact_k(data)
    biodiv_contr_ag_man=get_ag_man_biodiv_impacts(data, target_year)

    GBF2_raw_priority_degraded_area_r = get_GBF2_priority_degrade_area_r(data)
    GBF3_raw_MVG_area_vr=get_GBF3_MVG_area_vr(data)
    GBF3_names=get_GBF3_major_vegetation_names(data)
    GBF3_ind=get_GBF3_major_indices(data)
    GBF4_SNES_xr=get_GBF4_SNES_xr(data)
    GBF4_SNES_names=get_GBF4_SNES_names(data)
    GBF4_ECNES_xr=get_GBF4_ECNES_xr(data)
    GBF4_ECNES_names=get_GBF4_SNES_names(data)
    GBF8_raw_species_area_sr=get_GBF8_species_area_sr(data, target_year)
    GBF8_species_names=get_GBF8_species_names(data)
    GBF8_species_indices=get_GBF8_indices(data,target_year)

    savanna_eligible_r=get_savanna_eligible_r(data)
    priority_degraded_mask_idx=get_priority_degraded_mask_idx(data)

    
    scale_factors = {
        "Economy":       rescale_solver_input_data([ag_obj_mrj, non_ag_obj_rk, ag_man_objs]),
        "Demand":        rescale_solver_input_data([ag_q_mrp, non_ag_q_crk, ag_man_q_mrp]),
        "Biodiversity":  rescale_solver_input_data([ag_b_mrj, non_ag_b_rk, ag_man_b_mrj]),
        "GHG":(
            rescale_solver_input_data([ag_g_mrj, non_ag_g_rk, ag_man_g_mrj, ag_ghg_t_mrj])
            if settings.GHG_EMISSIONS_LIMITS != 'off' 
            else 1.0  
        ),        
        "Water":(
            rescale_solver_input_data([ag_w_mrj, non_ag_w_rk, ag_man_w_mrj])
            if settings.WATER_LIMITS == 'on'
            else 1.0
        ),         
        "GBF2":(
            rescale_solver_input_data([GBF2_raw_priority_degraded_area_r])
            if settings.BIODIVERSITY_TARGET_GBF_2 != "off"
            else 1.0),
        "GBF3":(
            rescale_solver_input_data([GBF3_raw_MVG_area_vr])
            if settings.BIODIVERSITY_TARGET_GBF_3 != "off"
            else 1.0
        ),
        "GBF4_SNES":(
            rescale_solver_input_data([GBF4_SNES_xr])
            if settings.BIODIVERSITY_TARGET_GBF_4_SNES == "on"
            else 1.0
        ),
        "GBF4_ECNES":(
            rescale_solver_input_data([GBF4_ECNES_xr])
            if settings.BIODIVERSITY_TARGET_GBF_4_ECNES == "on"
            else 1.0
        ),
        "GBF8":(
            rescale_solver_input_data([GBF8_raw_species_area_sr])
            if settings.BIODIVERSITY_TARGET_GBF_8 == "on"
            else 1.0
        ),
    }

    base_yr_prod = {
        "BASE_YR Economy(AUD)":        get_BASE_YR_economic_value(data),
        "BASE_YR Production (t)":      get_BASE_YR_production_t(data),
        "BASE_YR GHG (tCO2e)":         get_BASE_YR_GHG_t(data),
        "BASE_YR Water (ML)":          get_BASE_YR_water_ML(data),
        "BASE_YR Bio quality (score)": get_BASE_YR_overall_bio_value(data),
        "BASE_YR GBF_2 (score)":       get_BASE_YR_GBF2_score(data),
    }

    economic_contr_mrj=(ag_obj_mrj, non_ag_obj_rk,  ag_man_objs)
    economic_BASE_YR_prices=get_commodity_prices_BASE_YR(data)
    economic_target_yr_carbon_price=get_target_yr_carbon_price(data, target_year)
    
    offland_ghg=(
        data.OFF_LAND_GHG_EMISSION_C[target_index] / scale_factors["GHG"] 
        if settings.GHG_EMISSIONS_LIMITS != 'off' 
        else 0.0
    )

    lu2pr_pj=data.LU2PR
    pr2cm_cp=data.PR2CM
    limits=get_limits(data, target_year, scale_factors)
    desc2aglu=data.DESC2AGLU
    real_area=data.REAL_AREA

    land_use_culling.apply_agricultural_land_use_culling(
        ag_x_mrj, ag_c_mrj, ag_t_mrj, ag_r_mrj
    )
 
    return SolverInputData(
        base_year,
        target_year,
        
        ag_g_mrj,
        ag_w_mrj,
        ag_b_mrj,
        ag_x_mrj,
        ag_q_mrp,
        ag_ghg_t_mrj,
        
        non_ag_g_rk,
        non_ag_w_rk,
        non_ag_b_rk,
        non_ag_x_rk,
        non_ag_q_crk,
        non_ag_lb_rk,

        ag_man_g_mrj,
        ag_man_w_mrj,
        ag_man_b_mrj,
        ag_man_q_mrp,
        ag_man_limits,
        ag_man_lb_mrj,
        
        water_region_indices,
        water_region_names,
        
        biodiv_contr_ag_j,
        biodiv_contr_non_ag_k,
        biodiv_contr_ag_man,
        
        GBF2_raw_priority_degraded_area_r,
        GBF3_raw_MVG_area_vr,
        GBF3_names,
        GBF3_ind,
        GBF4_SNES_xr,
        GBF4_SNES_names,
        GBF4_ECNES_xr,
        GBF4_ECNES_names,
        GBF8_raw_species_area_sr,
        GBF8_species_names,
        GBF8_species_indices,
        
        savanna_eligible_r,
        priority_degraded_mask_idx,

        base_yr_prod,
        scale_factors,
        
        economic_contr_mrj,
        economic_BASE_YR_prices,
        economic_target_yr_carbon_price,
        
        offland_ghg,
        
        lu2pr_pj,
        pr2cm_cp,
        limits,
        desc2aglu,
        real_area
    )
```

## luto/solvers/solver.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J.,
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S.,
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.


"""
Provides minimalist Solver class and pure helper functions.
"""

import numpy as np
import gurobipy as gp
import luto.settings as settings

from collections import defaultdict
from dataclasses import dataclass
from typing import Optional, Any
from gurobipy import GRB

from luto import tools
from luto.solvers.input_data import SolverInputData
from luto.settings import (
    AG_MANAGEMENTS, 
    AG_MANAGEMENTS_REVERSIBLE, 
    NON_AG_LAND_USES, 
    NON_AG_LAND_USES_REVERSIBLE
)


# Set Gurobi environment.
gurenv = gp.Env(logfilename="gurobi.log", empty=True)  # (empty = True)
gurenv.setParam("Method", settings.SOLVE_METHOD)
gurenv.setParam("OutputFlag", settings.VERBOSE)
gurenv.setParam("Presolve", settings.PRESOLVE)
gurenv.setParam("Aggregate", settings.AGGREGATE)
gurenv.setParam("OptimalityTol", settings.OPTIMALITY_TOLERANCE)
gurenv.setParam("FeasibilityTol", settings.FEASIBILITY_TOLERANCE)
gurenv.setParam("BarConvTol", settings.BARRIER_CONVERGENCE_TOLERANCE)
gurenv.setParam("ScaleFlag", settings.SCALE_FLAG)
gurenv.setParam("NumericFocus", settings.NUMERIC_FOCUS)
gurenv.setParam("Threads", settings.THREADS)
gurenv.setParam("BarHomogeneous", settings.BARHOMOGENOUS)
gurenv.setParam("Crossover", settings.CROSSOVER)
gurenv.start()


@dataclass
class SolverSolution:
    lumap: np.ndarray
    lmmap: np.ndarray
    ammaps: dict[str, np.ndarray]
    ag_X_mrj: np.ndarray
    non_ag_X_rk: np.ndarray
    ag_man_X_mrj: dict[str, np.ndarray]
    prod_data: dict[str, Any]
    obj_val: dict[str, float]


class LutoSolver:
    """
    Class responsible for grouping the Gurobi model, relevant input data, and its variables.
    """

    def __init__(
        self,
        input_data: SolverInputData,
    ):

        self._input_data = input_data
        self.gurobi_model = gp.Model(f"LUTO {settings.VERSION}", env=gurenv)

        # Initialise variable stores
        self.X_ag_dry_vars_jr = None
        self.X_ag_irr_vars_jr = None
        self.X_non_ag_vars_kr = None
        self.X_ag_man_dry_vars_jr = None
        self.X_ag_man_irr_vars_jr = None
        self.V = None
        self.E = None
        self.W = None

        # Initialise constraint lookups
        self.cell_usage_constraint_r = {}
        self.ag_management_constraints_r = defaultdict(list)
        self.adoption_limit_constraints = []
        self.demand_penalty_constraints = []
        self.water_limit_constraints = []
        self.water_nyiled_exprs = {}
        self.ghg_expr = None
        self.ghg_consts_ub = None
        self.ghg_consts_lb = None
        self.ghg_consts_soft = []
        self.bio_GBF2_expr = None
        self.bio_GBF2_constrs = {}
        self.bio_GBF3_exprs = {}
        self.bio_GBF3_constrs = {}
        self.bio_GBF4_SNES_exprs = {}
        self.bio_GBF4_SNES_constrs = {}
        self.bio_GBF4_ECNES_exprs = {}
        self.bio_GBF4_ECNES_constrs = {}
        self.bio_GBF8_exprs = {}
        self.bio_GBF8_constrs = {}
        self.regional_adoption_constrs = []


    def formulate(self):
        """
        Performs the initial formulation of the model - setting up decision variables,
        constraints, and the objective.
        """
        print("Setting up the model...")
        self._setup_vars()
        self._setup_constraints()
        self._setup_objective()


    def _setup_vars(self):
        print("...Setting up decision variables...")
        self._setup_ag_vars()
        self._setup_non_ag_vars()
        self._setup_ag_management_variables()
        self._setup_deviation_penalties()

    def _setup_constraints(self):
        print("...Adding the constraints...")
        self._add_cell_usage_constraints()
        self._add_agricultural_management_constraints()
        self._add_agricultural_management_adoption_limit_constraints()
        self._add_demand_penalty_constraints()
        self._add_ghg_emissions_limit_constraints()
        self._add_biodiversity_constraints()
        self._add_regional_adoption_constraints()
        self._add_water_usage_limit_constraints() 
        
    def _setup_objective(self):
        """
        Formulate the objective based on settings.OBJECTIVE
        """
        print(f"...Setting up the objective function to {settings.OBJECTIVE}...")

        # Get objectives 
        self.obj_economy = self._setup_economy_objective()    
        self.obj_biodiv = self._setup_biodiversity_objective()   
        self.obj_penalties = self._setup_penalty_objectives()                                                                    
 
        # Set the objective function
        if settings.OBJECTIVE == "mincost":
            sense = GRB.MINIMIZE
            obj_wrap = (
                self.obj_economy  * settings.SOLVE_WEIGHT_ALPHA 
                - self.obj_biodiv * (1 - settings.SOLVE_WEIGHT_ALPHA)
            )
            objective = (
                obj_wrap * (1 - settings.SOLVE_WEIGHT_BETA) + 
                self.obj_penalties * settings.SOLVE_WEIGHT_BETA
            )
        elif settings.OBJECTIVE == "maxprofit":
            sense = GRB.MAXIMIZE
            obj_wrap = (
                self.obj_economy  * settings.SOLVE_WEIGHT_ALPHA 
                + self.obj_biodiv * (1 - settings.SOLVE_WEIGHT_ALPHA)
            )
            objective = (
                obj_wrap * (1 - settings.SOLVE_WEIGHT_BETA) 
                - self.obj_penalties * settings.SOLVE_WEIGHT_BETA
            )
        else:
            raise ValueError(f"    Unknown objective function: {settings.OBJECTIVE}")

        self.gurobi_model.setObjective(objective, sense)
           

    def _setup_ag_vars(self):
        print("    |__ setting up decision variables for agricultural land uses...")
        self.X_ag_dry_vars_jr = np.zeros(
            (self._input_data.n_ag_lus, self._input_data.ncells), dtype=object
        )
        self.X_ag_irr_vars_jr = np.zeros(
            (self._input_data.n_ag_lus, self._input_data.ncells), dtype=object
        )
        for j in range(self._input_data.n_ag_lus):
            dry_lu_cells = self._input_data.ag_lu2cells[0, j]
            for r in dry_lu_cells:
                self.X_ag_dry_vars_jr[j, r] = self.gurobi_model.addVar(
                    ub=1, name=f"X_ag_dry_{j}_{r}".replace(" ", "_")
                )

            irr_lu_cells = self._input_data.ag_lu2cells[1, j]
            for r in irr_lu_cells:
                self.X_ag_irr_vars_jr[j, r] = self.gurobi_model.addVar(
                    ub=1, name=f"X_ag_irr_{j}_{r}".replace(" ", "_")
                )

    def _setup_non_ag_vars(self):
        print("    |__ setting up decision variables for non-agricultural land uses...")
        self.X_non_ag_vars_kr = np.zeros(
            (self._input_data.n_non_ag_lus, self._input_data.ncells), dtype=object
        )
        
        for k, k_name in enumerate(NON_AG_LAND_USES):
            if not NON_AG_LAND_USES[k_name]:
                continue
            lu_cells = self._input_data.non_ag_lu2cells[k]
            for r in lu_cells:
                x_lb = (
                    0
                    if NON_AG_LAND_USES_REVERSIBLE[k_name]
                    else self._input_data.non_ag_lb_rk[r, k]
                )
                self.X_non_ag_vars_kr[k, r] = self.gurobi_model.addVar(
                    lb=x_lb,
                    ub=self._input_data.non_ag_x_rk[r, k],
                    name=f"X_non_ag_{k}_{r}".replace(" ", "_")
                )

    def _setup_ag_management_variables(self):
        print("    |__ setting up decision variables for agricultural management options...")
        self.X_ag_man_dry_vars_jr = {
            am: np.zeros((len(am_j_list), self._input_data.ncells), dtype=object)
            for am, am_j_list in self._input_data.am2j.items()
        }
        self.X_ag_man_irr_vars_jr = {
            am: np.zeros((len(am_j_list), self._input_data.ncells), dtype=object)
            for am, am_j_list in self._input_data.am2j.items()
        }

        for am, am_j_list in self._input_data.am2j.items():
            if not AG_MANAGEMENTS[am]:
                continue

            # Get snake_case version of the AM name for the variable name
            am_name = tools.am_name_snake_case(am)

            for j_idx, j in enumerate(am_j_list):
                # Create variable for all eligible cells - all lower bounds are zero
                dry_lu_cells = self._input_data.ag_lu2cells[0, j]
                irr_lu_cells = self._input_data.ag_lu2cells[1, j]

                # for savanna burning, remove extra ineligible cells
                if am_name == "savanna_burning":
                    dry_lu_cells = np.intersect1d(
                        dry_lu_cells, self._input_data.savanna_eligible_r
                    )

                for r in dry_lu_cells:
                    dry_x_lb = (
                        0
                        if AG_MANAGEMENTS_REVERSIBLE[am]
                        else self._input_data.ag_man_lb_mrj[am][0, r, j]
                    )
                    self.X_ag_man_dry_vars_jr[am][j_idx, r] = self.gurobi_model.addVar(
                        lb=dry_x_lb,
                        ub=1,
                        name=f"X_ag_man_dry_{am_name}_{j}_{r}".replace(" ", "_"),
                    )
                
                for r in irr_lu_cells:
                    irr_x_lb = (
                        0
                        if AG_MANAGEMENTS_REVERSIBLE[am]
                        else self._input_data.ag_man_lb_mrj[am][1, r, j]
                    )
                    self.X_ag_man_irr_vars_jr[am][j_idx, r] = self.gurobi_model.addVar(
                        lb=irr_x_lb,
                        ub=1,
                        name=f"X_ag_man_irr_{am_name}_{j}_{r}".replace(" ", "_"),
                    )

    def _setup_deviation_penalties(self):
        """
        Decision variables, V, E and W, and B for soft constraints.
        1) [V] Penalty vector for demand, each one corespondes a commodity, that minimises the deviations from demand.
        2) [E] A single penalty scalar for GHG emissions, minimises its deviation from the target.
        3) [W] Penalty vector for water usage, each one corespondes a region, that minimises the deviations from the target.
        4) [B] A single penalty scalar for biodiversity, minimises its deviation from the target.
        """
        print("    |__ Setting up decision variables for soft constraints...")
        
        self.V = self.gurobi_model.addMVar(self._input_data.ncms, lb=0, name="V") # force lb=0 to make sure demand penalties are positive; i.e., demand must be met or exceeded

        if settings.GHG_CONSTRAINT_TYPE == "soft":
            self.E = self.gurobi_model.addVar(name="E")

        if settings.WATER_CONSTRAINT_TYPE == "soft":
            num_regions = len(self._input_data.limits["water"].keys())
            self.W = self.gurobi_model.addMVar(num_regions, name="W")

        
    def _setup_economy_objective(self):
        print("    |__ setting up objective for economy...")
        
        # Get economic contributions
        ag_obj_mrj, non_ag_obj_rk, ag_man_objs = self._input_data.economic_contr_mrj

        ag_exprs = []
        for j in range(self._input_data.n_ag_lus):
            ag_exprs.append(
                ag_obj_mrj[0, self._input_data.ag_lu2cells[0, j], j]
                @ self.X_ag_dry_vars_jr[j, self._input_data.ag_lu2cells[0, j]]
                + ag_obj_mrj[1, self._input_data.ag_lu2cells[1, j], j]
                @ self.X_ag_irr_vars_jr[j, self._input_data.ag_lu2cells[1, j]]
            )

        ag_mam_exprs = []
        for am, am_j_list in self._input_data.am2j.items():
            if not AG_MANAGEMENTS[am]:
                continue
            for j_idx, j in enumerate(am_j_list):
                ag_mam_exprs.append(
                    ag_man_objs[am][0, self._input_data.ag_lu2cells[0, j], j_idx]
                    @ self.X_ag_man_dry_vars_jr[am][j_idx, self._input_data.ag_lu2cells[0, j]]
                    + ag_man_objs[am][1, self._input_data.ag_lu2cells[1, j], j_idx]
                    @ self.X_ag_man_irr_vars_jr[am][j_idx, self._input_data.ag_lu2cells[1, j]]
                )

        non_ag_exprs = []
        for k, k_name in enumerate(NON_AG_LAND_USES):
            if not NON_AG_LAND_USES[k_name]:
                continue
            non_ag_exprs.append(
                non_ag_obj_rk[:, k][self._input_data.non_ag_lu2cells[k]]
                @ self.X_non_ag_vars_kr[k, self._input_data.non_ag_lu2cells[k]]
            )
        
        self.economy_ag_contr = gp.quicksum(ag_exprs)
        self.economy_ag_man_contr = gp.quicksum(ag_mam_exprs)
        self.economy_non_ag_contr = gp.quicksum(non_ag_exprs)
        
        return (
            (self.economy_ag_contr + self.economy_ag_man_contr + self.economy_non_ag_contr) 
            * self._input_data.scale_factors['Economy'] 
            / 1e6 # Convert to million AUD
        )  
    
    
    def _setup_biodiversity_objective(self):
        print("    |__ setting up objective for biodiversity...")
        
        ag_exprs = []
        for j in range(self._input_data.n_ag_lus):
            ag_exprs.append(
                gp.quicksum(
                    self._input_data.ag_b_mrj[0, :, j] * self.X_ag_dry_vars_jr[j, :]
                )  
                + gp.quicksum(
                    self._input_data.ag_b_mrj[1, :, j] * self.X_ag_irr_vars_jr[j, :]
                )
                
            )
 
        ag_mam_exprs = []
        for am, am_j_list in self._input_data.am2j.items():
            if not AG_MANAGEMENTS[am]:
                continue
                
            for j_idx in range(len(am_j_list)):
                ag_mam_exprs.append(
                    gp.quicksum(
                        self._input_data.ag_man_b_mrj[am][0, :, j_idx]
                        * self.X_ag_man_dry_vars_jr[am][j_idx, :]
                    )  # Dryland alt. ag. management contributions
                    + gp.quicksum(
                        self._input_data.ag_man_b_mrj[am][1, :, j_idx]
                        * self.X_ag_man_irr_vars_jr[am][j_idx, :]
                    )  # Irrigated alt. ag. management contributions   
                )
    
        non_ag_exprs = []
        for k,k_name in enumerate(NON_AG_LAND_USES):
            if not NON_AG_LAND_USES[k_name]:
                continue
            non_ag_exprs.append(
                gp.quicksum(
                    self._input_data.non_ag_b_rk[:, k] * self.X_non_ag_vars_kr[k, :]
                )
            )
        
        self.bio_ag_contr = gp.quicksum(ag_exprs)
        self.bio_ag_man_contr = gp.quicksum(ag_mam_exprs)
        self.bio_non_ag_contr = gp.quicksum(non_ag_exprs)
        
        return (
            (self.bio_ag_contr + self.bio_non_ag_contr + self.bio_ag_man_contr) 
            * self._input_data.scale_factors['Biodiversity']
        )
        
        
    def _setup_penalty_objectives(self):
        print("    |__ setting up objective for soft constraints...")

        penalty_ghg = 0
        penalty_water = 0
        
        weight_ghg = 0
        weight_water = 0

        # Get the penalty values for each sector
        penalty_demand = (
            gp.quicksum(
                self.V[c] * self._input_data.scale_factors['Demand'] * price
                for c, price in enumerate(self._input_data.economic_BASE_YR_prices)
            ) 
            * settings.SOLVER_WEIGHT_DEMAND
            / 1e6  # Convert to million AUD
        )
    
        if settings.GHG_CONSTRAINT_TYPE == "soft":
            weight_ghg = settings.SOLVER_WEIGHT_GHG
            penalty_ghg = (
                self.E 
                 * self._input_data.scale_factors['GHG']
                 * weight_ghg
                 / self._input_data.base_yr_prod["BASE_YR GHG (tCO2e)"]
                 + 1
            ) 
        
        if settings.WATER_CONSTRAINT_TYPE == "soft":
            weight_water = settings.SOLVER_WEIGHT_WATER
            penalty_water = (
                gp.quicksum(v for v in self.W)
                 * self._input_data.scale_factors['Water']
                 * weight_water
                 / self._input_data.base_yr_prod["BASE_YR Water (ML)"].sum()
                 + 1
            ) / len(self._input_data.limits["water"].keys()) 

        return (penalty_demand + penalty_ghg + penalty_water) / (settings.SOLVER_WEIGHT_DEMAND + weight_ghg + weight_water)
        

        

    def _add_cell_usage_constraints(self, cells: Optional[np.array] = None):
        """
        Constraint that all of every cell is used for some land use.
        If `cells` is provided, only adds constraints for the given cells
        """
        print("    |__ Adding constraints for cell usage...")

        if cells is None:
            cells = np.array(range(self._input_data.ncells))

        x_ag_dry_vars = self.X_ag_dry_vars_jr[:, cells]
        x_ag_irr_vars = self.X_ag_irr_vars_jr[:, cells]
        x_non_ag_vars = self.X_non_ag_vars_kr[:, cells]

        # Create an array indexed by cell that contains the sums of each cell's variables.
        # Then, loop through the array and add the constraint that each expression must equal 1.
        X_sum_r = (
            x_ag_dry_vars.sum(axis=0)
            + x_ag_irr_vars.sum(axis=0)
            + x_non_ag_vars.sum(axis=0)
        )
        for r, expr in zip(cells, X_sum_r):
            self.cell_usage_constraint_r[r] = self.gurobi_model.addConstr(
                expr == 1, 
                name=f"const_cell_usage_{r}"
            )

    def _add_agricultural_management_constraints(
        self, cells: Optional[np.array] = None
    ):
        """
        Constraint handling alternative agricultural management options:
        Ag. man. variables cannot exceed the value of the agricultural variable.
        """
        print("    |__ Adding constraints for agricultural management options...")

        for am, am_j_list in self._input_data.am2j.items():
            for j_idx, j in enumerate(am_j_list):
                if cells is not None:
                    lm_dry_r_vals = [
                        r for r in cells if self._input_data.ag_x_mrj[0, r, j]
                    ]
                    lm_irr_r_vals = [
                        r for r in cells if self._input_data.ag_x_mrj[1, r, j]
                    ]
                else:
                    lm_dry_r_vals = self._input_data.ag_lu2cells[0, j]
                    lm_irr_r_vals = self._input_data.ag_lu2cells[1, j]

                for r in lm_dry_r_vals:
                    constr = self.gurobi_model.addConstr(
                        self.X_ag_man_dry_vars_jr[am][j_idx, r]
                        <= self.X_ag_dry_vars_jr[j, r],
                        name=f"const_ag_mam_dry_usage_{am}_{j}_{r}".replace(" ", "_"),
                    )
                    self.ag_management_constraints_r[r].append(constr)
                for r in lm_irr_r_vals:
                    constr = self.gurobi_model.addConstr(
                        self.X_ag_man_irr_vars_jr[am][j_idx, r]
                        <= self.X_ag_irr_vars_jr[j, r],
                        name=f"const_ag_mam_irr_usage_{am}_{j}_{r}".replace(" ", "_"),
                    )
                    self.ag_management_constraints_r[r].append(constr)

    def _add_agricultural_management_adoption_limit_constraints(self):
        """
        Add adoption limits constraints for agricultural management options.
        """
        print("    |__ Adding constraints for agricultural management adoption limits...")

        for am, am_j_list in self._input_data.am2j.items():
            for j_idx, j in enumerate(am_j_list):
                adoption_limit = self._input_data.ag_man_limits[am][j]

                # Sum of all usage of the AM option must be less than the limit
                ag_man_vars_sum = gp.quicksum(
                    self.X_ag_man_dry_vars_jr[am][j_idx, :]
                ) + gp.quicksum(self.X_ag_man_irr_vars_jr[am][j_idx, :])

                all_vars_sum = gp.quicksum(self.X_ag_dry_vars_jr[j, :]) + gp.quicksum(
                    self.X_ag_irr_vars_jr[j, :]
                )
                constr = self.gurobi_model.addConstr(
                    ag_man_vars_sum <= adoption_limit * all_vars_sum,
                    name=f"const_ag_mam_adoption_limit_{am}_{j}".replace(" ", "_"),
                )

                self.adoption_limit_constraints.append(constr)

    def _add_demand_penalty_constraints(self):
        """
        Constraints to penalise under and over production compared to demand.
        """
        print("    |__ Adding constraints for demand penalties...")
        
        self.ag_q_c = [gp.LinExpr(0) for _ in range(self._input_data.ncms)]
        for j in range(self._input_data.n_ag_lus):
            X_ag_dry_r = self.X_ag_dry_vars_jr[j, :]
            X_ag_irr_r = self.X_ag_irr_vars_jr[j, :]
            
            for p in range(self._input_data.nprs):
                if not self._input_data.lu2pr_pj[p, j]:
                    continue
                ag_q_p = (
                    gp.quicksum(
                        self._input_data.ag_q_mrp[0, :, p] * X_ag_dry_r
                    ) 
                    + gp.quicksum(
                        self._input_data.ag_q_mrp[1, :, p] * X_ag_irr_r
                    ) 
                )  
                
                for c in range(self._input_data.ncms):
                    if not self._input_data.pr2cm_cp[c, p]:
                        continue
                    self.ag_q_c[c] += ag_q_p
                        
                        
        self.ag_man_q_c = [gp.LinExpr(0) for _ in range(self._input_data.ncms)]
        for am, am_j_list in self._input_data.am2j.items():
            if not AG_MANAGEMENTS[am]:
                continue
            
            for j_idx,j in enumerate(am_j_list):
                X_ag_mam_dry_r = self.X_ag_man_dry_vars_jr[am][j_idx, :]
                X_ag_mam_irr_r = self.X_ag_man_irr_vars_jr[am][j_idx, :]
                
                for p in range(self._input_data.nprs):
                    if not self._input_data.lu2pr_pj[p, j]:
                        continue
                    ag_mam_q_p = (
                        gp.quicksum(
                            self._input_data.ag_man_q_mrp[am][0, :, p] * X_ag_mam_dry_r
                        ) 
                        + gp.quicksum(
                            self._input_data.ag_man_q_mrp[am][1, :, p] * X_ag_mam_irr_r
                        ) 
                    )  
                    
                    for c in range(self._input_data.ncms):
                        if not self._input_data.pr2cm_cp[c, p]:
                            continue
                        self.ag_man_q_c[c] += ag_mam_q_p


        self.non_ag_q_c = [gp.LinExpr(0) for _ in range(self._input_data.ncms)]
        for k,k_name in enumerate(NON_AG_LAND_USES):
            if not NON_AG_LAND_USES[k_name]:
                continue
            
            for c in range(self._input_data.ncms):
                self.non_ag_q_c[c] += gp.quicksum(
                    self._input_data.non_ag_q_crk[c, :, k] * self.X_non_ag_vars_kr[k, :]
                )
            

        # Total quantities in CM/c representation.
        self.total_q_exprs_c = [
            self.ag_q_c[c]
            + self.ag_man_q_c[c] 
            + self.non_ag_q_c[c] 
            for c in range(self._input_data.ncms)
        ]

        lower_bound_constraints = self.gurobi_model.addConstrs(
            (
                (self.total_q_exprs_c[c] - self._input_data.limits['demand_rescale'][c]) == self.V[c] 
                for c in range(self._input_data.ncms)
            ),  name="demand_soft_bound_lower"
        )

        # self.demand_penalty_constraints.extend(upper_bound_constraints.values())
        self.demand_penalty_constraints.extend(lower_bound_constraints.values())


    def _get_water_net_yield_expr_for_region(
        self,
        ind: np.ndarray,
    ) -> gp.LinExpr:
        """
        Get the Gurobi linear expression for the net water yield of a given region.
        """
        
        ag_exprs = []
        for j in range(self._input_data.n_ag_lus):
            ag_exprs.append(
                gp.quicksum(
                    self._input_data.ag_w_mrj[0, ind, j] * self.X_ag_dry_vars_jr[j, ind]
                )  # Dryland agriculture contribution
                + gp.quicksum(
                    self._input_data.ag_w_mrj[1, ind, j] * self.X_ag_irr_vars_jr[j, ind]
                )  # Irrigated agriculture contribution
            )
 
        ag_mam_exprs = []
        for am, am_j_list in self._input_data.am2j.items():
            if not AG_MANAGEMENTS[am]:
                continue
            
            for j_idx in range(len(am_j_list)):
                ag_mam_exprs.append(
                    gp.quicksum(
                        self._input_data.ag_man_w_mrj[am][0, ind, j_idx]
                        * self.X_ag_man_dry_vars_jr[am][j_idx, ind]
                    )  # Dryland alt. ag. management contributions
                    + gp.quicksum(
                        self._input_data.ag_man_w_mrj[am][1, ind, j_idx]
                        * self.X_ag_man_irr_vars_jr[am][j_idx, ind]
                    )  # Irrigated alt. ag. management contributions
                )

        non_ag_exprs = []
        for k in range(self._input_data.n_non_ag_lus):
            non_ag_exprs.append(
                gp.quicksum(
                    self._input_data.non_ag_w_rk[ind, k] * self.X_non_ag_vars_kr[k, ind]
                )  # Non-agricultural contribution
            )
        
        ag_contr = gp.quicksum(ag_exprs) 
        ag_man_contr = gp.quicksum(ag_mam_exprs)
        non_ag_contr = gp.quicksum(non_ag_exprs)
        return ag_contr + ag_man_contr + non_ag_contr


    def _add_water_usage_limit_constraints(self) -> None:
        
        if settings.WATER_LIMITS != "on": 
            print("    |__ TURNING OFF water usage constraints ...")
            return
        
        print("    |__ Adding constraints for water usage limits...")
        
        # Ensure water use remains below limit for each region
        for reg_idx, water_limit_rescale in self._input_data.limits["water_rescale"].items():
            
            w_limit_raw = water_limit_rescale * self._input_data.scale_factors['Water']
            ind = self._input_data.water_region_indices[reg_idx]
            reg_name = self._input_data.water_region_names[reg_idx]

            print(f"      |__ target (inside LUTO study area) is {w_limit_raw:15,.0f} ML for {reg_name}")

            self.water_nyiled_exprs[reg_idx] = self._get_water_net_yield_expr_for_region(ind)           # Water net yield inside LUTO study area

            if settings.WATER_CONSTRAINT_TYPE == "hard":
                constr = self.gurobi_model.addConstr(
                    self.water_nyiled_exprs[reg_idx] >= water_limit_rescale, 
                    name=f"water_yield_limit_{reg_name}".replace(" ", "_")
                )
            elif settings.WATER_CONSTRAINT_TYPE == "soft":
                constr = self.gurobi_model.addConstr(
                    water_limit_rescale - self.water_nyiled_exprs[reg_idx] <= self.W[reg_idx - 1],     # region index starts from 1
                    name=f"water_yield_limit_{reg_name.replace(' ', '_')}"
                )
            else:
                raise ValueError(
                    "Unknown choice for `WATER_CONSTRAINT_TYPE` setting: must be either 'hard' or 'soft'"
                ) 
                
            self.water_limit_constraints.append(constr)


    def _get_total_ghg_expr(self) -> gp.LinExpr:
        # Pre-calculate the coefficients for each variable,
        # both for regular culture and alternative agr. management options
        g_dry_coeff = (
            self._input_data.ag_g_mrj[0, :, :] + self._input_data.ag_ghg_t_mrj[0, :, :]
        )
        g_irr_coeff = (
            self._input_data.ag_g_mrj[1, :, :] + self._input_data.ag_ghg_t_mrj[1, :, :]
        )

        ghg_ag_exprs =[]
        for j in range(self._input_data.n_ag_lus):
            ghg_ag_exprs.append(
                gp.quicksum(
                    g_dry_coeff[:, j] * self.X_ag_dry_vars_jr[j, :]
                )
                + gp.quicksum(
                    g_irr_coeff[:, j] * self.X_ag_irr_vars_jr[j, :]
                )
            )
            
        ghg_ag_man_exprs = []
        for am, am_j_list in self._input_data.am2j.items():
            if not AG_MANAGEMENTS[am]:
                continue
            
            for j_idx in range(len(am_j_list)):
                ghg_ag_man_exprs.append(
                    gp.quicksum(
                        self._input_data.ag_man_g_mrj[am][0, :, j_idx]
                        * self.X_ag_man_dry_vars_jr[am][j_idx, :]
                    )  
                    + gp.quicksum(
                        self._input_data.ag_man_g_mrj[am][1, :, j_idx]
                        * self.X_ag_man_irr_vars_jr[am][j_idx, :]
                    )  
                )
                
        ghg_non_ag_exprs = []
        for k,k_name in enumerate(NON_AG_LAND_USES):
            if not NON_AG_LAND_USES[k_name]:
                continue
            ghg_non_ag_exprs.append(
                gp.quicksum(
                    self._input_data.non_ag_g_rk[:, k] * self.X_non_ag_vars_kr[k, :]
                )
            )
            
        self.ghg_ag_contr = gp.quicksum(ghg_ag_exprs)
        self.ghg_ag_man_contr = gp.quicksum(ghg_ag_man_exprs)
        self.ghg_non_ag_contr = gp.quicksum(ghg_non_ag_exprs)    
        
        return self.ghg_ag_contr + self.ghg_ag_man_contr + self.ghg_non_ag_contr + self._input_data.offland_ghg

    def _add_ghg_emissions_limit_constraints(self):
        """
        Add either hard or soft GHG constraints depending on settings.GHG_CONSTRAINT_TYPE
        """
        if settings.GHG_EMISSIONS_LIMITS == "off":
            print("    |__ TURNING OFF GHG emissions constraints ...")
            return
                
        ghg_limit_raw = self._input_data.limits["ghg"]
        ghg_limit_rescale = self._input_data.limits["ghg_rescale"]
        self.ghg_expr = self._get_total_ghg_expr()

        if settings.GHG_CONSTRAINT_TYPE == "hard":
            print(f"    |__ Adding constraints <hard> for GHG emissions: {ghg_limit_raw:,.0f} tCO2e")
            self.ghg_consts_ub = self.gurobi_model.addConstr(
                self.ghg_expr <= ghg_limit_rescale,
                name="ghg_emissions_limit_ub",
            )
        elif settings.GHG_CONSTRAINT_TYPE == "soft":
            print(f"    |__ Adding <soft> constraints for GHG emissions: {ghg_limit_raw:,.0f} tCO2e")
            self.ghg_consts_soft.append(
                self.gurobi_model.addConstr(
                    self.ghg_expr - ghg_limit_rescale <= self.E,
                    name="ghg_emissions_limit_soft_ub",
                )
            )
            self.ghg_consts_soft.append(
                self.gurobi_model.addConstr(
                    ghg_limit_rescale - self.ghg_expr <= self.E,
                    name="ghg_emissions_limit_soft_lb",
                )
            )
        else:
            raise ValueError(
                "    Unknown choice for `GHG_CONSTRAINT_TYPE` setting: must be either 'hard' or 'soft'"
            )
            
            
    def _add_biodiversity_constraints(self) -> None:
        print("    |__ Adding constraints for biodiversity...")
        self._add_GBF2_constraints()
        self._add_GBF3_major_vegetation_group_limit_constraints()
        self._add_GBF4_snes_constraints()
        self._add_GBF4_ecnes_constraints()
        self._add_GBF8_constraints()


    def _add_GBF2_constraints(self) -> None:
        
        if settings.BIODIVERSITY_TARGET_GBF_2 == "off":
            print("      |__ TURNING OFF constraints for biodiversity GBF 2...")
            return
        
        bio_ag_exprs = []
        bio_ag_man_exprs = []
        bio_non_ag_exprs = []
        
        for j in range(self._input_data.n_ag_lus):
            ind_dry = np.intersect1d(self._input_data.ag_lu2cells[0, j], self._input_data.priority_degraded_mask_idx)
            ind_irr = np.intersect1d(self._input_data.ag_lu2cells[1, j], self._input_data.priority_degraded_mask_idx)
            bio_ag_exprs.append(
                gp.quicksum(
                    self._input_data.GBF2_raw_priority_degraded_area_r[ind_dry]
                    * self._input_data.biodiv_contr_ag_j[j]
                    * self.X_ag_dry_vars_jr[j, ind_dry]
                )
                + gp.quicksum(
                    self._input_data.GBF2_raw_priority_degraded_area_r[ind_irr]
                    * self._input_data.biodiv_contr_ag_j[j]
                    * self.X_ag_irr_vars_jr[j, ind_irr]
                ) 
            )
        for am, am_j_list in self._input_data.am2j.items():
            if not AG_MANAGEMENTS[am]:
                continue
            for j_idx in range(len(am_j_list)):
                
                ind_dry = np.intersect1d(self._input_data.ag_lu2cells[0, j_idx], self._input_data.priority_degraded_mask_idx)
                ind_irr = np.intersect1d(self._input_data.ag_lu2cells[1, j_idx], self._input_data.priority_degraded_mask_idx)
                bio_ag_man_exprs.append(
                    gp.quicksum(self._input_data.GBF2_raw_priority_degraded_area_r[ind_dry]
                        * self._input_data.biodiv_contr_ag_man[am][j_idx][ind_dry]
                        * self.X_ag_man_dry_vars_jr[am][j_idx, ind_dry])
                    + gp.quicksum(
                        self._input_data.GBF2_raw_priority_degraded_area_r[ind_irr]
                        * self._input_data.biodiv_contr_ag_man[am][j_idx][ind_irr]
                        * self.X_ag_man_irr_vars_jr[am][j_idx, ind_irr]
                    )
                )  
        for k in range(self._input_data.n_non_ag_lus):
            ind = np.intersect1d(self._input_data.non_ag_lu2cells[k], self._input_data.priority_degraded_mask_idx)
            bio_non_ag_exprs.append(
                gp.quicksum(
                    self._input_data.GBF2_raw_priority_degraded_area_r[ind]
                    * self._input_data.biodiv_contr_non_ag_k[k]
                    * self.X_non_ag_vars_kr[k, ind]
                )
            )

        self.bio_GBF2_expr = (
            gp.quicksum(bio_ag_exprs) 
            + gp.quicksum(bio_ag_man_exprs) 
            + gp.quicksum(bio_non_ag_exprs)
        ) 


        print(f'      |__ Adding constraints for biodiversity GBF 2: {self._input_data.limits["GBF2"]:15,.0f}')
        
        self.bio_GBF2_constrs = self.gurobi_model.addConstr(
            self.bio_GBF2_expr >= self._input_data.limits["GBF2_rescale"], 
            name="bio_GBF2_priority_degraded_area_limit"
        )


    def _add_GBF3_major_vegetation_group_limit_constraints(self) -> None:
        if settings.BIODIVERSITY_TARGET_GBF_3 == "off":
            print("      |__ TURNING OFF constraints for biodiversity GBF 3 (major vegetation groups)")
            return

        v_limits = self._input_data.limits["GBF3_rescale"]
        v_names = self._input_data.GBF3_names
        v_ind = self._input_data.GBF3_ind

        print(f"      Adding constraints for biodiversity GBF 3...")

        for v, v_area_lb_rescale in enumerate(v_limits):
            
            v_area_lb_raw = v_area_lb_rescale * self._input_data.scale_factors['GBF3']
            
            if v_area_lb_raw == 0:
                print(f"        |__ target is {v_area_lb_raw:15,.0f} for {v_names[v]} (skipped modelling)  ")
                continue
            
            ind = v_ind[v]
            MVG_raw_area_r = self._input_data.GBF3_raw_MVG_area_vr[v, ind]

            ag_contr = gp.quicksum(
                gp.quicksum(
                    MVG_raw_area_r
                    * self._input_data.biodiv_contr_ag_j[j]
                    * self.X_ag_dry_vars_jr[j, ind]
                )  # Dryland agriculture contribution
                + gp.quicksum(
                    MVG_raw_area_r
                    * self._input_data.biodiv_contr_ag_j[j]
                    * self.X_ag_irr_vars_jr[j, ind]
                )  # Irrigated agriculture contribution
                for j in range(self._input_data.n_ag_lus)
            )

            ag_man_contr = gp.quicksum(
                gp.quicksum(
                    MVG_raw_area_r
                    * self._input_data.biodiv_contr_ag_man[am][j_idx][ind]
                    * self.X_ag_man_dry_vars_jr[am][j_idx, ind]
                )  # Dryland alt. ag. management contributions
                + gp.quicksum(
                    MVG_raw_area_r
                    * self._input_data.biodiv_contr_ag_man[am][j_idx][ind]
                    * self.X_ag_man_irr_vars_jr[am][j_idx, ind]
                )  # Irrigated alt. ag. management contributions
                for am, am_j_list in self._input_data.am2j.items()
                for j_idx in range(len(am_j_list))
            )

            non_ag_contr = gp.quicksum(
                gp.quicksum(
                    MVG_raw_area_r
                    * self._input_data.biodiv_contr_non_ag_k[k]
                    * self.X_non_ag_vars_kr[k, ind]
                )  # Non-agricultural contribution
                for k in range(self._input_data.n_non_ag_lus)
            )


            self.bio_GBF3_exprs[v] = ag_contr + ag_man_contr + non_ag_contr

            print(f"        |__ target is {v_area_lb_raw:15,.0f} for {v_names[v]} ")
            self.bio_GBF3_constrs[v] = self.gurobi_model.addConstr(
                self.bio_GBF3_exprs[v] >= v_area_lb_rescale,
                name=f"bio_GBF3_limit_{v_names[v]}".replace(" ", "_")
            )


    def _add_GBF4_snes_constraints(self) -> None:
        if settings.BIODIVERSITY_TARGET_GBF_4_SNES != "on":
            print('      |__ TURNING OFF constraints for biodiversity GBF 4 SNES...')
            return
        
        x_limits = self._input_data.limits["GBF4_SNES_rescale"]
        x_names = self._input_data.GBF4_SNES_names

        print(f"      |__ Adding constraints for biodiversity GBF 4 SNES...")
        
        for x, x_area_lb_rescale in enumerate(x_limits):
            x_area_lb_raw = x_area_lb_rescale * self._input_data.scale_factors['GBF4_SNES']
            ind = np.where(self._input_data.GBF4_SNES_xr[x] > 0)[0]

            if ind.size == 0:
                print(
                    f"        |__ WARNING: SNES species NOT added because of empty layer for {x_names[x]}")
                continue
            
            ag_contr = gp.quicksum(
                gp.quicksum(
                    self._input_data.GBF4_SNES_xr[x, ind]
                    * self._input_data.biodiv_contr_ag_j[j]
                    * self.X_ag_dry_vars_jr[j, ind]
                )  # Dryland agriculture contribution
                + gp.quicksum(
                    self._input_data.GBF4_SNES_xr[x, ind]
                    * self._input_data.biodiv_contr_ag_j[j]
                    * self.X_ag_irr_vars_jr[j, ind]
                )  # Irrigated agriculture contribution
                for j in range(self._input_data.n_ag_lus)
            )

            ag_man_contr = gp.quicksum(
                gp.quicksum(
                    self._input_data.GBF4_SNES_xr[x, ind]
                    * self._input_data.biodiv_contr_ag_man[am][j_idx][ind]
                    * self.X_ag_man_dry_vars_jr[am][j_idx, ind]
                )  # Dryland alt. ag. management contributions
                + gp.quicksum(
                    self._input_data.GBF4_SNES_xr[x, ind]
                    * self._input_data.biodiv_contr_ag_man[am][j_idx][ind]
                    * self.X_ag_man_irr_vars_jr[am][j_idx, ind]
                )  # Irrigated alt. ag. management contributions
                for am, am_j_list in self._input_data.am2j.items()
                for j_idx in range(len(am_j_list))
            )

            non_ag_contr = gp.quicksum(
                gp.quicksum(
                    self._input_data.GBF4_SNES_xr[x, ind]
                    * self._input_data.biodiv_contr_non_ag_k[k]
                    * self.X_non_ag_vars_kr[k, ind]
                )  # Non-agricultural contribution
                for k in range(self._input_data.n_non_ag_lus)
            )

            self.bio_GBF4_SNES_exprs[x] = ag_contr + ag_man_contr + non_ag_contr

            print(f"        |__ target is {x_area_lb_raw:15,.0f} for {x_names[x]}")
            self.bio_GBF4_SNES_constrs[x] = self.gurobi_model.addConstr(
                self.bio_GBF4_SNES_exprs[x] >= x_area_lb_rescale,
                name=f"bio_GBF4_SNES_limit_{x_names[x]}".replace(" ", "_"),
            )

    def _add_GBF4_ecnes_constraints(self) -> None:
        if settings.BIODIVERSITY_TARGET_GBF_4_ECNES != "on":
            print('      |__ TURNING OFF constraints for biodiversity GBF 4 ECNES...')
            return
        
        x_limits = self._input_data.limits["GBF4_ECNES_rescale"]
        x_names = self._input_data.GBF4_ECNES_names

        print(f"      |__ Adding constraints for biodiversity GBF 4 ECNES...")
        
        for x, x_area_lb_rescale in enumerate(x_limits):
            x_area_lb_raw = x_area_lb_rescale * self._input_data.scale_factors['GBF4_ECNES']
            ind = np.where(self._input_data.GBF4_ECNES_xr[x] > 0)[0]

            if ind.size == 0:
                print(
                    f"        |__ WARNING: ECNES species was NOT added because of empty layer for {x_names[x]}")
                continue
            
            ag_contr = gp.quicksum(
                gp.quicksum(
                    self._input_data.GBF4_ECNES_xr[x, ind]
                    * self._input_data.biodiv_contr_ag_j[j]
                    * self.X_ag_dry_vars_jr[j, ind]
                )  # Dryland agriculture contribution
                + gp.quicksum(
                    self._input_data.GBF4_ECNES_xr[x, ind]
                    * self._input_data.biodiv_contr_ag_j[j]
                    * self.X_ag_irr_vars_jr[j, ind]
                )  # Irrigated agriculture contribution
                for j in range(self._input_data.n_ag_lus)
            )

            ag_man_contr = gp.quicksum(
                gp.quicksum(
                    self._input_data.GBF4_ECNES_xr[x, ind]
                    * self._input_data.biodiv_contr_ag_man[am][j_idx][ind]
                    * self.X_ag_man_dry_vars_jr[am][j_idx, ind]
                )  # Dryland alt. ag. management contributions
                + gp.quicksum(
                    self._input_data.GBF4_ECNES_xr[x, ind]
                    * self._input_data.biodiv_contr_ag_man[am][j_idx][ind]
                    * self.X_ag_man_irr_vars_jr[am][j_idx, ind]
                )  # Irrigated alt. ag. management contributions
                for am, am_j_list in self._input_data.am2j.items()
                for j_idx in range(len(am_j_list))
            )

            non_ag_contr = gp.quicksum(
                gp.quicksum(
                    self._input_data.GBF4_ECNES_xr[x, ind]
                    * self._input_data.biodiv_contr_non_ag_k[k]
                    * self.X_non_ag_vars_kr[k, ind]
                )  # Non-agricultural contribution
                for k in range(self._input_data.n_non_ag_lus)
            )

            self.bio_GBF4_ECNES_exprs[x] = ag_contr + ag_man_contr + non_ag_contr


            print(f"        |__ target is {x_area_lb_raw:15,.0f} for {x_names[x]} ")
            self.bio_GBF4_ECNES_constrs[x] = self.gurobi_model.addConstr(
                self.bio_GBF4_ECNES_exprs[x] >= x_area_lb_rescale,
                name=f"bio_GBF4_ECNES_limit_{x_names[x]}".replace(" ", "_")
            )


    def _add_GBF8_constraints(self) -> None:
                
        if settings.BIODIVERSITY_TARGET_GBF_8 != "on":
            print('      |__ TURNING OFF constraints for biodiversity GBF 8...')
            return
        
        s_limits = self._input_data.limits["GBF8_rescale"]
        s_names = self._input_data.GBF8_species_names
        s_ind = self._input_data.GBF8_species_indices

        print(f"      |__ Adding constraints for biodiversity GBF 8...")
        
        for s, s_area_lb_rescale in enumerate(s_limits):
            
            ind = s_ind[s]
            s_area_lb_raw = s_area_lb_rescale * self._input_data.scale_factors['GBF8']
            GBF8_raw_area_r = self._input_data.GBF8_raw_species_area_sr[s, ind]
            
            ag_contr = gp.quicksum(
                gp.quicksum(
                    GBF8_raw_area_r
                    * self._input_data.biodiv_contr_ag_j[j]
                    * self.X_ag_dry_vars_jr[j, ind]
                )  # Dryland agriculture contribution
                + gp.quicksum(
                    GBF8_raw_area_r
                    * self._input_data.biodiv_contr_ag_j[j]
                    * self.X_ag_irr_vars_jr[j, ind]
                )  # Irrigated agriculture contribution
                for j in range(self._input_data.n_ag_lus)
            )

            ag_man_contr = gp.quicksum(
                gp.quicksum(
                    GBF8_raw_area_r
                    * self._input_data.biodiv_contr_ag_man[am][j_idx][ind]
                    * self.X_ag_man_dry_vars_jr[am][j_idx, ind]
                )  # Dryland alt. ag. management contributions
                + gp.quicksum(
                    GBF8_raw_area_r
                    * self._input_data.biodiv_contr_ag_man[am][j_idx][ind]
                    * self.X_ag_man_irr_vars_jr[am][j_idx, ind]
                )  # Irrigated alt. ag. management contributions
                for am, am_j_list in self._input_data.am2j.items()
                for j_idx in range(len(am_j_list))
            )

            non_ag_contr = gp.quicksum(
                gp.quicksum(
                    GBF8_raw_area_r
                    * self._input_data.biodiv_contr_non_ag_k[k]
                    * self.X_non_ag_vars_kr[k, ind]
                )  # Non-agricultural contribution
                for k in range(self._input_data.n_non_ag_lus)
            )

            # Divide by constant to reduce strain on the constraint matrix range
            self.bio_GBF8_exprs[s] = ag_contr + ag_man_contr + non_ag_contr
    
            print(f"        |__ target is {s_area_lb_raw:15,.0f} for {s_names[s]}")
            self.bio_GBF8_constrs[s] = self.gurobi_model.addConstr(
                self.bio_GBF8_exprs[s] >= s_area_lb_rescale,
                name=f"bio_GBF8_limit_{s_names[s]}".replace(" ", "_"),
            )


    def _add_regional_adoption_constraints(self) -> None:

        if settings.REGIONAL_ADOPTION_CONSTRAINTS == "off":
            print("      |__ TURNING OFF constraints for regional adoption...")
            return
                
        # Add adoption constraints for agricultural land uses
        reg_adopt_limits = self._input_data.limits["ag_regional_adoption"]
        for reg_id, j, lu_name, reg_ind, reg_area_limit in reg_adopt_limits:
            print(f"       |__ Adding constraints for {lu_name} in {settings.REGIONAL_ADOPTION_ZONE} region {reg_id} <= {reg_area_limit:,.0f} HA...")
            reg_expr = (
                  gp.quicksum(self._input_data.real_area[reg_ind] * self.X_ag_dry_vars_jr[j, reg_ind])
                + gp.quicksum(self._input_data.real_area[reg_ind] * self.X_ag_irr_vars_jr[j, reg_ind])
            )
            self.regional_adoption_constrs.append(self.gurobi_model.addConstr(reg_expr <= reg_area_limit, name=f"reg_adopt_limit_ag_{lu_name}_{reg_id}"))
        
        # Add adoption constraints for non-agricultural land uses
        reg_adopt_limits = self._input_data.limits["non_ag_regional_adoption"]
        for reg_id, k, lu_name, reg_ind, reg_area_limit in reg_adopt_limits:
            print(f"       |__ Adding constraints for {lu_name} in {settings.REGIONAL_ADOPTION_ZONE} region {reg_id} <= {reg_area_limit:,.0f} HA...")
            reg_expr = gp.quicksum(self._input_data.real_area[reg_ind] * self.X_non_ag_vars_kr[k, reg_ind])
            self.regional_adoption_constrs.append(self.gurobi_model.addConstr(reg_expr <= reg_area_limit, name=f"reg_adopt_limit_non_ag_{lu_name}_{reg_id}"))




    def update_formulation(
        self,
        input_data: SolverInputData,
        d_c: np.array,
        old_ag_x_mrj: np.ndarray,
        old_ag_man_lb_mrj: dict,
        old_non_ag_x_rk: np.ndarray,
        old_non_ag_lb_rk: np.ndarray,
        old_lumap: np.array,
        current_lumap: np.array,
        old_lmmap: np.array,
        current_lmmap: np.array,
    ):
        """
        Dynamically updates the existing formulation based on new input data and demands.
        """
        self._input_data = input_data
        self._input_data.limits['demand'] = d_c

        print("Updating variables...", flush=True)
        updated_cells = self._update_variables(
            old_ag_x_mrj,
            old_ag_man_lb_mrj,
            old_non_ag_x_rk,
            old_non_ag_lb_rk,
            old_lumap,
            current_lumap,
            old_lmmap,
            current_lmmap,
        )
        print("Updating constraints...", flush=True)
        self._update_constraints(updated_cells)

        print("Updating objective function...", flush=True)
        self._setup_objective()

    def _update_variables(
        self,
        old_ag_x_mrj: np.ndarray,
        old_ag_man_lb_mrj: dict,
        old_non_ag_x_rk: np.ndarray,
        old_non_ag_lb_rk: np.ndarray,
        old_lumap: np.array,
        current_lumap: np.array,
        old_lmmap: np.array,
        current_lmmap: np.array,
    ):
        """
        Updates the variables only for cells that have changed land use or land management.
        Returns an array of cells that have been updated.
        """
        # metrics
        num_cells_skipped = 0
        updated_cells = []

        for r in range(self._input_data.ncells):
            old_j = old_lumap[r]
            new_j = current_lumap[r]
            old_m = old_lmmap[r]
            new_m = current_lmmap[r]

            if (
                old_j == new_j
                and old_m == new_m
                and (old_ag_x_mrj[:, r, :] == self._input_data.ag_x_mrj[:, r, :]).all()
                and (old_non_ag_x_rk[r, :] == self._input_data.non_ag_x_rk[r, :]).all()
                and all(
                    old_non_ag_lb_rk[r, k] == self._input_data.non_ag_lb_rk[r, k]
                    for k, k_name in enumerate(NON_AG_LAND_USES)
                    if not NON_AG_LAND_USES_REVERSIBLE[k_name]
                )
                and all(
                    (old_ag_man_lb_mrj.get(am)[:, r, :] == self._input_data.ag_man_lb_mrj.get(am)[:, r, :]).all()
                    for am in (i for i in AG_MANAGEMENTS if AG_MANAGEMENTS[i])
                    if not AG_MANAGEMENTS_REVERSIBLE[am]
                )
            ):
                # cell has not changed between years. No need to update variables
                num_cells_skipped += 1
                continue

            # agricultural land usage
            self.gurobi_model.remove(
                list(self.X_ag_dry_vars_jr[:, r][np.where(self.X_ag_dry_vars_jr[:, r])])
            )
            self.gurobi_model.remove(
                list(self.X_ag_irr_vars_jr[:, r][np.where(self.X_ag_irr_vars_jr[:, r])])
            )
            self.X_ag_dry_vars_jr[:, r] = np.zeros(self._input_data.n_ag_lus)
            self.X_ag_irr_vars_jr[:, r] = np.zeros(self._input_data.n_ag_lus)
            for j in range(self._input_data.n_ag_lus):
                if self._input_data.ag_x_mrj[0, r, j]:
                    self.X_ag_dry_vars_jr[j, r] = self.gurobi_model.addVar(
                        ub=1, name=f"X_ag_dry_{j}_{r}"
                    )

                if self._input_data.ag_x_mrj[1, r, j]:
                    self.X_ag_irr_vars_jr[j, r] = self.gurobi_model.addVar(
                        ub=1, name=f"X_ag_irr_{j}_{r}"
                    )

            # non-agricultural land usage
            self.gurobi_model.remove(
                list(self.X_non_ag_vars_kr[:, r][np.where(self.X_non_ag_vars_kr[:, r])])
            )
            self.X_non_ag_vars_kr[:, r] = np.zeros(self._input_data.n_non_ag_lus)
            for k, k_name in enumerate(NON_AG_LAND_USES):
                if not NON_AG_LAND_USES[k_name]:
                    continue

                if self._input_data.non_ag_x_rk[r, k]:
                    x_lb = (
                        0
                        if NON_AG_LAND_USES_REVERSIBLE[k_name]
                        else self._input_data.non_ag_lb_rk[r, k]
                    )
                    self.X_non_ag_vars_kr[k, r] = self.gurobi_model.addVar(
                        lb=x_lb,
                        ub=self._input_data.non_ag_x_rk[r, k],
                        name=f"X_non_ag_{k}_{r}",
                    )

            # agricultural management
            for am, am_j_list in self._input_data.am2j.items():
                # remove old am variables
                self.gurobi_model.remove(
                    list(
                        self.X_ag_man_dry_vars_jr[am][:, r][
                            np.where(self.X_ag_man_dry_vars_jr[am][:, r])
                        ]
                    )
                )
                self.gurobi_model.remove(
                    list(
                        self.X_ag_man_irr_vars_jr[am][:, r][
                            np.where(self.X_ag_man_irr_vars_jr[am][:, r])
                        ]
                    )
                )
                self.X_ag_man_dry_vars_jr[am][:, r] = np.zeros(len(am_j_list))
                self.X_ag_man_irr_vars_jr[am][:, r] = np.zeros(len(am_j_list))

            for m, j in self._input_data.cells2ag_lu[r]:
                # replace am variables
                for am in self._input_data.j2am[j]:
                    if not AG_MANAGEMENTS[am]:
                        continue

                    # Get snake_case version of the AM name for the variable name
                    am_name = am.lower().replace(" ", "_")

                    x_lb = (
                        0
                        if AG_MANAGEMENTS_REVERSIBLE[am]
                        else self._input_data.ag_man_lb_mrj[am][m, r, j]
                    )
                    m_str = "dry" if m == 0 else "irr"
                    var_name = f"X_ag_man_{m_str}_{am_name}_{j}_{r}"

                    j_idx = self._input_data.am2j[am].index(j)
                    if m == 0:
                        self.X_ag_man_dry_vars_jr[am][j_idx, r] = (
                            self.gurobi_model.addVar(
                                lb=x_lb,
                                ub=1,
                                name=var_name,
                            )
                        )
                    else:
                        self.X_ag_man_irr_vars_jr[am][j_idx, r] = (
                            self.gurobi_model.addVar(
                                lb=x_lb,
                                ub=1,
                                name=var_name,
                            )
                        )

            updated_cells.append(r)

        updated_cells = np.array(updated_cells)
        print(f"    ...skipped {num_cells_skipped} cells, updated {len(updated_cells)} cells.\n")
        return updated_cells

    def _update_constraints(self, updated_cells: np.array):
        if len(updated_cells) == 0:
            print("No constraints need updating.")
            return

        print("  ...removing existing constraints...\n")
        for r in updated_cells:
            self.gurobi_model.remove(self.cell_usage_constraint_r.pop(r, []))
            self.gurobi_model.remove(self.ag_management_constraints_r.pop(r, []))

        self.gurobi_model.remove(self.adoption_limit_constraints)
        self.gurobi_model.remove(self.demand_penalty_constraints)
        if self.bio_GBF2_constrs is not None:
            self.gurobi_model.remove(self.bio_GBF2_constrs)
        if self.water_limit_constraints:
            self.gurobi_model.remove(self.water_limit_constraints)
        if self.bio_GBF3_constrs:
            for constr in self.bio_GBF3_constrs.values():
                self.gurobi_model.remove(constr)
        if self.bio_GBF4_SNES_constrs:
            for constr in self.bio_GBF4_SNES_constrs.values():
                self.gurobi_model.remove(constr)
        if self.bio_GBF4_ECNES_constrs:
            for constr in self.bio_GBF4_ECNES_constrs.values():
                self.gurobi_model.remove(constr)
        if self.bio_GBF8_constrs:
            for constr in self.bio_GBF8_constrs.values():
                self.gurobi_model.remove(constr)
        

        self.adoption_limit_constraints = []
        self.demand_penalty_constraints = []
        self.water_limit_constraints = []
        self.bio_GBF3_exprs = {}
        self.bio_GBF3_constrs = {}
        self.bio_GBF8_exprs = {}
        self.bio_GBF8_constrs = {}
        self.bio_GBF4_SNES_exprs = {}
        self.bio_GBF4_SNES_constrs = {}
        self.bio_GBF4_ECNES_exprs = {}
        self.bio_GBF4_ECNES_constrs = {}

        if self.ghg_consts_ub is not None:
            self.gurobi_model.remove(self.ghg_consts_ub)
            self.ghg_consts_ub = None

        if self.ghg_consts_lb is not None:
            self.gurobi_model.remove(self.ghg_consts_lb)
            self.ghg_consts_lb = None

        if len(self.ghg_consts_soft) > 0:
            for constr in self.ghg_consts_soft:
                self.gurobi_model.remove(constr)
            self.ghg_consts_soft = []

        if self.regional_adoption_constrs:
            self.gurobi_model.remove(self.regional_adoption_constrs)

        self.regional_adoption_constrs = []

        self._add_cell_usage_constraints(updated_cells)
        self._add_agricultural_management_constraints(updated_cells)
        self._add_agricultural_management_adoption_limit_constraints()
        self._add_demand_penalty_constraints()
        self._add_water_usage_limit_constraints()
        self._add_ghg_emissions_limit_constraints()
        self._add_biodiversity_constraints()
        self._add_regional_adoption_constraints()

    def solve(self) -> SolverSolution:
        print("Starting solve...\n")

        # Magic.
        self.gurobi_model.optimize()

        print("Completed solve, collecting results...\n", flush=True)

        prod_data = {}  # Dictionary that stores information about production and GHG emissions for the write module

        # Collect optimised decision variables in one X_mrj Numpy array.
        X_dry_sol_rj = np.zeros(
            (self._input_data.ncells, self._input_data.n_ag_lus)
        ).astype(np.float32)
        X_irr_sol_rj = np.zeros(
            (self._input_data.ncells, self._input_data.n_ag_lus)
        ).astype(np.float32)
        non_ag_X_sol_rk = np.zeros(
            (self._input_data.ncells, self._input_data.n_non_ag_lus)
        ).astype(np.float32)
        am_X_dry_sol_rj = {
            am: np.zeros((self._input_data.ncells, self._input_data.n_ag_lus)).astype(
                np.float32
            )
            for am in self._input_data.am2j
        }
        am_X_irr_sol_rj = {
            am: np.zeros((self._input_data.ncells, self._input_data.n_ag_lus)).astype(
                np.float32
            )
            for am in self._input_data.am2j
        }

        # Get agricultural results
        for j in range(self._input_data.n_ag_lus):
            for r in self._input_data.ag_lu2cells[0, j]:
                X_dry_sol_rj[r, j] = self.X_ag_dry_vars_jr[j, r].X
            for r in self._input_data.ag_lu2cells[1, j]:
                X_irr_sol_rj[r, j] = self.X_ag_irr_vars_jr[j, r].X

        # Get non-agricultural results
        for k, lu in enumerate(settings.NON_AG_LAND_USES):
            if not settings.NON_AG_LAND_USES[lu]:
                non_ag_X_sol_rk[:, k] = np.zeros(self._input_data.ncells)
                continue

            for r in self._input_data.non_ag_lu2cells[k]:
                non_ag_X_sol_rk[r, k] = self.X_non_ag_vars_kr[k, r].X

        # Get agricultural management results
        for am, am_j_list in self._input_data.am2j.items():
            for j_idx, j in enumerate(am_j_list):
                eligible_dry_cells = self._input_data.ag_lu2cells[0, j]
                eligible_irr_cells = self._input_data.ag_lu2cells[1, j]

                if am == "Savanna Burning":
                    eligible_dry_cells = np.intersect1d(
                        eligible_dry_cells, self._input_data.savanna_eligible_r
                    )
                    eligible_irr_cells = np.intersect1d(
                        eligible_irr_cells, self._input_data.savanna_eligible_r
                    )

                for r in eligible_dry_cells:
                    am_X_dry_sol_rj[am][r, j] = self.X_ag_man_dry_vars_jr[am][
                        j_idx, r
                    ].X
                for r in eligible_irr_cells:
                    am_X_irr_sol_rj[am][r, j] = self.X_ag_man_irr_vars_jr[am][
                        j_idx, r
                    ].X

        """Note that output decision variables are mostly 0 or 1 but in some cases they are somewhere in between which creates issues
            when converting to maps etc. as individual cells can have non-zero values for multiple land-uses and land management type.
            This code creates a boolean X_mrj output matrix and ensure that each cell has one and only one land-use and land management"""

        # Process agricultural land usage information
        # Stack dryland and irrigated decision variables
        ag_X_mrj = np.stack((X_dry_sol_rj, X_irr_sol_rj))  # Float32
        ag_X_mrj_processed = ag_X_mrj

        ## Note - uncomment the following block of code to revert the processed agricultural variables to be binary.

        # ag_X_mrj_shape = ag_X_mrj.shape

        # # Reshape so that cells are along the first axis and land management and use are flattened along second axis i.e. (XXXXXXX,  56)
        # ag_X_mrj_processed = np.moveaxis(ag_X_mrj, 1, 0)
        # ag_X_mrj_processed = ag_X_mrj_processed.reshape(ag_X_mrj_processed.shape[0], -1)

        # # Boolean matrix where the maximum value for each cell across all land management types and land uses is True
        # ag_X_mrj_processed = ag_X_mrj_processed.argmax(axis=1)[:, np.newaxis] == range(
        #     ag_X_mrj_processed.shape[1]
        # )

        # # Reshape to mrj structure
        # ag_X_mrj_processed = ag_X_mrj_processed.reshape(
        #     (ag_X_mrj_shape[1], ag_X_mrj_shape[0], ag_X_mrj_shape[2])
        # )
        # ag_X_mrj_processed = np.moveaxis(ag_X_mrj_processed, 0, 1)

        # Process non-agricultural land usage information
        # Boolean matrix where the maximum value for each cell across all non-ag LUs is True
        non_ag_X_rk_processed = non_ag_X_sol_rk.argmax(axis=1)[:, np.newaxis] == range(
            self._input_data.n_non_ag_lus
        )

        # Make land use and land management maps
        # Vector indexed by cell that denotes whether the cell is non-agricultural land (True) or agricultural land (False)
        non_ag_bools_r = non_ag_X_sol_rk.max(axis=1) > ag_X_mrj.max(axis=(0, 2))

        # Update processed variables accordingly
        ag_X_mrj_processed[:, non_ag_bools_r, :] = False
        non_ag_X_rk_processed[~non_ag_bools_r, :] = False

        # Process agricultural management variables
        # Repeat the steps for the regular agricultural management variables
        ag_man_X_mrj_processed = {}
        for am in self._input_data.am2j:
            ag_man_processed = np.stack((am_X_dry_sol_rj[am], am_X_irr_sol_rj[am]))

            ## Note - uncomment the following block of code to revert the processed AM variables to be binary.

            # ag_man_X_shape = ag_man_processed.shape

            # ag_man_processed = np.moveaxis(ag_man_processed, 1, 0)
            # ag_man_processed = ag_man_processed.reshape(ag_man_processed.shape[0], -1)

            # ag_man_processed = (
            #        ag_man_processed.argmax(axis = 1)[:, np.newaxis]
            #     == range(ag_man_processed.shape[1])
            # )
            # ag_man_processed = ag_man_processed.reshape(
            #     (ag_man_X_shape[1], ag_man_X_shape[0], ag_man_X_shape[2])
            # )
            # ag_man_processed = np.moveaxis(ag_man_processed, 0, 1)
            ag_man_X_mrj_processed[am] = ag_man_processed

        # Calculate 1D array (maps) of land-use and land management, considering only agricultural LUs
        lumap = ag_X_mrj_processed.sum(axis=0).argmax(axis=1).astype("int8")
        lmmap = ag_X_mrj_processed.sum(axis=2).argmax(axis=0).astype("int8")

        # Update lxmaps and processed variable matrices to consider non-agricultural LUs
        lumap[non_ag_bools_r] = (
            non_ag_X_sol_rk[non_ag_bools_r, :].argmax(axis=1)
            + settings.NON_AGRICULTURAL_LU_BASE_CODE
        )
        lmmap[non_ag_bools_r] = 0  # Assume that all non-agricultural land uses are dryland

        # Process agricultural management usage info

        # Make ammaps (agricultural management maps) using the lumap and lmmap. There is a
        # separate ammap for each agricultural management option, because they can be stacked.
        ammaps = {
            am: np.zeros(self._input_data.ncells, dtype=np.int8)
            for am in AG_MANAGEMENTS
        }
        for r in range(self._input_data.ncells):
            cell_j = lumap[r]
            cell_m = lmmap[r]

            if cell_j >= settings.NON_AGRICULTURAL_LU_BASE_CODE:
                # Non agricultural land use - no agricultural management option
                continue

            for am in self._input_data.j2am[cell_j]:
                if cell_m == 0:
                    am_var_val = am_X_dry_sol_rj[am][r, cell_j]
                else:
                    am_var_val = am_X_irr_sol_rj[am][r, cell_j]

                if am_var_val >= settings.AGRICULTURAL_MANAGEMENT_USE_THRESHOLD:
                    ammaps[am][r] = 1

        # Process production amount for each commodity
        prod_data["Production"] = (
            [
                self.total_q_exprs_c[c].getValue() * self._input_data.scale_factors['Demand']
                for c in range(self._input_data.ncms)
            ]
            if self.total_q_exprs_c 
            else 0
        ) 
        prod_data["GHG"] = (
            self.ghg_expr.getValue() * self._input_data.scale_factors['GHG']
            if self.ghg_expr
            else 0
        )
        prod_data["Water"] = (
            {
                k: v.getValue() * self._input_data.scale_factors['Water'] 
                for k,v in self.water_nyiled_exprs.items()
            }                    
            if settings.WATER_LIMITS == "on"                      
            else 0
        )
        prod_data["BIO (GBF2) value (ha)"] = (
            0                                                                               
            if settings.BIODIVERSITY_TARGET_GBF_2 == "off"         
            else self.bio_GBF2_expr.getValue() * self._input_data.scale_factors['GBF2']       
        )
        prod_data["BIO (GBF3) value (ha)"]=(
            0                                                                               
            if settings.BIODIVERSITY_TARGET_GBF_3 == "off"         
            else {
                k: v.getValue() * self._input_data.scale_factors['GBF3'] 
                for k,v in self.bio_GBF3_exprs.items()
            }
        )
        prod_data["BIO (GBF4) SNES value (ha)"] = (
            {k: v.getValue() * self._input_data.scale_factors['GBF4_SNES'] for k,v in self.bio_GBF4_SNES_exprs.items()}                   
            if settings.BIODIVERSITY_TARGET_GBF_4_SNES == "on"     
            else 0
        )
        prod_data["BIO (GBF4) ECNES value (ha)"] = (
            {k: v.getValue() * self._input_data.scale_factors['GBF4_ECNES'] for k,v in self.bio_GBF4_ECNES_exprs.items()}                  
            if settings.BIODIVERSITY_TARGET_GBF_4_ECNES == "on"    
            else 0
        )
        prod_data["BIO (GBF8) value (ha)"] = (
            {k: v.getValue() * self._input_data.scale_factors['GBF8'] for k,v in self.bio_GBF8_exprs.items()}   
            if settings.BIODIVERSITY_TARGET_GBF_8 == "on"          
            else 0
        )
                

        return SolverSolution(
            lumap=lumap,
            lmmap=lmmap,
            ammaps=ammaps,
            ag_X_mrj=ag_X_mrj_processed,
            non_ag_X_rk=non_ag_X_sol_rk,
            ag_man_X_mrj=ag_man_X_mrj_processed,
            prod_data=prod_data,
            obj_val={
                "ObjVal":(
                    None 
                    if self.gurobi_model.Status != GRB.OPTIMAL 
                    else self.gurobi_model.ObjVal
                ),
                
                "Obj Economy":                      self.obj_economy.getValue() * settings.SOLVE_WEIGHT_ALPHA,
                "Obj Biodiversity":                 self.obj_biodiv.getValue() * (1 - settings.SOLVE_WEIGHT_ALPHA),
                "Obj Penalties":                    self.obj_penalties.getValue() * settings.SOLVE_WEIGHT_BETA,
                
                'Economy (AUD) Ag':                 self.economy_ag_contr.getValue() * self._input_data.scale_factors['Economy'],
                'Economy (AUD) Non-Ag Value':       self.economy_non_ag_contr.getValue() * self._input_data.scale_factors['Economy'],
                'Economy (AUD) Ag-Man Value':       self.economy_ag_man_contr.getValue() * self._input_data.scale_factors['Economy'],                
                
                "Bio quality (score) Ag":           self.bio_ag_contr.getValue() * self._input_data.scale_factors['Biodiversity'],
                "Bio quality (score) Non-Ag":       self.bio_non_ag_contr.getValue() * self._input_data.scale_factors['Biodiversity'],
                "Bio quality (score) Ag-Man":       self.bio_ag_man_contr.getValue() * self._input_data.scale_factors['Biodiversity'],

                "Deviation Production (t)":[
                    prod_data["Production"][c] - self._input_data.limits['demand'][c]
                    for c in range(self._input_data.ncms)
                ],   
                "Deviation Water (ML)":(
                    [
                        prod_data["Water"][i] - water_limit
                        for i,water_limit in self._input_data.limits['water'].items()
                    ]                                                                        
                    if settings.WATER_LIMITS == "on"       
                    else 0
                ),         
                "Deviation GHG (tCO2e)":(
                    [ prod_data["GHG"] - self._input_data.limits['ghg'] ]                                                                        
                    if settings.GHG_CONSTRAINT_TYPE == "soft"              
                    else 0
                ),
                "Deviation BIO (GBF2) value (ha)":(
                    0                                                                             
                    if settings.BIODIVERSITY_TARGET_GBF_2 == "off"         
                    else [
                        prod_data["BIO (GBF2) value (ha)"] - self._input_data.limits['GBF2']
                    ]         
                ),
                "Deviation BIO (GBF3) value (ha)":(
                    0                                                                               
                    if settings.BIODIVERSITY_TARGET_GBF_3 == "off"         
                    else [
                        v - self._input_data.limits['GBF3'][k]
                        for k,v in prod_data["BIO (GBF3) value (ha)"].items()
                    ]
                ),
                "Deviation BIO (GBF4) SNES value (ha)":(
                    [
                        v - self._input_data.limits['GBF4_SNES'][k]
                        for k,v in prod_data["BIO (GBF4) SNES value (ha)"].items() 
                    ]                  
                    if settings.BIODIVERSITY_TARGET_GBF_4_SNES == "on"     
                    else 0
                ),
                "Deviation BIO (GBF4) ECNES value (ha)":(
                    [
                        v - self._input_data.limits['GBF4_ECNES'][k]
                        for k,v in prod_data["BIO (GBF4) ECNES value (ha)"].items()
                    ]
                    if settings.BIODIVERSITY_TARGET_GBF_4_ECNES == "on"    
                    else 0
                ),
                "Deviation BIO (GBF8) value (ha)":(
                    [
                        v - self._input_data.limits['GBF8'][k]
                        for k,v in prod_data["BIO (GBF8) value (ha)"].items()   
                    ]
                    if settings.BIODIVERSITY_TARGET_GBF_8 == "on"          
                    else 0
                ),
            }
        )
```

## luto/tests/README.md

```markdown
# Tests

Tests have been included to help ensure the robustness of functionality implemented by the Biarri team. These have been implemented using [pytest](https://docs.pytest.org/en/stable/contents.html), and they make use of [hypothesis](https://hypothesis.readthedocs.io/en/latest/) for property-based testing.

To run the tests, execute `python -m pytest` from the root directory of this repository.
```

## luto/tests/test_land_use_culling.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import math
import random
from typing import Any
from unittest.mock import patch

import hypothesis.strategies as st
import numpy as np
from hypothesis import given
import pytest

from luto.economics import land_use_culling

MAX_M = 2
MAX_R = 400
MAX_J = 28


def _generate_mock_mrj_matrix(
    values: list[Any], m: int = 0, r: int = 0, max_m: int = MAX_M, max_r: int = MAX_R
) -> np.ndarray:
    """
    Generates a matrix with shape (max_m, max_r, len(values)), and unpacks the
    `values` into the matrix at coordinates [m, r, :].

    Acts as a mock of an `mrj` matrix.
    """
    matrix = np.zeros((max_m, max_r, len(values))).astype(np.float32)
    matrix[m, r, :] = np.array(values)
    return matrix


@given(
    st.lists(st.floats(-150, 150), min_size=MAX_J, max_size=MAX_J),
    st.integers(min_value=3, max_value=16),
    st.floats(min_value=0.0, max_value=1.0),
)
def test_percentage_cost_mask(
    land_use_costs: list[float],
    num_valid: int,
    land_use_cull_percentage: float,
):
    """
    Ensure that getting the percentage cost mask works as expected

    land_use_costs: randomly generated cost metric for land usage options
    num_valid: the number of land usage options that are considered 'valid' to start with
        - used to construct a dummy x_mrj_mask
    land_use_cull_percentage: the percentage of land usage options to cull
    """
    m = random.randint(0, MAX_M - 1)
    r = random.randint(0, MAX_R - 1)

    # generate cost metric matrix
    costs_mrj = _generate_mock_mrj_matrix(land_use_costs, m=m, r=r)

    # generate random x_mrj_mask based on num_valid
    is_valid_land_use = [True for _ in range(num_valid)] + [
        False for _ in range(len(land_use_costs) - num_valid)
    ]
    random.shuffle(is_valid_land_use)
    x_mrj_mask = _generate_mock_mrj_matrix(is_valid_land_use, m=m, r=r).astype(bool)

    # determine which costs should be excluded
    num_costs_to_exclude = math.ceil(land_use_cull_percentage * num_valid)
    costs_to_consider = [
        cost for i, cost in enumerate(land_use_costs) if is_valid_land_use[i]
    ]
    costs_to_exclude = sorted(costs_to_consider, reverse=True)[0:num_costs_to_exclude]

    # get and validate the cost mask with the given percentage settings
    with patch(
        "luto.economics.land_use_culling.LAND_USAGE_CULL_PERCENTAGE",
        land_use_cull_percentage,
    ):
        cost_mask = land_use_culling.get_percentage_cost_mask(
            m, r, x_mrj_mask, costs_mrj
        )

    for i, cost_value in enumerate(land_use_costs):
        is_culled = not cost_mask[i]
        if is_culled:
            assert (cost_value in costs_to_exclude) or not is_valid_land_use[i]


@given(
    st.lists(st.floats(-150, 150), min_size=MAX_J, max_size=MAX_J),
    st.integers(min_value=3, max_value=16),
    st.integers(min_value=3, max_value=16),
)
def test_absolute_cost_mask(
    land_use_costs: list[float],
    num_valid: int,
    max_land_uses: int,
):
    """
    Ensure that getting the absolute cost mask modifies the x_mrj matrix as expected

    land_use_costs: randomly generated cost metric for land usage options
    num_valid: the number of land usage options that are considered 'valid' to start with
        - used to construct a dummy x_mrj_mask
    max_land_uses: the maximum number of land use options that should not be culled
    """
    m = random.randint(0, MAX_M - 1)
    r = random.randint(0, MAX_R - 1)

    # generate cost metric matrix
    costs_mrj = _generate_mock_mrj_matrix(land_use_costs, m=m, r=r)

    # generate random x_mrj_mask based on num_valid
    is_valid_land_use = [True for _ in range(num_valid)] + [
        False for _ in range(len(land_use_costs) - num_valid)
    ]
    random.shuffle(is_valid_land_use)
    x_mrj_mask = _generate_mock_mrj_matrix(is_valid_land_use, m=m, r=r).astype(bool)

    # determine which costs should be excluded
    num_costs_to_exclude = max(num_valid - max_land_uses, 0)
    costs_to_consider = [
        cost for i, cost in enumerate(land_use_costs) if is_valid_land_use[i]
    ]
    costs_to_exclude = sorted(costs_to_consider, reverse=True)[0:num_costs_to_exclude]

    # get and validate the cost mask with the given percentage settings
    with patch(
        "luto.economics.land_use_culling.MAX_LAND_USES_PER_CELL",
        max_land_uses,
    ):
        cost_mask = land_use_culling.get_absolute_cost_mask(m, r, x_mrj_mask, costs_mrj)

    if max_land_uses > num_valid:
        assert cost_mask is None
        return

    for i, cost_value in enumerate(land_use_costs):
        is_culled = not cost_mask[i]
        if is_culled:
            assert (cost_value in costs_to_exclude) or not is_valid_land_use[i]


@pytest.mark.parametrize(
    ("cull_mode", "cull_param", "cull_param_value"),
    [
        ("none", None, None),
        ("percentage", "LAND_USAGE_CULL_PERCENTAGE", 0.3),
        ("absolute", "MAX_LAND_USES_PER_CELL", 8),
    ],
)
def test_apply_agricultural_land_use_culling(
    cull_mode: str,
    cull_param: str,
    cull_param_value: Any,
):
    """
    Basic smoke test for the 'apply_agricultural_land_use_culling' function.

    If cull_mode is 'none', ensure the x_mrj matrix is not modified.
    Otherwise, ensure that the number of x_mrj values that are 1 is reduced.
    """
    m = random.randint(0, MAX_M - 1)
    r = random.randint(0, MAX_R - 1)

    x_mrj = _generate_mock_mrj_matrix([1 for _ in range(MAX_J)], m=m, r=r).astype(int)
    old_x_mrj = x_mrj.copy()

    cost_values = [random.random() for _ in range(MAX_J)]
    c_mrj = t_mrj = r_mrj = _generate_mock_mrj_matrix(cost_values, m=m, r=r)

    with (
        patch("luto.economics.land_use_culling.CULL_MODE", cull_mode),
        patch(f"luto.economics.land_use_culling.{cull_param}", cull_param_value),
    ):
        land_use_culling.apply_agricultural_land_use_culling(x_mrj, c_mrj, t_mrj, r_mrj)

    if cull_mode == "none":
        assert sum(x_mrj[m, r, :]) == MAX_J
        assert (x_mrj == old_x_mrj).all()
    else:
        assert sum(x_mrj[m, r, :]) < MAX_J
        assert (x_mrj != old_x_mrj).any()
```

## luto/tools/create_task_runs/bash_scripts/conda_env.yml

```yaml
name: luto
channels:
  - conda-forge
  - defaults
dependencies:
  - python=3.12
  - numpy==1.26.4
  - pandas==2.2.2
  - rasterio==1.3.9
  - scipy==1.13.0
  - matplotlib==3.8.4
  - h5py==3.11.0
  - openpyxl==3.1.2
  - pytest==8.2.1
  - pytables==3.9.2
  - hypothesis==6.102.4
  - lxml==5.2.2
  - folium==0.16.0
  - contextily==1.6.0
  - imageio==2.34.1
  - geopandas==0.14.4
  - ipython==8.24.0
  - rioxarray==0.15.5
  - xarray==2024.5.0
  - dask==2024.5.1
  - h5netcdf==1.3.0
  - ipykernel==6.29.4
  - sparse==0.15.4
  - nbformat==5.10.4
  - dill==0.3.8
  - netcdf4=1.7.2
  - pip
  - pip:
      - gurobipy==11.0.2
      - numpy_financial==1.0.0
      - tables==3.9.2
```

## luto/tools/create_task_runs/bash_scripts/conver_raw_data.sh

```bash
# Run the simulation
python <<-INNER_EOF
# Activate the Conda environment
source ~/miniforge3/etc/profile.d/conda.sh
conda activate luto
from luto.dataprep import create_new_dataset
create_new_dataset()
INNER_EOF
```

## luto/tools/create_task_runs/bash_scripts/create_env.sh

```bash
#!/bin/bash

# Add the Conda binaries to the PATH
export PATH="$HOME/miniforge3/bin:$PATH"


# Install mini-forge
if [[ ! -d $HOME/miniforge3 ]]
then
    curl -L -O "https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh"
    bash Miniforge3-$(uname)-$(uname -m).sh -b -p $HOME/miniforge3
    rm Miniforge3-$(uname)-$(uname -m).sh
fi

# Initialize mamba or conda
mamba init
```

## luto/tools/create_task_runs/bash_scripts/install_pkg.sh

```bash
#!/bin/bash

# Add the Conda binaries to the PATH
source ~/.bashrc

# Create a new Conda environment, and install the required packages
mamba env create -f conda_env.yml
```

## luto/tools/create_task_runs/bash_scripts/python_script.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import os
import shutil
import zipfile
import luto.simulation as sim
import luto.settings as settings



# Run the simulation
data = sim.load_data()
sim.run(data=data)


# Set up report directory and archive path
report_dir = f"{data.path}"
archive_path ='./Run_Archive.zip'


# Zip the output directory, and remove the original directory
with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
    for root, dirs, files in os.walk(report_dir):
        for file in files:
            abs_path = os.path.join(root, file)
            rel_path = os.path.relpath(abs_path, start=report_dir)
            zipf.write(abs_path, arcname=rel_path)


# Remove all files after archiving
for item in os.listdir('.'):
    if item != 'Run_Archive.zip':
        try:
            if os.path.isfile(item) or os.path.islink(item):
                os.unlink(item)  
            elif os.path.isdir(item):
                shutil.rmtree(item) 
        except Exception as e:
            print(f"Failed to delete {item}. Reason: {e}")
```

## luto/tools/create_task_runs/bash_scripts/task_cmd.sh

```bash
#!/bin/bash

# Read the settings_bash file ==> JOB_NAME, QUEUE, NCPUS, MEM, TIME
source luto/settings_bash.py

# Activate the Conda environment and get the path to the Python executable
source ~/.bashrc
conda activate luto
PYTHON=$(which python)

# Create a temporary script file
SCRIPT_PBS=$(mktemp)

cat << EOF > $SCRIPT_PBS
#!/bin/bash
#PBS -N ${JOB_NAME}
#PBS -q ${QUEUE}
#PBS -l storage=scratch/${PROJECT}+gdata/${PROJECT}
#PBS -l ncpus=${NCPUS}
#PBS -l mem=${MEM}
#PBS -l jobfs=10GB
#PBS -l walltime=${TIME}
#PBS -l wd="$(dirname "$0")"

${PYTHON} python_script.py
EOF

# Submit the job to PBS
qsub ${SCRIPT_PBS}

# Remove the temporary script file
rm $SCRIPT_PBS
```

## luto/tools/create_task_runs/create_grid_search_tasks.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.


import numpy as np
from luto.tools.create_task_runs.helpers import (
    get_settings_df,
    get_grid_search_param_df,
    get_grid_search_settings_df, 
    create_task_runs,
)

# Define the root dir for the task runs
TASK_ROOT_DIR = '../Custom_runs/20250902_RES3_NON_AG_2_5_10_15_20_25_30' # Do not include the trailing slash (/) in the end of the path


# Set the grid search parameters
grid_search = {
    ###############################################################
    # Task run settings for submitting the job to the cluster
    ###############################################################
    'MEM': ['96GB'],
    'NCPUS':[24],
    'TIME': ['12:00:00'],
    'QUEUE': ['normalsr'],                                                  # normalsr for CPU, hugemembw for memory intensive jobs
    
 
    ###############################################################
    # Working settings for the model run
    ###############################################################
    'OBJECTIVE': ['maxprofit'],                                             # 'maxprofit' or 'mincost'
    'RESFACTOR': [3],
    'SIM_YEARS': [range(2020, 2051, 5)],                                    # Years to run the model 
    'WRITE_THREADS': [2],
    
 
    ###############################################################
    # Model run settings
    ###############################################################
    
    
    # --------------- Scenarios ---------------
    'SSP': ['245'],                                                         #'126', '245', '370', '585'
    

    # --------------- Target deviation weight ---------------
    'SOLVER_WEIGHT_DEMAND': [1], 
    'SOLVER_WEIGHT_GHG': [1],
    'SOLVER_WEIGHT_WATER': [1],
    'SOLVER_WEIGHT_GBF2': [1],


    # --------------- Social license ---------------
    'EXCLUDE_NO_GO_LU': [False],                                            # True or False
    'REGIONAL_ADOPTION_CONSTRAINTS': ['off', 'NON_AG_UNIFORM'],             # 'off', 'on', 'NON_AG_UNIFORM'    
    'REGIONAL_ADOPTION_NON_AG_UNIFORM': [2, 5, 10, 15, 20, 25, 30],         # Only work under 'NON_AG_UNIFORM'; None or numbers between 0-100 (both inclusive);  E.g., 5 means each non-ag land can not exceed 5% adoption in every region
    'REGIONAL_ADOPTION_ZONE': ['NRM_CODE', 'NRM_CODE'],                     # One of 'ABARES_AAGIS', 'LGA_CODE', 'NRM_CODE', 'IBRA_ID', 'SLA_5DIGIT'


    # --------------- GHG settings ---------------
    'GHG_EMISSIONS_LIMITS': ['low', 'high'],                                # 'off', 'low', 'medium', 'high'
    'CARBON_PRICES_FIELD': ['CONSTANT'],
    'GHG_CONSTRAINT_TYPE': ['hard'],                                        # 'hard' or 'soft'
    'USE_GHG_SCOPE_1': [True],                                              # True or False

    
    # --------------- Water constraints ---------------
    'WATER_REGION_DEF':['Drainage Division'],                               # 'River Region' or 'Drainage Division' Bureau of Meteorology GeoFabric definition
    'WATER_LIMITS': ['on'],                                                 # 'on' or 'off'
    'WATER_CONSTRAINT_TYPE': ['hard'],                                      # 'hard' or 'soft'
    'WATER_PENALTY': [1e-5],
    'INCLUDE_WATER_LICENSE_COSTS': [1],
    
    # --------------- Biodiversity overall ---------------
    'HABITAT_CONDITION': ['USER_DEFINED'],                                  # One of [10, 25, 50, 75, 90], or 'USER_DEFINED'              
    'CONNECTIVITY_SOURCE': ['NCI'],
    'GBF2_PRIORITY_DEGRADED_AREAS_PERCENTAGE_CUT': [20, 40],                # Percentage of degraded areas to cut in GBF2 priority areas
    
    # --------------- Biodiversity settings - GBF 2 ---------------
    'BIODIVERSITY_TARGET_GBF_2': ['high'],                                  # 'off', 'low', 'medium', 'high'
    'GBF2_CONSTRAINT_TYPE': ['hard'],                                       # 'hard' or 'soft'

    # --------------- Biodiversity settings - GBF 3 ---------------
    'BIODIVERSITY_TARGET_GBF_3': ['off'],                                   # 'off', 'medium', 'high', 'USER_DEFINED'
    
    # --------------- Biodiversity settings - GBF 4 ---------------
    'BIODIVERSITY_TARGET_GBF_4_SNES': ['off'],                              # 'on' or 'off'.
    'BIODIVERSITY_TARGET_GBF_4_ECNES': ['off'],                             # 'on' or 'off'.

    # --------------- Biodiversity settings - GBF 8 ---------------
    'BIODIVERSITY_TARGET_GBF_8': ['off'],                                   # 'on' or 'off'

    ###############################################################
    # Scenario settings for the model run
    ###############################################################
    'SOLVE_WEIGHT_ALPHA': [1],                                              # between 0 and 1, if 1 will turn off biodiversity objective, if 0 will turn off profit objective
    'SOLVE_WEIGHT_BETA':  [0.5],         
    
    
    #-------------------- Diet BAU --------------------
    'DIET_DOM': ['BAU',],                                                   # 'BAU' or 'FLX'
    'DIET_GLOB': ['BAU',],                                                  # 'BAU' or 'FLX'
    'WASTE': [1],                                                           # 1 or 0.5
    'FEED_EFFICIENCY': ['BAU'],                                             # 'BAU' or 'High'
    #---------------------Diet FLX --------------------
    # 'DIET_DOM': ['FLX',],                                                 # 'BAU' or 'FLX'
    # 'DIET_GLOB': ['FLX',],                                                # 'BAU' or 'FLX'
    # 'WASTE': [0.5],                                                       # 1 or 0.5
    # 'FEED_EFFICIENCY': ['High'],                                          # 'BAU' or 'High'
}


duplicate_runs = {
    'REGIONAL_ADOPTION_CONSTRAINTS': ('off', 'REGIONAL_ADOPTION_NON_AG_UNIFORM'),
    'BIODIVERSITY_TARGET_GBF_2': ('off', 'GBF2_PRIORITY_DEGRADED_AREAS_PERCENTAGE_CUT'),
}




if __name__ == '__main__':
    
    # Create the grid settings parameters
    default_settings_df = get_settings_df(TASK_ROOT_DIR)
    grid_search_param_df = get_grid_search_param_df(grid_search)
    grid_search_settings_df = get_grid_search_settings_df(TASK_ROOT_DIR, default_settings_df, grid_search_param_df)
    
    # Remove unnecessary runs
    rm_idx = []
    for idx, row in grid_search_param_df.iterrows():
        for k, v in duplicate_runs.items():
            if (row[k] == v[0]) and (str(row[v[1]]) != str(grid_search[v[1]][0])):
                rm_idx.append(row['run_idx'])
                
    grid_search_param_df = grid_search_param_df[~grid_search_param_df['run_idx'].isin(rm_idx)]
    grid_search_param_df.to_csv(f'{TASK_ROOT_DIR}/grid_search_parameters.csv', index=False)
    print(f'Removed {len(set(rm_idx))} unnecessary runs!')
    
    # Get full settings df
    grid_search_settings_df = get_grid_search_settings_df(TASK_ROOT_DIR, default_settings_df, grid_search_param_df)

    # 1) Submit task to a single linux machine, and run simulations parallely
    # create_task_runs(TASK_ROOT_DIR, grid_search_settings_df, mode='single', n_workers=min(len(grid_search_param_df), 100))

    # 2) Submit task to multiple linux computation nodes
    create_task_runs(TASK_ROOT_DIR, grid_search_settings_df, mode='cluster', max_concurrent_tasks = 200)
```

## luto/tools/create_task_runs/helpers.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import os, re, json
import shutil, itertools, subprocess, zipfile
import pandas as pd

from tqdm.auto import tqdm
from typing import Literal
from joblib import delayed, Parallel

from luto import settings
from luto.tools.create_task_runs.parameters import EXCLUDE_DIRS, SERVER_PARAMS


def get_settings_df(task_root_dir:str) -> pd.DataFrame:
    '''
    Save the default settings file to a datafram.
    '''

    # Save the settings template to the root task folder
    if not os.path.exists(task_root_dir):
        os.makedirs(task_root_dir, exist_ok=True)
    
    # Get the settings from luto.settings
    with open('luto/settings.py', 'r') as file, \
         open(f'{task_root_dir}/non_str_val.txt', 'w') as non_str_val_file:
        
        # Regex patterns that matches variable assignments from settings
        lines = file.readlines()
        parameter_reg = re.compile(r"^(\s*[A-Z].*?)\s*=") # Keys are uppercase and start with a letter
        settings_keys = [match[1].strip() for line in lines if (match := parameter_reg.match(line))]

        # Reorder the settings dictionary to match the order in the settings.py file
        settings_dict = {i: getattr(settings, i) for i in dir(settings) if i.isupper()}
        settings_dict = {key: settings_dict[key] for key in settings_keys if key in settings_dict}

        # Write the non-string values to a file; this helps to evaluate the settings later
        for k, v in settings_dict.items():
            if not isinstance(v, str):
                non_str_val_file.write(f'{k}\n')

    # Create a template for custom settings
    settings_df = pd.DataFrame({k:[v] for k,v in settings_dict.items()}).T.reset_index()
    settings_df.columns = ['Name','Default_run']
    settings_df = settings_df.map(str)    
         
    return settings_df



def get_grid_search_param_df(grid_dict:dict) -> None:
    '''
    Permutate the grid search parameters and save them to a datafram.
    '''
    # Create a list of dictionaries with all possible permutations
    grid_dict = {k: [str(i) for i in v] for k, v in grid_dict.items()}
    keys, values = zip(*grid_dict.items())
    permutations = [dict(zip(keys, v)) for v in itertools.product(*values)]

    # Save the grid search parameters to the root task folder
    permutations_df = pd.DataFrame(permutations)
    permutations_df.insert(0, 'run_idx', [i for i in range(1, len(permutations_df) + 1)])

    # Report the grid search parameters
    print(f'Grid search template has been created with {len(permutations_df)} permutations!')
    for k, v in grid_dict.items():
        if len(v) > 1:
            print(f'    {k:<50} : {len(v)} values')
    
    return permutations_df
    

def update_settings(settings_dict:dict, job_name:str):
    '''
    Update the task run settings with parameters for the server, and change the data path to absolute path.
    E.g. job name, input directory, raw data directory, and threads.
    '''
    settings_dict['JOB_NAME'] = job_name
    settings_dict['INPUT_DIR'] = os.path.abspath(settings_dict['INPUT_DIR']).replace('\\','/')
    settings_dict['RAW_DATA'] = os.path.abspath(settings_dict['RAW_DATA']).replace('\\','/')
    settings_dict['THREADS'] = settings_dict['NCPUS']

    return settings_dict


def get_grid_search_settings_df(task_root_dir:str, settings_df:pd.DataFrame, grid_search_param_df:pd.DataFrame) -> pd.DataFrame:
    '''
    Loop through the grid search parameters and create a settings template for each run.
    '''
    
    template_grid_search = settings_df.copy()
    task_dir = os.path.basename(os.path.normpath(task_root_dir))

    # Loop through the permutations DataFrame and create new columns with updated settings
    run_settings_dfs = []
    for _, row in grid_search_param_df.iterrows():
        settings_dict = template_grid_search.set_index('Name')['Default_run'].to_dict()
        settings_dict.update(row.to_dict())
        settings_dict = update_settings(settings_dict, f'{task_dir}_Run_{row['run_idx']:04}')
        run_settings_dfs.append(pd.Series(settings_dict, name=f'Run_{row['run_idx']:04}'))
    
    template_grid_search = pd.concat(run_settings_dfs, axis=1).reset_index(names='Name')
    template_grid_search.to_csv(f'{task_root_dir}/grid_search_template.csv', index=False)
    
    grid_search_param_df = grid_search_param_df.loc[:, grid_search_param_df.nunique() > 1]
    grid_search_param_df.to_csv(f'{task_root_dir}/grid_search_parameters_unique.csv', index=False)

    return template_grid_search



def copy_folder_custom(source, destination, ignore_dirs=None):
    ignore_dirs = set() if ignore_dirs is None else set(ignore_dirs)
    os.makedirs(destination, exist_ok=True)
    jobs = []
    for item in os.listdir(source):
        if item in ignore_dirs: continue   
        s = os.path.join(source, item)
        d = os.path.join(destination, item)
        jobs += copy_folder_custom(s, d) if os.path.isdir(s) else [(s, d)]
    return jobs   

def create_run_folders(task_root_dir:str, col:str, n_workers:int):
    src_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../'))
    dst_dir = f'{task_root_dir}/{col}'
    # Copy the files from the source to the destination
    from_to_files = copy_folder_custom(src_dir, dst_dir, EXCLUDE_DIRS)
    Parallel(n_jobs=n_workers)(delayed(shutil.copy2)(s, d) for s, d in from_to_files)
    # Create an output folder for the task
    os.makedirs(f'{dst_dir}/output', exist_ok=True)
    
    
def submit_task(task_root_dir:str, col:str, mode:Literal['single','cluster'], max_concurrent_tasks): 
    shutil.copyfile('luto/tools/create_task_runs/bash_scripts/task_cmd.sh', f'{task_root_dir}/{col}/task_cmd.sh')
    shutil.copyfile('luto/tools/create_task_runs/bash_scripts/python_script.py', f'{task_root_dir}/{col}/python_script.py')
    
    # Wait until the number of running jobs is less than max_concurrent_tasks
    if os.name == 'posix':
        while True:
            try:
                running_jobs = int(subprocess.run('qselect | wc -l', shell=True, capture_output=True, text=True).stdout.strip())
            except Exception as e:
                print(f"Error checking running jobs: {e}")
            if running_jobs < max_concurrent_tasks:
                break
            else:
                print(f"Max concurrent tasks reached ({running_jobs}/{max_concurrent_tasks}), waiting to submit {col}...")
                import time; time.sleep(10)
        
    # Open log files for the task run
    with open(f'{task_root_dir}/{col}/run_std.log', 'w') as std_file, \
         open(f'{task_root_dir}/{col}/run_err.log', 'w') as err_file:
        if mode == 'single': 
            subprocess.run(['python', 'python_script.py'], cwd=f'{task_root_dir}/{col}', stdout=std_file, stderr=err_file, check=True)
        elif mode == 'cluster' and os.name == 'posix':
            subprocess.run(['bash', 'task_cmd.sh'], cwd=f'{task_root_dir}/{col}', stdout=std_file, stderr=err_file, check=True)
        else:
            raise ValueError('Mode must be either "single" or "cluster"!')

    
def write_settings(task_dir:str, settings_dict:dict):
    with open(f'{task_dir}/luto/settings.py', 'w') as file:
        for k, v in settings_dict.items():
            if isinstance(v, str):
                file.write(f'{k}="{v}"\n')
            else:
                file.write(f'{k}={v}\n')
        
                
def write_terminal_vars(task_dir:str, col:str, settings_dict:dict):
    with open(f'{task_dir}/luto/settings_bash.py', 'w') as bash_file:
        for key, value in settings_dict.items():
            if key not in SERVER_PARAMS:
                continue
            if isinstance(value, str):
                bash_file.write(f'export {key}="{value}"\n')
            else:
                bash_file.write(f'export {key}={value}\n')
        


def create_task_runs(
    task_root_dir:str, 
    custom_settings:pd.DataFrame, 
    mode:Literal['single','cluster']='single', 
    n_workers:int=4,
    max_concurrent_tasks:int=300,
) -> None:
    '''
    Submit the tasks to the cluster using the custom settings.\n
    Parameters
     custom_settings (pd.DataFrame):The custom settings DataFrame.
     python_path (str, only works if mode == "single"): The path to the python executable.
     mode (str): The mode to submit the tasks. Options are "single" or "cluster".
     n_workers (int): The number of workers to use for parallel processing. 
    '''
    
    if mode not in ['single', 'cluster']:
        raise ValueError('Mode must be either "single" or "cluster"!')
   
    # Read the custom settings file
    custom_settings = custom_settings.dropna(how='all', axis=1)
    custom_settings = custom_settings.set_index('Name')
    # Replace TRUE/FALSE (Excel) with True/False (Python)
    custom_settings = custom_settings.replace({'TRUE': 'True', 'FALSE': 'False'})
    # Check if there are any custom settings
    if custom_settings.columns.size == 0:
        raise ValueError('No custom settings found in the settings_template.csv file!')
    # Evaluate settings that are not originally strings
    with open(f'{task_root_dir}/non_str_val.txt', 'r') as file:
        eval_vars = file.read().splitlines()
        custom_settings.loc[eval_vars] = custom_settings.loc[eval_vars].map(str).map(eval)
        
    def task_wraper(col):
        settings_dict = custom_settings.loc[:, col].copy()
        create_run_folders(task_root_dir, col, n_workers)
        write_settings(f'{task_root_dir}/{col}', settings_dict)
        write_terminal_vars(f'{task_root_dir}/{col}', col, settings_dict)
        submit_task(task_root_dir, col, mode, max_concurrent_tasks)
    
    # Run the tasks in parallel
    tasks = [delayed(task_wraper)(col) for col in custom_settings.columns]
    for result in tqdm(Parallel(n_jobs=n_workers, return_as='generator')(tasks), total=len(tasks)):
        pass



def return_zipped_df(json_dir_path, filename):
    with zipfile.ZipFile(os.path.join(json_dir_path), 'r') as zip_ref:
        with zip_ref.open(f'data/{filename}') as f:
            return pd.concat([
                pd.json_normalize(record, 'data', ['name'])\
                    .rename(columns={0: 'year', 1: 'val'})\
                    .assign(region=region)
                for region,record in json.load(f).items()
            ])

def return_plain_df(json_dir_path, filename):
    with open(os.path.join(json_dir_path, filename), 'r') as f:
        return pd.concat([
            pd.json_normalize(record, 'data', ['name'])\
                .rename(columns={0: 'year', 1: 'val'})\
                .assign(region=region)
            for region,record in json.load(f).items()
        ])



def load_json_data(json_dir_path, filename):
    if json_dir_path.endswith('.zip'):
        return return_zipped_df(json_dir_path, filename)
    else:
        return return_plain_df(json_dir_path, filename)



def process_area_category(json_dir_path):
    return load_json_data(json_dir_path, 'Area_overview_2_Category.json')

def process_area_non_ag_lu(json_dir_path):
    return load_json_data(json_dir_path, 'Area_NonAg_1_Land-use.json')

def process_area_ag_man(json_dir_path):
    return load_json_data(json_dir_path, 'Area_Am_1_Type.json')

def process_economic_data(json_dir_path):
    return load_json_data(json_dir_path, 'Economics_overview.json')


def process_transition_cost_data(json_dir_path):
    if json_dir_path.endswith('.zip'):
        with zipfile.ZipFile(os.path.join(json_dir_path), 'r') as zip_ref:
            with zip_ref.open(f'data/economics_8_transition_ag2ag_cost_4_transition_matrix.json') as f:
                transition_data = json.load(f)
    else:
        with open(os.path.join(json_dir_path, 'economics_8_transition_ag2ag_cost_4_transition_matrix.json'), 'r') as f:
            transition_data = json.load(f)
            
    categories = dict(enumerate(transition_data["categories"]))

    # Extract matrix to DataFrame
    data_df = pd.DataFrame()
    for data in transition_data["series"]:
        df_yr = pd.DataFrame(data["data"], columns=['from', 'to', 'val'])
        df_yr['val'] = df_yr['val'].astype(float)   # Ensure 'val' is float
        df_yr[['from', 'to']] = df_yr[['from', 'to']].map(lambda x: categories.get(x, x))
        df_yr['year'] = data['Year']
        df_yr = df_yr.fillna(0.0)                   # Fill NaN values with 0 and infer types
        data_df = pd.concat([data_df, df_yr], ignore_index=True)
            
    # Combine 'from' and 'to' columns into a single 'name' column
    data_df['name'] = data_df.apply(lambda x: [x['from'], x['to']], axis=1)  
    return data_df


def process_production_quantity_data(json_dir_path):
    return load_json_data(json_dir_path, 'Production_sum_1_Commodity.json')

def process_production_deviation_data(json_dir_path):
    df = load_json_data(json_dir_path, 'Production_achive_percent.json')
    df['val'] = df['val'] - 100 # Achiment percent to deviation percent
    return df

def process_GHG_data(json_dir_path):
    return load_json_data(json_dir_path, 'GHG_overview.json')

def process_GHG_deviation_data(json_dir_path):
    df = load_json_data(json_dir_path, 'GHG_overview.json').query('region == "AUSTRALIA"')
    df_target = df.query('name == "GHG emission limit"')
    df_actual = df.query('name == "Net emissions"')
    df_deviation = df_target.merge(df_actual, on=['year','region'], suffixes=('_target', '_actual'))
    df_deviation['name'] = 'GHG deviation'
    df_deviation['val'] = df_deviation['val_actual'] - df_deviation['val_target']
    return df_deviation

def process_bio_obj_data(json_dir_path):
    return load_json_data(json_dir_path, 'BIO_GBF2_overview_1_Type.json')



def get_report_df(json_dir_path, run_paras):
    
    df_area_all_lu = process_area_category(json_dir_path)
    df_area_non_ag_lu = process_area_non_ag_lu(json_dir_path)
    df_area_ag_man = process_area_ag_man(json_dir_path)
    df_economy = process_economic_data(json_dir_path)
    # df_transition_cost = process_transition_cost_data(json_dir_path)
    df_ghg = process_GHG_data(json_dir_path)
    df_ghg_deviation = process_GHG_deviation_data(json_dir_path)
    df_demand_deviation = process_production_deviation_data(json_dir_path)
    df_bio_objective = process_bio_obj_data(json_dir_path)

    report_df = pd.concat([
        df_area_all_lu[['year', 'name', 'region', 'val']].assign(Type='Area_broad_category_ha'),
        df_area_non_ag_lu[['year', 'name', 'region', 'val']].assign(Type='Area_non_ag_lu_ha'),
        df_area_ag_man[['year', 'name', 'region', 'val']].assign(Type='Area_ag_man_ha'),
        df_economy[['year', 'name', 'region', 'val']].assign(Type='Economic_AUD'),
        # df_transition_cost[['year', 'name', 'region', 'val']].assign(Type='Transition_cost_AUD'),
        df_demand_deviation[['year', 'name', 'region', 'val']].assign(Type='Production_deviation_pct'),
        df_ghg[['year', 'name', 'region', 'val']].assign(Type='GHG_emissions_tCO2e'),
        df_ghg_deviation[['year', 'name', 'region', 'val']].assign(Type='GHG_Deviation_pct'),
        df_bio_objective[['year', 'name', 'region', 'val']].assign(Type='Biodiversity_obj_score'),
    ]).assign(**run_paras).reset_index(drop=True)

    return report_df



def process_task_root_dirs(task_root_dir, n_workers=10):
    
    grid_search_params = pd.read_csv(f"{task_root_dir}/grid_search_parameters_unique.csv")
    run_dirs = [i for i in os.listdir(task_root_dir) if os.path.isdir(os.path.join(task_root_dir, i))]
    run_dirs = sorted([i for i in run_dirs if 'Run_' in i])
    
    tasks = []
    for run_dir in run_dirs:
        run_idx = int(run_dir.split('_')[-1])
        run_paras = grid_search_params.query(f'run_idx == {int(run_idx)}').to_dict(orient='records')[0]

        # Depending on output structure, the report can be found in different places
        output_dir = os.path.join(task_root_dir, run_dir, 'output')
        json_dir_path = os.path.join(task_root_dir, run_dir, 'DATA_REPORT.zip')

        if os.path.exists(output_dir):
            out_dirs = [d for d in os.listdir(output_dir) if os.path.isdir(os.path.join(output_dir, d))]
            if not out_dirs:
                print(f'{run_dir}: No output directories found in Run_{run_idx}!')
                continue
            else:
                last_dir = sorted([d for d in os.listdir(output_dir) if os.path.isdir(os.path.join(output_dir, d))])[-1]
                json_dir_path = os.path.join(output_dir, last_dir, 'DATA_REPORT', 'data')

        if not os.path.exists(json_dir_path):
            print(f'{run_dir}: DATA_REPORT not found in Run_{run_idx}!')
            continue
        
        # Json to df
        tasks.append(delayed(get_report_df)(json_dir_path, run_paras))
        
        
    # Concatenate the results, only keep the columns with more than 1 unique value
    out_df = pd.concat(
        tqdm(Parallel(n_jobs=n_workers, return_as='generator')(tasks), total=len(tasks)), 
        ignore_index=True
    )
    
    return out_df
```

## luto/tools/create_task_runs/parameters.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.


EXCLUDE_DIRS = [
    'input', 
    'output', 
    '.git', 
    '.vscode', 
    '__pycache__', 
    'jinzhu_inspect_code',
    'docs',
]

SERVER_PARAMS = ['MEM', 'NCPUS', 'TIME', 'QUEUE', 'JOB_NAME']
```

## luto/tools/Manual_jupyter_books/Add_tags_to_jb.ipynb

```text
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('N:/LUF-Modelling/LUTO2_JZ/luto-2.0')\n",
    "from luto.tools.Manual_jupyter_books.helpers import add_meta_to_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_paths = glob('luto/tools/Manual_jupyter_books/*.ipynb')\n",
    "for nb_path in nb_paths:\n",
    "    add_meta_to_nb(nb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
```

## luto/tools/Manual_jupyter_books/asset/sa2_2011_aus/SA2_2011_AUST_continental_simplified.cpg

```text
UTF-8
```

## luto/tools/Manual_jupyter_books/asset/sa2_2011_aus/SA2_2011_AUST_continental_simplified.prj

```text
GEOGCS["GCS_GDA_1994",DATUM["D_GDA_1994",SPHEROID["GRS_1980",6378137.0,298.257222101]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]
```

## luto/tools/Manual_jupyter_books/asset/sa2_2011_aus/SA2_2011_AUST_continental_simplified.shp.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<metadata xml:lang="en"><Esri><CreaDate>20240820</CreaDate><CreaTime>13260000</CreaTime><ArcGISFormat>1.0</ArcGISFormat><SyncOnce>FALSE</SyncOnce><DataProperties><itemProps><itemName Sync="TRUE">SA2_2011_AUST_continental_Si</itemName><imsContentType Sync="TRUE">002</imsContentType><itemLocation><linkage Sync="TRUE">file://\\JINZHU\C$\Users\Jinzhu\Documents\ArcGIS\Default.gdb</linkage><protocol Sync="TRUE">Local Area Network</protocol></itemLocation></itemProps><coordRef><type Sync="TRUE">Geographic</type><geogcsn Sync="TRUE">GCS_GDA_1994</geogcsn><csUnits Sync="TRUE">Angular Unit: Degree (0.017453)</csUnits><peXml Sync="TRUE">&lt;GeographicCoordinateSystem xsi:type='typens:GeographicCoordinateSystem' xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance' xmlns:xs='http://www.w3.org/2001/XMLSchema' xmlns:typens='http://www.esri.com/schemas/ArcGIS/10.4'&gt;&lt;WKT&gt;GEOGCS[&amp;quot;GCS_GDA_1994&amp;quot;,DATUM[&amp;quot;D_GDA_1994&amp;quot;,SPHEROID[&amp;quot;GRS_1980&amp;quot;,6378137.0,298.257222101]],PRIMEM[&amp;quot;Greenwich&amp;quot;,0.0],UNIT[&amp;quot;Degree&amp;quot;,0.0174532925199433],AUTHORITY[&amp;quot;EPSG&amp;quot;,4283]]&lt;/WKT&gt;&lt;XOrigin&gt;-400&lt;/XOrigin&gt;&lt;YOrigin&gt;-400&lt;/YOrigin&gt;&lt;XYScale&gt;1111948722.2222221&lt;/XYScale&gt;&lt;ZOrigin&gt;-100000&lt;/ZOrigin&gt;&lt;ZScale&gt;10000&lt;/ZScale&gt;&lt;MOrigin&gt;-100000&lt;/MOrigin&gt;&lt;MScale&gt;10000&lt;/MScale&gt;&lt;XYTolerance&gt;8.9831528411952133e-009&lt;/XYTolerance&gt;&lt;ZTolerance&gt;0.001&lt;/ZTolerance&gt;&lt;MTolerance&gt;0.001&lt;/MTolerance&gt;&lt;HighPrecision&gt;true&lt;/HighPrecision&gt;&lt;LeftLongitude&gt;-180&lt;/LeftLongitude&gt;&lt;WKID&gt;4283&lt;/WKID&gt;&lt;LatestWKID&gt;4283&lt;/LatestWKID&gt;&lt;/GeographicCoordinateSystem&gt;</peXml></coordRef></DataProperties><SyncDate>20240820</SyncDate><SyncTime>13192700</SyncTime><ModDate>20240820</ModDate><ModTime>13192700</ModTime></Esri><dataIdInfo><envirDesc Sync="TRUE"> Version 6.2 (Build 9200) ; Esri ArcGIS 10.4.0.5524</envirDesc><dataLang><languageCode value="eng" Sync="TRUE"></languageCode><countryCode value="AUS" Sync="TRUE"></countryCode></dataLang><idCitation><resTitle Sync="TRUE">SA2_2011_AUST_continental_Si</resTitle><presForm><PresFormCd value="005" Sync="TRUE"></PresFormCd></presForm></idCitation><spatRpType><SpatRepTypCd value="001" Sync="TRUE"></SpatRepTypCd></spatRpType></dataIdInfo><mdLang><languageCode value="eng" Sync="TRUE"></languageCode><countryCode value="AUS" Sync="TRUE"></countryCode></mdLang><distInfo><distFormat><formatName Sync="TRUE">File Geodatabase Feature Class</formatName></distFormat></distInfo><mdHrLv><ScopeCd value="005" Sync="TRUE"></ScopeCd></mdHrLv><mdHrLvName Sync="TRUE">dataset</mdHrLvName><refSysInfo><RefSystem><refSysID><identCode code="4283" Sync="TRUE"></identCode><idCodeSpace Sync="TRUE">EPSG</idCodeSpace><idVersion Sync="TRUE">8.3.4(3.0.1)</idVersion></refSysID></RefSystem></refSysInfo><spatRepInfo><VectSpatRep><geometObjs Name="SA2_2011_AUST_continental_Si"><geoObjTyp><GeoObjTypCd value="002" Sync="TRUE"></GeoObjTypCd></geoObjTyp><geoObjCnt Sync="TRUE">0</geoObjCnt></geometObjs><topLvl><TopoLevCd value="001" Sync="TRUE"></TopoLevCd></topLvl></VectSpatRep></spatRepInfo><spdoinfo><ptvctinf><esriterm Name="SA2_2011_AUST_continental_Si"><efeatyp Sync="TRUE">Simple</efeatyp><efeageom code="4" Sync="TRUE"></efeageom><esritopo Sync="TRUE">FALSE</esritopo><efeacnt Sync="TRUE">0</efeacnt><spindex Sync="TRUE">TRUE</spindex><linrefer Sync="TRUE">FALSE</linrefer></esriterm></ptvctinf></spdoinfo><eainfo><detailed Name="SA2_2011_AUST_continental_Si"><enttyp><enttypl Sync="TRUE">SA2_2011_AUST_continental_Si</enttypl><enttypt Sync="TRUE">Feature Class</enttypt><enttypc Sync="TRUE">0</enttypc></enttyp><attr><attrlabl Sync="TRUE">OBJECTID</attrlabl><attalias Sync="TRUE">FID</attalias><attrtype Sync="TRUE">OID</attrtype><attwidth Sync="TRUE">4</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale><attrdef Sync="TRUE">Internal feature number.</attrdef><attrdefs Sync="TRUE">Esri</attrdefs><attrdomv><udom Sync="TRUE">Sequential unique whole numbers that are automatically generated.</udom></attrdomv></attr><attr><attrlabl Sync="TRUE">Shape</attrlabl><attalias Sync="TRUE">Shape</attalias><attrtype Sync="TRUE">Geometry</attrtype><attwidth Sync="TRUE">0</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale><attrdef Sync="TRUE">Feature geometry.</attrdef><attrdefs Sync="TRUE">Esri</attrdefs><attrdomv><udom Sync="TRUE">Coordinates defining the features.</udom></attrdomv></attr><attr><attrlabl Sync="TRUE">SA2_MAIN11</attrlabl><attalias Sync="TRUE">SA2_MAIN11</attalias><attrtype Sync="TRUE">String</attrtype><attwidth Sync="TRUE">9</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale></attr><attr><attrlabl Sync="TRUE">SA2_5DIG11</attrlabl><attalias Sync="TRUE">SA2_5DIG11</attalias><attrtype Sync="TRUE">String</attrtype><attwidth Sync="TRUE">5</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale></attr><attr><attrlabl Sync="TRUE">SA2_NAME11</attrlabl><attalias Sync="TRUE">SA2_NAME11</attalias><attrtype Sync="TRUE">String</attrtype><attwidth Sync="TRUE">50</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale></attr><attr><attrlabl Sync="TRUE">SA3_CODE11</attrlabl><attalias Sync="TRUE">SA3_CODE11</attalias><attrtype Sync="TRUE">String</attrtype><attwidth Sync="TRUE">5</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale></attr><attr><attrlabl Sync="TRUE">SA3_NAME11</attrlabl><attalias Sync="TRUE">SA3_NAME11</attalias><attrtype Sync="TRUE">String</attrtype><attwidth Sync="TRUE">50</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale></attr><attr><attrlabl Sync="TRUE">SA4_CODE11</attrlabl><attalias Sync="TRUE">SA4_CODE11</attalias><attrtype Sync="TRUE">String</attrtype><attwidth Sync="TRUE">3</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale></attr><attr><attrlabl Sync="TRUE">SA4_NAME11</attrlabl><attalias Sync="TRUE">SA4_NAME11</attalias><attrtype Sync="TRUE">String</attrtype><attwidth Sync="TRUE">50</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale></attr><attr><attrlabl Sync="TRUE">GCC_CODE11</attrlabl><attalias Sync="TRUE">GCC_CODE11</attalias><attrtype Sync="TRUE">String</attrtype><attwidth Sync="TRUE">5</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale></attr><attr><attrlabl Sync="TRUE">GCC_NAME11</attrlabl><attalias Sync="TRUE">GCC_NAME11</attalias><attrtype Sync="TRUE">String</attrtype><attwidth Sync="TRUE">50</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale></attr><attr><attrlabl Sync="TRUE">STE_CODE11</attrlabl><attalias Sync="TRUE">STE_CODE11</attalias><attrtype Sync="TRUE">String</attrtype><attwidth Sync="TRUE">1</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale></attr><attr><attrlabl Sync="TRUE">STE_NAME11</attrlabl><attalias Sync="TRUE">STE_NAME11</attalias><attrtype Sync="TRUE">String</attrtype><attwidth Sync="TRUE">50</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale></attr><attr><attrlabl Sync="TRUE">ALBERS_SQM</attrlabl><attalias Sync="TRUE">ALBERS_SQM</attalias><attrtype Sync="TRUE">Double</attrtype><attwidth Sync="TRUE">8</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale></attr><attr><attrlabl Sync="TRUE">Shape_Length</attrlabl><attalias Sync="TRUE">Shape_Length</attalias><attrtype Sync="TRUE">Double</attrtype><attwidth Sync="TRUE">8</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale><attrdef Sync="TRUE">Length of feature in internal units.</attrdef><attrdefs Sync="TRUE">Esri</attrdefs><attrdomv><udom Sync="TRUE">Positive real numbers that are automatically generated.</udom></attrdomv></attr><attr><attrlabl Sync="TRUE">Shape_Area</attrlabl><attalias Sync="TRUE">Shape_Area</attalias><attrtype Sync="TRUE">Double</attrtype><attwidth Sync="TRUE">8</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale><attrdef Sync="TRUE">Area of feature in internal units squared.</attrdef><attrdefs Sync="TRUE">Esri</attrdefs><attrdomv><udom Sync="TRUE">Positive real numbers that are automatically generated.</udom></attrdomv></attr></detailed></eainfo><mdDateSt Sync="TRUE">20240820</mdDateSt></metadata>
```

## luto/tools/Manual_jupyter_books/helpers/parameters.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.


# Define the legend parameters
LEGEND_PARAMS = {
    'bbox_to_anchor': (0.15, 0.22),
    'loc': 'upper left',
    'ncol': 1,
    'fontsize': 8,
    'framealpha': 0.3,
    'columnspacing': 10}

# The dictionary to add meta to notebooks
NOTEBOOK_META_DICT = {
    "# HIDDEN": "hide-cell",            # Hide the cell and output
    "# HIDE CODE": "remove-input",      # Remove the input and keep the output
    "# REMOVE": "remove-cell"           # Remove the cell and output
}
```

## luto/tools/Manual_jupyter_books/helpers/__init__.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.


import re
import numpy as np
import nbformat as nbf
import xarray as xr
import rioxarray as rxr
import rasterio
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches

from itertools import product
from luto.tools.Manual_jupyter_books.helpers.parameters import NOTEBOOK_META_DICT
from luto.tools.spatializers import get_coarse2D_map



def full_res_1d_raw_to_2d(data, arr:np.ndarray) -> np.ndarray:
    '''
    This function converts a 1D numpy array to an 2D array with the same shape as `NLUM_MASK`.
    
    Inputs
    ------
    data: Data
        The Data object that contains the metadata of the 2D array.
    arr: np.ndarray
        The 1D array that will be converted to an 2D array.
    
    Returns
    -------
        The 2D array that has the same shape as `NLUM_MASK`.
    '''
    LUMAP_FullRes_2D = np.full(data.NLUM_MASK.shape, data.NODATA).astype(np.float32) 
    np.place(LUMAP_FullRes_2D, data.NLUM_MASK, arr)
    return LUMAP_FullRes_2D
    



def arr_to_xr(data, arr:np.ndarray) -> xr.DataArray:
    '''
    This function converts a 1D numpy array to an 2D xarray DataArray with `transform` and `lon/lat`.
    
    Inputs
    ------
    data: Data
        The Data object that contains the metadata of the 2D array.  
    arr: np.ndarray
        The 1D array that will be converted to an xarray DataArray.
        
    Returns
    -------
        The xarray DataArray that contains the 2D array.
    '''
    
    # Check if the array is full resolution raw
    full_res_raw = (arr.size == data.LUMAP_NO_RESFACTOR.size)
    
    # Get the geo metadata of the array
    if full_res_raw:
        geo_meta = data.GEO_META_FULLRES
        arr_2d = np.full(data.NLUM_MASK.shape, data.NODATA).astype(np.float32) 
        np.place(arr_2d, data.NLUM_MASK, arr)
    else:
        geo_meta = data.GEO_META
        arr_2d = data.LUMAP_2D_RESFACTORED.copy().astype(np.float32)
        np.place(
            arr_2d, 
            (arr_2d != data.MASK_LU_CODE) & (arr_2d != data.NODATA), 
            arr
        )                    

    # Mask the nodata values to nan
    arr_2d = np.where(arr_2d == data.NODATA, np.nan, arr_2d)   

    with rasterio.io.MemoryFile() as memfile:
        with memfile.open(**geo_meta) as dataset:
            # Write the array data to the virtual dataset
            dataset.write(arr_2d, 1)
            # Read the virtual dataset into an xarray DataArray
            da_raster = rxr.open_rasterio(memfile).squeeze(drop=True)
            # Make sure the DataArray has the correct values. The rxr.open_rasterio function will loss the values of the array
            da_raster.values = arr_2d
            # Drop all attributes
            da_raster.attrs = {}
            
    return da_raster

    


def mrj_to_xr(data, in_mrj:np.ndarray) -> xr.DataArray:
    '''
    This function converts a `mrj` array to an xarray DataArray and give each dimension a valida name.
        - The `m` dimension will have names from ['dry', 'irr']; 
        - The `j` dimension will have names from ['Apples', 'Beef - modified land', 'Beef - natural land', 'Citrus', ...,  'Winter legumes', 'Winter oilseeds'].
        - The `r` dimension will be expanded into `x` and `y` (lon/lat) coordinates.
        
    Note
    ----
    When converting the 1D array to 2D, some pixels are lost. \n
    This is because the 1D array can not be converted to a perfect square. \n
    We fill these lost pixels with `np.nan`.
    
    Inputs
    ------
    data: Data
        The Data object that contains the metadata of the 2D array.
    in_mrj: np.ndarray
        The 3D array that will be converted to an xarray DataArray.

    Returns
    -------
        The xarray DataArray that is georeferenced and have valid dimension names.
    '''
    # The `j` dimension can be one of `AGRICULTURAL_LANDUSES` and `PRODUCTS`. Determine the correct dimension names according to the length of the `j` dimension.
    j_vals = data.AGRICULTURAL_LANDUSES if in_mrj.shape[2] == len(data.AGRICULTURAL_LANDUSES) else data.PRODUCTS
    
    mrj_xr = []
    for m,j in product(range(in_mrj.shape[0]), range(in_mrj.shape[2])):
        arr = in_mrj[m,:,j]
        lm = data.LANDMANS[m]
        lu = j_vals[j]
        map_xr = arr_to_xr(data, arr).expand_dims({'lm': [lm], 'lu': [lu]})
        mrj_xr.append(map_xr)
        
    return xr.combine_by_coords(mrj_xr)





def map_to_4band(_map:np.ndarray, color_dict:dict) -> np.ndarray:
    '''
    Convert a 2D map to a 4-band map (RGBA).
    
    Inputs
    ------
     - _map: 2D array, the map to be converted.
     - color_dict: dict, the color mapping dict.
    
    Returns
    -------
     - 4D array, the 4-band RGBA map.
    '''
    arr_4band = np.zeros((_map.shape[0], _map.shape[1], 4), dtype='uint8')

    for k, v in color_dict.items():
        arr_4band[_map == k] = v
        
    return arr_4band


def get_color_lookup(_map:np.ndarray, cell_names:list, colors:dict):
    '''
    Get the color lookup for the map.
    
    Input
    -----
    - _map: 1D np.ndarray, the map
    - cell_names: list, the cell names
    - colors: dict, the color dict
    
    Output
    ------
    - color_dict: dict, the color dict
    - color_desc_dict: dict, the color description dict
    '''
    cell_vals = [i for i in np.unique(_map) if not np.isnan(i)]

    color_dict = dict(zip(cell_vals, colors))
    color_desc_dict = dict(zip(colors, cell_names))
    return color_dict, color_desc_dict



def plot_4band_map(arr_4band:np.ndarray, color_desc_dict:dict, legend_opt:dict, ax=None):
    '''
    Plot the 4-band map.
    
    Input
    -----
    - arr_4band: np.ndarray, the 4-band map
    - color_desc_dict: dict, the color description dict
    - legend_opt: dict, the legend options
    - ax: matplotlib.axes.Axes, the axes to plot the map
        
    Output
    ------
    - None
    '''
    if ax is None:
        fig, ax = plt.subplots()
        ax.imshow(arr_4band)
    else:
        ax.imshow(arr_4band)

    patches = [mpatches.Patch(color=tuple(value / 255 for value in k), label=v) 
                for k, v in color_desc_dict.items()]

    plt.legend(handles=patches, **legend_opt)
    
    
    
    
def map_to_plot(_map, colors, cell_names, legend_params, ax=None):
    '''
    Function to plot the 4-band map.
    
    Inputs
    ------
    - _map: np.ndarray
        The map to be plotted.
    - colors: dict
        The color dictionary.
    - cell_names: list
        The cell names.
    - legend_params: dict
        The legend parameters.
        
    Returns
    -------
    - None
    '''
    # Get the color lookup dictionary
    color_dict, color_desc_dict = get_color_lookup(_map, cell_names, colors)

    # Get the 4-band map
    arr_4band = map_to_4band(_map, color_dict)

    # Plot the 4-band map
    plot_4band_map(arr_4band, color_desc_dict, legend_params, ax)
    
    
    
def add_meta_to_nb(ipath):

    # Search through each notebook and look for the text, add a tag if necessary
    ntbk = nbf.read(ipath, nbf.NO_CONVERT)

    for cell in ntbk.cells:
        cell_tags = cell.get('metadata', {}).get('tags', [])
        for key, val in NOTEBOOK_META_DICT.items():
            if key in cell['source']:
                cell_tags = [val]
        if len(cell_tags) > 0:
            cell['metadata']['tags'] = cell_tags

    nbf.write(ntbk, ipath)
```

## luto/tools/plotmap.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.



"""
To plot neoLUTO spatial arrays.

Based on code by: Brett Bryan (b.bryan@deakin.edu.au)
Adaptation: Fjalar de Haan (f.dehaan@deakin.edu.au)
Colour scheme by: Carla Archibald (c.archibald@deakin.edu.au)

Flagged as deprecated by Jinzhu Wang (jinzhu.wang@deakin.edu.au) at 13 Aug 2025
"""


import os.path
import sys

import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import matplotlib.colors as mcolors

import numpy as np

import rasterio

import luto.settings as settings

colours = { 'Non-agricultural land': '#666b65'
          , 'Unallocated - natural land': '#c3cada'
          , 'Unallocated - modified land': '#a8a8b4'
          , 'Winter cereals': '#fcb819'
          , 'Summer cereals': '#f0c662'
          , 'Rice': '#7f7969'
          , 'Winter legumes': '#49482a'
          , 'Summer legumes': '#757448'
          , 'Winter oilseeds': '#d6a193'
          , 'Summer oilseeds': '#d8b6b4'
          , 'Sugar': '#bc8463'
          , 'Hay': '#c47646'
          , 'Cotton': '#c3cada'
          , 'Other non-cereal crops': '#bf8d7e'
          , 'Vegetables': '#a88571'
          , 'Citrus': '#e79029'
          , 'Apples': '#a63634'
          , 'Pears': '#ad5d44'
          , 'Stone fruit': '#704228'
          , 'Tropical stone fruit': '#408dd5'
          , 'Nuts': '#6f4328'
          , 'Plantation fruit': '#a76d5f'
          , 'Grapes': '#7298c7'
          , 'Dairy - natural land': '#beb678'
          , 'Beef - natural land': '#d4bea6'
          , 'Sheep - natural land': '#e2bd76'
          , 'Dairy - modified land': '#9c9d13'
          , 'Beef - modified land': '#b09c83'
          , 'Sheep - modified land': '#f0c662'
          , 'Water bodies, cities etc.': '#FFFFFF'
          }

id2desc = { -2: 'Water bodies, cities etc.'
          , -1: 'Non-agricultural land'
          , 0: 'Apples'
          , 1: 'Beef - modified land'
          , 2: 'Beef - natural land'
          , 3: 'Citrus'
          , 4: 'Cotton'
          , 5: 'Dairy - modified land'
          , 6: 'Dairy - natural land'
          , 7: 'Grapes'
          , 8: 'Hay'
          , 9: 'Nuts'
          , 10: 'Other non-cereal crops'
          , 11: 'Pears'
          , 12: 'Plantation fruit'
          , 13: 'Rice'
          , 14: 'Sheep - modified land'
          , 15: 'Sheep - natural land'
          , 16: 'Stone fruit'
          , 17: 'Sugar'
          , 18: 'Summer cereals'
          , 19: 'Summer legumes'
          , 20: 'Summer oilseeds'
          , 21: 'Tropical stone fruit'
          , 22: 'Unallocated - modified land'
          , 23: 'Unallocated - natural land'
          , 24: 'Vegetables'
          , 25: 'Winter cereals'
          , 26: 'Winter legumes'
          , 27: 'Winter oilseeds'
          }

clist = [colours[key] for key in list(id2desc.values())]

fpath = os.path.join(settings.INPUT_DIR, 'NLUM_2010-11_mask.tif')
with rasterio.open(fpath) as rst:
    nlum_mask = rst.read(1)
    mask2D = np.full(nlum_mask.shape, -2)
    nonzeroes = np.nonzero(nlum_mask)

def plotmap(lumap, labels=True):

    # Reconstitute the 2D array.
    themap = mask2D.copy()
    themap[nonzeroes] = lumap
    themap += 2 # Shift all lu-codes by two so the colour list starts at zero.

    # Land uses and their number. For colour maps and legends.
    lus = np.unique(themap)
    nlus, = lus.shape

    # Build the legend.
    if labels: # Use the land-use list colour scheme and labels.
        cmap = matplotlib.colors.ListedColormap(clist)
        im = plt.imshow(themap, cmap=cmap, resample=False)
        patches = [ mpatches.Patch( color=cmap(i)
                                  , label="{l} ({code})".format( l=lu
                                                               , code=i ) )
                    for i, lu in enumerate(list(id2desc.values())) ]
    else: # Use random colour scheme and labels.
        # cmap = matplotlib.colors.ListedColormap(np.random.rand(nlus, 3))
        cmap = matplotlib.colors.ListedColormap(clist)
        im = plt.imshow(themap, cmap=cmap, resample=False)
        patches = [ mpatches.Patch( color=cmap(i)
                                  , label="LU {code}".format(code=i) )
                    for i in range(len(lus)) ]

    # Attach legend to plot.
    plt.legend( handles=patches
              , loc='lower left'
              , bbox_to_anchor=(0, 0)
              , borderaxespad=0
              , ncol=3
              , fontsize='xx-small'
              , frameon=False
              )

    # Finally.
    plt.show()

def _plotmap(lumap):

    # Reconstitute the 2D array.
    themap = mask2D.copy()
    themap[nonzeroes] = lumap

    def clr(lu): return mcolors.hex2color(desc2col[id2desc[lu]])
    colourise = np.vectorize(clr)

    themapc = np.transpose(colourise(themap), (1, 2, 0))

    # Land uses and their number. For colour maps and legends.
    lus = np.unique(themap)
    nlus, = lus.shape

    # Build the legend.
    im = plt.imshow(themapc, interpolation='none')

    # Get the colours.
    colours = [im.cmap(lu) for lu in lus]

    # Make patches of each colour.
    patches = [ mpatches.Patch( color=mcolors.hex2color(desc2col[id2desc[lus[i]]])
                              , label="{lu} ({l})".format( lu=id2desc[lus[i]]
                                                         , l=lus[i] ) )
                for i in range(nlus) ]


    # Attach legend to plot.
    plt.legend( handles=patches
              , loc='lower left'
              , bbox_to_anchor=(0, 0)
              , borderaxespad=0
              , ncol=3
              , fontsize='xx-small'
              , frameon=False
              )

    # Finally.
    plt.show()

if __name__ == '__main__':
    labels = True
    lumap = np.load(sys.argv[1])
    if len(sys.argv) > 2 and sys.argv[2] == '--random-legend':
        labels=False
    plotmap(lumap, labels=labels)
```

## luto/tools/report/create_report_data.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import os
import json
import re
import pandas as pd
import numpy as np
from luto import settings

from luto.economics.off_land_commodity import get_demand_df
from luto.tools.report.data_tools import get_all_files

from luto.tools.report.data_tools.parameters import (
    AG_LANDUSE,
    COLORS,
    COLORS_RANK,
    COLORS_AM_NONAG,
    COLORS_COMMODITIES,
    COLORS_ECONOMY_TYPE,
    COLORS_GHG,
    COLORS_LM,
    COLORS_LU,
    COMMODITIES_ALL,
    COMMODITIES_OFF_LAND,
    GHG_CATEGORY,
    GHG_NAMES,
    LANDUSE_ALL_RENAMED,
    LU_CROPS,
    LU_LVSTKS,
    LU_UNALLOW,
    RENAME_AM_NON_AG,
    RENAME_NON_AG,
    SPATIAL_MAP_DICT
)


def save_report_data(raw_data_dir:str):
    """
    Saves the report data in the specified directory.

    Parameters
    raw_data_dir (str): The directory path where the raw output data is.

    Returns
    None
    """
    # Set the save directory
    SAVE_DIR = f'{raw_data_dir}/DATA_REPORT/data'
    years = sorted(settings.SIM_YEARS)

    # Create the directory if it does not exist
    if not os.path.exists(SAVE_DIR):
        os.makedirs(SAVE_DIR)

    # Get all LUTO output files and store them in a dataframe
    files = get_all_files(raw_data_dir).reset_index(drop=True)
    files['Year'] = files['Year'].astype(int)
    files = files.query('Year.isin(@years)')
    
    # Function to get rank color based on value
    def get_rank_color(x):
        if x in [None, np.nan, 'N.A.']:
            return COLORS_RANK['N.A.']
        elif x <= 10:
            return COLORS_RANK['1-10']
        elif x <= 20:
            return COLORS_RANK['11-20']
        else:
            return COLORS_RANK['>=21']

        
    def format_with_suffix(x):
        if pd.isna(x) or x == 0:
            return "0"
        suffixes = ['', 'K', 'M', 'B', 'T']
        # Determine the appropriate suffix
        magnitude = 0
        while abs(x) >= 1000 and magnitude < len(suffixes)-1:
            magnitude += 1
            x /= 1000.0
        # Format with 2 significant digits
        if x < 10:
            formatted = f"{x:.2f}"
        else:
            formatted = f"{int(round(x))}"
        return f"{formatted} {suffixes[magnitude]}"
    
    # Land-use group and colors
    lu_group_raw = pd.read_csv('luto/tools/report/VUE_modules/assets/lu_group.csv')
    colors_lu_category = lu_group_raw.set_index('Category')['color_HEX'].to_dict()
    colors_lu_category.update({'Agri-Management': "#D5F100"})
    lu_group = lu_group_raw.set_index(['Category', 'color_HEX'])\
        .apply(lambda x: x.str.split(', ').explode())\
        .reset_index()
    
        

    ####################################################
    #                    1) Area Change                #
    ####################################################
    area_dvar_paths = files.query('category == "area"').reset_index(drop=True)
    
    ag_dvar_dfs = area_dvar_paths.query('base_name == "area_agricultural_landuse"').reset_index(drop=True)
    ag_dvar_area = pd.concat([pd.read_csv(path) for path in ag_dvar_dfs['path']], ignore_index=True)
    ag_dvar_area['Source'] = 'Agricultural Landuse'
    ag_dvar_area['Category'] = ag_dvar_area['Land-use'].apply(lu_group.set_index('Land-use')['Category'].to_dict().get)
    ag_dvar_area['Area (ha)'] = ag_dvar_area['Area (ha)'].round(2)

    non_ag_dvar_dfs = area_dvar_paths.query('base_name == "area_non_agricultural_landuse"').reset_index(drop=True)
    non_ag_dvar_area = pd.concat([pd.read_csv(path) for path in non_ag_dvar_dfs['path'] if not pd.read_csv(path).empty], ignore_index=True)
    non_ag_dvar_area['Land-use'] = non_ag_dvar_area['Land-use'].replace(RENAME_NON_AG)
    non_ag_dvar_area['Category'] = non_ag_dvar_area['Land-use'].apply(lu_group.set_index('Land-use')['Category'].to_dict().get)
    non_ag_dvar_area['Source'] = 'Non-Agricultural Landuse'
    non_ag_dvar_area['Water_supply'] = 'NA'
    non_ag_dvar_area['Area (ha)'] = non_ag_dvar_area['Area (ha)'].round(2)

    am_dvar_dfs = area_dvar_paths.query('base_name == "area_agricultural_management"').reset_index(drop=True)
    am_dvar_area = pd.concat([pd.read_csv(path) for path in am_dvar_dfs['path'] if not pd.read_csv(path).empty], ignore_index=True)
    am_dvar_area = am_dvar_area.replace(RENAME_AM_NON_AG)
    am_dvar_area['Source'] = 'Agricultural Management'
    am_dvar_area['Area (ha)'] = am_dvar_area['Area (ha)'].round(2)
    

    # -------------------- Area ranking --------------------
    area_ranking_raw = pd.concat([ag_dvar_area, non_ag_dvar_area, am_dvar_area])
    
    area_ranking_type = area_ranking_raw\
        .groupby(['Year', 'region', 'Source'])[['Area (ha)']]\
        .sum(numeric_only=True)\
        .reset_index()\
        .sort_values(['Year', 'Source', 'Area (ha)'], ascending=[True, True, False])\
        .assign(Rank=lambda x: x.groupby(['Year', 'Source']).cumcount())\
        .round({'Area (ha)': 2})
         
    area_ranking_total = area_ranking_raw\
        .query('Water_supply.isin(["ALL", "NA"])')\
        .groupby(['Year', 'region'])[["Area (ha)"]]\
        .sum(numeric_only=True)\
        .reset_index()\
        .sort_values(['Year', 'Area (ha)'], ascending=[True, False])\
        .assign(Rank=lambda x: x.groupby(['Year']).cumcount(), Source='Total')\
        .round({'Area (ha)': 2})
        
    area_ranking = pd.concat([area_ranking_type, area_ranking_total], ignore_index=True)

    area_ranking = area_ranking.set_index(['Year', 'region', 'Source'])\
        .reindex(
            index=pd.MultiIndex.from_product(
                [years, area_ranking['region'].unique(), area_ranking['Source'].unique()],
                names=['Year', 'region', 'source']), fill_value=None 
         )\
        .reset_index()\
        .assign(color=lambda x: x['Rank'].map(get_rank_color))
        

    out_dict = {}
    for (region, source), df in area_ranking.groupby(['region', 'source']):
        df = df.drop(['region'], axis=1)
        
        if region not in out_dict:
            out_dict[region] = {}
        if source not in out_dict[region]:
            out_dict[region][source] = {}

        out_dict[region][source]['Rank'] = df.set_index('Year')['Rank'].replace({np.nan: None}).to_dict()
        out_dict[region][source]['color'] = df.set_index('Year')['color'].replace({np.nan: None}).to_dict()
        out_dict[region][source]['value'] = df.set_index('Year')['Area (ha)'].apply( lambda x: format_with_suffix(x)).to_dict()

    filename = 'Area_ranking'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')
        

    # -------------------- Area overview --------------------
    
    area_df = pd.concat([
        ag_dvar_area, 
        non_ag_dvar_area, 
        am_dvar_area.assign(**{'Land-use':'Agri-Management', 'Category':'Agri-Management'})
        ], ignore_index=True)
    
    group_cols = ['Land-use', 'Category', 'Source']
    for idx, col in enumerate(group_cols):
 
        df_region = area_df\
            .query('Water_supply != "ALL"')\
            .groupby(['Year', 'region', col])[['Area (ha)']]\
            .sum()\
            .reset_index()\
            .round({'Area (ha)': 2})
        df_wide = df_region.groupby([col, 'region'])[['Year','Area (ha)']]\
            .apply(lambda x: x[['Year','Area (ha)']].values.tolist())\
            .reset_index()
        df_wide.columns = ['name', 'region','data']
        df_wide['type'] = 'column'

        if col == "Land-use":
            df_wide['color'] = df_wide['name'].apply(lambda x: COLORS_LU[x])
            df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
            df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
        elif col == 'Category':
            df_wide['color'] = df_wide['name'].apply(lambda x: colors_lu_category[x])
        elif col == 'Source':
            df_wide['name_order'] = df_wide['name'].apply(lambda x: ['Agricultural Management', 'Agricultural Landuse', 'Non-Agricultural Landuse'].index(x))
            df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])

        out_dict = {}
        for region, df in df_wide.groupby('region'):
            df = df.drop('region', axis=1)
            out_dict[region] = df.to_dict(orient='records')

        filename = f'Area_overview_{idx+1}_{col.replace(" ", "_")}'
        with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
            f.write(f'window["{filename}"] = ')
            json.dump(out_dict, f, separators=(',', ':'), indent=2)
            f.write(';\n')
            
    
    
    # -------------------- Area by Agricultural land --------------------
    df_wide = ag_dvar_area\
        .groupby(['region', 'Water_supply', 'Land-use'])[['Year','Area (ha)']]\
        .apply(lambda x: x[['Year','Area (ha)']].values.tolist())\
        .reset_index()

    df_wide.columns = ['region', 'water', 'name', 'data']
    df_wide['type'] = 'column'
    df_wide['color'] = df_wide['name'].apply(lambda x: COLORS_LU[x])

    out_dict = {}
    for (region, water), df in df_wide.groupby(['region', 'water']):
        df = df.drop(['region', 'water'], axis=1)
        if region not in out_dict:
            out_dict[region] = {}
        if water not in out_dict[region]:
            out_dict[region][water] = []
        out_dict[region][water] = df.to_dict(orient='records')
        
    filename = 'Area_Ag'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')


    # -------------------- Area by Agricultural Management Area (ha) Land use --------------------
    df_wide = am_dvar_area\
        .groupby(['region', 'Type', 'Water_supply', 'Land-use'])[['Year','Area (ha)']]\
        .apply(lambda x: x[['Year','Area (ha)']].values.tolist())\
        .reset_index()
    df_wide.columns = ['region', '_type', 'water', 'name', 'data']
    df_wide['type'] = 'column'
    
    df_wide['color'] = df_wide['name'].apply(lambda x: COLORS_LU[x])
    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])

    out_dict = {}
    for (region, _type, water), df in df_wide.groupby(['region', '_type', 'water']):
        df = df.drop(['region', 'water', '_type'], axis=1)
        if region not in out_dict:
            out_dict[region] = {}
        if _type not in out_dict[region]:
            out_dict[region][_type] = {}
        if water not in out_dict[region][_type]:
            out_dict[region][_type][water] = {}
            
        out_dict[region][_type][water] = df.to_dict(orient='records')
        
    filename = f'Area_Am'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')
            
            
    # -------------------- Area by Non-Agricultural Landuse --------------------
    df_wide = non_ag_dvar_area\
        .groupby(['region', 'Land-use'])[['Year', 'Area (ha)']]\
        .apply(lambda x: x[['Year','Area (ha)']].values.tolist())\
        .reset_index()
    df_wide.columns = ['region', 'name', 'data']
    df_wide['type'] = 'column'

    df_wide['color'] = df_wide['name'].apply(lambda x: COLORS_AM_NONAG[x])
    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
   
    out_dict = {}
    for region, df in df_wide.groupby('region'):
        df = df.drop('region', axis=1)
        out_dict[region] = df.to_dict(orient='records')
        
    filename = 'Area_NonAg'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')
            
            


    # # -------------------- Transition areas (start-end) --------------------
    # transition_path = files.query('category =="transition_matrix"')
    # transition_df_region = pd.read_csv(transition_path['path'].values[0], index_col=0).reset_index() 
    # transition_df_region = transition_df_region.replace(RENAME_AM_NON_AG)

    # transition_df_AUS = transition_df_region.groupby(['From Land-use', 'To Land-use'])[['Area (ha)']].sum().reset_index()
    # transition_df_AUS['region'] = 'AUSTRALIA'

    # transition_df = pd.concat([transition_df_AUS, transition_df_region], ignore_index=True)


    # out_dict = {}
    # for (region, df) in transition_df.groupby('region'):
    #     out_dict[region] = {}
        
    #     transition_mat = df.pivot(index='From Land-use', columns='To Land-use', values='Area (ha)')
    #     transition_mat = transition_mat.reindex(index=AG_LANDUSE, columns=LANDUSE_ALL_RENAMED)
    #     transition_mat = transition_mat.fillna(0)
    #     total_area_from = transition_mat.sum(axis=1).values.reshape(-1, 1)
        
    #     transition_df_pct = transition_mat / total_area_from * 100
    #     transition_df_pct = transition_df_pct.fillna(0).replace([np.inf, -np.inf], 0)

    #     transition_mat['SUM'] = transition_mat.sum(axis=1)
    #     transition_mat.loc['SUM'] = transition_mat.sum(axis=0)

    #     heat_area = transition_mat.style.background_gradient(
    #         cmap='Oranges',
    #         axis=1,
    #         subset=pd.IndexSlice[:transition_mat.index[-2], :transition_mat.columns[-2]]
    #     ).format('{:,.0f}')

    #     heat_pct = transition_df_pct.style.background_gradient(
    #         cmap='Oranges',
    #         axis=1,
    #         vmin=0,
    #         vmax=100
    #     ).format('{:,.2f}')

    #     heat_area_html = heat_area.to_html()
    #     heat_pct_html = heat_pct.to_html()

    #     # Replace '0.00' with '-' in the html
    #     heat_area_html = re.sub(r'(?<!\d)0(?!\d)', '-', heat_area_html)
    #     heat_pct_html = re.sub(r'(?<!\d)0.00(?!\d)', '-', heat_pct_html)

    #     out_dict[region]['area'] = heat_area_html
    #     out_dict[region]['pct'] = heat_pct_html

    # filename = 'Area_transition_start_end'
    # with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
    #     f.write(f'window["{filename}"] = ')
    #     json.dump(out_dict, f, separators=(',', ':'), indent=2)
    #     f.write(';\n')
        
        
    # # -------------------- Transition areas (year-to-year) --------------------
    # transition_path = files.query('base_name =="crosstab-lumap"')
    # transition_df_region = pd.concat([pd.read_csv(path) for path in transition_path['path']], ignore_index=True)
    # transition_df_region = transition_df_region.replace(RENAME_AM_NON_AG)

    # transition_df_AUS = transition_df_region.groupby(['Year', 'From land-use', 'To land-use'])[['Area (ha)']].sum().reset_index()
    # transition_df_AUS['region'] = 'AUSTRALIA'

    # transition_df = pd.concat([transition_df_AUS, transition_df_region], ignore_index=True)
    
    # out_dict = {region: {'area': {}, 'pct':{}} for region in transition_df['region'].unique()}
    # for (year, region), df in transition_df.groupby(['Year', 'region']):
        
    #     transition_mat = df.pivot(index='From land-use', columns='To land-use', values='Area (ha)')
    #     transition_mat = transition_mat.reindex(index=AG_LANDUSE, columns=LANDUSE_ALL_RENAMED)
    #     transition_mat = transition_mat.fillna(0)
    #     total_area_from = transition_mat.sum(axis=1).values.reshape(-1, 1)
        
    #     transition_df_pct = transition_mat / total_area_from * 100
    #     transition_df_pct = transition_df_pct.fillna(0).replace([np.inf, -np.inf], 0)

    #     transition_mat['SUM'] = transition_mat.sum(axis=1)
    #     transition_mat.loc['SUM'] = transition_mat.sum(axis=0)

    #     heat_area = transition_mat.style.background_gradient(
    #         cmap='Oranges',
    #         axis=1,
    #         subset=pd.IndexSlice[:transition_mat.index[-2], :transition_mat.columns[-2]]
    #     ).format('{:,.0f}')

    #     heat_pct = transition_df_pct.style.background_gradient(
    #         cmap='Oranges',
    #         axis=1,
    #         vmin=0,
    #         vmax=100
    #     ).format('{:,.2f}')

    #     heat_area_html = heat_area.to_html()
    #     heat_pct_html = heat_pct.to_html()

    #     # Replace '0.00' with '-' in the html
    #     heat_area_html = re.sub(r'(?<!\d)0(?!\d)', '-', heat_area_html)
    #     heat_pct_html = re.sub(r'(?<!\d)0.00(?!\d)', '-', heat_pct_html)

    #     out_dict[region]['area'][str(year)] = heat_area_html
    #     out_dict[region]['pct'][str(year)] = heat_pct_html
        
    # filename = 'Area_transition_year_to_year'
    # with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
    #     f.write(f'window["{filename}"] = ')
    #     json.dump(out_dict, f, separators=(',', ':'), indent=2)
    #     f.write(';\n')
        
        

    ####################################################
    #                   2) Production                  #
    ####################################################
    
    demand_files = files.query('category == "quantity"')
    
    quantity_LUTO = demand_files\
        .query('base_name == "quantity_production_t_separate"')\
        .reset_index(drop=True)
    quantity_LUTO = pd.concat(
            [pd.read_csv(path).assign(Year=Year) for Year,path in quantity_LUTO[['Year','path']].values.tolist()],
            ignore_index=True)\
        .assign(Commodity= lambda x: x['Commodity'].str.capitalize())\
        .replace({'Sheep lexp': 'Sheep live export', 'Beef lexp': 'Beef live export'})\
        .replace(RENAME_AM_NON_AG)\
        .query('Year.isin(@years) and abs(`Production (t/KL)`) > 1e-6')\
        .round({'`Production (t/KL)`': 2})
    quantity_LUTO.loc[
        quantity_LUTO['Type'] == 'Non-Agricultural',
        'Water_supply'
    ] = 'NA'
    
    

    # # -------------------- Demand --------------------
    
    # DEMAND_DATA_long = get_demand_df()\
    #     .replace({'Beef lexp': 'Beef live export', 'Sheep lexp': 'Sheep live export'})\
    #     .set_index(['Commodity', 'Type', 'Year'])\
    #     .reindex(COMMODITIES_ALL, level=0)\
    #     .reset_index()\
    #     .replace(RENAME_AM_NON_AG)\
    #     .assign(on_off_land=lambda x: np.where(x['Commodity'].isin(COMMODITIES_OFF_LAND), 'Off-land', 'On-land'))
    
    # group_cols = ['Type', 'on_off_land', 'Commodity']

    # for idx, col in enumerate(group_cols):


    #     _df = DEMAND_DATA_long.query(f'Year.isin({years})')
            
    #     df_AUS = _df\
    #         .groupby(['Year', col])[['Quantity (tonnes, KL)']]\
    #         .sum()\
    #         .reset_index()\
    #         .round({'Quantity (tonnes, KL)': 2})
    #     df_AUS_wide = df_AUS.groupby([col])[['Year','Quantity (tonnes, KL)']]\
    #         .apply(lambda x: x[['Year','Quantity (tonnes, KL)']].values.tolist())\
    #         .reset_index()
    #     df_AUS_wide.columns = ['name','data']
    #     df_AUS_wide['type'] = 'column'
 
    #     if col == "Land-use":
    #         df_AUS_wide['color'] = df_AUS_wide['name'].apply(lambda x: COLORS_LU[x])
    #         df_AUS_wide['name_order'] = df_AUS_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
    #         df_AUS_wide = df_AUS_wide.sort_values('name_order').drop(columns=['name_order'])
    #     elif col.lower() == 'commodity':
    #         df_AUS_wide['color'] = df_AUS_wide['name'].apply(lambda x: COLORS_COMMODITIES[x])
    #         df_AUS_wide['name_order'] = df_AUS_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
    #         df_AUS_wide = df_AUS_wide.sort_values('name_order').drop(columns=['name_order'])
 
    #     filename = f'Production_demand_{idx+1}_{col.replace(" ", "_")}'
    #     with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
    #         f.write(f'window["{filename}"] = ')
    #         df_AUS_wide.to_json(f, orient='records', indent=2)
    #         f.write(';\n')


    # # -------------------- Production limit. --------------------
    # demand_limit = DEMAND_DATA_long.query('Type == "Domestic" and on_off_land == "On-land" and Year.isin(@years)')
    # demand_limit_wide = demand_limit.groupby(['Commodity', 'Year'])[['Quantity (tonnes, KL)']]\
    #     .sum()\
    #     .reset_index()\
    #     .groupby('Commodity')[['Year','Quantity (tonnes, KL)']]\
    #     .apply(lambda x: x[['Year','Quantity (tonnes, KL)']].values.tolist())\
    #     .reset_index()
    # demand_limit_wide.columns = ['name','data']
    # demand_limit_wide['type'] = 'column'
    # filename = 'Production_demand_4_Limit'
    # with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
    #     f.write(f'window["{filename}"] = ')
    #     demand_limit_wide.to_json(f, orient='records', indent=2)
    #     f.write(';\n')



    # -------------------- Overview: sum of commodity production --------------------
    df_wide = quantity_LUTO\
        .query('Water_supply != "ALL" and am != "ALL"')\
        .groupby(['region', 'Commodity'])[['Year', 'Production (t/KL)']]\
        .apply(lambda x: x[['Year','Production (t/KL)']].values.tolist())\
        .reset_index()
    df_wide.columns = ['region', 'name', 'data']
    df_wide['type'] = 'column'
    df_wide['color'] = df_wide['name'].apply(lambda x: COLORS_COMMODITIES[x])
    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])

    out_dict = {}
    for region, df in df_wide.groupby('region'):
        df = df.drop('region', axis=1)
        out_dict[region] = df.to_dict(orient='records')
        
    filename = f'Production_overview_sum'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')




    # -------------------- Overview: Australia production achievement (%) --------------------
    quantity_diff = demand_files.query('base_name == "quantity_comparison"').reset_index(drop=True)
    quantity_diff = pd.concat([pd.read_csv(path) for path in quantity_diff['path']], ignore_index=True)
    quantity_diff = quantity_diff.replace({'Sheep lexp': 'Sheep live export', 'Beef lexp': 'Beef live export'})
    quantity_diff = quantity_diff[['Year','Commodity','Prop_diff (%)']].rename(columns={'Prop_diff (%)': 'Demand Achievement (%)'})

    mask_AUS = quantity_diff.groupby('Commodity'
        )['Demand Achievement (%)'
        ].transform(lambda x: abs(round(x) - 100) > 0.01)
    quantity_diff_AUS = quantity_diff[mask_AUS].copy()
    quantity_diff_wide_AUS = quantity_diff_AUS\
        .groupby(['Commodity'])[['Year','Demand Achievement (%)']]\
        .apply(lambda x: list(map(list,zip(x['Year'], x['Demand Achievement (%)']))))\
        .reset_index()
        
    quantity_diff_wide_AUS['type'] = 'line'
    quantity_diff_wide_AUS.columns = ['name','data', 'type']

    quantity_diff_wide_AUS_data = {
        'AUSTRALIA': quantity_diff_wide_AUS.to_dict(orient='records')
    }
    filename = 'Production_overview_AUS_achive_percent'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(quantity_diff_wide_AUS_data, f, separators=(',', ':'), indent=2)
        f.write(';\n')    
    
    
    
    
    # -------------------- Commodity production for ag --------------------
    df_wide = quantity_LUTO\
        .query(f'Type == "Agricultural"')\
        .groupby(['region', 'Water_supply', 'Commodity'])[['Year','Production (t/KL)']]\
        .apply(lambda x: x[['Year','Production (t/KL)']].values.tolist())\
        .reset_index()

    df_wide.columns = ['region', 'water', 'name', 'data']
    df_wide['type'] = 'column'
    df_wide['color'] = df_wide['name'].apply(lambda x: COLORS_COMMODITIES[x])
    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])

    out_dict = {}
    for (region, water), df in df_wide.groupby(['region', 'water']):
        df = df.drop(['region', 'water'], axis=1)
        if region not in out_dict:
            out_dict[region] = {}
        if water not in out_dict[region]:
            out_dict[region][water] = {}
        out_dict[region][water] = df.to_dict(orient='records')
        
    filename = f'Production_Ag'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')
        
    # -------------------- Commodity production for ag-man --------------------
    df_wide = quantity_LUTO\
        .query(f'Type == "Agricultural Management"')\
        .groupby(['region', 'am', 'Water_supply', 'Commodity'])[['Year','Production (t/KL)']]\
        .apply(lambda x: x[['Year','Production (t/KL)']].values.tolist())\
        .reset_index()

    df_wide.columns = ['region', '_type', 'water', 'name', 'data']
    df_wide['type'] = 'column'
    df_wide['color'] = df_wide['name'].apply(lambda x: COLORS_COMMODITIES[x])
    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])

    out_dict = {}
    for (region, _type, water), df in df_wide.groupby(['region', '_type', 'water']):
        df = df.drop(['region', '_type', 'water'], axis=1)
        if region not in out_dict:
            out_dict[region] = {}
        if _type not in out_dict[region]:
            out_dict[region][_type] = {}
        if water not in out_dict[region][_type]:
            out_dict[region][_type][water] = {}
        out_dict[region][_type][water] = df.to_dict(orient='records')
        
    filename = f'Production_Am'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')
        
        
    # -------------------- Commodity production for non-ag --------------------
    df_wide = quantity_LUTO\
        .query(f'Type == "Non-Agricultural"')\
        .groupby(['region', 'Commodity'])[['Year','Production (t/KL)']]\
        .apply(lambda x: x[['Year','Production (t/KL)']].values.tolist())\
        .reset_index()

    df_wide.columns = ['region', 'name', 'data']
    df_wide['type'] = 'column'
    df_wide['color'] = df_wide['name'].apply(lambda x: COLORS_COMMODITIES[x])
    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])

    out_dict = {}
    for region, df in df_wide.groupby('region'):
        df = df.drop(['region'], axis=1)
        out_dict[region] = df.to_dict(orient='records')
        
    filename = f'Production_NonAg'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')
            
            
    



    ####################################################
    #                  3) Economics                    #
    ####################################################
    
    # -------------------- Get the revenue and cost data --------------------
    revenue_ag_df = files.query('base_name == "revenue_ag"').reset_index(drop=True)
    revenue_ag_df = pd.concat([pd.read_csv(path) for path in revenue_ag_df['path']], ignore_index=True)
    revenue_ag_df = revenue_ag_df.replace(RENAME_AM_NON_AG).assign(Source='Agricultural land-use (revenue)')
    
    cost_ag_df = files.query('base_name == "cost_ag"').reset_index(drop=True)
    cost_ag_df = pd.concat([pd.read_csv(path) for path in cost_ag_df['path']], ignore_index=True)
    cost_ag_df = cost_ag_df.replace(RENAME_AM_NON_AG).assign(Source='Agricultural land-use (cost)')
    cost_ag_df['Value ($)'] = cost_ag_df['Value ($)'] * -1          # Convert cost to negative value
    
    revenue_am_df = files.query('base_name == "revenue_agricultural_management"').reset_index(drop=True)
    revenue_am_df = pd.concat([pd.read_csv(path) for path in revenue_am_df['path']], ignore_index=True)
    revenue_am_df = revenue_am_df.replace(RENAME_AM_NON_AG).assign(Source='Agricultural Management (revenue)')
    
    cost_am_df = files.query('base_name == "cost_agricultural_management"').reset_index(drop=True)
    cost_am_df = pd.concat([pd.read_csv(path) for path in cost_am_df['path']], ignore_index=True)
    cost_am_df = cost_am_df.replace(RENAME_AM_NON_AG).assign(Source='Agricultural Management (cost)')
    cost_am_df['Value ($)'] = cost_am_df['Value ($)'] * -1          # Convert cost to negative value

    revenue_non_ag_df = files.query('base_name == "revenue_non_ag"').reset_index(drop=True)
    revenue_non_ag_df = pd.concat([pd.read_csv(path) for path in revenue_non_ag_df['path']], ignore_index=True)
    revenue_non_ag_df = revenue_non_ag_df.replace(RENAME_AM_NON_AG).assign(Source='Non-agricultural land-use (revenue)')
    revenue_non_ag_df['Water_supply'] = 'NA'

    cost_non_ag_df = files.query('base_name == "cost_non_ag"').reset_index(drop=True)
    cost_non_ag_df = pd.concat([pd.read_csv(path) for path in cost_non_ag_df['path']], ignore_index=True)
    cost_non_ag_df = cost_non_ag_df.replace(RENAME_AM_NON_AG).assign(Source='Non-agricultural land-use (cost)')
    cost_non_ag_df['Value ($)'] = cost_non_ag_df['Value ($)'] * -1  # Convert cost to negative value
    cost_non_ag_df['Water_supply'] = 'NA'
    
    cost_transition_ag2ag_df = files.query('base_name == "cost_transition_ag2ag"').reset_index(drop=True)
    cost_transition_ag2ag_df = pd.concat([pd.read_csv(path) for path in cost_transition_ag2ag_df['path'] if not pd.read_csv(path).empty], ignore_index=True)
    cost_transition_ag2ag_df = cost_transition_ag2ag_df.replace(RENAME_AM_NON_AG).assign(Source='Transition cost (Ag2Ag)')
    cost_transition_ag2ag_df['Value ($)'] = cost_transition_ag2ag_df['Cost ($)']  * -1          # Convert cost to negative value
    cost_transition_ag2ag_df['Water_supply'] = 'NA'

    cost_transition_ag2non_ag_df = files.query('base_name == "cost_transition_ag2non_ag"').reset_index(drop=True)
    cost_transition_ag2non_ag_df = pd.concat([pd.read_csv(path) for path in cost_transition_ag2non_ag_df['path'] if not pd.read_csv(path).empty], ignore_index=True)
    cost_transition_ag2non_ag_df = cost_transition_ag2non_ag_df.replace(RENAME_AM_NON_AG).assign(Source='Transition cost (Ag2Non-Ag)')
    cost_transition_ag2non_ag_df['Value ($)'] = cost_transition_ag2non_ag_df['Cost ($)'] * -1   # Convert cost to negative value
    cost_transition_ag2non_ag_df['Water_supply'] = 'NA'

    cost_transition_non_ag2ag_df = files.query('base_name == "cost_transition_non_ag2_ag"').reset_index(drop=True)
    cost_transition_non_ag2ag_df = pd.concat([pd.read_csv(path) for path in cost_transition_non_ag2ag_df['path'] if not pd.read_csv(path).empty], ignore_index=True)
    cost_transition_non_ag2ag_df = cost_transition_non_ag2ag_df.replace(RENAME_AM_NON_AG).assign(Source='Transition cost (Non-Ag2Ag)').dropna(subset=['Cost ($)'])
    cost_transition_non_ag2ag_df['Value ($)'] = cost_transition_non_ag2ag_df['Cost ($)'] * -1   # Convert cost to negative value
    cost_transition_non_ag2ag_df['Water_supply'] = 'NA'

    economics_df = pd.concat(
            [
                revenue_ag_df, 
                revenue_am_df, 
                revenue_non_ag_df,
                cost_ag_df, 
                cost_am_df, 
                cost_non_ag_df,
                cost_transition_ag2ag_df, 
                cost_transition_ag2non_ag_df,
                cost_transition_non_ag2ag_df
            ]
        ).round({'Value ($)': 2}
        ).query('abs(`Value ($)`) > 1e-6'
        ).reset_index(drop=True) 
        
    order = [
        'Agricultural land-use (revenue)', 
        'Agricultural Management (revenue)', 
        'Non-agricultural land-use (revenue)',
        'Agricultural land-use (cost)', 
        'Agricultural Management (cost)', 
        'Non-agricultural land-use (cost)',
        'Transition cost (Ag2Ag)',
        'Transition cost (Ag2Non-Ag)',
        'Transition cost (Non-Ag2Ag)',
        'Profit'
    ]


    # -------------------- Economic ranking --------------------
    revenue_df = pd.concat([revenue_ag_df, revenue_am_df, revenue_non_ag_df]
        ).groupby(['Year', 'region']
        )[['Value ($)']].sum(numeric_only=True
        ).reset_index(
        ).sort_values(['Year', 'Value ($)'], ascending=[True, False]
        ).assign(Rank=lambda x: x.groupby(['Year']).cumcount()
        ).assign(Source='Revenue'
        ).round({'Percent': 2})
    cost_df = pd.concat([cost_ag_df, cost_am_df, cost_non_ag_df]
        ).groupby(['Year', 'region']
        )[['Value ($)']].sum(numeric_only=True
        ).reset_index(
        ).assign(**{'Value ($)': lambda x: abs(x['Value ($)'])}
        ).sort_values(['Year', 'Value ($)'], ascending=[True, False]
        ).assign(Rank=lambda x: x.groupby(['Year']).cumcount()
        ).assign(Source='Cost'
        ).round({ 'Percent': 2}) 
    profit_df = revenue_df.merge(
        cost_df, on=['Year', 'region'], suffixes=('_revenue', '_cost')
        ).assign(**{'Value ($)': lambda x: x['Value ($)_revenue'] - x['Value ($)_cost']}
        ).drop(columns=['Value ($)_revenue', 'Value ($)_cost']
        ).sort_values(['Year', 'Value ($)'], ascending=[True, False]
        ).assign(Rank=lambda x: x.groupby(['Year']).cumcount()
        ).assign(Source='Total'
        ).round({'Value ($)': 2})

    ranking_df = pd.concat([revenue_df, cost_df, profit_df]).assign(color= lambda x: x['Rank'].map(get_rank_color))
        

    out_dict = {}
    for (region, source), df in ranking_df.groupby(['region', 'Source']):
        if region not in out_dict:
            out_dict[region] = {}
        if not source in out_dict[region]:
            out_dict[region][source] = {}
        
        df = df.drop(columns='region')
        out_dict[region][source]['Rank'] = df.set_index('Year')['Rank'].replace({np.nan: None}).to_dict()
        out_dict[region][source]['color'] = df.set_index('Year')['color'].replace({np.nan: None}).to_dict()
        out_dict[region][source]['value'] = df.set_index('Year')['Value ($)'].apply( lambda x: format_with_suffix(x)).to_dict()

    filename = 'Economics_ranking'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')
        

    # -------------------- Economy overview --------------------

    # Overview: sum of revenue, cost, and profit by region
    rev_cost_net_region = economics_df.groupby(['region', 'Source', 'Year']
        )[['Value ($)']].sum(numeric_only=True
        ).reset_index()
        
    dfs = []
    for region, df in rev_cost_net_region.groupby('region'):
        df_col = df.groupby(['Source'])[['Year','Value ($)']]\
            .apply(lambda x: x[['Year', 'Value ($)']].values.tolist())\
            .reset_index()
        df_col.columns = ['name','data']
        df_col['type'] = 'column'
        
        df_col.loc[len(df_col)] = [
            'Profit',
            df.groupby(['Year'])[['Value ($)']].sum(numeric_only=True).reset_index().values.tolist(),
            'line',
        ]
        df_col['region'] = region
        dfs.append(df_col)

    rev_cost_wide_json = pd.concat(dfs, ignore_index=True)
    rev_cost_wide_json['name_order'] = rev_cost_wide_json['name'].map({name: i for i, name in enumerate(order)})
    rev_cost_wide_json = rev_cost_wide_json.sort_values(['region', 'name_order']).drop(columns=['name_order']).reset_index(drop=True)


    out_dict = {}
    for region,df in rev_cost_wide_json.groupby('region'):
        df = df.drop(columns='region')
        df.columns = ['name','data','type']
        out_dict[region] = df.to_dict(orient='records')
        
    filename = 'Economics_overview_sum'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')
    
    
    # Overview: ag cost/revenue by type
    economics_ag = pd.concat([revenue_ag_df, cost_ag_df])\
        .query('Type != "ALL" and abs(`Value ($)`) > 1')\
        .groupby(['region', 'Type', 'Water_supply','Year'])['Value ($)']\
        .sum()\
        .reset_index()\
        .round({'Value ($)': 2})
  
    
    df_wide = economics_ag\
        .groupby(['region', 'Type', 'Water_supply'])[['Year', 'Value ($)']]\
        .apply(lambda x: x[['Year', 'Value ($)']].values.tolist())\
        .reset_index()
    df_wide.columns = ['region', 'name', 'water', 'data']
    df_wide['type'] = 'column'
    df_wide['color'] = df_wide.apply(lambda x: COLORS_ECONOMY_TYPE[x['name']], axis=1)
    df_wide['name_order'] = df_wide['name'].apply(lambda x: list(COLORS_ECONOMY_TYPE.keys()).index(x) if x in COLORS_ECONOMY_TYPE else -1)
    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])


    out_dict = {}
    for (region, water), df in df_wide.groupby(['region', 'water']):
        df = df.drop(['region', 'water'], axis=1)
        if region not in out_dict:
            out_dict[region] = {}
        if water not in out_dict[region]:
            out_dict[region][water] = {}
        out_dict[region][water] = df.to_dict(orient='records')
        
    filename = f'Economics_overview_Ag'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')
        
    
    # Overview: ag-man cost/revenue by type
    economics_am = pd.concat([
            revenue_am_df.assign(Rev_Cost='Revenue'), 
            cost_am_df.assign(Rev_Cost='Cost'),]
        ).query('`Management Type` != "ALL" and abs(`Value ($)`) > 1'
        ).round({'Value ($)': 2}
        ).groupby(['region', 'Management Type', 'Water_supply', 'Rev_Cost', 'Year'])[['Value ($)']
        ].sum(
        ).reset_index()
    
    df_wide = economics_am.groupby(['region', 'Management Type', 'Water_supply', 'Rev_Cost'])[[ 'Year', 'Value ($)']]\
        .apply(lambda x: x[['Year', 'Value ($)']].values.tolist())\
        .reset_index()
        
    df_wide.columns = ['region', 'name', 'water', 'Rev_Cost', 'data']
    df_wide['type'] = 'column'
    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)
    df_wide['id'] = df_wide.apply(lambda x: x['name'] if x['Rev_Cost'] == 'Revenue' else None, axis=1)
    df_wide['linkedTo'] = df_wide.apply(lambda x: x['name'] if x['Rev_Cost'] == 'Cost' else None, axis=1)
    df_wide.loc[df_wide['name'] == 'Early dry-season savanna burning', 'linkedTo'] = None


    out_dict = {}
    for (region, water), df in df_wide.groupby(['region', 'water']):
        df = df.drop(['region', 'water', 'Rev_Cost'], axis=1)
        if region not in out_dict:
            out_dict[region] = {}
        if water not in out_dict[region]:
            out_dict[region][water] = {}
        out_dict[region][water] = df.to_dict(orient='records')
        
    filename = f'Economics_overview_Am'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')
        
        
    # Overview: non-ag cost/revenue by type
    economics_non_ag = pd.concat([
            revenue_non_ag_df.assign(Rev_Cost='Revenue'), 
            cost_non_ag_df.assign(Rev_Cost='Cost')]
        ).query('abs(`Value ($)`) > 1'
        ).round({'Value ($)': 2}
        ).groupby(['region', 'Land-use', 'Rev_Cost', 'Year'])[['Value ($)']
        ].sum(
        ).reset_index()
    
    df_wide = economics_non_ag.groupby(['region', 'Land-use', 'Rev_Cost'])[['Year','Value ($)']]\
        .apply(lambda x: x[['Year', 'Value ($)']].values.tolist())\
        .reset_index()
    df_wide.columns = ['region', 'name', 'Rev_Cost', 'data']
    df_wide['type'] = 'column'
    
    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
    df_wide['id'] = df_wide.apply(lambda x: x['name'] if x['Rev_Cost'] == 'Revenue' else None, axis=1)
    df_wide['linkedTo'] = df_wide.apply(lambda x: x['name'] if x['Rev_Cost'] == 'Cost' else None, axis=1)
    df_wide.loc[df_wide['name'].isin([
        'Environmental plantings (mixed species)',
        'Riparian buffer restoration (mixed species)',
        'Carbon plantings (monoculture)',
        'Destocked - natural land'
        ]), 'linkedTo'] = None

    
    out_dict = {}
    for region, df in df_wide.groupby('region'):
        df = df.drop(['region','Rev_Cost'], axis=1)
        out_dict[region] = df.to_dict(orient='records')

    filename = f'Economics_overview_Non_Ag'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')
 
 
 
 
    # -------------------- Economics for ag --------------------
    revenue_ag_df = revenue_ag_df.assign(Rev_Cost='Revenue')
    cost_ag_df = cost_ag_df.assign(Rev_Cost='Cost')

    economics_ag = pd.concat([revenue_ag_df, cost_ag_df]
        ).round({'Value ($)': 2}
        ).query('abs(`Value ($)`) > 1'
        ).reset_index(drop=True)

    df_wide = economics_ag\
        .groupby(['region', 'Type', 'Water_supply', 'Rev_Cost', 'Land-use'])[['Year','Value ($)']]\
        .apply(lambda x: x[['Year', 'Value ($)']].values.tolist())\
        .reset_index()\
        .round({'Value ($)': 2})

    df_wide.columns = ['region', '_type', 'water', 'Rev_Cost', 'name', 'data']
    df_wide['type'] = 'column'
    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
    df_wide['id'] = df_wide.apply(lambda x: x['name'] if x['Rev_Cost'] == 'Revenue' else None, axis=1)
    df_wide['linkedTo'] = df_wide.apply(lambda x: x['name'] if x['Rev_Cost'] == 'Cost' else None, axis=1)


    out_dict = {}
    for (region, _type, water), df in df_wide.groupby(['region', '_type', 'water']):
        df = df.drop(['region', '_type', 'water', 'Rev_Cost'], axis=1)
        if region not in out_dict:
            out_dict[region] = {}
        if _type not in out_dict[region]:
            out_dict[region][_type] = {}
        if water not in out_dict[region][_type]:
            out_dict[region][_type][water] = {}
        out_dict[region][_type][water] = df.to_dict(orient='records')
        
    filename = 'Economics_Ag'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')
    


    # -------------------- Economics for ag-management --------------------
    revenue_am_df = revenue_am_df.assign(Rev_Cost='Revenue')
    cost_am_df = cost_am_df.assign(Rev_Cost='Cost')

    economics_am = pd.concat([revenue_am_df, cost_am_df]
        ).round({'Value ($)': 2}
        ).query('abs(`Value ($)`) > 1'
        ).reset_index(drop=True)

    df_wide = economics_am\
        .groupby(['region', 'Management Type', 'Water_supply', 'Land-use', 'Rev_Cost'])[['Year', 'Value ($)']]\
        .apply(lambda x: x[['Year', 'Value ($)']].values.tolist())\
        .reset_index()\
        .round({'Value ($)': 2})
  
    df_wide.columns = ['region', '_type', 'water', 'name', 'Rev_Cost', 'data']
    df_wide['type'] = 'column'
    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
    df_wide['id'] = df_wide.apply(lambda x: x['name'] if x['Rev_Cost'] == 'Revenue' else None, axis=1)
    df_wide['linkedTo'] = df_wide.apply(lambda x: x['name'] if x['Rev_Cost'] == 'Cost' else None, axis=1)
    df_wide.loc[df_wide['name'] == 'Early dry-season savanna burning', 'linkedTo'] = None

    
    out_dict = {}
    for (region,_type,water), df in df_wide.groupby(['region', '_type', 'water']):
        df = df.drop(['region', '_type', 'water','Rev_Cost'], axis=1)
        if region not in out_dict:
            out_dict[region] = {}
        if _type not in out_dict[region]:
            out_dict[region][_type] = {}
        if water not in out_dict[region][_type]:
            out_dict[region][_type][water] = {}
        out_dict[region][_type][water] = df.to_dict(orient='records')
        
    filename = f'Economics_Am'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')


    # -------------------- Economics for non-agriculture --------------------

    # This is the same as the "Economics_overview_Non_Ag" 




    # # -------------------- Transition cost for Ag2Ag --------------------
    # cost_transition_ag2ag_df['Value ($)'] = cost_transition_ag2ag_df['Value ($)'] * -1  # Convert from negative to positive
    # group_cols = ['Type', 'From land-use', 'To land-use']
    
    # for idx, col in enumerate(group_cols):
    #     df_AUS = cost_transition_ag2ag_df\
    #         .groupby(['Year', col])[['Value ($)']]\
    #         .sum()\
    #         .reset_index()\
    #         .round({'Value ($)': 2})
    #     df_AUS_wide = df_AUS.groupby([col])[['Year','Value ($)']]\
    #         .apply(lambda x: x[['Year', 'Value ($)']].values.tolist())\
    #         .reset_index()\
    #         .assign(region='AUSTRALIA')
    #     df_AUS_wide.columns = ['name', 'data','region']
    #     df_AUS_wide['type'] = 'column'

    #     df_region = cost_transition_ag2ag_df\
    #         .groupby(['Year', 'region', col])\
    #         .sum()\
    #         .reset_index()\
    #         .round({'Value ($)': 2})
    #     df_region_wide = df_region.groupby([col, 'region'])[['Year','Value ($)']]\
    #         .apply(lambda x: x[['Year', 'Value ($)']].values.tolist())\
    #         .reset_index()
    #     df_region_wide.columns = ['name', 'region', 'data']
    #     df_region_wide['type'] = 'column'
        
        
    #     df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
        
    #     out_dict = {}
    #     for region, df in df_wide.groupby('region'):
    #         df = df.drop(['region'], axis=1)
    #         out_dict[region] = df.to_dict(orient='records')
            
    #     filename = f'Economics_transition_split_ag2ag_{idx+1}_{col.replace(" ", "_")}'
    #     with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
    #         f.write(f'window["{filename}"] = ')
    #         json.dump(out_dict, f, separators=(',', ':'), indent=2)
    #         f.write(';\n')
      

    # # -------------------- Transition cost matrix for Ag2Ag --------------------
    # cost_transition_ag2ag_trans_mat_AUS = cost_transition_ag2ag_df\
    #     .groupby(['Year','From land-use', 'To land-use'])\
    #     .sum(numeric_only=True)\
    #     .reset_index()\
    #     .round({'Value ($)': 2})\
    #     .query('abs(`Value ($)`) > 1e-6')\
    #     .assign(region='AUSTRALIA')

    # cost_transition_ag2ag_trans_mat_region_df = cost_transition_ag2ag_df\
    #     .groupby(['Year','From land-use', 'To land-use', 'region'])\
    #     .sum(numeric_only=True)\
    #     .reset_index()\
    #     .round({'Value ($)': 2})
        
        
    # cost_transition_ag2ag_trans_mat = pd.concat([
    #     cost_transition_ag2ag_trans_mat_AUS,
    #     cost_transition_ag2ag_trans_mat_region_df
    # ])


    # out_dict_area = {}
    # for (region,year),df in cost_transition_ag2ag_trans_mat.groupby(['region', 'Year']):
        
    #     out_dict_area.setdefault(region, {})
        
    #     transition_mat = df.pivot(index='From land-use', columns='To land-use', values='Value ($)')
    #     transition_mat = transition_mat.reindex(index=AG_LANDUSE, columns=AG_LANDUSE)
    #     transition_mat = transition_mat.fillna(0)
    #     total_area_from = transition_mat.sum(axis=1).values.reshape(-1, 1)
        
    #     transition_mat['SUM'] = transition_mat.sum(axis=1)
    #     transition_mat.loc['SUM'] = transition_mat.sum(axis=0)

    #     heat_area = transition_mat.style.background_gradient(
    #         cmap='Oranges',
    #         axis=1,
    #         subset=pd.IndexSlice[:transition_mat.index[-2], :transition_mat.columns[-2]]
    #     ).format('{:,.0f}')

    #     heat_area_html = heat_area.to_html()
    #     heat_area_html = re.sub(r'(?<!\d)0(?!\d)', '-', heat_area_html)

    #     out_dict_area[region][str(year)] = rf'{heat_area_html}'

    # filename = 'Economics_transition_mat_ag2ag'
    # with open(f'{SAVE_DIR}/{filename}.js', 'w', encoding='utf-8') as f:
    #     f.write(f'window["{filename}"] = ')
    #     json.dump(out_dict_area, f, separators=(',', ':'), indent=2)
    #     f.write(';\n')






    # # -------------------- Transition cost for Ag2Non-Ag --------------------
    # cost_transition_ag2non_ag_df['Value ($)'] = cost_transition_ag2non_ag_df['Value ($)'] * -1  # Convert from negative to positive
    # group_cols = ['Cost type', 'From land-use', 'To land-use']
    
    # for idx, col in enumerate(group_cols):
    #     df_AUS = cost_transition_ag2non_ag_df\
    #         .groupby(['Year', col])[['Value ($)']]\
    #         .sum()\
    #         .reset_index()\
    #         .round({'Value ($)': 2})
    #     df_AUS_wide = df_AUS.groupby([col])[['Year','Value ($)']]\
    #         .apply(lambda x: x[['Year', 'Value ($)']].values.tolist())\
    #         .reset_index()\
    #         .assign(region='AUSTRALIA')
    #     df_AUS_wide.columns = ['name', 'data','region']
    #     df_AUS_wide['type'] = 'column'

    #     df_region = cost_transition_ag2non_ag_df\
    #         .groupby(['Year', 'region', col])\
    #         .sum()\
    #         .reset_index()\
    #         .round({'Value ($)': 2})
    #     df_region_wide = df_region.groupby([col, 'region'])[['Year','Value ($)']]\
    #         .apply(lambda x: x[['Year', 'Value ($)']].values.tolist())\
    #         .reset_index()
    #     df_region_wide.columns = ['name', 'region', 'data']
    #     df_region_wide['type'] = 'column'
        
        
    #     df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
        
    #     out_dict = {}
    #     for region, df in df_wide.groupby('region'):
    #         df = df.drop(['region'], axis=1)
    #         out_dict[region] = df.to_dict(orient='records')
            
    #     filename = f'Economics_transition_split_Ag2NonAg_{idx+1}_{col.replace(" ", "_")}'
    #     with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
    #         f.write(f'window["{filename}"] = ')
    #         json.dump(out_dict, f, separators=(',', ':'), indent=2)
    #         f.write(';\n')
        
  
    # # -------------------- Transition cost matrix for Ag2Non-Ag --------------------
    # cost_transition_ag2nonag_trans_mat_AUS = cost_transition_ag2non_ag_df\
    #     .groupby(['Year','From land-use', 'To land-use'])\
    #     .sum(numeric_only=True)\
    #     .reset_index()\
    #     .round({'Value ($)': 2})\
    #     .assign(region='AUSTRALIA')

    # cost_transition_ag2nonag_trans_mat_region_df = cost_transition_ag2non_ag_df\
    #     .groupby(['Year','From land-use', 'To land-use', 'region'])\
    #     .sum(numeric_only=True)\
    #     .reset_index()\
    #     .round({'Value ($)': 2})
        
        
    # cost_transition_ag2nonag_trans_mat = pd.concat([
    #     cost_transition_ag2nonag_trans_mat_AUS,
    #     cost_transition_ag2nonag_trans_mat_region_df
    # ])


    # out_dict_area = {}
    # for (region,year),df in cost_transition_ag2nonag_trans_mat.groupby(['region', 'Year']):
        
    #     out_dict_area.setdefault(region, {})
        
    #     transition_mat = df.pivot(index='From land-use', columns='To land-use', values='Value ($)')
    #     transition_mat = transition_mat.reindex(index=AG_LANDUSE, columns=RENAME_NON_AG.values())
    #     transition_mat = transition_mat.fillna(0)
    #     total_area_from = transition_mat.sum(axis=1).values.reshape(-1, 1)
        
    #     transition_mat['SUM'] = transition_mat.sum(axis=1)
    #     transition_mat.loc['SUM'] = transition_mat.sum(axis=0)

    #     heat_area = transition_mat.style.background_gradient(
    #         cmap='Oranges',
    #         axis=1,
    #         subset=pd.IndexSlice[:transition_mat.index[-2], :transition_mat.columns[-2]]
    #     ).format('{:,.0f}')

    #     heat_area_html = heat_area.to_html()
    #     heat_area_html = re.sub(r'(?<!\d)0(?!\d)', '-', heat_area_html)

    #     out_dict_area[region][str(year)] = rf'{heat_area_html}'

    # filename = 'Economics_transition_mat_ag2nonag'
    # with open(f'{SAVE_DIR}/{filename}.js', 'w', encoding='utf-8') as f:
    #     f.write(f'window["{filename}"] = ')
    #     json.dump(out_dict_area, f, separators=(',', ':'), indent=2)
    #     f.write(';\n')
    
    
    
    

    # # -------------------- Transition cost for Non-Ag to Ag --------------------
    # cost_transition_non_ag2ag_df['Value ($)'] = cost_transition_non_ag2ag_df['Value ($)'] * -1  # Convert from negative to positive
    # group_cols = ['Cost type', 'From land-use', 'To land-use']
    
    # for idx, col in enumerate(group_cols):
    #     df_AUS = cost_transition_non_ag2ag_df\
    #         .groupby(['Year', col])[['Value ($)']]\
    #         .sum()\
    #         .reset_index()\
    #         .round({'Value ($)': 2})
    #     df_AUS_wide = df_AUS.groupby([col])[['Year','Value ($)']]\
    #         .apply(lambda x: x[['Year', 'Value ($)']].values.tolist())\
    #         .reset_index()\
    #         .assign(region='AUSTRALIA')
    #     df_AUS_wide.columns = ['name', 'data','region']
    #     df_AUS_wide['type'] = 'column'

    #     df_region = cost_transition_non_ag2ag_df\
    #         .groupby(['Year', 'region', col])\
    #         .sum()\
    #         .reset_index()\
    #         .round({'Value ($)': 2})
    #     df_region_wide = df_region.groupby([col, 'region'])[['Year','Value ($)']]\
    #         .apply(lambda x: x[['Year', 'Value ($)']].values.tolist())\
    #         .reset_index()
    #     df_region_wide.columns = ['name', 'region', 'data']
    #     df_region_wide['type'] = 'column'
        
        
    #     df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
        
    #     out_dict = {}
    #     for region, df in df_wide.groupby('region'):
    #         df = df.drop(['region'], axis=1)
    #         out_dict[region] = df.to_dict(orient='records')
            
    #     filename = f'Economics_transition_split_NonAg2Ag_{idx+1}_{col.replace(" ", "_")}'
    #     with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
    #         f.write(f'window["{filename}"] = ')
    #         json.dump(out_dict, f, separators=(',', ':'), indent=2)
    #         f.write(';\n')
    
    
    
    # # -------------------- Transition cost matrix for Non-Ag to Ag --------------------
    # cost_transition_nonag2ag_trans_mat_AUS = cost_transition_non_ag2ag_df\
    #     .groupby(['Year','From land-use', 'To land-use'])\
    #     .sum(numeric_only=True)\
    #     .reset_index()\
    #     .round({'Value ($)': 2})\
    #     .assign(region='AUSTRALIA')

    # cost_transition_nonag2ag_trans_mat_region_df = cost_transition_non_ag2ag_df\
    #     .groupby(['Year','From land-use', 'To land-use', 'region'])\
    #     .sum(numeric_only=True)\
    #     .reset_index()\
    #     .round({'Value ($)': 2})
        
        
    # cost_transition_nonag2ag_trans_mat = pd.concat([
    #     cost_transition_nonag2ag_trans_mat_AUS,
    #     cost_transition_nonag2ag_trans_mat_region_df
    # ])


    # out_dict_area = {}
    # for (region,year),df in cost_transition_nonag2ag_trans_mat.groupby(['region', 'Year']):
        
    #     out_dict_area.setdefault(region, {})
        
    #     transition_mat = df.pivot(index='From land-use', columns='To land-use', values='Value ($)')
    #     transition_mat = transition_mat.reindex(index=RENAME_NON_AG.values(), columns=AG_LANDUSE)
    #     transition_mat = transition_mat.fillna(0)
    #     total_area_from = transition_mat.sum(axis=1).values.reshape(-1, 1)
        
    #     transition_mat['SUM'] = transition_mat.sum(axis=1)
    #     transition_mat.loc['SUM'] = transition_mat.sum(axis=0)

    #     heat_area = transition_mat.style.background_gradient(
    #         cmap='Oranges',
    #         axis=1,
    #         subset=pd.IndexSlice[:transition_mat.index[-2], :transition_mat.columns[-2]]
    #     ).format('{:,.0f}')

    #     heat_area_html = heat_area.to_html()
    #     heat_area_html = re.sub(r'(?<!\d)0(?!\d)', '-', heat_area_html)

    #     out_dict_area[region][str(year)] = rf'{heat_area_html}'

    # filename = 'Economics_transition_mat_nonag2ag'
    # with open(f'{SAVE_DIR}/{filename}.js', 'w', encoding='utf-8') as f:
    #     f.write(f'window["{filename}"] = ')
    #     json.dump(out_dict_area, f, separators=(',', ':'), indent=2)
    #     f.write(';\n')




    ####################################################
    #                       4) GHGs                    #
    ####################################################
    if settings.GHG_EMISSIONS_LIMITS != 'off':
        filter_str = '''
        category == "GHG" 
        and base_name.str.contains("GHG_emissions") 
       
        '''.replace('\n', ' ').replace('  ', ' ')

        GHG_files = files.query(filter_str).reset_index(drop=True)

        GHG_ag = GHG_files.query('base_name.str.contains("agricultural_landuse")').reset_index(drop=True)
        GHG_ag = pd.concat([pd.read_csv(path) for path in GHG_ag['path']], ignore_index=True)
        GHG_ag = GHG_ag.replace(GHG_NAMES).round({'Value (t CO2e)': 2})
        
        GHG_non_ag = GHG_files.query('base_name.str.contains("no_ag_reduction")').reset_index(drop=True)
        GHG_non_ag = pd.concat([pd.read_csv(path) for path in GHG_non_ag['path'] if not pd.read_csv(path).empty], ignore_index=True)
        GHG_non_ag = GHG_non_ag.replace(RENAME_AM_NON_AG).round({'Value (t CO2e)': 2})
        GHG_non_ag['Water_supply'] = 'NA'
        
        GHG_ag_man = GHG_files.query('base_name.str.contains("agricultural_management")').reset_index(drop=True)
        GHG_ag_man = pd.concat([pd.read_csv(path) for path in GHG_ag_man['path'] if not pd.read_csv(path).empty], ignore_index=True)
        GHG_ag_man = GHG_ag_man.replace(RENAME_AM_NON_AG).round({'Value (t CO2e)': 2})
        
        GHG_transition = GHG_files.query('base_name.str.contains("transition_penalty")').reset_index(drop=True)
        GHG_transition = pd.concat([pd.read_csv(path) for path in GHG_transition['path'] if not pd.read_csv(path).empty], ignore_index=True)
        GHG_transition = GHG_transition.replace(RENAME_AM_NON_AG).round({'Value (t CO2e)': 2})

        GHG_off_land = GHG_files.query('base_name.str.contains("offland_commodity")')
        GHG_off_land = pd.concat([pd.read_csv(path) for path in GHG_off_land['path']], ignore_index=True).round({'Value (t CO2e)': 2})
        GHG_off_land['Value (t CO2e)'] = GHG_off_land['Total GHG Emissions (tCO2e)']
        GHG_off_land['Commodity'] = GHG_off_land['COMMODITY'].apply(lambda x: x[0].capitalize() + x[1:])
        GHG_off_land = GHG_off_land.drop(columns=['COMMODITY', 'Total GHG Emissions (tCO2e)'])
        GHG_off_land['Emission Source'] = GHG_off_land['Emission Source']\
            .replace({
                'CO2': 'Carbon Dioxide (CO2)',
                'CH4': 'Methane (CH4)',
                'N2O': 'Nitrous Oxide (N2O)'
            })
   
        GHG_land = pd.concat([GHG_ag, GHG_non_ag, GHG_ag_man, GHG_transition], axis=0).query('abs(`Value (t CO2e)`) > 1e-6').reset_index(drop=True)
        GHG_land['Land-use type'] = GHG_land['Land-use'].apply(lu_group.set_index('Land-use')['Category'].to_dict().get)
        net_land = GHG_land.query('region == "AUSTRALIA" and Water_supply != "ALL"').groupby('Year')[['Value (t CO2e)']].sum(numeric_only=True).reset_index()


        GHG_limit = GHG_files.query('base_name == "GHG_emissions"')
        GHG_limit = pd.concat([pd.read_csv(path) for path in GHG_limit['path']], ignore_index=True)
        GHG_limit = GHG_limit.query('Variable == "GHG_EMISSIONS_LIMIT_TCO2e"').copy()
        GHG_limit['Value (t CO2e)'] = GHG_limit['Emissions (t CO2e)']
        GHG_limit_wide = list(map(list,zip(GHG_limit['Year'],GHG_limit['Value (t CO2e)'])))
        
        order_GHG = [
            'Agricultural land-use',
            'Agricultural Management',
            'Non-Agricultural land-use',
            'Off-land emissions',
            'Unallocated natural to modified',
            'Unallocated natural to livestock natural',
            'Livestock natural to modified',
            'Net emissions',
            'GHG emission limit'
        ]
   

        # -------------------- GHG overview --------------------
        net_offland_AUS = GHG_off_land.groupby('Year')[['Value (t CO2e)']].sum(numeric_only=True).reset_index()
        net_offland_AUS_wide = net_offland_AUS[['Year','Value (t CO2e)']].values.tolist()
        
        net_land_AUS_wide = GHG_land\
            .query('region == "AUSTRALIA" and Water_supply != "ALL"')\
            .groupby(['Year','Type'])[['Value (t CO2e)']]\
            .sum(numeric_only=True)\
            .reset_index()\
            .groupby(['Type'])[['Year','Value (t CO2e)']]\
            .apply(lambda x:x[['Year', 'Value (t CO2e)']].values.tolist())\
            .reset_index()
        net_land_AUS_wide.columns = ['name','data']
        net_land_AUS_wide['type'] = 'column'
            
        net_land_AUS_wide.loc[len(net_land_AUS_wide)] = [
            'Off-land emissions', 
            net_offland_AUS_wide, 
            'column'
        ]
        net_land_AUS_wide.loc[len(net_land_AUS_wide)] = [
            'Net emissions',
            list(zip(years, (net_land['Value (t CO2e)'] + net_offland_AUS['Value (t CO2e)']))),
            'line'
        ]
        net_land_AUS_wide.loc[len(net_land_AUS_wide)] = [
            'GHG emission limit',
            GHG_limit_wide,
            'line'
        ]

        net_land_AUS_wide['name_order'] = net_land_AUS_wide['name'].apply(lambda x: order_GHG.index(x))
        net_land_AUS_wide = net_land_AUS_wide.sort_values('name_order').drop(columns=['name_order'])
        
        GHG_AUS_overview = {'AUSTRALIA': json.loads(net_land_AUS_wide.to_json(orient='records'))}
        
        GHG_region = {}
        for region,df in GHG_land.query('region != "AUSTRALIA"').groupby('region'):
            df_reg = df\
                .groupby(['Year','Type'])[['Value (t CO2e)']]\
                .sum(numeric_only=True)\
                .reset_index()
            df_reg = df_reg\
                .groupby(['Type'])[['Year','Value (t CO2e)']]\
                .apply(lambda x:x[['Year', 'Value (t CO2e)']].values.tolist())\
                .reset_index()
            df_reg.columns = ['name','data']
            df_reg['type'] = 'column'
            
            df_reg.loc[len(df_reg)] = [
                'Net emissions', 
                list(zip(years, (df.groupby('Year')['Value (t CO2e)'].sum().values))),
                'line'
            ]

            df_reg['name_order'] = df_reg['name'].apply(lambda x: order_GHG.index(x))
            df_reg = df_reg.sort_values('name_order').drop(columns=['name_order'])
            GHG_region[region] = json.loads(df_reg.to_json(orient='records'))
            
            
        GHG_json = {**GHG_AUS_overview,  **GHG_region}
        filename = 'GHG_overview'
        with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
            f.write(f'window["{filename}"] = ')
            json.dump(GHG_json, f, separators=(',', ':'), indent=2)
            f.write(';\n')


        # -------------------- GHG ranking --------------------
        GHG_rank_emission_region = GHG_land\
            .query('`Value (t CO2e)` > 0')\
            .groupby(['Year', 'region'])\
            .sum(numeric_only=True)\
            .reset_index()\
            .sort_values(['Year', 'Value (t CO2e)'], ascending=[True, False])\
            .assign(Rank=lambda x: x.groupby(['Year']).cumcount())\
            .assign(Type='GHG emissions')
        GHG_rank_sequestration_region = GHG_land\
            .query('`Value (t CO2e)` < 0')\
            .assign(**{'Value (t CO2e)': lambda x: abs(x['Value (t CO2e)'])})\
            .groupby(['Year', 'region'])\
            .sum(numeric_only=True)\
            .reset_index()\
            .sort_values(['Year', 'Value (t CO2e)'], ascending=[True, False])\
            .assign(Rank=lambda x: x.groupby(['Year']).cumcount())\
            .assign(Type='GHG sequestrations')
        GHG_rank_region_net = GHG_rank_emission_region\
            .merge(GHG_rank_sequestration_region, on=['Year', 'region'], how='outer', suffixes=('_emission', '_sequestration'))\
            .assign(**{'Value (t CO2e)': lambda x: x['Value (t CO2e)_emission'] - x['Value (t CO2e)_sequestration']})\
            .assign(Type='Total')


        GHG_rank = pd.concat([
            GHG_rank_emission_region, 
            GHG_rank_sequestration_region, 
            GHG_rank_region_net,
            ], axis=0, ignore_index=True).reset_index(drop=True)\
            .round({'Value (t CO2e)':2})\
            .assign(color=lambda x: x['Rank'].map(get_rank_color))
     

        out_dict = {}
        for (region, e_type), df in GHG_rank.groupby(['region', 'Type']):
            if region not in out_dict:
                out_dict[region] = {}
            if e_type not in out_dict[region]:
                out_dict[region][e_type] = {}

            df = df.drop(columns='region')
            out_dict[region][e_type]['Rank'] = df.set_index('Year')['Rank'].replace({np.nan: None}).to_dict()
            out_dict[region][e_type]['color'] = df.set_index('Year')['color'].replace({np.nan: None}).to_dict()
            out_dict[region][e_type]['value'] = df.set_index('Year')['Value (t CO2e)'].apply( lambda x: format_with_suffix(x)).to_dict()

        filename = 'GHG_ranking'
        with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
            f.write(f'window["{filename}"] = ')
            json.dump(out_dict, f, separators=(',', ':'), indent=2)
            f.write(';\n')
            
            



        # -------------------- GHG by agricultural land-use --------------------
        GHG_ag = GHG_land.query('Type == "Agricultural land-use"') 
        GHG_CO2 = GHG_ag.query('~Source.isin(@GHG_CATEGORY.keys())').copy()
        GHG_CO2['GHG Category'] = 'CO2'

        GHG_nonCO2 = GHG_ag.query('Source.isin(@GHG_CATEGORY.keys())').copy()
        GHG_nonCO2['GHG Category'] = GHG_nonCO2['Source'].apply(lambda x: GHG_CATEGORY[x].keys())
        GHG_nonCO2['Multiplier'] = GHG_nonCO2['Source'].apply(lambda x: GHG_CATEGORY[x].values())
        GHG_nonCO2 = GHG_nonCO2.explode(['GHG Category','Multiplier']).reset_index(drop=True)
        GHG_nonCO2['Value (t CO2e)'] = GHG_nonCO2['Value (t CO2e)'] * GHG_nonCO2['Multiplier']
        GHG_nonCO2 = GHG_nonCO2.drop(columns=['Multiplier'])

        GHG_ag_emissions_long = pd.concat([GHG_CO2, GHG_nonCO2], axis=0).reset_index(drop=True)
        GHG_ag_emissions_long['GHG Category'] = GHG_ag_emissions_long['GHG Category']\
            .replace({
                'CH4': 'Methane (CH4)', 
                'N2O': 'Nitrous Oxide (N2O)', 
                'CO2': 'Carbon Dioxide (CO2)'
            })

        df_wide = GHG_ag_emissions_long\
            .groupby(['region', 'Source', 'Water_supply', 'Land-use', 'Year'])[['Value (t CO2e)']]\
            .sum()\
            .reset_index()\
            .round({'Value (t CO2e)': 2})
        df_wide = df_wide.groupby(['region', 'Source', 'Water_supply', 'Land-use'])[['Year','Value (t CO2e)']]\
            .apply(lambda x: x[['Year', 'Value (t CO2e)']].values.tolist())\
            .reset_index()
        df_wide.columns = ['region', 'source', 'water', 'name', 'data']
        df_wide['type'] = 'column'
        df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
        df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
        df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])

        out_dict = {}
        for (region, source, water), df in df_wide.groupby(['region', 'source', 'water']):
            df = df.drop(['region', 'source', 'water'], axis=1)
            if region not in out_dict:
                out_dict[region] = {}
            if source not in out_dict[region]:
                out_dict[region][source] = {}
            if water not in out_dict[region][source]:
                out_dict[region][source][water] = {}
            out_dict[region][source][water] = df.to_dict(orient='records')
            
        filename = 'GHG_Ag'
        with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
            f.write(f'window["{filename}"] = ')
            json.dump(out_dict, f, separators=(',', ':'), indent=2)
            f.write(';\n')



        # -------------------- GHG by Non-Agricultural --------------------
        Non_ag_reduction_long = GHG_land.query('Type == "Non-Agricultural land-use"').reset_index(drop=True)
        Non_ag_reduction_long['Value (t CO2e)'] *= -1  # Convert from negative to positive
        
        df_region = Non_ag_reduction_long\
            .groupby(['Year', 'region', 'Land-use'])[['Value (t CO2e)']]\
            .sum()\
            .reset_index()\
            .round({'Value (t CO2e)': 2})
        df_wide = df_region.groupby(['Land-use', 'region'])[['Year','Value (t CO2e)']]\
            .apply(lambda x: x[['Year', 'Value (t CO2e)']].values.tolist())\
            .reset_index()
        df_wide.columns = ['name', 'region', 'data']
        df_wide['type'] = 'column'
        
        df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)
        df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
        df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
        
        out_dict = {}
        for region, df in df_wide.groupby('region'):
            df = df.drop(['region'], axis=1)
            out_dict[region] = df.to_dict(orient='records')

        filename = f'GHG_NonAg'
        with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
            f.write(f'window["{filename}"] = ')
            json.dump(out_dict, f, separators=(',', ':'), indent=2)
            f.write(';\n')



        # -------------------- GHG by Agricultural Managements --------------------
        Ag_man_sequestration_long = GHG_land.query('Type == "Agricultural Management"').reset_index(drop=True)
        Ag_man_sequestration_long['Value (t CO2e)'] = Ag_man_sequestration_long['Value (t CO2e)'] * -1  # Convert from negative to positive
        group_cols = ['Land-use', 'Land-use type', 'Agricultural Management Type', 'Water_supply']

        df_region = Ag_man_sequestration_long\
            .groupby(['region', 'Agricultural Management Type', 'Water_supply', 'Land-use', 'Year'])[['Value (t CO2e)']]\
            .sum()\
            .reset_index()\
            .round({'Value (t CO2e)': 2})
        df_wide = df_region.groupby(['region', 'Agricultural Management Type', 'Water_supply', 'Land-use'])[['Year','Value (t CO2e)']]\
            .apply(lambda x: x[['Year', 'Value (t CO2e)']].values.tolist())\
            .reset_index()
        df_wide.columns = ['region', '_type', 'water', 'name', 'data']
        df_wide['type'] = 'column'
        df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
        df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
        df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])

        out_dict = {}
        for (region,_type,water), df in df_wide.groupby(['region', '_type', 'water']):
            df = df.drop(['region', '_type', 'water'], axis=1)
            if region not in out_dict:
                out_dict[region] = {}
            if _type not in out_dict[region]:
                out_dict[region][_type] = {}
            if water not in out_dict[region][_type]:
                out_dict[region][_type][water] = {}
            out_dict[region][_type][water] = df.to_dict(orient='records')
            
        filename = 'GHG_Am'
        with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
            f.write(f'window["{filename}"] = ')
            json.dump(out_dict, f, separators=(',', ':'), indent=2)
            f.write(';\n')

        


    ####################################################
    #                     5) Water                     #
    ####################################################
    
    water_files = files.query('category == "water"').reset_index(drop=True)

    water_net_yield_watershed = water_files.query('base_name == "water_yield_separate_watershed"')
    water_net_yield_watershed = pd.concat([pd.read_csv(path) for path in water_net_yield_watershed['path']], ignore_index=True)
    water_net_yield_watershed = water_net_yield_watershed\
        .replace(RENAME_AM_NON_AG)\
        .query('abs(`Water Net Yield (ML)`) > 1e-6')\
        .rename(columns={'Water Net Yield (ML)': 'Value (ML)'})
    water_net_yield_watershed['Water Supply'] = water_net_yield_watershed['Water Supply'].replace(np.nan, 'NA')


    water_net_yield_NRM_region = water_files.query('base_name == "water_yield_separate_NRM"')
    water_net_yield_NRM_region = pd.concat([pd.read_csv(path) for path in water_net_yield_NRM_region['path']], ignore_index=True)
    water_net_yield_NRM_region = water_net_yield_NRM_region\
        .replace(RENAME_AM_NON_AG)\
        .query('abs(`Water Net Yield (ML)`) > 1e-6')\
        .rename(columns={'Water Net Yield (ML)': 'Value (ML)'})
        
    water_ag_AUS = water_net_yield_NRM_region\
        .query('Type == "Agricultural Landuse"')\
        .groupby(['Water Supply', 'Landuse', 'Year',])[['Value (ML)']]\
        .sum(numeric_only=True)\
        .reset_index()\
        .assign(region='AUSTRALIA')
        
    water_am_AUS = water_net_yield_NRM_region\
        .query('Type == "Agricultural Management"')\
        .groupby(['Agri-Management', 'Water Supply', 'Landuse', 'Year'])[['Value (ML)']]\
        .sum(numeric_only=True)\
        .reset_index()\
        .assign(region='AUSTRALIA')
        
    water_nonag_AUS = water_net_yield_NRM_region\
        .query('Type == "Non-Agricultural Landuse"')\
        .groupby(['Landuse', 'Year'])[['Value (ML)']]\
        .sum(numeric_only=True)\
        .reset_index()\
        .assign(
            region='AUSTRALIA',
            name_order=lambda x: x['Landuse'].apply(lambda y: LANDUSE_ALL_RENAMED.index(y)))\
        .sort_values('name_order')\
        .drop(columns=['name_order'])


    hist_and_public_wny_water_region = water_files.query('base_name == "water_yield_limits_and_public_land"')
    hist_and_public_wny_water_region = pd.concat([pd.read_csv(path) for path in hist_and_public_wny_water_region['path']], ignore_index=True)

    water_outside_LUTO = hist_and_public_wny_water_region[['Year','Region', 'Water yield outside LUTO (ML)']].rename(
        columns={'Water yield outside LUTO (ML)': 'Value (ML)'}
    )
    water_climate_change_impact = hist_and_public_wny_water_region[['Year','Region', 'Climate Change Impact (ML)']].rename(
        columns={'Climate Change Impact (ML)': 'Value (ML)'}
    )
    water_domestic_use = hist_and_public_wny_water_region[['Year','Region', 'Domestic Water Use (ML)']].rename(
        columns={'Domestic Water Use (ML)': 'Value (ML)'})
    water_domestic_use['Value (ML)'] *= -1  # Domestic water use is negative, indicating a water loss (consumption)
    
    water_yield_limit = hist_and_public_wny_water_region[['Year','Region', 'Water Yield Limit (ML)']].rename(
        columns={'Water Yield Limit (ML)': 'Value (ML)'}
    )
    water_net_yield = hist_and_public_wny_water_region[['Year','Region', 'Water Net Yield (ML)']].rename(
        columns={'Water Net Yield (ML)': 'Value (ML)'}
    )
    

    water_targets_before_relaxation = water_files.query('base_name == "water_yield_relaxed_region_raw"')
    water_targets_before_relaxation = pd.concat([pd.read_csv(path) for path in water_targets_before_relaxation['path']], ignore_index=True)



    # -------------------- Water yield overview for Australia --------------------
    water_inside_LUTO_sum = water_net_yield_watershed\
        .query('`Water Supply` != "ALL" and `Agri-Management` != "ALL"')\
        .groupby(['Year','Type'])[['Value (ML)']]\
        .sum(numeric_only=True)\
        .round({'Value (ML)': 2})\
        .reset_index()
    water_inside_LUTO_sum_wide = water_inside_LUTO_sum\
        .groupby('Type')[['Year','Value (ML)']]\
        .apply(lambda x: list(map(list,zip(x['Year'],x['Value (ML)']))))\
        .reset_index()\
        .round({'Value (ML)': 2})
    water_inside_LUTO_sum_wide.columns = ['name','data']
    water_inside_LUTO_sum_wide['type'] = 'column'
    
        
    water_outside_LUTO_total = water_outside_LUTO\
        .groupby('Year')\
        .sum(numeric_only=True)\
        .round({'Value (ML)': 2})\
        .reset_index()[['Year','Value (ML)']].values.tolist()
    water_CCI = water_climate_change_impact\
        .groupby('Year')\
        .sum(numeric_only=True)\
        .round({'Value (ML)': 2})\
        .reset_index()[['Year','Value (ML)']].values.tolist()
    water_domestic = water_domestic_use\
        .groupby('Year')\
        .sum(numeric_only=True)\
        .round({'Value (ML)': 2})\
        .reset_index()[['Year','Value (ML)']].values.tolist()
    water_net_yield_sum = water_net_yield\
        .groupby('Year')\
        .sum(numeric_only=True)\
        .round({'Value (ML)': 2})\
        .reset_index()[['Year','Value (ML)']].values.tolist()
    water_limit = water_yield_limit\
        .groupby('Year')\
        .sum(numeric_only=True)\
        .round({'Value (ML)': 2})\
        .reset_index()[['Year','Value (ML)']].values.tolist()
  
    water_yield_df_AUS = water_inside_LUTO_sum_wide.copy()
    water_yield_df_AUS.loc[len(water_yield_df_AUS)] = ['Outside LUTO Study Area', water_outside_LUTO_total,  'column']
    water_yield_df_AUS.loc[len(water_yield_df_AUS)] = ['Climate Change Impact', water_CCI,  'column']
    water_yield_df_AUS.loc[len(water_yield_df_AUS)] = ['Domestic Water Use', water_domestic,  'column']
    water_yield_df_AUS.loc[len(water_yield_df_AUS)] = ['Water Net Yield', water_net_yield_sum, 'line']
    water_yield_df_AUS.loc[len(water_yield_df_AUS)] = ['Water Limit', water_limit, 'line']

    water_yield_AUS = {
        'AUSTRALIA': json.loads(water_yield_df_AUS.to_json(orient='records'))
    }

    # -------------------- Water yield overview for watershed region --------------------
    water_yield_region = {}
    for reg_name in water_net_yield['Region'].unique():

        water_inside_LUTO_region = water_net_yield.query('Region == @reg_name').copy()
        water_inside_yield_wide = water_inside_LUTO_region[['Year','Value (ML)']].values.tolist()

        water_outside_LUTO_region = water_outside_LUTO.query('Region == @reg_name').copy()
        water_outside_yield_wide = water_outside_LUTO_region[['Year','Value (ML)']].values.tolist()

        water_CCI = water_climate_change_impact.query('Region == @reg_name').copy()
        water_CCI_wide = water_CCI[['Year','Value (ML)']].values.tolist()
        
        water_domestic = water_domestic_use.query('Region == @reg_name').copy()
        water_domestic_wide = water_domestic[['Year','Value (ML)']].values.tolist()

        water_net_yield_sum = water_net_yield.query('Region == @reg_name').copy()
        water_net_yield_sum_wide = water_net_yield_sum[['Year','Value (ML)']].values.tolist()

        water_limit = water_yield_limit.query('Region == @reg_name').copy()
        water_limit_wide = water_limit[['Year','Value (ML)']].values.tolist()

        water_df = pd.DataFrame([
            ['Water Yield Inside LUTO Study Area', water_inside_yield_wide, 'column', None, None],
            ['Water Yield Outside LUTO Study Area', water_outside_yield_wide, 'column', None, None],
            ['Climate Change Impact', water_CCI_wide, 'column', None, None],
            ['Domestic Water Use', water_domestic_wide, 'column', None, None],
            ['Water Net Yield', water_net_yield_sum_wide, 'line', None, None],
            ['Water Limit (model)', water_limit_wide, 'line', 'black', None],
        ],
            columns=['name','data','type','color','dashStyle']
        )
        
        # Add historical water limit if it exists for this region
        if reg_name in water_targets_before_relaxation['Region Name'].values:
            raw_targets = water_targets_before_relaxation.query('`Region Name` == @reg_name')[['Year','Target']].values.tolist()
            water_df.loc[len(water_df)] = ['Water Limit (historical level)', raw_targets, 'line', '#2176cc', 'Dash']

        water_yield_region[reg_name] = water_df.to_dict(orient='records')
        
        
    # Combine Australia and regions
    water_yield_region = {**water_yield_AUS, **water_yield_region}
    
    
    filename = 'Water_overview_watershed'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as outfile:
        outfile.write(f'window["{filename}"] = ')
        json.dump(water_yield_region, outfile, separators=(',', ':'), indent=2)
        outfile.write(';\n')
        
   

    # -------------------- Water yield ranking by NRM --------------------
    water_ranking_type_region = water_net_yield_NRM_region\
        .query('`Water Supply` != "ALL" and `Agri-Management` != "ALL"')\
        .groupby(['Year', 'region_NRM', 'Type'])[['Value (ML)']]\
        .sum(numeric_only=True)\
        .reset_index()\
        .sort_values(['Year', 'Type', 'Value (ML)'], ascending=[True, True, False])
    water_ranking_type_AUS = water_net_yield_NRM_region\
        .groupby(['Year', 'Type'])[['Value (ML)']]\
        .sum(numeric_only=True)\
        .reset_index()\
        .sort_values(['Year', 'Type', 'Value (ML)'], ascending=[True, True, False])\
        .assign(Rank=0,  region_NRM='AUSTRALIA')
        
        
    water_ranking_net_region = water_net_yield_NRM_region\
        .query('`Water Supply` != "ALL" and `Agri-Management` != "ALL"')\
        .groupby(['Year', 'region_NRM'])[['Value (ML)']]\
        .sum(numeric_only=True)\
        .reset_index()\
        .sort_values(['Year', 'Value (ML)'], ascending=[True, False])\
        .assign(Rank=lambda x: x.groupby('Year').cumcount() + 1)\
        .assign(Type='Total')
    water_ranking_net_AUS = water_net_yield_NRM_region\
        .query('`Water Supply` != "ALL" and `Agri-Management` != "ALL"')\
        .groupby(['Year'])[['Value (ML)']]\
        .sum(numeric_only=True)\
        .reset_index()\
        .sort_values(['Year', 'Value (ML)'], ascending=[True, False])\
        .assign(Rank=0, Type='Total', region_NRM='AUSTRALIA')
        
    
    water_ranking = pd.concat([
        water_ranking_type_region, 
        water_ranking_type_AUS, 
        water_ranking_net_region, 
        water_ranking_net_AUS
        ], axis=0, ignore_index=True).reset_index(drop=True)
    water_ranking = water_ranking\
        .set_index(['region_NRM', 'Year', 'Type'])\
        .reindex(
            index=pd.MultiIndex.from_product(
                [water_ranking['region_NRM'].unique(), water_ranking['Year'].unique(), water_ranking['Type'].unique()],
                names=['region_NRM', 'Year', 'Type']), fill_value=None)\
        .reset_index()\
        .assign(color=lambda x: x['Rank'].map(get_rank_color))\
        .round({'Percent': 2, 'Value (ML)': 2})

 
    out_dict = {}
    for (region, w_type), df in water_ranking.groupby(['region_NRM', 'Type']):
        if region not in out_dict:
            out_dict[region] = {}
        if w_type not in out_dict[region]:
            out_dict[region][w_type] = {}

        df = df.drop(columns='region_NRM')
        out_dict[region][w_type]['Rank'] = df.set_index('Year')['Rank'].replace({np.nan: None}).to_dict()
        out_dict[region][w_type]['color'] = df.set_index('Year')['color'].replace({np.nan: None}).to_dict()
        out_dict[region][w_type]['value'] = df.set_index('Year')['Value (ML)'].apply( lambda x: format_with_suffix(x)).to_dict()

    filename = 'Water_ranking_NRM'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')



    # -------------------- Water yield overview by NRM region --------------------
    group_cols = ['Landuse', 'Type']
    out_dict = {region: [] for region in water_net_yield_NRM_region['region_NRM'].unique()}
    out_dict['AUSTRALIA'] = water_yield_df_AUS.to_dict(orient='records')
    for idx, col in enumerate(group_cols):

        df_region = water_net_yield_NRM_region\
            .query('`Water Supply` != "ALL" and `Agri-Management` != "ALL"')\
            .groupby(['Year', 'region_NRM', col])\
            .sum()\
            .reset_index()\
            .round({'Value (ML)': 2})
        df_region_wide = df_region.groupby([col, 'region_NRM'])[['Year','Value (ML)']]\
            .apply(lambda x: x[['Year', 'Value (ML)']].values.tolist())\
            .reset_index()
        df_region_wide.columns = ['name', 'region_NRM', 'data']
        df_region_wide['type'] = 'column'
        if col == 'Landuse':
            df_region_wide['color'] = df_region_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
            df_region_wide['name_order'] = df_region_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
            df_region_wide = df_region_wide.sort_values('name_order').drop(columns=['name_order'])
        
        
        for region, df in df_region_wide.groupby('region_NRM'):
            df = df.drop(['region_NRM'], axis=1)
            out_dict[region] = df.to_dict(orient='records')
            
    filename = f'Water_overview_NRM_{col.replace(" ", "_")}'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')



    # -------------------- Water yield for Ag by NRM --------------------
    water_ag = pd.concat([
        water_ag_AUS,
        water_net_yield_NRM_region.query('Type == "Agricultural Landuse"').rename(columns={'region_NRM': 'region'})
        ], ignore_index=True)
    
    df_region_wide = water_ag.groupby(['region', 'Water Supply', 'Landuse'])[['Year','Value (ML)']]\
        .apply(lambda x: x[['Year', 'Value (ML)']].values.tolist())\
        .reset_index()
  
    df_region_wide.columns = ['region', 'water', 'name',  'data']
    df_region_wide['type'] = 'column'
    df_region_wide['color'] = df_region_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
    df_region_wide['name_order'] = df_region_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
    df_region_wide = df_region_wide.sort_values('name_order').drop(columns=['name_order'])

    out_dict = {}
    for (region, water), df in df_region_wide.groupby(['region', 'water']):
        df = df.drop(['region'], axis=1)
        if region not in out_dict:
            out_dict[region] = {}
        if water not in out_dict[region]:
            out_dict[region][water] = {}
        out_dict[region][water] = df.to_dict(orient='records')
        
        
    filename = f'Water_Ag_NRM'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')
        

        
            
    # -------------------- Water yield for Am by NRM region --------------------
    water_am = pd.concat(
        [water_am_AUS,
         water_net_yield_NRM_region.query('Type == "Agricultural Management"').rename(columns={'region_NRM': 'region'})],
        ignore_index=True
    )

    df_region_wide = water_am.groupby(['region', 'Agri-Management', 'Water Supply', 'Landuse'])[['Year','Value (ML)']]\
        .apply(lambda x: x[['Year', 'Value (ML)']].values.tolist())\
        .reset_index()
    df_region_wide.columns = ['region', '_type', 'water', 'name',  'data']
    df_region_wide['type'] = 'column'
    df_region_wide['color'] = df_region_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
    df_region_wide['name_order'] = df_region_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
    df_region_wide = df_region_wide.sort_values('name_order').drop(columns=['name_order'])

    out_dict = {}
    for (region,_type,water), df in df_region_wide.groupby(['region', '_type', 'water']):
        df = df.drop(['region', '_type', 'water'], axis=1)
        if region not in out_dict:
            out_dict[region] = {}
        if _type not in out_dict[region]:
            out_dict[region][_type] = {}
        if water not in out_dict[region][_type]:
            out_dict[region][_type][water] = {}
        out_dict[region][_type][water] = df.to_dict(orient='records')
        
    filename = f'Water_Am_NRM'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')
            
            
    # -------------------- Water yield for non-agricultural landuse by NRM region --------------------
    water_nonag = pd.concat([
        water_nonag_AUS,
        water_net_yield_NRM_region.query('Type == "Non-Agricultural Landuse"').rename(columns={'region_NRM': 'region'})
        ], ignore_index=True)

    df_region_wide = water_nonag.groupby(['region', 'Landuse'])[['Year','Value (ML)']]\
        .apply(lambda x: x[['Year', 'Value (ML)']].values.tolist())\
        .reset_index()
    df_region_wide.columns = ['region', 'name', 'data']
    df_region_wide['type'] = 'column'
    df_region_wide['color'] = df_region_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)
    df_region_wide['name_order'] = df_region_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
    df_region_wide = df_region_wide.sort_values('name_order').drop(columns=['name_order'])

    out_dict = {}
    for region, df in df_region_wide.groupby('region'):
        df = df.drop(['region'], axis=1)
        out_dict[region] = df.to_dict(orient='records')
        
    filename = f'Water_NonAg_NRM'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')
        



    #########################################################
    #                   6) Biodiversity                     #
    #########################################################

    filter_str = '''
        category == "biodiversity"
       
        and base_name == "biodiversity_overall_priority_scores"
    '''.strip().replace('\n','')
    
    bio_paths = files.query(filter_str).reset_index(drop=True)
    bio_df = pd.concat([pd.read_csv(path) for path in bio_paths['path']])\
        .replace(RENAME_AM_NON_AG)\
        .rename(columns={'Contribution Relative to Base Year Level (%)': 'Value (%)'})\
        .query('abs(`Value (%)`) > 1e-6')\
        .round({'Value (%)': 6})
        
        
        
    # ---------------- Biodiversity ranking ----------------
    bio_rank_type_region = bio_df\
        .query('abs(`Value (%)`) > 1e-6')\
        .groupby(['Year', 'region', 'Type'])\
        .sum(numeric_only=True)\
        .reset_index()\
        .sort_values(['Year', 'Type', 'Value (%)'], ascending=[True, True, False])\
        .assign(Rank=lambda x: x.groupby(['Year', 'Type']).cumcount() + 1)\
        .assign(Percent=lambda x: x['Value (%)'] / x.groupby(['Year', 'Type'])['Value (%)'].transform('sum') * 100)\
        .assign(color=lambda x: x['Rank'].map(get_rank_color))\
        .round({'Percent': 2, 'Area Weighted Score (ha)': 2})
    bio_rank_type_AUS = bio_df\
        .query('abs(`Value (%)`) > 1e-6')\
        .groupby(['Year', 'Type'])\
        .sum(numeric_only=True)\
        .reset_index()\
        .sort_values(['Year', 'Type', 'Value (%)'], ascending=[True, True, False])\
        .assign(Rank='N.A.', Percent=100, region='AUSTRALIA')\
        .round({'Percent': 2, 'Area Weighted Score (ha)': 2})
        
    bio_rank_total_region = bio_df\
        .query('abs(`Value (%)`) > 1e-6')\
        .groupby(['Year', 'region'])\
        .sum(numeric_only=True)\
        .reset_index()\
        .sort_values(['Year', 'Value (%)'], ascending=[True, False])\
        .assign(Rank=lambda x: x.groupby(['Year']).cumcount() + 1)\
        .assign(Percent=lambda x: x['Value (%)'] / x.groupby(['Year'])['Value (%)'].transform('sum') * 100)\
        .assign(Type='Total')\
        .round({'Percent': 2, 'Area Weighted Score (ha)': 2})
    bio_rank_total_AUS = bio_df\
        .query('abs(`Value (%)`) > 1e-6')\
        .groupby(['Year'])\
        .sum(numeric_only=True)\
        .reset_index()\
        .sort_values(['Year', 'Value (%)'], ascending=[True, False])\
        .assign(Rank='N.A.', Percent=100, Type='Total', region='AUSTRALIA')\
        .round({'Percent': 2, 'Area Weighted Score (ha)': 2})


    bio_rank = pd.concat([
        bio_rank_type_region,
        bio_rank_total_region,
        bio_rank_type_AUS,
        bio_rank_total_AUS], axis=0, ignore_index=True).reset_index(drop=True)
    bio_rank = bio_rank\
        .set_index(['region', 'Year', 'Type'])\
        .reindex(
            index=pd.MultiIndex.from_product(
                [bio_rank['region'].unique(), bio_rank['Year'].unique(), bio_rank['Type'].unique()],
                names=['region', 'Year', 'Type']),fill_value=None)\
        .reset_index()\
        .assign(color=lambda x: x['Rank'].map(get_rank_color))

            
    out_dict = {}
    for (region, b_type), df in bio_rank.groupby(['region', 'Type']):
        if region not in out_dict:
            out_dict[region] = {}
        if b_type not in out_dict[region]:
            out_dict[region][b_type] = {}

        df = df.drop(columns='region')
        out_dict[region][b_type]['Rank'] = df.set_index('Year')['Rank'].replace({np.nan: None}).to_dict()
        out_dict[region][b_type]['Percent'] = df.set_index('Year')['Percent'].replace({np.nan: 0}).to_dict()
        out_dict[region][b_type]['color'] = df.set_index('Year')['color'].replace({np.nan: None}).to_dict()
        out_dict[region][b_type]['value'] = df.set_index('Year')['Area Weighted Score (ha)'].apply( lambda x: format_with_suffix(x)).to_dict()

        
    filename = 'Biodiversity_ranking'
    with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(out_dict, f, separators=(',', ':'), indent=2)
        f.write(';\n')



    # ---------------- Biodiversity quality overview  ----------------
    group_cols = ['Type']
    for idx, col in enumerate(group_cols):
        df_AUS = bio_df\
            .groupby(['Year', col])[['Value (%)']]\
            .sum()\
            .reset_index()
        df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
            .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
            .reset_index()\
            .assign(region='AUSTRALIA')
        df_AUS_wide.columns = ['name', 'data','region']
        df_AUS_wide['type'] = 'column'

        df_region = bio_df\
            .groupby(['Year', 'region', col])\
            .sum()\
            .reset_index()\
            .query('abs(`Value (%)`) > 1e-6')
        df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
            .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
            .reset_index()
        df_region_wide.columns = ['name', 'region', 'data']
        df_region_wide['type'] = 'column'
        
        
        df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
        
        if col == "Landuse":
            df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
            df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
            df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
        elif col == 'Water_supply':
            df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
        elif col.lower() == 'commodity':
            df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
            df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
            df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
        elif col == 'Agricultural Management Type':
            df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)
        
        
        out_dict = {}
        for region, df in df_wide.groupby('region'):
            df = df.drop(['region'], axis=1)
            out_dict[region] = df.to_dict(orient='records')

        filename = f'BIO_quality_overview_{idx+1}_{col.replace(" ", "_")}'
        with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
            f.write(f'window["{filename}"] = ')
            json.dump(out_dict, f, separators=(',', ':'), indent=2)
            f.write(';\n')
    
    
    
    # ---------------- Biodiversity quality by Agricultural Landuse  ----------------
    bio_df_ag = bio_df.query('Type == "Agricultural Landuse"').copy()
    group_cols = ['Landuse']
    for idx, col in enumerate(group_cols):
        df_AUS = bio_df_ag\
            .groupby(['Year', col])[['Value (%)']]\
            .sum()\
            .reset_index()
        df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
            .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
            .reset_index()\
            .assign(region='AUSTRALIA')
        df_AUS_wide.columns = ['name', 'data','region']
        df_AUS_wide['type'] = 'column'

        df_region = bio_df_ag\
            .groupby(['Year', 'region', col])\
            .sum()\
            .reset_index()\
            .query('abs(`Value (%)`) > 1e-6')
        df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
            .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
            .reset_index()
        df_region_wide.columns = ['name', 'region', 'data']
        df_region_wide['type'] = 'column'
        
        
        df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
        
        if col == "Landuse":
            df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
            df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
            df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
        elif col == 'Water_supply':
            df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
        elif col.lower() == 'commodity':
            df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
            df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
            df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
        elif col == 'Agricultural Management Type':
            df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)
        
        
        out_dict = {}
        for region, df in df_wide.groupby('region'):
            df = df.drop(['region'], axis=1)
            out_dict[region] = df.to_dict(orient='records')
            
        filename = f'BIO_quality_split_Ag_{idx+1}_{col.replace(" ", "_")}'
        with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
            f.write(f'window["{filename}"] = ')
            json.dump(out_dict, f, separators=(',', ':'), indent=2)
            f.write(';\n')
            
    # ---------------- Biodiversity quality by Agricultural Management  ----------------
    bio_df_am = bio_df.query('Type == "Agricultural Management"').copy()
    group_cols = ['Landuse','Agri-Management']
    for idx, col in enumerate(group_cols):
        df_AUS = bio_df_am\
            .groupby(['Year', col])[['Value (%)']]\
            .sum()\
            .reset_index()
        df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
            .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
            .reset_index()\
            .assign(region='AUSTRALIA')
        df_AUS_wide.columns = ['name', 'data','region']
        df_AUS_wide['type'] = 'column'

        df_region = bio_df_am\
            .groupby(['Year', 'region', col])\
            .sum()\
            .reset_index()\
            .query('abs(`Value (%)`) > 1e-6')
        df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
            .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
            .reset_index()
        df_region_wide.columns = ['name', 'region', 'data']
        df_region_wide['type'] = 'column'
        
        
        df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
        
        if col == "Landuse":
            df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
            df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
            df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
        elif col == 'Water_supply':
            df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
        elif col.lower() == 'commodity':
            df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
            df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
            df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
        elif col == 'Agricultural Management Type':
            df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)
        
        
        out_dict = {}
        for region, df in df_wide.groupby('region'):
            df = df.drop(['region'], axis=1)
            out_dict[region] = df.to_dict(orient='records')
            
        filename = f'BIO_quality_split_Am_{idx+1}_{col.replace(" ", "_")}'
        with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
            f.write(f'window["{filename}"] = ')
            json.dump(out_dict, f, separators=(',', ':'), indent=2)
            f.write(';\n')


    # ---------------- Biodiversity quality by Non-Agricultural  ----------------
    bio_df_nonag = bio_df.query('Type == "Non-Agricultural land-use"').copy()
    group_cols = ['Landuse']
    for idx, col in enumerate(group_cols):
        df_AUS = bio_df_nonag\
            .groupby(['Year', col])[['Value (%)']]\
            .sum()\
            .reset_index()
        df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
            .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
            .reset_index()\
            .assign(region='AUSTRALIA')
        df_AUS_wide.columns = ['name', 'data','region']
        df_AUS_wide['type'] = 'column'

        df_region = bio_df_nonag\
            .groupby(['Year', 'region', col])\
            .sum()\
            .reset_index()\
            .query('abs(`Value (%)`) > 1e-6')
        df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
            .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
            .reset_index()
        df_region_wide.columns = ['name', 'region', 'data']
        df_region_wide['type'] = 'column'
        
        
        df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
        
        if col == "Landuse":
            df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
            df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
            df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
        elif col == 'Water_supply':
            df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
        elif col.lower() == 'commodity':
            df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
            df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
            df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
        elif col == 'Agricultural Management Type':
            df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)
        
        
        out_dict = {}
        for region, df in df_wide.groupby('region'):
            df = df.drop(['region'], axis=1)
            out_dict[region] = df.to_dict(orient='records')
            
        filename = f'BIO_quality_split_NonAg_{idx+1}_{col.replace(" ", "_")}'
        with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
            f.write(f'window["{filename}"] = ')
            json.dump(out_dict, f, separators=(',', ':'), indent=2)
            f.write(';\n')
    
    
        
    
    if settings.BIODIVERSITY_TARGET_GBF_2 != 'off':

        filter_str = '''
            category == "biodiversity" 
            
            and base_name == "biodiversity_GBF2_priority_scores"
        '''.strip('').replace('\n','')
        
        bio_paths = files.query(filter_str).reset_index(drop=True)
        bio_df = pd.concat([pd.read_csv(path) for path in bio_paths['path']])
        bio_df = bio_df.replace(RENAME_AM_NON_AG)\
            .rename(columns={'Contribution Relative to Pre-1750 Level (%)': 'Value (%)'})\
            .query('abs(`Value (%)`) > 1e-6')\
            .round(6)
        

        # ---------------- (GBF2) overview  ----------------
        bio_df_target = bio_df.groupby(['Year'])[['Priority Target (%)']].agg('first').reset_index()
        bio_df_target = bio_df_target[['Year','Priority Target (%)']].values.tolist()

        group_cols = ['Type']
        for idx, col in enumerate(group_cols):
            df_AUS = bio_df\
                .groupby(['Year', col])[['Value (%)']]\
                .sum()\
                .reset_index()
            df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                .reset_index()\
                .assign(region='AUSTRALIA')
            df_AUS_wide.columns = ['name', 'data','region']
            df_AUS_wide['type'] = 'column'
            df_AUS_wide.loc[len(df_AUS_wide)] = ['Target (%)', bio_df_target, 'line', None]

            df_region = bio_df\
                .groupby(['Year', 'region', col])\
                .sum()\
                .reset_index()\
                .query('abs(`Value (%)`) > 1e-6')
            df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                .reset_index()
            df_region_wide.columns = ['name', 'region', 'data']
            df_region_wide['type'] = 'column'
            
            
            df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
            
            if col == "Landuse":
                df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
            elif col == 'Water_supply':
                df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
            elif col.lower() == 'commodity':
                df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
            elif col == 'Agricultural Management Type':
                df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)
            
            
            out_dict = {}
            for region, df in df_wide.groupby('region'):
                df = df.drop(['region'], axis=1)
                out_dict[region] = df.to_dict(orient='records')

            filename = f'BIO_GBF2_overview_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')


        # ---------------- (GBF2) Agricultural Landuse  ----------------
        bio_df_ag = bio_df.query('Type == "Agricultural Landuse"').copy()

        group_cols = ['Landuse']
        for idx, col in enumerate(group_cols):
            df_AUS = bio_df_ag\
                .groupby(['Year', col])[['Value (%)']]\
                .sum()\
                .reset_index()
            df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                .reset_index()\
                .assign(region='AUSTRALIA')
            df_AUS_wide.columns = ['name', 'data','region']
            df_AUS_wide['type'] = 'column'

            df_region = bio_df_ag\
                .groupby(['Year', 'region', col])\
                .sum()\
                .reset_index()\
                .query('abs(`Value (%)`) > 1e-6')
            df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                .reset_index()
            df_region_wide.columns = ['name', 'region', 'data']
            df_region_wide['type'] = 'column'
            
            
            df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
            
            if col == "Landuse":
                df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
            elif col == 'Water_supply':
                df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
            elif col.lower() == 'commodity':
                df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
            elif col == 'Agricultural Management Type':
                df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)
            
            
            out_dict = {}
            for region, df in df_wide.groupby('region'):
                df = df.drop(['region'], axis=1)
                out_dict[region] = df.to_dict(orient='records')

            filename = f'BIO_GBF2_split_Ag_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')
                
        # ---------------- (GBF2) Agricultural Management  ----------------
        bio_df_am = bio_df.query('Type == "Agricultural Management"').copy()

        group_cols = ['Landuse', 'Agri-Management']
        for idx, col in enumerate(group_cols):
            df_AUS = bio_df_am\
                .groupby(['Year', col])[['Value (%)']]\
                .sum()\
                .reset_index()
            df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                .reset_index()\
                .assign(region='AUSTRALIA')
            df_AUS_wide.columns = ['name', 'data','region']
            df_AUS_wide['type'] = 'column'

            df_region = bio_df_am\
                .groupby(['Year', 'region', col])\
                .sum()\
                .reset_index()\
                .query('abs(`Value (%)`) > 1e-6')
            df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                .reset_index()
            df_region_wide.columns = ['name', 'region', 'data']
            df_region_wide['type'] = 'column'
            
            
            df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
            
            if col == "Landuse":
                df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
            elif col == 'Water_supply':
                df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
            elif col.lower() == 'commodity':
                df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
            elif col == 'Agricultural Management Type':
                df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)
            
            
            out_dict = {}
            for region, df in df_wide.groupby('region'):
                df = df.drop(['region'], axis=1)
                out_dict[region] = df.to_dict(orient='records')

            filename = f'BIO_GBF2_split_Am_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')
                
                
        # ---------------- (GBF2) Agricultural Management  ----------------
        bio_df_nonag = bio_df.query('Type == "Non-Agricultural land-use"').copy()

        group_cols = ['Landuse']
        for idx, col in enumerate(group_cols):
            df_AUS = bio_df_nonag\
                .groupby(['Year', col])[['Value (%)']]\
                .sum()\
                .reset_index()
            df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                .reset_index()\
                .assign(region='AUSTRALIA')
            df_AUS_wide.columns = ['name', 'data','region']
            df_AUS_wide['type'] = 'column'

            df_region = bio_df_nonag\
                .groupby(['Year', 'region', col])\
                .sum()\
                .reset_index()\
                .query('abs(`Value (%)`) > 1e-6')
            df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                .reset_index()
            df_region_wide.columns = ['name', 'region', 'data']
            df_region_wide['type'] = 'column'
            
            
            df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
            
            if col == "Landuse":
                df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
            elif col == 'Water_supply':
                df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
            elif col.lower() == 'commodity':
                df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
            elif col == 'Agricultural Management Type':
                df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)
            
            
            out_dict = {}
            for region, df in df_wide.groupby('region'):
                df = df.drop(['region'], axis=1)
                out_dict[region] = df.to_dict(orient='records')

            filename = f'BIO_GBF2_split_NonAg_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')
        
   
            
    
    if settings.BIODIVERSITY_TARGET_GBF_3 != 'off':
        filter_str = '''
            category == "biodiversity" 
            
            and base_name.str.contains("biodiversity_GBF3")
        '''.strip().replace('\n','')
        
        bio_paths = files.query(filter_str).reset_index(drop=True)
        bio_df = pd.concat([pd.read_csv(path, low_memory=False) for path in bio_paths['path']])
        bio_df = bio_df.replace(RENAME_AM_NON_AG)\
            .rename(columns={'Contribution Relative to Pre-1750 Level (%)': 'Value (%)', 'Vegetation Group': 'species'})\
            .query('abs(`Value (%)`) > 1e-6')\
            .round(6)
        
        
        # ---------------- (GBF3) Overview  ----------------
        bio_df_target = bio_df.groupby(['Year', 'species'])[['Target_by_Percent']].agg('first').reset_index()

        group_cols = ['Type']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df['species'].unique():
                target_species = bio_df_target.query('species == @species')[['Year', 'Target_by_Percent']].values.tolist()
                scores_species = bio_df.query('species == @species')
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'
                df_AUS_wide.loc[len(df_AUS_wide)] = ['Target (%)', target_species, 'AUSTRALIA',  'line']

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF3_overview_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')
                
                
                
        # ---------------- (GBF3) Agricultural Landuse  ----------------
        bio_df_ag = bio_df.query('Type == "Agricultural Landuse"').copy()
        
        group_cols = ['Landuse']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df_ag['species'].unique():
                scores_species = bio_df_ag.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF3_split_Ag_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')


        # ---------------- (GBF3) Agricultural Management  ----------------
        bio_df_am = bio_df.query('Type == "Agricultural Management"').copy()

        group_cols = ['Landuse', 'Agri-Management']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df_am['species'].unique():
                scores_species = bio_df_am.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF3_split_Am_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')


        # ---------------- (GBF3) Non-agricultural management  ----------------
        bio_df_nonag = bio_df.query('Type == "Non-Agricultural land-use"').copy()

        group_cols = ['Landuse']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df_nonag['species'].unique():
                scores_species = bio_df_nonag.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF3_split_NonAg_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')
            
            
            
            
    
    if settings.BIODIVERSITY_TARGET_GBF_4_SNES == 'on':
        
        # -------------------- Get biodiversity dataframe --------------------
        filter_str = '''
            category == "biodiversity" 
            
            and base_name.str.contains("biodiversity_GBF4_SNES_scores")
        '''.strip().replace('\n', '')
        
        bio_paths = files.query(filter_str).reset_index(drop=True)
        bio_df = pd.concat([pd.read_csv(path) for path in bio_paths['path']])
        bio_df = bio_df.replace(RENAME_AM_NON_AG)\
            .rename(columns={'Contribution Relative to Pre-1750 Level (%)': 'Value (%)'})\
            .query('abs(`Value (%)`) > 1e-6')\
            .round(6)
        
        # ---------------- (GBF4 SNES) Overview  ----------------
        bio_df_target = bio_df.groupby(['Year', 'species'])[['Target by Percent (%)']].agg('first').reset_index()

        group_cols = ['Type']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df['species'].unique():
                target_species = bio_df_target.query('species == @species')[['Year', 'Target by Percent (%)']].values.tolist()
                scores_species = bio_df.query('species == @species')                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'
                df_AUS_wide.loc[len(df_AUS_wide)] = ['Target (%)', target_species, 'AUSTRALIA',  'line']

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF4_SNES_overview_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')
                
                
                
        # ---------------- (GBF4 SNES) Agricultural Landuse  ----------------
        bio_df_ag = bio_df.query('Type == "Agricultural Landuse"').copy()
        
        group_cols = ['Landuse']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df_ag['species'].unique():
                scores_species = bio_df_ag.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF4_SNES_split_Ag_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')


        # ---------------- (GBF4 SNES) Agricultural Management  ----------------
        bio_df_am = bio_df.query('Type == "Agricultural Management"').copy()

        group_cols = ['Landuse', 'Agri-Management']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df_am['species'].unique():
                scores_species = bio_df_am.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF4_SNES_split_Am_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')

        # ---------------- (GBF4 SNES) Non-agricultural management  ----------------
        bio_df_nonag = bio_df.query('Type == "Non-Agricultural land-use"').copy()

        group_cols = ['Landuse']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df_nonag['species'].unique():
                scores_species = bio_df_nonag.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF4_SNES_split_NonAg_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')
            
            
            
    if settings.BIODIVERSITY_TARGET_GBF_4_ECNES == 'on':
        # -------------------- Get biodiversity dataframe --------------------
        filter_str = '''
            category == "biodiversity" 
            
            and base_name.str.contains("biodiversity_GBF4_ECNES_scores")
        '''.strip().replace('\n', '')
        
        bio_paths = files.query(filter_str).reset_index(drop=True)
        bio_df = pd.concat([pd.read_csv(path) for path in bio_paths['path']])
        bio_df = bio_df.replace(RENAME_AM_NON_AG)\
            .rename(columns={'Contribution Relative to Pre-1750 Level (%)': 'Value (%)'})\
            .query('abs(`Value (%)`) > 1e-6')\
            .round(6)
        
        
        # ---------------- (GBF4 ECNES) Overview  ----------------
        bio_df_target = bio_df.groupby(['Year', 'species'])[['Target by Percent (%)']].agg('first').reset_index()

        group_cols = ['Type']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df['species'].unique():
                target_species = bio_df_target.query('species == @species')[['Year', 'Target by Percent (%)']].values.tolist()
                scores_species = bio_df.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'
                df_AUS_wide.loc[len(df_AUS_wide)] = ['Target (%)', target_species, 'AUSTRALIA',  'line']

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF4_ECNES_overview_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')
                
                
                
        # ---------------- (GBF4 ECNES) Agricultural Landuse  ----------------
        bio_df_ag = bio_df.query('Type == "Agricultural Landuse"').copy()
        
        group_cols = ['Landuse']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df_ag['species'].unique():
                scores_species = bio_df_ag.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF4_ECNES_split_Ag_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')


        # ---------------- (GBF4 ECNES) Agricultural Management  ----------------
        bio_df_am = bio_df.query('Type == "Agricultural Management"').copy()

        group_cols = ['Landuse', 'Agri-Management']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df_am['species'].unique():
                scores_species = bio_df_am.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF4_ECNES_split_Am_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')

        # ---------------- (GBF4 ECNES) Non-agricultural management  ----------------
        bio_df_nonag = bio_df.query('Type == "Non-Agricultural land-use"').copy()

        group_cols = ['Landuse']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df_nonag['species'].unique():
                scores_species = bio_df_nonag.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF4_ECNES_split_NonAg_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')
        
        
        

    if settings.BIODIVERSITY_TARGET_GBF_8 == 'on':
        
        filter_str = '''
            category == "biodiversity" 
            
            and base_name.str.contains("biodiversity_GBF8_species_scores")
        '''.strip().replace('\n','')
        
        bio_paths = files.query(filter_str).reset_index(drop=True)
        bio_df = pd.concat([pd.read_csv(path) for path in bio_paths['path']])
        bio_df = bio_df.replace(RENAME_AM_NON_AG)\
            .rename(columns={'Contribution Relative to Pre-1750 Level (%)': 'Value (%)', 'Species':'species'})\
            .query('abs(`Value (%)`) > 1e-6')\
            .round(6)
        
        # ---------------- (GBF8 SPECIES) Overview  ----------------
        bio_df_target = bio_df.groupby(['Year', 'species'])[['Target_by_Percent']].agg('first').reset_index()

        group_cols = ['Type']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df['species'].unique():
                target_species = bio_df_target.query('species == @species')[['Year', 'Target_by_Percent']].values.tolist()
                scores_species = bio_df.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'
                df_AUS_wide.loc[len(df_AUS_wide)] = ['Target (%)', target_species, 'AUSTRALIA',  'line']

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF8_SPECIES_overview_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')
                
                
                
        # ---------------- (GBF8 SPECIES) Agricultural Landuse  ----------------
        bio_df_ag = bio_df.query('Type == "Agricultural Landuse"').copy()
        
        group_cols = ['Landuse']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df_ag['species'].unique():
                scores_species = bio_df_ag.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF8_SPECIES_split_Ag_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')


        # ---------------- (GBF8 SPECIES) Agricultural Management  ----------------
        bio_df_am = bio_df.query('Type == "Agricultural Management"').copy()

        group_cols = ['Landuse', 'Agri-Management']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df_am['species'].unique():
                scores_species = bio_df_am.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF8_SPECIES_split_Am_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')

        # ---------------- (GBF8 SPECIES) Non-agricultural management  ----------------
        bio_df_nonag = bio_df.query('Type == "Non-Agricultural land-use"').copy()

        group_cols = ['Landuse']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df_nonag['species'].unique():
                scores_species = bio_df_nonag.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF8_SPECIES_split_NonAg_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')
        
        
        
        
        # -------------------- Get biodiversity dataframe --------------------
        filter_str = '''
            category == "biodiversity" 
            
            and base_name.str.contains("biodiversity_GBF8_groups_scores")
        '''.strip().replace('\n','')
        
        bio_paths = files.query(filter_str).reset_index(drop=True)
        bio_df = pd.concat([pd.read_csv(path) for path in bio_paths['path']])
        bio_df = bio_df.replace(RENAME_AM_NON_AG)\
            .rename(columns={'Contribution Relative to Pre-1750 Level (%)': 'Value (%)', 'Group':'species'})\
            .query('abs(`Value (%)`) > 1e-6')\
            .round(6)

        # ---------------- (GBF8 GROUP) Overview  ----------------
        group_cols = ['Type']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df['species'].unique():
                scores_species = bio_df.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF8_GROUP_overview_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')
                
                
                
        # ---------------- (GBF8 GROUP) Agricultural Landuse  ----------------
        bio_df_ag = bio_df.query('Type == "Agricultural Landuse"').copy()
        
        group_cols = ['Landuse']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df_ag['species'].unique():
                scores_species = bio_df_ag.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF8_GROUP_split_Ag_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')


        # ---------------- (GBF8 GROUP) Agricultural Management  ----------------
        bio_df_am = bio_df.query('Type == "Agricultural Management"').copy()

        group_cols = ['Landuse', 'Agri-Management']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df_am['species'].unique():
                scores_species = bio_df_am.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF8_GROUP_split_Am_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')

        # ---------------- (GBF8 GROUP) Non-agricultural management  ----------------
        bio_df_nonag = bio_df.query('Type == "Non-Agricultural land-use"').copy()

        group_cols = ['Landuse']
        for idx, col in enumerate(group_cols):
            out_dict = {region: {} for region in bio_df['region'].unique()}
            out_dict['AUSTRALIA'] = {}
            for species in bio_df_nonag['species'].unique():
                scores_species = bio_df_nonag.query('species == @species')
                
                
                df_AUS = scores_species\
                    .groupby(['Year', col])[['Value (%)']]\
                    .sum()\
                    .reset_index()
                df_AUS_wide = df_AUS.groupby([col])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()\
                    .assign(region='AUSTRALIA')
                df_AUS_wide.columns = ['name', 'data','region']
                df_AUS_wide['type'] = 'column'

                df_region = scores_species\
                    .groupby(['Year', 'region', col])\
                    .sum()\
                    .reset_index()\
                    .query('abs(`Value (%)`) > 1e-6')
                df_region_wide = df_region.groupby([col, 'region'])[['Year','Value (%)']]\
                    .apply(lambda x: x[['Year', 'Value (%)']].values.tolist())\
                    .reset_index()
                df_region_wide.columns = ['name', 'region', 'data']
                df_region_wide['type'] = 'column'
                
                
                df_wide = pd.concat([df_AUS_wide, df_region_wide], axis=0, ignore_index=True)
                
                if col == "Landuse":
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LU[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: LANDUSE_ALL_RENAMED.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Water_supply':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_LM[x['name']], axis=1)
                elif col.lower() == 'commodity':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_COMMODITIES[x['name']], axis=1)
                    df_wide['name_order'] = df_wide['name'].apply(lambda x: COMMODITIES_ALL.index(x))
                    df_wide = df_wide.sort_values('name_order').drop(columns=['name_order'])
                elif col == 'Agricultural Management Type':
                    df_wide['color'] = df_wide.apply(lambda x: COLORS_AM_NONAG[x['name']], axis=1)

                for region, df in df_wide.groupby('region'):
                    df = df.drop(['region'], axis=1)
                    out_dict[region][species] = df.to_dict(orient='records')

            filename = f'BIO_GBF8_GROUP_split_NonAg_{idx+1}_{col.replace(" ", "_")}'
            with open(f'{SAVE_DIR}/{filename}.js', 'w') as f:
                f.write(f'window["{filename}"] = ')
                json.dump(out_dict, f, separators=(',', ':'), indent=2)
                f.write(';\n')
                
  

    
    #########################################################
    # Supporting information               
    #########################################################       
    with open(f'{raw_data_dir}/model_run_settings.txt', 'r', encoding='utf-8') as src_file:
        settings_dict = {i.split(':')[0].strip(): ''.join(i.split(':')[1:]).strip() for i in src_file.readlines()}
        settings_dict = [{'parameter': k, 'val': v} for k, v in settings_dict.items()]
        
    with open(f'{raw_data_dir}/RES_{settings.RESFACTOR}_mem_log.txt', 'r', encoding='utf-8') as src_file:
        mem_logs = src_file.readlines()
        mem_logs = [i.split('\t') for i in mem_logs]
        mem_logs = [{'time': i[0], 'mem (GB)': i[1].strip()} for i in mem_logs]
        mem_logs_df = pd.DataFrame(mem_logs)
        mem_logs_df['time'] = pd.to_datetime(mem_logs_df['time'], format='%Y-%m-%d %H:%M:%S')
        mem_logs_df['time'] = mem_logs_df['time'].astype('int64') // 10**6  # convert to milliseconds
        mem_logs_df['mem (GB)'] = mem_logs_df['mem (GB)'].astype(float)
        mem_logs_obj = [{
            'name': f'Memory Usage (RES {settings.RESFACTOR})',
            'data': mem_logs_df.values.tolist()
        }]

    supporting = {
        'model_run_settings': settings_dict,
        'years': years,
        'colors': COLORS,
        'colors_ranking': COLORS_RANK,
        'mem_logs': mem_logs_obj,
        'RENAME_AM_NON_AG': RENAME_AM_NON_AG,
        'SPATIAL_MAP_DICT': SPATIAL_MAP_DICT
    }
    
    filename = 'Supporting_info'
    with open(f"{SAVE_DIR}/{filename}.js", 'w') as f:
        f.write(f'window["{filename}"] = ')
        json.dump(supporting, f, separators=(',', ':'), indent=2)
        f.write(';\n')
```

## luto/tools/report/create_report_layers.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.


import json
import os
import base64
import numpy as np
import pandas as pd
import xarray as xr

from io import BytesIO
from PIL import Image
from joblib import delayed, Parallel

from luto import settings
from luto.data import Data
from luto.tools.report.data_tools import get_all_files
from luto.tools.report.data_tools.parameters import RENAME_AM_NON_AG



def tuple_dict_to_nested(flat_dict):
    nested_dict = {}
    for key_tuple, value in flat_dict.items():
        current_level = nested_dict
        for key in key_tuple[:-1]:
            if key not in current_level:
                current_level[key] = {}
            current_level = current_level[key]
        current_level[key_tuple[-1]] = value
    return nested_dict
        
        
def hex_color_to_numeric(hex: str) -> tuple:
    hex = hex.lstrip('#')
    if len(hex) == 6:
        hex = hex + 'FF'  # Add full opacity if alpha is not provided
    return tuple(int(hex[i:i+2], 16) for i in (0, 2, 4, 6))



def get_color_legend(data:Data) -> dict:

    color_csvs = {
        'lumap': 'luto/tools/report/VUE_modules/assets/lumap_colors_grouped.csv',
        'lm': 'luto/tools/report/VUE_modules/assets/lm_colors.csv',
        'ag': 'luto/tools/report/VUE_modules/assets/lumap_colors.csv',
        'non_ag': 'luto/tools/report/VUE_modules/assets/non_ag_colors.csv',
        'am': 'luto/tools/report/VUE_modules/assets/ammap_colors.csv',
    }
    
    return {
        'Land-use': {
            'color_csv': color_csvs['lumap'], 
            'legend': pd.read_csv(color_csvs['lumap']).query('lu_code in @data.AGLU2DESC').set_index('lu_desc')['lu_color_HEX'].to_dict()
            },
        'Water-supply': {
            'color_csv': color_csvs['lm'],
            'legend': pd.read_csv(color_csvs['lm']).set_index('lu_desc')['lu_color_HEX'].to_dict()
            },
        'Agricultural Land-use': {
            'color_csv': color_csvs['ag'],
            'legend': pd.read_csv(color_csvs['ag']).query('lu_code in @data.AGLU2DESC').set_index('lu_desc')['lu_color_HEX'].to_dict()
            },
        'Non-agricultural Land-use': {
            'color_csv': color_csvs['non_ag'],
            'legend': pd.read_csv(color_csvs['non_ag']).query('lu_code in @data.NONAGLU2DESC').set_index('lu_desc')['lu_color_HEX'].to_dict()
            },
        'Agricultural Management': {
            'color_csv': color_csvs['am'],
            'legend': pd.read_csv(color_csvs['am']).query('lu_desc in @data.AG_MAN_DESC').set_index('lu_desc')['lu_color_HEX'].to_dict()
        }
    }


   
def array_to_base64(arr_4band: np.ndarray, bbox: list, min_max:list) -> dict:

    # Create PIL Image from RGBA array
    image = Image.fromarray(arr_4band, 'RGBA')
    
    # Convert to base64 string
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
    
    return {
        'img_str': 'data:image/png;base64,' + img_str,
        'bounds': [
            [bbox[1], bbox[0]],
            [bbox[3], bbox[2]]
        ],
        'min_max': min_max
    }



def map2base64_interger(f:str, color_csv:str, attrs:tuple = ()) -> dict:
    
        with xr.open_dataset(f) as ds:
            img = ds['__xarray_dataarray_variable__'].compute()
            img_geo = ds['spatial_ref'].attrs['crs_wkt']

        # Convert the 1D array to a RGBA array
        color_csv = pd.read_csv(color_csv)
        color_csv['color_numeric'] = color_csv['lu_color_HEX'].apply(hex_color_to_numeric)
        color_dict = color_csv.set_index('lu_code')['color_numeric'].to_dict()
        color_dict[-1] = (0,0,0,0)    # Nodata pixels are transparent
 
        # Get the bounding box, then reproject to Mercator
        img = img.rio.write_crs(img_geo)
        bbox = img.rio.bounds()
        img = img.rio.reproject('EPSG:3857') # To Mercator with Nearest Neighbour
        img = np.nan_to_num(img, nan=-1).astype('int16')

        # Convert to RGBA array
        arr_4band = np.zeros((img.shape[0], img.shape[1], 4), dtype='uint8')
        for k, v in color_dict.items():
            arr_4band[img == k] = v

        return attrs, array_to_base64(arr_4band, bbox, [])
    
    
    
def map2base64_float(rxr_path:str, arr_lyr:xr.DataArray, attrs:tuple) -> dict|None:

        # Get an template rio-xarray, it will be used to convert 1D array to its 2D map format
        with xr.open_dataset(rxr_path) as rxr_ds:
            rxr_arr = rxr_ds['__xarray_dataarray_variable__']
            rxr_crs = rxr_ds['spatial_ref'].attrs['crs_wkt']

        # Skip if the layer is empty
        if arr_lyr.sum() == 0:
            return 

        # Normalize the layer
        min_val = np.nanmin(arr_lyr.values)
        max_val = np.nanmax(arr_lyr.values)
        arr_lyr.values = (arr_lyr - min_val) / (max_val - min_val)

        # Convert the 1D array to a 2D array
        np.place(rxr_arr.data, rxr_arr.data>=0, arr_lyr.data)  # Set negative values to NaN
        rxr_arr = xr.where(rxr_arr<0, np.nan, rxr_arr)
        rxr_arr = rxr_arr.rio.write_crs(rxr_crs)

        # Get bounding box, then reproject to Mercator
        bbox = rxr_arr.rio.bounds()
        rxr_arr = rxr_arr.rio.reproject('EPSG:3857') # To Mercator with Nearest Neighbour

        # Convert layer to integer; after this 0 is nodata, -100 is outside LUTO area
        rxr_arr.values *= 100
        rxr_arr = np.where(np.isnan(rxr_arr), 0, rxr_arr).astype('int32')

        # Convert the 1D array to a RGBA array
        color_dict = pd.read_csv('luto/tools/report/VUE_modules/assets/float_img_colors.csv')
        if max_val == 0:
            color_dict.loc[range(100), 'lu_color_HEX'] = color_dict.loc[range(100), 'lu_color_HEX'].values[::-1]
            min_val, max_val = max_val, min_val
        color_dict['color_numeric'] = color_dict['lu_color_HEX'].apply(hex_color_to_numeric)
        color_dict = color_dict.set_index('lu_code')['color_numeric'].to_dict()

        color_dict[0] = (0,0,0,0)    # Nodata pixels are transparent

        arr_4band = np.zeros((rxr_arr.shape[0], rxr_arr.shape[1], 4), dtype='uint8')
        for k, v in color_dict.items():
            arr_4band[rxr_arr == k] = v

        # Generate base64 and overlay info
        return attrs, array_to_base64(arr_4band, bbox, [float(max_val), float(min_val)])
    
    

def get_map_obj_float(data:Data, files_df:pd.DataFrame, save_path:str, workers:int=settings.WRITE_THREADS) -> dict:

    # Get an template rio-xarray, it will be used to convert 1D array to its 2D map format
    template_xr = f'{data.path}/out_{sorted(settings.SIM_YEARS)[0]}/xr_map_lumap_{sorted(settings.SIM_YEARS)[0]}.nc'
    
    # Get dim info
    with xr.open_dataarray(files_df.iloc[0]['path']) as arr_eg:
        loop_dims = set(arr_eg.dims) - set(['cell', 'y', 'x'])
        
        dim_vals = pd.MultiIndex.from_product(
            [arr_eg[dim].values for dim in loop_dims],
            names=loop_dims
        ).to_list()

        loop_sel = [dict(zip(loop_dims, val)) for val in dim_vals]
        
    # Loop through each year
    task = []
    for _,row in files_df.iterrows():
        xr_arr = xr.load_dataarray(row['path'])
        _year = row['Year']
        
        for sel in loop_sel:
            arr_sel = xr_arr.sel(**sel) 
            
            # Rename keys; also serve as reordering the keys
            sel_rename = {}
            if 'am' in sel:
                sel_rename['am'] = RENAME_AM_NON_AG.get(sel['am'], sel['am'])
            if 'lm' in sel:
                sel_rename['lm'] =  {'irr': 'Irrigated', 'dry': 'Dryland'}.get(sel['lm'], sel['lm'])
            if 'lu' in sel:
                sel_rename['lu'] = RENAME_AM_NON_AG.get(sel['lu'], sel['lu'])
            if 'Commodity' in sel:
                commodity = sel['Commodity'].capitalize()
                sel_rename['Commodity'] = {
                    'Sheep lexp': 'Sheep live export',
                    'Beef lexp': 'Beef live export'
                }.get(commodity, commodity)
                
            task.append(
                delayed(map2base64_float)(template_xr, arr_sel, tuple(list(sel_rename.values()) + [_year]))
            )    
            
    # Gather results and save to JSON
    output = {}
    for res in Parallel(n_jobs=workers, return_as='generator')(task):
        if res is None:continue
        attr, val = res
        output[attr] = val
        
    # To nested dict
    output = tuple_dict_to_nested(output)

    if not os.path.exists(os.path.dirname(save_path)):
        os.makedirs(os.path.dirname(save_path), exist_ok=True)

    with open(save_path, 'w') as f:
        filename = os.path.basename(save_path).replace('.js', '')
        f.write(f'window["{filename}"] = ')
        json.dump(output, f, separators=(',', ':'), indent=2)
        f.write(';\n')
        

def get_map_obj_interger(files_df:pd.DataFrame, save_path:str, colors_legend, workers:int=settings.WRITE_THREADS) -> dict:
    
    map_mosaic_lumap = files_df.query('base_name == "xr_map_lumap"'
        ).assign(
            _type='Land-use', 
            color_csv=colors_legend['Land-use']['color_csv'], 
            legend_info=str(colors_legend['Land-use']['legend'])
        )
    map_mosaic_lmmap = files_df.query('base_name == "xr_map_lmmap"'
        ).assign(
            _type='Water-supply',
            color_csv=colors_legend['Water-supply']['color_csv'],
            legend_info=str(colors_legend['Water-supply']['legend'])
        )
    map_mosaic_ag = files_df.query('base_name == "xr_map_ag_argmax"'
        ).assign(
            _type='Agricultural Land-use',
            color_csv=colors_legend['Agricultural Land-use']['color_csv'],
            legend_info=str(colors_legend['Agricultural Land-use']['legend'])
        )
    map_mosaic_non_ag = files_df.query('base_name == "xr_map_non_ag_argmax"'
        ).assign(
            _type='Non-agricultural Land-use',
            color_csv=colors_legend['Non-agricultural Land-use']['color_csv'],
            legend_info=str(colors_legend['Non-agricultural Land-use']['legend'])
        )
    map_mosaic_am = files_df.query('base_name == "xr_map_am_argmax"'
        ).assign(
            _type='Agricultural Management',
            color_csv=colors_legend['Agricultural Management']['color_csv'],
            legend_info=str(colors_legend['Agricultural Management']['legend'])
        )
    map_mosaic = pd.concat([
        map_mosaic_lumap,
        map_mosaic_lmmap,
        map_mosaic_ag,
        map_mosaic_non_ag,
        map_mosaic_am
    ], ignore_index=True)

    
    task = []
    for _, row in map_mosaic.iterrows():
        task.append(
            delayed(map2base64_interger)(
                row['path'], 
                row['color_csv'], 
                (row['_type'], row['Year'], row['legend_info'])
            )
        )

    output = {}
    for res in Parallel(n_jobs=settings.WRITE_THREADS, return_as='generator')(task):
        if res is None:continue
        (_type, _year, legend), val = res
        if _type not in output:
            output[_type] = {}
        if _year not in output[_type]:
            output[_type][_year] = {}
        output[_type][_year] = {
            **val,
            'legend': eval(legend)
        }
        
    # Save to JSON
    if not os.path.exists(os.path.dirname(save_path)):
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
    with open(save_path, 'w') as f:
        filename = os.path.basename(save_path).replace('.js', '')
        f.write(f'window["{filename}"] = ')
        json.dump(output, f, separators=(',', ':'), indent=2)
        f.write(';\n')




def save_report_layer(data:Data, raw_data_dir:str):
    """
    Saves the report data in the specified directory.

    Parameters
    ----------
    data (Data): The Data object containing the metadata and settings.
    raw_data_dir (str): The directory where the raw data is stored.
    
    Returns
    -------
    None
    """
    
    SAVE_DIR = f'{raw_data_dir}/DATA_REPORT/data'
    years = sorted(settings.SIM_YEARS)

    # Create the directory if it does not exist
    if not os.path.exists(f'{SAVE_DIR}/map_layers'):
        os.makedirs(f'{SAVE_DIR}/map_layers', exist_ok=True)

    # Get all LUTO output files and store them in a dataframe
    files = get_all_files(raw_data_dir).query('category == "xarray_layer"')
    files['Year'] = files['Year'].astype(int)
    files = files.query('Year.isin(@years)')
    
    
    
    ####################################################
    #                   1) Mosaic maps                 #
    ####################################################
    
    save_path = f'{SAVE_DIR}/map_layers/map_dvar_mosaic.js'
    colors_legend= get_color_legend(data)
    get_map_obj_interger(files, save_path, colors_legend)


 
    ####################################################
    #                   2) Dvar Layer                  #
    ####################################################
    
    dvar_ag = files.query('base_name == "xr_map_ag"')
    get_map_obj_float(data, dvar_ag, f'{SAVE_DIR}/map_layers/map_dvar_Ag.js')
    
    dvar_am = files.query('base_name == "xr_map_am"')
    get_map_obj_float(data, dvar_am, f'{SAVE_DIR}/map_layers/map_dvar_Am.js')
    
    dvar_nonag = files.query('base_name == "xr_map_non_ag"')
    get_map_obj_float(data, dvar_nonag, f'{SAVE_DIR}/map_layers/map_dvar_NonAg.js')
    
    
    
    ####################################################
    #                   3) Area Layer                  #
    ####################################################

    files_area = files.query('base_name.str.contains("area")')

    area_ag = files_area.query('base_name == "xr_area_agricultural_landuse"')
    get_map_obj_float(data, area_ag, f'{SAVE_DIR}/map_layers/map_area_Ag.js')

    area_am = files_area.query('base_name == "xr_area_agricultural_management"')
    get_map_obj_float(data, area_am, f'{SAVE_DIR}/map_layers/map_area_Am.js')

    area_nonag = files_area.query('base_name == "xr_area_non_agricultural_landuse"')
    get_map_obj_float(data, area_nonag, f'{SAVE_DIR}/map_layers/map_area_NonAg.js')



    ####################################################
    #                  4) Biodiversity                 #
    ####################################################

    files_bio = files.query('base_name.str.contains("biodiversity")')

    # GBF2
    bio_GBF2_ag = files_bio.query('base_name == "xr_biodiversity_GBF2_priority_ag"')
    get_map_obj_float(data, bio_GBF2_ag, f'{SAVE_DIR}/map_layers/map_bio_GBF2_Ag.js')

    bio_GBF2_am = files_bio.query('base_name == "xr_biodiversity_GBF2_priority_ag_management"')
    get_map_obj_float(data, bio_GBF2_am, f'{SAVE_DIR}/map_layers/map_bio_GBF2_Am.js')

    bio_GBF2_nonag = files_bio.query('base_name == "xr_biodiversity_GBF2_priority_non_ag"')
    get_map_obj_float(data, bio_GBF2_nonag, f'{SAVE_DIR}/map_layers/map_bio_GBF2_NonAg.js')

    # Overall priority
    bio_overall_ag = files_bio.query('base_name == "xr_biodiversity_overall_priority_ag"')
    get_map_obj_float(data, bio_overall_ag, f'{SAVE_DIR}/map_layers/map_bio_overall_Ag.js')

    bio_overall_am = files_bio.query('base_name == "xr_biodiversity_overall_priority_ag_management"')
    get_map_obj_float(data, bio_overall_am, f'{SAVE_DIR}/map_layers/map_bio_overall_Am.js')

    bio_overall_nonag = files_bio.query('base_name == "xr_biodiversity_overall_priority_non_ag"')
    get_map_obj_float(data, bio_overall_nonag, f'{SAVE_DIR}/map_layers/map_bio_overall_NonAg.js')



    ####################################################
    #                    5) Cost                       #
    ####################################################

    files_cost = files.query('base_name.str.contains("cost")')

    cost_ag = files_cost.query('base_name == "xr_cost_ag"')
    get_map_obj_float(data, cost_ag, f'{SAVE_DIR}/map_layers/map_cost_Ag.js')

    cost_am = files_cost.query('base_name == "xr_cost_agricultural_management"')
    get_map_obj_float(data, cost_am, f'{SAVE_DIR}/map_layers/map_cost_Am.js')

    cost_nonag = files_cost.query('base_name == "xr_cost_non_ag"')
    get_map_obj_float(data, cost_nonag, f'{SAVE_DIR}/map_layers/map_cost_NonAg.js')

    # cost_transition = files_cost.query('base_name == "xr_cost_transition_ag2ag"')
    # get_map_obj_float(data, cost_transition, f'{SAVE_DIR}/map_layers/map_cost_transition.js')



    ####################################################
    #                    6) GHG                        #
    ####################################################

    files_ghg = files.query('base_name.str.contains("GHG")')

    ghg_ag = files_ghg.query('base_name == "xr_GHG_ag"')
    get_map_obj_float(data, ghg_ag, f'{SAVE_DIR}/map_layers/map_GHG_Ag.js')

    ghg_am = files_ghg.query('base_name == "xr_GHG_ag_management"')
    get_map_obj_float(data, ghg_am, f'{SAVE_DIR}/map_layers/map_GHG_Am.js')

    ghg_nonag = files_ghg.query('base_name == "xr_GHG_non_ag"')
    get_map_obj_float(data, ghg_nonag, f'{SAVE_DIR}/map_layers/map_GHG_NonAg.js')



    ####################################################
    #                  7) Quantities                   #
    ####################################################

    files_quantities = files.query('base_name.str.contains("quantities")')

    quantities_ag = files_quantities.query('base_name == "xr_quantities_agricultural"')
    get_map_obj_float(data, quantities_ag, f'{SAVE_DIR}/map_layers/map_quantities_Ag.js')

    quantities_am = files_quantities.query('base_name == "xr_quantities_agricultural_management"')
    get_map_obj_float(data, quantities_am, f'{SAVE_DIR}/map_layers/map_quantities_Am.js')

    quantities_nonag = files_quantities.query('base_name == "xr_quantities_non_agricultural"')
    get_map_obj_float(data, quantities_nonag, f'{SAVE_DIR}/map_layers/map_quantities_NonAg.js')



    ####################################################
    #                   8) Revenue                     #
    ####################################################

    files_revenue = files.query('base_name.str.contains("revenue")')

    revenue_ag = files_revenue.query('base_name == "xr_revenue_ag"')
    get_map_obj_float(data, revenue_ag, f'{SAVE_DIR}/map_layers/map_revenue_Ag.js')

    revenue_am = files_revenue.query('base_name == "xr_revenue_agricultural_management"')
    get_map_obj_float(data, revenue_am, f'{SAVE_DIR}/map_layers/map_revenue_Am.js')

    revenue_nonag = files_revenue.query('base_name == "xr_revenue_non_ag"')
    get_map_obj_float(data, revenue_nonag, f'{SAVE_DIR}/map_layers/map_revenue_NonAg.js')



    ####################################################
    #                9) Transition Cost                #
    ####################################################

    # files_transition = files.query('base_name.str.contains("transition")')

    # transition_cost = files_transition.query('base_name == "xr_transition_cost_ag2non_ag"')
    # get_map_obj_float(data, transition_cost, f'{SAVE_DIR}/map_layers/map_transition_cost.js')

    # transition_ghg = files_transition.query('base_name == "xr_transition_GHG"')
    # get_map_obj_float(data, transition_ghg, f'{SAVE_DIR}/map_layers/map_transition_GHG.js')



    ####################################################
    #               10) Water Yield                    #
    ####################################################

    files_water = files.query('base_name.str.contains("water_yield")')

    water_ag = files_water.query('base_name == "xr_water_yield_ag"')
    get_map_obj_float(data, water_ag, f'{SAVE_DIR}/map_layers/map_water_yield_Ag.js')

    water_am = files_water.query('base_name == "xr_water_yield_ag_management"')
    get_map_obj_float(data, water_am, f'{SAVE_DIR}/map_layers/map_water_yield_Am.js')

    water_nonag = files_water.query('base_name == "xr_water_yield_non_ag"')
    get_map_obj_float(data, water_nonag, f'{SAVE_DIR}/map_layers/map_water_yield_NonAg.js')
```

## luto/tools/report/data_tools/parameters.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

from itertools import cycle
import luto.settings as settings


# Get the root directory of the data
YR_BASE = 2010

# Define the commodity categories
COMMODITIES_ON_LAND = [
    'Apples','Beef live export','Beef meat','Citrus','Cotton','Dairy','Grapes',
    'Hay','Nuts','Other non-cereal crops', 'Pears', 'Plantation fruit',
    'Rice', 'Sheep live export', 'Sheep meat', 'Sheep wool', 'Stone fruit', 'Sugar',
    'Summer cereals', 'Summer legumes', 'Summer oilseeds', 'Tropical stone fruit',
    'Vegetables','Winter cereals','Winter legumes','Winter oilseeds'
]

COMMODITIES_OFF_LAND = ['Aquaculture', 'Chicken', 'Eggs', 'Pork' ]

COMMODITIES_ALL = COMMODITIES_ON_LAND + COMMODITIES_OFF_LAND


LU_CROPS = [
    'Apples','Citrus','Cotton','Grapes','Hay','Nuts','Other non-cereal crops',
    'Pears','Plantation fruit','Rice','Stone fruit','Sugar','Summer cereals',
    'Summer legumes','Summer oilseeds','Tropical stone fruit','Vegetables',
    'Winter cereals','Winter legumes','Winter oilseeds'
]

LU_LVSTKS = [
    'Beef - natural land','Dairy - natural land','Sheep - natural land',
    'Beef - modified land','Dairy - modified land','Sheep - modified land'
]

LU_UNALLOW = ['Unallocated - modified land', 'Unallocated - natural land']




# Define land use code for am and non-ag land uses
AM_SELECT = [i for i in settings.AG_MANAGEMENTS if settings.AG_MANAGEMENTS[i]]
AM_DESELECT = [i for i in settings.AG_MANAGEMENTS if not settings.AG_MANAGEMENTS[i]]
AM_MAP_CODES = {i:(AM_SELECT.index(i) + 1) for i in AM_SELECT}

NON_AG_SELECT = [i for i in settings.NON_AG_LAND_USES if settings.NON_AG_LAND_USES[i]]
NON_AG_DESELECT = [i for i in settings.NON_AG_LAND_USES if not settings.NON_AG_LAND_USES[i]]
NON_AG_MAP_CODES = {i:(NON_AG_SELECT.index(i) + 1) for i in NON_AG_SELECT}

AM_NON_AG_CODES = {**AM_MAP_CODES, **NON_AG_MAP_CODES}
AM_NON_AG_REMOVED_DESC = AM_DESELECT + NON_AG_DESELECT


# Define the file name patterns for each category
GHG_FNAME2TYPE = {'GHG_emissions_separate_agricultural_landuse': 'Agricultural Landuse',
                  'GHG_emissions_separate_agricultural_management': 'Agricultural Management',
                  'GHG_emissions_separate_no_ag_reduction': 'Non-Agricultural Landuse',
                  'GHG_emissions_separate_transition_penalty': 'Transition Penalty',
                  'GHG_emissions_offland_commodity': 'Offland Commodity',}


AG_LANDUSE_MERGE_LANDTYPE = ['Apples', 'Beef', 'Citrus', 'Cotton', 'Dairy', 'Grapes', 'Hay', 'Nuts', 'Other non-cereal crops',
                             'Pears', 'Plantation fruit', 'Rice', 'Sheep', 'Stone fruit', 'Sugar', 'Summer cereals',
                             'Summer legumes', 'Summer oilseeds', 'Tropical stone fruit', 'Unallocated - modified land', 
                             'Unallocated - natural land', 'Vegetables', 'Winter cereals', 'Winter legumes', 'Winter oilseeds']


# Define the renaming of the Agricultural-Managment and Non-Agricultural 
RENAME_AM = {
    "Asparagopsis taxiformis": "Methane reduction (livestock)",
    "Precision Agriculture": "Agricultural technology (fertiliser)", 
    "Ecological Grazing": "Regenerative agriculture (livestock)", 
    "Savanna Burning": "Early dry-season savanna burning",
    "AgTech EI": "Agricultural technology (energy)",
    'Biochar': "Biochar (soil amendment)",
    'HIR - Beef': "Human-induced regeneration (Beef)",
    'HIR - Sheep': "Human-induced regeneration (Sheep)",

}

RENAME_NON_AG = {
    "Environmental Plantings": "Environmental plantings (mixed species)",
    "Riparian Plantings": "Riparian buffer restoration (mixed species)",
    "Sheep Agroforestry": "Agroforestry (mixed species + sheep)",
    "Beef Agroforestry": "Agroforestry (mixed species + beef)",
    "Carbon Plantings (Block)": "Carbon plantings (monoculture)",
    "Sheep Carbon Plantings (Belt)": "Farm forestry (hardwood timber + sheep)",
    "Beef Carbon Plantings (Belt)": "Farm forestry (hardwood timber + beef)",
    "BECCS": "BECCS (Bioenergy with Carbon Capture and Storage)",
    "Destocked - natural land": "Destocked - natural land",
}

RENAME_AM_NON_AG = {**RENAME_AM, **RENAME_NON_AG}

# Read the land uses from the file
with open(f'{settings.INPUT_DIR}/ag_landuses.csv') as f:
    AG_LANDUSE = [line.strip() for line in f]
    
    
# This will be used in the HTML for reporting spatial maps
SPATIAL_MAP_DICT = {
    'Int_Map': ['lumap', 'non_ag', 'ammap', 'lmmap'],       # Each cell is an integer, representing a land-use for [AG, AM, Non-AG]
    'Ag_LU': AG_LANDUSE,                                    # Percentage of Agricultural Landuse to a cell
    'Ag_Mgt': list(settings.AG_MANAGEMENTS.keys()),         # Percentage of Agricultural Management to a cell                 
    'Non-Ag_LU': list(settings.NON_AG_LAND_USES.keys())     # Percentage of Non-Agricultural Landuse to a cell
}


# Get the non-agricultural land uses raw names
NON_AG_LANDUSE_RAW = list(settings.NON_AG_LAND_USES.keys())
NON_AG_LANDUSE_RAW = [i for i in NON_AG_LANDUSE_RAW if settings.NON_AG_LAND_USES[i]]


# Merge the land uses
LANDUSE_ALL_RAW = AG_LANDUSE + NON_AG_LANDUSE_RAW
LANDUSE_ALL_RENAMED = ['Agri-Management'] + AG_LANDUSE + list(RENAME_NON_AG.values())  + ['Outside LUTO study area'] 




# Define the GHG categories
GHG_NAMES = {
    # Agricultural Landuse
    'TCO2E_CHEM_APPL': 'Chemical Application',
    'TCO2E_CROP_MGT': 'Crop Management',
    'TCO2E_CULTIV': 'Cultivation',
    'TCO2E_FERT_PROD': 'Fertiliser production',
    'TCO2E_HARVEST': 'Harvesting',
    'TCO2E_IRRIG': 'Irrigation',
    'TCO2E_PEST_PROD': 'Pesticide production',
    'TCO2E_SOWING': 'Sowing',
    'TCO2E_ELEC': 'Electricity Use livestock',
    'TCO2E_FODDER': 'Fodder production',
    'TCO2E_FUEL': 'Fuel Use livestock',
    'TCO2E_IND_LEACH_RUNOFF': 'Agricultural soils: Indirect leaching and runoff',
    'TCO2E_MANURE_MGT': 'Livestock Manure Management (biogenic)',
    'TCO2E_SEED': 'Pasture Seed production',
    'TCO2E_SOIL': 'Agricultural soils: Direct Soil Emissions (biogenic)',
    'TCO2E_DUNG_URINE': 'Agricultural soils: Animal production, dung and urine',
    'TCO2E_ENTERIC': 'Livestock Enteric Fermentation (biogenic)',
    # Agricultural Management
    'TCO2E_Asparagopsis taxiformis': 'Asparagopsis taxiformis', 
    'TCO2E_Precision Agriculture': 'Precision Agriculture',
    'TCO2E_Ecological Grazing': 'Ecological Grazing',
    # Non-Agricultural Landuse
    'TCO2E_Agroforestry': 'Agroforestry', 
    'TCO2E_Environmental Plantings': 'Environmental Plantings',
    'TCO2E_Riparian Plantings': 'Riparian Plantings',
    'TCO2E_Carbon Plantings (Belt)': 'Carbon Plantings (Belt)',
    'TCO2E_Carbon Plantings (Block)': 'Carbon Plantings (Block)',
    'TCO2E_BECCS': 'BECCS',
    'TCO2E_Savanna Burning': 'Savanna Burning',
    'TCO2E_AgTech EI': 'AgTech EI',
}

GHG_CATEGORY = {
    'Agricultural soils: Animal production, dung and urine': {"CH4":0.5,"CO2":0.5},
    'Livestock Enteric Fermentation (biogenic)':{'CH4':1},
    'Agricultural soils: Direct Soil Emissions (biogenic)':{"N2O":1},
    
    'Asparagopsis taxiformis':{'Asparagopsis taxiformis':1},
    'Precision Agriculture':{'Precision Agriculture':1},
    'Ecological Grazing':{'Ecological Grazing':1}
}



# Colors for reporting HTML to loop through
COLORS = [
    "#8085e9",
    "#f15c80",
    "#e4d354",
    "#2b908f",
    "#f45b5b",
    "#7cb5ec",
    "#434348",
    "#90ed7d",
    "#f7a35c",
    "#91e8e1",
]

COLORS_RANK = {
    '1-10': "#ff8f5e",
    '11-20': "#d5e5a3",
    '>=21': "#91e8e1",
    'N.A.': "#e8eaed",
}

pattern_path = {
    'path': 
        {
            'd': "M 0 0 L 10 10 M 10 0 L 0 10", 
            'stroke': "#cccccc", 
            'strokeWidth': 1,
        },
    'width': 10,
    'height': 10,
}

COLORS_LU = dict(zip(LANDUSE_ALL_RENAMED, cycle(COLORS)))
COLORS_LU.update({'Outside LUTO study area': "#C7BFBF"})
COLORS_LU.update({'Agri-Management': "#D5F100"})
COLORS_LM = dict(zip(['Dryland', 'Irrigated'], ["#f7a35c", "#7cb5ec"]))
COLORS_COMMODITIES = dict(zip(COMMODITIES_ALL, cycle(COLORS)))
COLORS_AM_NONAG = dict(zip(list(RENAME_AM_NON_AG.values()) + ['ALL'], cycle(COLORS)))
COLORS_GHG = dict(zip(GHG_NAMES.values(), cycle(COLORS)))

COLORS_ECONOMY_TYPE = dict(zip(
    [
        'Live Exports', 'Meat', 'Milk', 'Wool', 'Crop', 'Area cost',
        'Fixed depreciation cost', 'Fixed labour cost', 'Fixed operating cost',
        'Quantity cost', 'Water cost', 'ALL'
    ],
     cycle(COLORS)
))


PATTERNS_LU = {k:{'pattern':{**pattern_path, 'backgroundColor': v} } for k,v in COLORS_LU.items()}
PATTERNS_LM = {k: {'pattern': {**pattern_path, 'backgroundColor': v}} for k, v in COLORS_LM.items()}
PATTERNS_COMMODITIES = {k: {'pattern': {**pattern_path, 'backgroundColor': v}} for k, v in COLORS_COMMODITIES.items()}
PATTERNS_AM_NONAG = {k: {'pattern': {**pattern_path, 'backgroundColor': v}} for k, v in COLORS_AM_NONAG.items()}
PATTERNS_GHG = {k: {'pattern': {**pattern_path, 'backgroundColor': v}} for k, v in COLORS_GHG.items()}
PATTERNS_ECONOMY_TYPE = {k: {'pattern': {**pattern_path, 'backgroundColor': v}} for k, v in COLORS_ECONOMY_TYPE.items()}
```

## luto/tools/report/data_tools/__init__.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.

import os
import re
import pandas as pd

from luto.tools.report.data_tools.parameters import YR_BASE


def extract_dtype_from_path(path):
    """
    Extracts the data type and year type from a given file path.

    Args:
        path (str): The file path.

    Returns
        tuple: A tuple containing the year type and data type extracted from the file path.
    """
    # Define the output categories and its corresponding file patterns
    f_cat = {
            # decision variables (npy files)
            'ag_X_mrj':['ag_X_mrj'],
            'ag_man_X_mrj':['ag_man_X_mrj'],
            'non_ag_X_rk':['non_ag_X_rk'],
            # CSVs
            'GHG':['GHG'],
            'water':['water'],
            'cross_table':['crosstab','switches'],
            'area':['area'],
            'transition_matrix':['transition_matrix'],
            'quantity':['quantity'],
            'revenue':['revenue'],
            'cost':['cost'],
            'biodiversity':['biodiversity'],
            # Maps (GeoTIFFs)
            'ammap':['ammap'],
            'lumap':['lumap'],
            'lmmap':['lmmap'],
            'non_ag':['non_ag'],
            'Ag_LU':['Ag_LU'], 
            'Ag_Mgt':['Ag_Mgt'],
            'Land_Mgt':['Land_Mgt'],
            'Non-Ag':['Non-Ag'],
            # Metrics xarrays
            'xarray_layer':['xr_'],
    }

    # Get the base name of the file path
    base_name = os.path.basename(path)

    # Check the file type
    for ftype, fpat in f_cat.items():

        search_result = []
        for pat in fpat:
            # Registry to check the start of the base name
            reg = re.compile(fr'^{pat}')
            search_result.append(bool(reg.search(base_name)))

        # If any of the patterns are found, break the loop
        if any(search_result): 
            break
        else:
            ftype = 'Unknown'

    return ftype



def get_all_files(data_root):
    """
    Retrieve a list of file paths from the specified data root directory.

    Args:
        data_root (str): The root directory to search for files.

    Returns
        pandas.DataFrame: A DataFrame containing the file paths, along with 
        additional columns for year, year types, category, base name, and 
        base extension.
    """
    file_paths = []

    # Walk through the folder and its subfolders
    for foldername, _, filenames in os.walk(data_root):
        for filename in filenames:
            # Create the full path to the file by joining the foldername and filename
            file_path = os.path.join(foldername, filename)
            # Append the file path to the list
            file_paths.append(file_path)

    # Only filepath containing "out_" are valid paths
    file_paths = sorted([i for i in file_paths if 'out_' in i])

    # Get the year from the file name
    file_paths = pd.DataFrame({'path':file_paths})
    file_paths.insert(0, 'Year', [re.compile(r'out_(\d{4})').findall(i)[0] for i in file_paths['path']])

    # Try to get the year type and category from the file path
    f_cats = [extract_dtype_from_path(i) for i in file_paths['path']]

    # Append the year type and category to the file paths
    file_paths.insert(1, 'category', f_cats)

    # Get the base name and extension of the file path
    file_paths[['base_name','base_ext']] = [os.path.splitext(os.path.basename(i)) for i in file_paths['path']]
    file_paths = file_paths.reindex(columns=['Year','category','base_name','base_ext','path'])

    # Remove the datatime stamp <YYYY_MM_DD__HH_mm_SS> from the base_name
    file_paths['base_name'] = file_paths['base_name'].apply(lambda x: re.sub(r'_\d{4}','',x))
    
    # Report the unknown files
    unknown_files = file_paths.query('category == "Unknown"')
    if not unknown_files.empty:
        print(f"Unknown files found: {unknown_files['path'].tolist()}")
        
    # Remove rows with category = 'Unknown'
    file_paths = file_paths.query('category != "Unknown"').reset_index(drop=True)
    

    return file_paths
```

## luto/tools/report/VUE_modules/assets/AUS_STATE_SIMPLIFIED/STE11aAust_mercator_simplified.cpg

```text
UTF-8
```

## luto/tools/report/VUE_modules/assets/AUS_STATE_SIMPLIFIED/STE11aAust_mercator_simplified.prj

```text
PROJCS["WGS_1984_Web_Mercator_Auxiliary_Sphere",GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",SPHEROID["WGS_1984",6378137.0,298.257223563]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]],PROJECTION["Mercator_Auxiliary_Sphere"],PARAMETER["False_Easting",0.0],PARAMETER["False_Northing",0.0],PARAMETER["Central_Meridian",0.0],PARAMETER["Standard_Parallel_1",0.0],PARAMETER["Auxiliary_Sphere_Type",0.0],UNIT["Meter",1.0]]
```

## luto/tools/report/VUE_modules/assets/NRM_SIMPLIFY_FILTER/NRM_AUS_SIMPLIFIED.cpg

```text
UTF-8
```

## luto/tools/report/VUE_modules/assets/NRM_SIMPLIFY_FILTER/NRM_AUS_SIMPLIFIED.prj

```text
PROJCS["WGS_1984_Web_Mercator_Auxiliary_Sphere",GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",SPHEROID["WGS_1984",6378137.0,298.257223563]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]],PROJECTION["Mercator_Auxiliary_Sphere"],PARAMETER["False_Easting",0.0],PARAMETER["False_Northing",0.0],PARAMETER["Central_Meridian",0.0],PARAMETER["Standard_Parallel_1",0.0],PARAMETER["Auxiliary_Sphere_Type",0.0],UNIT["Meter",1.0]]
```

## luto/tools/report/VUE_modules/assets/NRM_SIMPLIFY_FILTER/NRM_AUS_SIMPLIFIED.shp.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<metadata xml:lang="en"><Esri><CreaDate>20250902</CreaDate><CreaTime>14564800</CreaTime><ArcGISFormat>1.0</ArcGISFormat><SyncOnce>FALSE</SyncOnce><DataProperties><itemProps><itemName Sync="TRUE">nrm2025_v_simplify</itemName><imsContentType Sync="TRUE">002</imsContentType><itemSize Sync="TRUE">0.000</itemSize><itemLocation><linkage Sync="TRUE">file://\\JINZHU\C$\Users\Jinzhu\Desktop\New folder\nrm2025_v_simplify.shp</linkage><protocol Sync="TRUE">Local Area Network</protocol></itemLocation></itemProps><coordRef><type Sync="TRUE">Geographic</type><geogcsn Sync="TRUE">GCS_GDA_1994</geogcsn><csUnits Sync="TRUE">Angular Unit: Degree (0.017453)</csUnits><peXml Sync="TRUE">&lt;GeographicCoordinateSystem xsi:type='typens:GeographicCoordinateSystem' xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance' xmlns:xs='http://www.w3.org/2001/XMLSchema' xmlns:typens='http://www.esri.com/schemas/ArcGIS/10.4'&gt;&lt;WKT&gt;GEOGCS[&amp;quot;GCS_GDA_1994&amp;quot;,DATUM[&amp;quot;D_GDA_1994&amp;quot;,SPHEROID[&amp;quot;GRS_1980&amp;quot;,6378137.0,298.257222101]],PRIMEM[&amp;quot;Greenwich&amp;quot;,0.0],UNIT[&amp;quot;Degree&amp;quot;,0.0174532925199433],AUTHORITY[&amp;quot;EPSG&amp;quot;,4283]]&lt;/WKT&gt;&lt;XOrigin&gt;-400&lt;/XOrigin&gt;&lt;YOrigin&gt;-400&lt;/YOrigin&gt;&lt;XYScale&gt;11258999068426.238&lt;/XYScale&gt;&lt;ZOrigin&gt;-100000&lt;/ZOrigin&gt;&lt;ZScale&gt;10000&lt;/ZScale&gt;&lt;MOrigin&gt;-100000&lt;/MOrigin&gt;&lt;MScale&gt;10000&lt;/MScale&gt;&lt;XYTolerance&gt;8.9831528411952133e-009&lt;/XYTolerance&gt;&lt;ZTolerance&gt;0.001&lt;/ZTolerance&gt;&lt;MTolerance&gt;0.001&lt;/MTolerance&gt;&lt;HighPrecision&gt;true&lt;/HighPrecision&gt;&lt;LeftLongitude&gt;-180&lt;/LeftLongitude&gt;&lt;WKID&gt;4283&lt;/WKID&gt;&lt;LatestWKID&gt;4283&lt;/LatestWKID&gt;&lt;/GeographicCoordinateSystem&gt;</peXml></coordRef></DataProperties><SyncDate>20250902</SyncDate><SyncTime>14550600</SyncTime><ModDate>20250902</ModDate><ModTime>14550600</ModTime></Esri><dataIdInfo><envirDesc Sync="TRUE"> Version 6.2 (Build 9200) ; Esri ArcGIS 10.4.0.5524</envirDesc><dataLang><languageCode value="eng" Sync="TRUE"></languageCode><countryCode value="AUS" Sync="TRUE"></countryCode></dataLang><idCitation><resTitle Sync="TRUE">nrm2025_v_simplify</resTitle><presForm><PresFormCd value="005" Sync="TRUE"></PresFormCd></presForm></idCitation><spatRpType><SpatRepTypCd value="001" Sync="TRUE"></SpatRepTypCd></spatRpType></dataIdInfo><mdLang><languageCode value="eng" Sync="TRUE"></languageCode><countryCode value="AUS" Sync="TRUE"></countryCode></mdLang><mdChar><CharSetCd value="004" Sync="TRUE"></CharSetCd></mdChar><distInfo><distFormat><formatName Sync="TRUE">Shapefile</formatName></distFormat><distTranOps><transSize Sync="TRUE">0.000</transSize></distTranOps></distInfo><mdHrLv><ScopeCd value="005" Sync="TRUE"></ScopeCd></mdHrLv><mdHrLvName Sync="TRUE">dataset</mdHrLvName><refSysInfo><RefSystem><refSysID><identCode code="4283" Sync="TRUE"></identCode><idCodeSpace Sync="TRUE">EPSG</idCodeSpace><idVersion Sync="TRUE">8.3.4(3.0.1)</idVersion></refSysID></RefSystem></refSysInfo><spatRepInfo><VectSpatRep><geometObjs Name="nrm2025_v_simplify"><geoObjTyp><GeoObjTypCd value="002" Sync="TRUE"></GeoObjTypCd></geoObjTyp><geoObjCnt Sync="TRUE">0</geoObjCnt></geometObjs><topLvl><TopoLevCd value="001" Sync="TRUE"></TopoLevCd></topLvl></VectSpatRep></spatRepInfo><spdoinfo><ptvctinf><esriterm Name="nrm2025_v_simplify"><efeatyp Sync="TRUE">Simple</efeatyp><efeageom code="4" Sync="TRUE"></efeageom><esritopo Sync="TRUE">FALSE</esritopo><efeacnt Sync="TRUE">0</efeacnt><spindex Sync="TRUE">FALSE</spindex><linrefer Sync="TRUE">FALSE</linrefer></esriterm></ptvctinf></spdoinfo><eainfo><detailed Name="nrm2025_v_simplify"><enttyp><enttypl Sync="TRUE">nrm2025_v_simplify</enttypl><enttypt Sync="TRUE">Feature Class</enttypt><enttypc Sync="TRUE">0</enttypc></enttyp><attr><attrlabl Sync="TRUE">FID</attrlabl><attalias Sync="TRUE">FID</attalias><attrtype Sync="TRUE">OID</attrtype><attwidth Sync="TRUE">4</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale><attrdef Sync="TRUE">Internal feature number.</attrdef><attrdefs Sync="TRUE">Esri</attrdefs><attrdomv><udom Sync="TRUE">Sequential unique whole numbers that are automatically generated.</udom></attrdomv></attr><attr><attrlabl Sync="TRUE">Shape</attrlabl><attalias Sync="TRUE">Shape</attalias><attrtype Sync="TRUE">Geometry</attrtype><attwidth Sync="TRUE">0</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale><attrdef Sync="TRUE">Feature geometry.</attrdef><attrdefs Sync="TRUE">Esri</attrdefs><attrdomv><udom Sync="TRUE">Coordinates defining the features.</udom></attrdomv></attr><attr><attrlabl Sync="TRUE">ID</attrlabl><attalias Sync="TRUE">ID</attalias><attrtype Sync="TRUE">Integer</attrtype><attwidth Sync="TRUE">10</attwidth><atprecis Sync="TRUE">10</atprecis><attscale Sync="TRUE">0</attscale></attr><attr><attrlabl Sync="TRUE">GRIDCODE</attrlabl><attalias Sync="TRUE">GRIDCODE</attalias><attrtype Sync="TRUE">Integer</attrtype><attwidth Sync="TRUE">10</attwidth><atprecis Sync="TRUE">10</atprecis><attscale Sync="TRUE">0</attscale></attr><attr><attrlabl Sync="TRUE">Area</attrlabl><attalias Sync="TRUE">Area</attalias><attrtype Sync="TRUE">Single</attrtype><attwidth Sync="TRUE">13</attwidth><atprecis Sync="TRUE">0</atprecis><attscale Sync="TRUE">0</attscale></attr></detailed></eainfo><mdDateSt Sync="TRUE">20250902</mdDateSt></metadata>
```

## luto/tools/report/VUE_modules/components/chart_container.js

```javascript
window.Highchart = {
  props: {
    chartData: {
      type: Object,
      required: true,
    },
    selectedLanduse: {
      type: String,
      default: 'ALL',
    },
    draggable: {
      type: Boolean,
      default: false,
    },
    zoomable: {
      type: Boolean,
      default: false,
    }
  },
  setup(props) {
    const { ref, onMounted, onUnmounted, watch, inject, computed } = Vue
    const isCollapsed = inject('isCollapsed', ref(false))

    // Reactive state for loading status and datasets
    const chartElement = ref(null);
    const isLoading = ref(true);
    const ChartInstance = ref(null);
    const position = ref({ x: 0, y: 0 });
    const isDragging = ref(false);
    const dragStartPos = ref({ x: 0, y: 0 });
    const scale = ref(1);
    const zoomStep = 0.1;

    // Apply landuse highlighting to chart data
    const applyHighlighting = (chartData) => {
      if (!props.selectedLanduse || props.selectedLanduse === 'ALL' || !chartData.series) {
        return chartData;
      }

      const highlightedSeries = chartData.series.map(series => ({
        ...series,
        color: series.name === props.selectedLanduse
          ? series.color
          : (typeof Highcharts !== 'undefined' && Highcharts.color
            ? Highcharts.color(series.color).setOpacity(0.3).get()
            : series.color),
        borderWidth: series.name === props.selectedLanduse ? 2 : 0,
        borderColor: series.name === props.selectedLanduse ? '#1f2937' : 'transparent'
      }));

      return {
        ...chartData,
        series: highlightedSeries
      };
    };

    // Function to handle dataset loading and chart creation
    const createChart = () => {
      isLoading.value = true;

      // Apply highlighting to chart data before creating chart
      const processedChartData = applyHighlighting(props.chartData);

      // Create new chart with explicit responsive options
      ChartInstance.value = Highcharts.chart(
        chartElement.value,
        {
          ...processedChartData,
          chart: (processedChartData.chart || {}),
        }
      );

      isLoading.value = false;
    };

    // Function to handle window resize
    const handleResize = () => { createChart(); };

    // Dragging functionality
    const startDrag = (event) => {
      if (!props.draggable) return;
      isDragging.value = true;
      dragStartPos.value = {
        x: event.clientX - position.value.x,
        y: event.clientY - position.value.y
      };
    };

    const onDrag = (event) => {
      if (isDragging.value) {
        position.value = {
          x: event.clientX - dragStartPos.value.x,
          y: event.clientY - dragStartPos.value.y
        };
      }
    };

    const stopDrag = () => {
      isDragging.value = false;
    };

    // Zoom functionality
    const zoomIn = () => {
      if (!props.zoomable) return;
      scale.value += zoomStep;
    };

    const zoomOut = () => {
      if (!props.zoomable) return;
      if (scale.value > zoomStep) {
        scale.value -= zoomStep;
      }
    };

    const handleWheel = (event) => {
      if (!props.zoomable) return;
      event.preventDefault();
      if (event.deltaY < 0) {
        zoomIn();
      } else {
        zoomOut();
      }
    };

    // Function to update the chart with new series data
    const updateChart = (chart, newChartData) => {
      try {
        // Apply highlighting before updating
        const processedData = applyHighlighting(newChartData);
        
        // Make a deep copy of the processed chart data to avoid reference issues
        const newData = JSON.parse(JSON.stringify(processedData));

        // Update the chart configuration options first (except series)
        for (const key in newData) {
          if (key !== 'series') {
            chart.update({ [key]: newData[key] }, false);
          }
        }

        // Handle series data updates safely
        if (newData.series && Array.isArray(newData.series)) {
          // Step 1: Remove excess series if there are more in the chart than in new data
          while (chart.series.length > newData.series.length) {
            if (chart.series[chart.series.length - 1]) {
              chart.series[chart.series.length - 1].remove(false);
            }
          }

          // Step 2: Update existing series or add new ones
          newData.series.forEach((seriesConfig, index) => {
            if (index < chart.series.length) {
              // Series exists, update it safely
              if (chart.series[index]) {
                // Simple setData approach to avoid removePoint errors
                chart.series[index].setData(seriesConfig.data || [], false);

                // Update other properties but not the data (already updated)
                const { data, ...otherProps } = seriesConfig;
                chart.series[index].update(otherProps, false);
              }
            } else {
              // Series doesn't exist, add it
              chart.addSeries(seriesConfig, false);
            }
          });
        }

        // Final redraw to apply all changes with animation
        chart.redraw();
      } catch (error) {
        console.error("Error updating chart:", error);
        // Fallback to complete recreation if update fails
        createChart();
      }
    }

    onMounted(() => {
      createChart();
      window.addEventListener('resize', handleResize);
      window.addEventListener('mousemove', onDrag);
      window.addEventListener('mouseup', stopDrag);
    });

    onUnmounted(() => {
      window.removeEventListener('resize', handleResize);
      window.removeEventListener('mousemove', onDrag);
      window.removeEventListener('mouseup', stopDrag);
    });

    // Watch for changes in chart data with infinite loop prevention
    let isUpdating = false;
    watch(() => props.chartData, (newValue) => { 
      // Prevent infinite loops
      if (isUpdating) {
        return;
      }
      
      isUpdating = true;
      
      try {
        updateChart(ChartInstance.value, newValue);
      } finally {
        // Reset flag after a delay to ensure all reactive updates complete
        setTimeout(() => {
          isUpdating = false;
        }, 100);
      }
    }, { deep: true });

    // Watch for sidebar collapsed state changes via inject
    watch(isCollapsed, () => {
      setTimeout(() => {
        createChart();
      }, 300); // Wait for sidebar animation to complete
    });

    // Watch for selectedLanduse changes to re-apply highlighting
    watch(() => props.selectedLanduse, () => {
      if (ChartInstance.value && props.chartData) {
        updateChart(ChartInstance.value, props.chartData);
      }
    });

    return {
      chartElement,
      isLoading,
      ChartInstance,
      position,
      startDrag,
      scale,
      zoomIn,
      zoomOut,
      handleWheel
    };
  },
  template: `
    <div class="m-2 relative" 
      :style="{ transform: 'translate(' + position.x + 'px, ' + position.y + 'px) scale(' + scale + ')', cursor: draggable ? 'move' : 'default' }" 
      @mousedown="startDrag"
      @wheel.prevent="handleWheel">
      <div v-if="isLoading" class="flex justify-center items-center text-lg">Loading data...</div>
      <div ref="chartElement" id="chart-container"></div>
      <div v-if="zoomable" class="absolute top-[40px] right-2 flex flex-col space-y-1">
        <button @click="zoomIn" class="bg-white/80 hover:bg-white text-gray-800 w-8 h-8 rounded-full shadow flex items-center justify-center">+</button>
        <button @click="zoomOut" class="bg-white/80 hover:bg-white text-gray-800 w-8 h-8 rounded-full shadow flex items-center justify-center">-</button>
      </div>
    </div>
  `
}
```

## luto/tools/report/VUE_modules/components/filterable_dropdown.js

```javascript
window.FilterableDropdown = {
  props: {
    useSearch: {
      type: Boolean,
      default: true
    },
    items: {
      type: Array,
      default: () => []
    },
    selectedValue: {
      type: String,
      default: ''
    },
    placeholder: {
      type: String,
      default: 'Select item...'
    },
    searchPlaceholder: {
      type: String,
      default: 'Search...'
    }
  },
  setup(props, { emit }) {
    const { ref, inject, onMounted, watch } = Vue;
    const items = ref([]);
    const selectedItem = ref('');
    const isOpen = ref(false);
    const searchTerm = ref('');

    // Use injected global region if no items prop provided (backwards compatibility)
    const globalSelectedRegion = inject('globalSelectedRegion', null);

    onMounted(async () => {
      if (props.items && props.items.length > 0) {
        items.value = [...props.items];
        selectedItem.value = props.selectedValue;
      } else {
        // Legacy behavior for regions
        await window.loadScript("./data/geo/NRM_AUS.js", 'NRM_AUS');
        const regions = window.NRM_AUS.features.map(feature => feature.properties.NRM_REGION);
        const otherRegions = regions.filter(region => region !== 'AUSTRALIA').sort();
        items.value = ['AUSTRALIA', ...otherRegions];
        selectedItem.value = globalSelectedRegion?.value || '';
      }
    });

    // Watch for prop changes
    watch(() => props.selectedValue, (newValue) => {
      selectedItem.value = newValue;
    }, { immediate: true });

    watch(() => props.items, (newItems) => {
      if (newItems && newItems.length > 0) {
        items.value = [...newItems];
      }
    }, { immediate: true, deep: true });

    return {
      selectedItem,
      isOpen,
      searchTerm,
      items,
      globalSelectedRegion
    };
  },
  computed: {
    filteredItems() {
      if (!this.useSearch || !this.searchTerm) return this.items;
      return this.items.filter(item =>
        item.toLowerCase().includes(this.searchTerm.toLowerCase())
      );
    }
  },
  mounted() {
    document.addEventListener('mousedown', this.handleClickOutside);
  },
  beforeUnmount() {
    document.removeEventListener('mousedown', this.handleClickOutside);
  },
  methods: {
    handleClickOutside(event) {
      if (this.$refs.dropdownRef && !this.$refs.dropdownRef.contains(event.target)) {
        this.isOpen = false;
      }
    },
    handleItemSelect(item) {
      this.selectedItem = item;
      this.isOpen = false;
      this.searchTerm = '';

      // Emit change event for parent components
      this.$emit('change', item);

      // Legacy support: update global region if available
      if (this.globalSelectedRegion) {
        this.globalSelectedRegion = item;
      }
    },
    toggleDropdown() {
      this.isOpen = !this.isOpen;
    },
    clearSearch() {
      this.searchTerm = '';
    }
  },
  template: `
    <div class="relative py-2 px-2" ref="dropdownRef">
      <!-- Main dropdown trigger button - displays selected region or placeholder -->
      <button
        @click="toggleDropdown"
        class="w-full py-1 px-1 text-left bg-white border border-gray-300 rounded-lg shadow-sm hover:border-gray-400 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-blue-500 transition-colors"
      >
        <div class="flex items-center justify-between">
          <span class="text-[0.8rem]" :class="selectedItem ? 'text-gray-900' : 'text-gray-500'">
            {{ selectedItem || placeholder }}
          </span>
          <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-5 h-5 text-gray-400 transition-transform" :class="isOpen ? 'rotate-180' : ''">
            <path d="m6 9 6 6 6-6"/>
          </svg>
        </div>
      </button>

      <!-- Dropdown content - only visible when isOpen is true -->
      <div v-if="isOpen" class="absolute mr-2 z-10 mt-1 bg-white border border-gray-300 rounded-lg shadow-lg">
        <!-- Search input field with search icon -->
        <div v-if="useSearch" class="p-0.5 border-b border-gray-200 h-8">
          <div class="relative">
            <svg width="8" height="8" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="absolute left-3 top-1/2 transform -translate-y-1/2 w-4 h-4 text-gray-400">
              <circle cx="11" cy="11" r="8"/>
              <path d="m21 21-4.3-4.3"/>
            </svg>
            <input
              class="text-[0.75rem]"
              type="text"
              :placeholder="searchPlaceholder"
              v-model="searchTerm"
              class="pl-10 pr-1 py-1 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-blue-500"
            />
          </div>
        </div>

        <!-- Scrollable list of filtered region items -->
        <div class="max-h-80 overflow-y-auto">
          <div class="py-0.5">
            <button
              v-for="(item, index) in filteredItems"
              :key="index"
              @click="handleItemSelect(item)"
              class="text-[0.8rem] w-full px-1 py-0.5 text-left hover:bg-blue-50 focus:bg-blue-50 focus:outline-none transition-colors"
            >
              <span class="block text-gray-900">{{ item }}</span>
            </button>
          </div>
        </div>

      </div>

      
    </div>
  `
};
```

## luto/tools/report/VUE_modules/components/helpers.js

```javascript
window.loadScript = (src, name) => {
    return new Promise((resolve, reject) => {
        const existingScript = document.querySelector(`script[src="${src}"]`);

        if (existingScript && window[name]) {
            resolve();
            return;
        }

        const script = document.createElement("script");
        script.src = src;
        document.head.appendChild(script);

        script.onload = async () => {
            const timeout = 5000;
            const startTime = Date.now();
            while (!window[name]) {
                if (Date.now() - startTime > timeout) {
                    reject(new Error(`Global variable ${name} not available within timeout`));
                    return;
                }
                await new Promise(resolve => setTimeout(resolve, 10));
            }
            resolve();
        };

        script.onerror = () => reject(new Error(`Failed to load script: ${src}`));
    });
};
```

## luto/tools/report/VUE_modules/components/map_geojson.js

```javascript
window.map_geojson = {
    props: {
        height: {
            type: String,
            default: '500px',
        },
        selectRankingColors: {
            type: Object,
        },
    },
    setup(props) {
        const { ref, onMounted, watch, nextTick, inject } = Vue;

        const mapElement = ref(null);
        const mapInstance = ref(null);
        const activeRegionName = inject('globalSelectedRegion');
        const hoverTooltip = ref(null);
        const geoJSONLayer = ref(null);
        const featureStyles = ref({});
        const australiaBounds = L.latLngBounds([-42, 113], [-12, 154]);

        const defaultStyle = {
            color: "#fefefe",
            fillColor: "#d2d7dd",
            fillOpacity: 0.5,
            weight: 1.5,
        };

        const highlightStyle = {
            color: "#0b0b0b",
            fillColor: "#0b0b0b",
            fillOpacity: 0.5,
            weight: 0.1,
        };

        onMounted(() => {

            // Initialize basic map with disabled controls
            const map = L.map(mapElement.value, {
                zoomControl: false,
                attributionControl: false,
                zoomSnap: 0.1,
                dragging: false,
                scrollWheelZoom: false,
                doubleClickZoom: false,
            });

            // Set view to Australia
            map.setView(australiaBounds.getCenter(), 3.9, { animate: false });

            // Store map instance for later use
            mapInstance.value = map;

            // Get style function for each feature
            const getFeatureStyle = (feature) => {
                const regionName = feature.properties.NRM_REGION;
                let style = { ...defaultStyle };

                if (props.selectRankingColors && props.selectRankingColors[regionName]) {
                    style.fillColor = props.selectRankingColors[regionName];
                }

                featureStyles.value[regionName] = style;
                return style;
            };

            // Add GeoJSON layer with mouse effects
            geoJSONLayer.value = L.geoJSON(window['NRM_AUS'], {
                style: getFeatureStyle,
                onEachFeature: (feature, layer) => {
                    layer.options.regionName = feature.properties.NRM_REGION;

                    // Set initial style
                    if (activeRegionName.value === feature.properties.NRM_REGION) {
                        layer.setStyle(highlightStyle);
                    }

                    // Mouse events
                    layer.on({
                        mousemove: (e) => {
                            const layer_e = e.target;

                            if (layer_e._path) {
                                layer_e._path.style.cursor = 'default';
                            }

                            // Remove previous tooltip
                            if (hoverTooltip.value) {
                                map.removeLayer(hoverTooltip.value);
                                hoverTooltip.value = null;
                            }

                            // Create hover tooltip
                            hoverTooltip.value = L.tooltip({
                                permanent: false,
                                direction: "top",
                            });
                            hoverTooltip.value.setContent(feature.properties.NRM_REGION);
                            hoverTooltip.value.setLatLng(e.latlng);
                            hoverTooltip.value.addTo(map);
                        },
                        mouseout: (e) => {
                            const layer_e = e.target;

                            // Remove tooltip
                            if (hoverTooltip.value) {
                                map.removeLayer(hoverTooltip.value);
                                hoverTooltip.value = null;
                            }

                            if (layer_e.options.regionName === activeRegionName.value) {
                                layer_e.setStyle(highlightStyle);
                            }
                        },
                        click: (e) => {
                            const layer_e = e.target;

                            // Toggle selection
                            if (layer_e.options.regionName === activeRegionName.value) {
                                // Deselect - restore original style
                                const regionName = layer_e.options.regionName;
                                if (featureStyles.value[regionName]) {
                                    layer_e.setStyle(featureStyles.value[regionName]);
                                } else {
                                    layer_e.setStyle(defaultStyle);
                                }
                                activeRegionName.value = 'AUSTRALIA';
                                return;
                            }

                            // Remove highlight from all regions
                            geoJSONLayer.value.eachLayer(function (layer) {
                                const regionName = layer.options.regionName;
                                if (featureStyles.value[regionName]) {
                                    layer.setStyle(featureStyles.value[regionName]);
                                } else {
                                    layer.setStyle(defaultStyle);
                                }
                            });

                            // Highlight new selection
                            layer_e.setStyle(highlightStyle);
                            activeRegionName.value = layer_e.options.regionName;
                        },
                    });
                },
            }).addTo(map);

            // Ensure map size is correct after initialization
            setTimeout(() => {
                map.invalidateSize();
            }, 100);

        });


        // Function to update map colors when selectRankingColors changes
        const updateMapStyles = () => {
            if (!geoJSONLayer.value) return;

            geoJSONLayer.value.eachLayer(function (layer) {
                const regionName = layer.options.regionName;

                // Skip currently selected region
                if (regionName === activeRegionName.value) return;

                // Update style with new colors
                let style = { ...defaultStyle };
                if (props.selectRankingColors && props.selectRankingColors[regionName]) {
                    style.fillColor = props.selectRankingColors[regionName];
                }

                featureStyles.value[regionName] = style;
                layer.setStyle(style);
            });
        };

        // Watch for ranking color changes
        watch(() => props.selectRankingColors, updateMapStyles, { deep: true });

        // Watch for height changes and update map size
        watch(
            () => props.height,
            async (newHeight) => {
                if (mapInstance.value) {
                    await nextTick();
                    setTimeout(() => {
                        mapInstance.value.invalidateSize();
                    }, 50);
                }
            },
            { immediate: false }
        );

        return {
            mapElement,
            activeRegionName,
            props,
        };
    },
    template: `
      <div>
        <div ref="mapElement" :style="{ background: 'transparent', height: props.height + ' !important', width: '100%' }"></div>
      </div>
    `,
};
```

## luto/tools/report/VUE_modules/components/ranking_cards.js

```javascript
// Ranking Cards Element
// This component displays ranking cards with progress indicators for various metrics

window.RankingCards = {
  props: {
    rankingData: {
      type: Object,
      required: true
    },
    selectRegion: {
      type: String,
      required: true
    },
    selectYear: {
      type: Number,
      required: true
    },
  },


  template: `
    <div class="flex flex-wrap gap-4 justify-between h-[230px]">
      <!-- Economics Card -->
      <div class="flex-1 rounded-lg p-3 shadow-md flex flex-col bg-gradient-to-r from-[#e6ba7f] to-[#eacca2]" >
        <h4 class="text-white text-center text-lg mb-2">Economics</h4>
        <div class="text-2xl text-center font-bold text-white mb-1">{{ rankingData['Economics'][selectRegion]['Total']['value'][selectYear] }}</div>
        <div class="text-white/80 text-center text-[12px] mb-4">Australian Dollar</div>
        <div class="mt-auto">
          <div class="flex justify-between text-white text-[14px] py-1 border-t border-white/20">
            <span>Cost</span>
            <span>{{ rankingData['Economics'][selectRegion]['Cost']['value'][selectYear] }}</span>
          </div>
          <div class="flex justify-between text-white text-[14px] py-1 border-t border-white/20">
            <span>Revenue</span>
            <span>{{ rankingData['Economics'][selectRegion]['Revenue']['value'][selectYear] }}</span>
          </div>
        </div>
      </div>
      
      <!-- Area Card -->
      <div class="flex-1  rounded-lg p-3 shadow-md flex flex-col bg-gradient-to-r from-blue-400 to-cyan-400" >
        <h4 class="text-white text-center text-lg mb-2">Area</h4>
        <div class="text-2xl text-center font-bold text-white mb-1">{{ rankingData['Area'][selectRegion]['Total']['value'][selectYear] }}</div>
        <div class="text-white/80 text-center text-[12px] mb-4">Hectares</div>
        <div class="mt-auto">
          <div class="flex justify-between text-white text-[14px] py-1 border-t border-white/20">
            <span>Ag Land</span>
            <span>{{ rankingData['Area'][selectRegion]['Agricultural Landuse']['value'][selectYear] }}</span>
          </div>
          <div class="flex justify-between text-white text-[14px] py-1 border-t border-white/20">
            <span>Ag Mgt</span>
            <span>{{ rankingData['Area'][selectRegion]['Agricultural Management']['value'][selectYear] }}</span>
          </div>
          <div class="flex justify-between text-white text-[14px] py-1 border-t border-white/20">
            <span>Non-Ag</span>
            <span>{{ rankingData['Area'][selectRegion]['Non-Agricultural Landuse']['value'][selectYear] }}</span>
          </div>
        </div>
      </div>
      
      <!-- GHG Card -->
      <div class="flex-1  rounded-lg p-3 shadow-md flex flex-col bg-gradient-to-r from-green-400 to-green-500" >
        <h4 class="text-white text-center text-lg mb-2">GHG Impact</h4>
        <div class="text-2xl text-center font-bold text-white mb-1">{{ rankingData['GHG'][selectRegion]['Total']['value'][selectYear] }}</div>
        <div class="text-white/80 text-center text-[12px] mb-4">tCO2e</div>
        <div class="mt-auto">
          <div class="flex justify-between text-white text-[14px] py-1 border-t border-white/20">
            <span>Emissions</span>
            <span>{{ rankingData['GHG'][selectRegion]['GHG emissions']['value'][selectYear] }}</span>
          </div>
          <div class="flex justify-between text-white text-[14px] py-1 border-t border-white/20">
            <span>Reduction</span>
            <span>{{ rankingData['GHG'][selectRegion]['GHG sequestrations']['value'][selectYear] }}</span>
          </div>
        </div>
      </div>
      
      <!-- Water Card -->
      <div class="flex-1  rounded-lg p-3 shadow-md flex flex-col bg-gradient-to-r from-rose-400 to-amber-300" >
        <h4 class="text-white text-center text-lg mb-2">Water Usage</h4>
        <div class="text-2xl text-center font-bold text-white mb-1">{{ rankingData['Water'][selectRegion]['Total']['value'][selectYear] }}</div>
        <div class="text-white/80 text-center text-[12px] mb-4">Megaliters</div>
        <div class="mt-auto">
          <div class="flex justify-between text-white text-[14px] py-1 border-t border-white/20">
            <span>Ag Land</span>
            <span>{{ rankingData['Water'][selectRegion]['Agricultural Landuse']['value'][selectYear] }}</span>
          </div>
          <div class="flex justify-between text-white text-[14px] py-1 border-t border-white/20">
            <span>Ag Mgt</span>
            <span>{{ rankingData['Water'][selectRegion]['Agricultural Management']['value'][selectYear] }}</span>
          </div>
          <div class="flex justify-between text-white text-[14px] py-1 border-t border-white/20">
            <span>NonAg</span>
            <span>{{ rankingData['Water'][selectRegion]['Non-Agricultural Landuse']['value'][selectYear] }}</span>
          </div>
        </div>
      </div>
      
      <!-- Biodiversity Card -->
      <div class="flex-1  rounded-lg p-3 shadow-md flex flex-col bg-gradient-to-r from-[#918be9] to-[#e2cbfa]" >
        <h4 class="text-white text-center text-lg mb-2">Biodiversity</h4>
        <div class="text-2xl text-center font-bold text-white mb-1">{{ rankingData['Biodiversity'][selectRegion]['Total']['value'][selectYear] }}</div>
        <div class="text-white/80 text-center text-[12px] mb-4">Priority Weighted Hectares</div>
        <div class="mt-auto">
          <div class="flex justify-between text-white text-[14px] py-1 border-t border-white/20">
            <span>Ag Land</span>
            <span>{{ rankingData['Biodiversity'][selectRegion]['Agricultural Landuse']['value'][selectYear] }}</span>
          </div>
          <div class="flex justify-between text-white text-[14px] py-1 border-t border-white/20">
            <span>Ag Mgt</span>
            <span>{{ rankingData['Biodiversity'][selectRegion]['Agricultural Management']['value'][selectYear] }}</span>
          </div>
          <div class="flex justify-between text-white text-[14px] py-1 border-t border-white/20">
            <span>Non-Ag</span>
            <span>{{ rankingData['Biodiversity'][selectRegion]['Non-Agricultural land-use']['value'][selectYear] }}</span>
          </div>
        </div>
      </div>
    </div>
  `,
};
```

## luto/tools/report/VUE_modules/components/regions_map.js

```javascript
window.RegionsMap = {

  props: {
    mapData: {
      type: String,
      required: true
    },
  },

  setup(props) {
    const { ref, inject, onMounted, computed } = Vue;
    const globalMapViewpoint = inject('globalMapViewpoint');
    const selectedRegion = inject('globalSelectedRegion');

    const map = ref(null);
    const boundingBox = ref(null);
    const loadScript = window.loadScript;                       // DataConstructor has been registered in index.html [DataConstructor.js] [helpers.js]
    const selectedBaseMap = ref('OpenStreetMap');
    const tileLayers = ref({});
    const baseMapOptions = ref(['OpenStreetMap', 'Satellite', 'None']);



    const initMap = () => {
      // Initialize the map with saved viewpoint
      map.value = L.map('map', {
        zoomControl: false
      }).setView(globalMapViewpoint.value.center, globalMapViewpoint.value.zoom);

      // Save current view on map events
      map.value.on('moveend zoomend', () => {
        globalMapViewpoint.value.center = [map.value.getCenter().lat, map.value.getCenter().lng];
        globalMapViewpoint.value.zoom = map.value.getZoom();
      });

      // Create tile layers but don't add them yet
      tileLayers.value = {
        OSM: L.tileLayer('https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', {
          attribution: '© OpenStreetMap contributors',
          maxZoom: 18
        }),
        Satellite: L.tileLayer('https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}', {
          attribution: 'Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community',
          maxZoom: 18
        })
      };

      // Add initial base map
      const initialMapType = selectedBaseMap.value === 'OpenStreetMap' ? 'OSM' : selectedBaseMap.value;
      if (initialMapType !== 'None') {
        tileLayers.value[initialMapType].addTo(map.value);
      }
    };

    // Update map when region changes - only animate if region actually changed
    const updateMap = (forceAnimation = false) => {
      // Check if this is a real region change or just a page navigation
      const regionChanged = globalMapViewpoint.value.lastSelectedRegion !== selectedRegion.value;

      if (!regionChanged && !forceAnimation) {
        // Just update the region layer without animation
        updateRegionLayerOnly();
        return;
      }

      // Update the last selected region
      globalMapViewpoint.value.lastSelectedRegion = selectedRegion.value;

      // Fade out existing elements first
      fadeOutExistingElements().then(() => {
        // Remove existing rectangles after fade out
        if (boundingBox.value) {
          map.value.removeLayer(boundingBox.value);
        }

        // Calculate bounds for smooth transition
        const bbox = window.NRM_AUS_centroid_bbox[selectedRegion.value].bounding_box;
        const bounds = [
          [bbox[1], bbox[0]], // Southwest corner
          [bbox[3], bbox[2]]  // Northeast corner
        ];

        // Smooth pan and zoom to the new region
        map.value.flyToBounds(bounds, {
          padding: [20, 20],
          duration: 1.5,
          easeLinearity: 0.25
        });

        // Add new elements with a delay to allow map transition
        setTimeout(() => {
          addRegionLayer();
        }, 500);
      });
    };

    // Update only the region layer without map animation
    const updateRegionLayerOnly = () => {
      // Remove existing rectangles
      if (boundingBox.value) {
        map.value.removeLayer(boundingBox.value);
      }

      // Add new region layer immediately
      addRegionLayer();
    };

    // Fade out existing map elements
    const fadeOutExistingElements = () => {
      return new Promise((resolve) => {
        if (boundingBox.value) {
          animateRectangleOpacity(boundingBox.value, 0.2, 0, 300);
        }
        setTimeout(resolve, 300);
      });
    };

    // Add new elements to the map
    const addRegionLayer = () => {
      // Skip adding region overlay for AUSTRALIA
      if (selectedRegion.value === 'AUSTRALIA') {
        return;
      }

      // Find the actual region feature from NRM_AUS data
      const regionLayer = window.NRM_AUS.features.find(feature =>
        feature.properties.NRM_REGION === selectedRegion.value
      );

      // Add the actual region polygon with initial opacity 0
      boundingBox.value = L.geoJSON(regionLayer, {
        style: {
          color: '#3b82f6',
          weight: 2,
          fillColor: '#3b82f6',
          fillOpacity: 0,
          opacity: 0
        }
      }).addTo(map.value);

      // Fade in new elements
      setTimeout(() => {
        animateRectangleOpacity(boundingBox.value, 0, 0.2, 500);
      }, 200);
    };

    // Animation functions
    const animateRectangleOpacity = (rectangle, startFillOpacity, endFillOpacity, duration) => {
      const startTime = Date.now();
      const startStrokeOpacity = startFillOpacity > 0 ? 1 : 0;
      const endStrokeOpacity = endFillOpacity > 0 ? 1 : 0;

      const animate = () => {
        const elapsed = Date.now() - startTime;
        const progress = Math.min(elapsed / duration, 1);
        const easedProgress = easeInOut(progress);

        const currentFillOpacity = startFillOpacity + (endFillOpacity - startFillOpacity) * easedProgress;
        const currentStrokeOpacity = startStrokeOpacity + (endStrokeOpacity - startStrokeOpacity) * easedProgress;

        rectangle.setStyle({
          fillOpacity: currentFillOpacity,
          opacity: currentStrokeOpacity
        });

        if (progress < 1) {
          requestAnimationFrame(animate);
        }
      };
      requestAnimationFrame(animate);
    };

    const easeInOut = (t) => {
      return t < 0.5 ? 2 * t * t : -1 + (4 - 2 * t) * t;
    };

    // Load region data and initialize map on component mount
    onMounted(async () => {
      try {
        // Load region data
        await loadScript("services/MapService.js", 'MapService');
        await loadScript('data/geo/NRM_AUS_centroid_bbox.js', 'NRM_AUS_centroid_bbox');
        await loadScript('data/geo/NRM_AUS.js', 'NRM_AUS');

        // Initialize map first
        initMap();

        // Skip initial map data load - will be loaded by the watcher when props are populated
        // The watch handler will take care of loading map data when props are ready

        // Update map if a region is already selected
        if (selectedRegion.value) {
          updateMap();
        }
      } catch (error) {
        console.error('Failed to initialize RegionsMap:', error);
      }
    });

    const loadMapData = async () => {

      // Always remove existing overlays first
      map.value.eachLayer((layer) => {
        if (layer instanceof L.ImageOverlay) {
          map.value.removeLayer(layer);
        }
      });

      const data = props.mapData;

      if (!data.img_str || !data.bounds) {
        console.warn('Map data is missing required properties (img_str or bounds):', data);
        // No overlay will be added - map shows base layer only
        return;
      }

      // Add new image overlay only if data is valid
      const imageOverlay = L.imageOverlay(
        data.img_str,
        data.bounds,
        {
          className: 'crisp-image'
        }
      ).addTo(map.value);

      // Apply CSS to disable image interpolation
      setTimeout(() => {
        const imgElement = imageOverlay.getElement();
        if (imgElement) {
          imgElement.style.imageRendering = 'pixelated';
          imgElement.style.imageRendering = '-moz-crisp-edges';
          imgElement.style.imageRendering = 'crisp-edges';
        }
      }, 100);
    };

    Vue.watch(() => props.mapData, (newVal) => {
      loadMapData();
    });

    Vue.watch(selectedRegion, (newValue, oldValue) => {
      if (newValue) {
        // Only trigger animation if this is a real region change (not a page navigation)
        const forceAnimation = oldValue !== undefined && oldValue !== newValue;
        updateMap(forceAnimation);
      }
    });

    const handleBaseMapChange = (mapType) => {
      selectedBaseMap.value = mapType;
      // Map display names to internal values
      const mapTypeMap = {
        'OpenStreetMap': 'OSM',
        'Satellite': 'Satellite',
        'None': 'None'
      };
      changeBaseMap(mapTypeMap[mapType]);
    };

    const changeBaseMap = (mapType) => {
      // Remove all existing tile layers
      Object.values(tileLayers.value).forEach(layer => {
        if (map.value.hasLayer(layer)) {
          map.value.removeLayer(layer);
        }
      });

      // Add new tile layer if not 'None'
      if (mapType !== 'None' && tileLayers.value[mapType]) {
        tileLayers.value[mapType].addTo(map.value);
      }
    };

    return {
      selectedRegion,
      updateMap,
      selectedBaseMap,
      changeBaseMap,
      baseMapOptions,
      handleBaseMapChange
    };
  },
  template: `
    <div class="bg-white h-screen flex flex-col">
    
      <!-- Map Container with Controls Overlay - Base map selector and map element -->
      <div class="bg-white shadow-lg flex-1 relative">

        <!-- Base Map Selector - Dropdown to switch between map types -->
        <div class="absolute top-[40px] left-[20px] z-50 bg-white/70 rounded-lg shadow-lg z-[9999]">
          <div style="min-width: 150px;">
            <filterable-dropdown
              :use-search="false"
              :items="baseMapOptions"
              :selected-value="selectedBaseMap"
              placeholder="Select base map"
              @change="handleBaseMapChange"
            />
          </div>
        </div>

        <!-- Map Container - Leaflet map will be initialized here -->
        <div id="map" class="w-full h-full relative z-10"></div>
      </div>
    </div>
  `
};
```

## luto/tools/report/VUE_modules/components/sidebar.js

```javascript
window.Sidebar = {
  emits: ['update:isCollapsed'],
  setup(props, { emit }) {
    const { ref, computed } = Vue;
    // Function to standardize SVG icons for consistent display
    const standardizeIcon = (icon) => {
      // Add a fixed viewBox to ensure consistent sizing
      return icon.replace('<svg', '<svg width="24" height="24"');
    };

    const navItems = [
      { id: "home", label: "Home", path: "/", icon: standardizeIcon(window.NavIcons.home) },
      { id: "area", label: "Area Analysis", path: "/area", icon: standardizeIcon(window.NavIcons.area) },
      { id: "production", label: "Production Analysis", path: "/production", icon: standardizeIcon(window.NavIcons.production) },
      { id: "economy", label: "Economics", path: "/economics", icon: standardizeIcon(window.NavIcons.economy) },
      { id: "GHG", label: "GHG Analysis", path: "/ghg", icon: standardizeIcon(window.NavIcons.GHG) },
      { id: "water", label: "Water Analysis", path: "/water", icon: standardizeIcon(window.NavIcons.water) },
      { id: "biodiversity", label: "Biodiversity", path: "/biodiversity", icon: standardizeIcon(window.NavIcons.biodiversity) },
      { id: "map", label: "Map View", path: "/map", icon: standardizeIcon(window.NavIcons.map) },
      { id: "settings", label: "Settings and Log", path: "/settings", icon: standardizeIcon(window.NavIcons.settings) },
    ];

    const CommonIcons = {
      Expand: standardizeIcon(window.CommonIcons.Expand),
      Collapse: standardizeIcon(window.CommonIcons.Collapse),
    }

    const isCollapsed = ref(false);

    const toggleCollapse = () => {
      isCollapsed.value = !isCollapsed.value;
      emit('update:isCollapsed', isCollapsed.value);
    };

    // Get route info for highlighting active menu item
    const route = VueRouter.useRoute();
    const activeIndex = computed(() => {
      return route.path;
    });

    return {
      navItems,
      CommonIcons,
      isCollapsed,
      toggleCollapse,
      activeIndex,
    };
  },

  template: `
    <div>

      <div class="flex items-center h-[80px]">
        <!-- Logo -->
        <div v-if="!isCollapsed" class="flex-1 flex items-center transition-opacity duration-300">
          <img class="rounded-full w-10 h-10" src="resources/LUTO.png" alt="LUTO 2.0" />
          <span class="ml-2 text-sm font-semibold">LUTO 2.0</span>
        </div>
        <!-- Toggle button -->
        <div class="w-6 h-6 items-center ml-2 cursor-pointer" @click="toggleCollapse">
          <span v-if="!isCollapsed" v-html="CommonIcons.Collapse"></span>
          <span v-else  v-html="CommonIcons.Expand"></span>
        </div>
      </div>

      <!-- Menu -->
      <nav>
        <ul class="transition-all duration-300 ease-in-out">
          <li v-for="item in navItems" :key="item.id">
            <router-link :to="item.path" class="flex flex-nowrap ml-2 py-3 cursor-pointer" 
              :class="{ 'bg-gray-50 border-l-4 border-blue-700': activeIndex === item.path }">
              <span v-html="item.icon" class="w-6 h-6 items-center justify-center"></span>
              <span v-if="!isCollapsed" class="ml-2 text-sm w-[180px]">{{ item.label }}</span>
            </router-link>
          </li>
        </ul>
      </nav>
    </div>
  `,
};
```

## luto/tools/report/VUE_modules/dataTransform/01_JSON2JS_dataTrans.py

```python
import pathlib
import json
import pandas as pd
from glob import glob
from tqdm.auto import tqdm


files = glob('assets/*.json') + glob('assets/map_metrics/*.json')

# JSON files to JS files
for f in tqdm(files, total=len(files)):
    with open(f, 'r', encoding='utf-8') as src_file:
        f_name = pathlib.Path(f).name.replace('.json', '')
        f_name = f"map_{f_name}" if "map_metrics" in f else f_name
        data = json.load(src_file)
        
    with open(f'data/{f_name}.js', 'w', encoding='utf-8') as dest_file:
        dest_file.write(f'window["{f_name}"] = {json.dumps(data, indent=2)};\n')
```

## luto/tools/report/VUE_modules/dataTransform/02_SHP2GEOJSON.py

```python
import json
import geopandas as gpd
from io import BytesIO
from shapely.ops import unary_union

NRM_AUS = gpd.read_file('luto/tools/report/VUE_modules/assets/NRM_SIMPLIFY_FILTER/NRM_AUS_SIMPLIFIED.shp')
NRM_AUS_crs = NRM_AUS.crs
NRM_AUS = NRM_AUS.dissolve(by='NRM_REGION')[['geometry']].reset_index()

# Reproject to EPSG:4326 (WGS84 lat/lng) for Leaflet compatibility
if NRM_AUS.crs.to_epsg() != 4326:
    NRM_AUS = NRM_AUS.to_crs('EPSG:4326')
    
with BytesIO() as geojson_bytes:
    NRM_AUS.to_file(geojson_bytes, driver='GeoJSON')
    geojson_bytes.seek(0)
    geojson_str = eval(geojson_bytes.getvalue().decode('utf-8'))
    
with open('luto/tools/report/VUE_modules/data/geo/NRM_AUS.js', 'w', encoding='utf-8') as f:
    f.write(f'window.NRM_AUS = {json.dumps(geojson_str, indent=2)};\n')


# Save centroids and bounding box of NRM to JS object
NRM_AUS.loc[len(NRM_AUS)] = ['AUSTRALIA', unary_union(NRM_AUS.geometry.values)]
NRM_AUS = NRM_AUS.set_crs(NRM_AUS_crs, allow_override=True)
NRM_AUS['centroid'] = NRM_AUS.geometry.centroid.apply(lambda p: [p.y, p.x])
NRM_AUS['bounding_box'] = NRM_AUS.geometry.bounds.values.tolist()
centroid_bbox = NRM_AUS.set_index('NRM_REGION')[['centroid', 'bounding_box']].to_dict(orient='index')

with open('luto/tools/report/VUE_modules/data/geo/NRM_AUS_centroid_bbox.js', 'w', encoding='utf-8') as f:
    f.write(f'window.NRM_AUS_centroid_bbox = {json.dumps(centroid_bbox, indent=2)};\n')



# Save AUSTRALIA STATE to JS object
AUS_STATE = gpd.read_file('luto/tools/report/VUE_modules/assets/AUS_STATE_SIMPLIFIED/STE11aAust_mercator_simplified.shp')
AUS_STATE = AUS_STATE.dissolve(by='STATE_NAME').reset_index()

# Reproject to EPSG:4326 (WGS84 lat/lng) for Leaflet compatibility
if AUS_STATE.crs.to_epsg() != 4326:
    AUS_STATE = AUS_STATE.to_crs('EPSG:4326')

with BytesIO() as geojson_bytes:
    AUS_STATE.to_file(geojson_bytes, driver='GeoJSON')
    geojson_bytes.seek(0)
    geojson_str = eval(geojson_bytes.getvalue().decode('utf-8'))

with open('luto/tools/report/VUE_modules/data/geo/AUS_STATE.js', 'w', encoding='utf-8') as f:
    f.write(f'window.AUS_STATE = {json.dumps(geojson_str, indent=2)};\n')
```

## luto/tools/report/VUE_modules/index.html

```html
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>LUTO 2 Report</title>

    <!-- Resources -->
    <script src="lib/vue.global.prod_3.5.18.js"></script>
    <script src="lib/vue-router.global_4.5.1.js"></script>
    <script src="lib/tailwind_3.4.16.js"></script>
    <script src="lib/Highcharts-12.3.0/highcharts.js"></script>
    <script src="lib/Highcharts-12.3.0/accessibility.js"></script>
    <script src="lib/Highcharts-12.3.0/data.js"></script>
    <script src="lib/Highcharts-12.3.0/exporting.js"></script>
    <script src="lib/Highcharts-12.3.0/offline-exporting.js"></script>
    <script src="lib/Highcharts-12.3.0/export-data.js"></script>
    <link rel="stylesheet" href="lib/element-plus_2.10.4.css" />
    <script src="lib/element-plus_2.10.4.js"></script>

    <link rel="stylesheet" href="lib/leaflet_1.9.4.css" />
    <script src="lib/leaflet_1.9.4.js"></script>

    <!-- Load icons.js -->
    <script src="./resources/icons.js"></script>

    <!-- Components -->
    <script src="./components/helpers.js" defer></script>
    <script src="./components/map_geojson.js" defer></script>
    <script src="./components/sidebar.js" defer></script>
    <script src="./components/chart_container.js" defer></script>
    <script src="./components/ranking_cards.js" defer></script>
    <script src="./components/filterable_dropdown.js" defer></script>
    <script src="./components/regions_map.js" defer></script>
    <script src="./services/DataService.js" defer></script>
    <script src="./services/MapService.js" defer></script>
    <script src="./services/DataConstructor.js" defer></script>

    <!-- Views -->
    <script src="./views/Home.js" defer></script>
    <script src="./views/Area.js" defer></script>
    <script src="./views/Economics.js" defer></script>
    <script src="./views/GHG.js" defer></script>
    <script src="./views/Water.js" defer></script>
    <script src="./views/Production.js" defer></script>
    <script src="./views/Biodiversity.js" defer></script>
    <script src="./views/Map.js" defer></script>
    <script src="./views/Settings.js" defer></script>
    <script src="./views/NotFound.js" defer></script>

    <!-- Routes -->
    <script src="./routes/route.js" defer></script>

    <!-- Main app -->
    <script src="./index.js" defer></script>

    <style>
      body {
        font-family: sans-serif;
      }
    </style>

    <!-- Data (load on demand) -->
  </head>

  <body>
    <div id="app"></div>
  </body>
</html>
```

## luto/tools/report/VUE_modules/index.js

```javascript
const { createApp } = Vue;

// Initialize app
const app = createApp({
    setup() {
        const { ref, provide } = Vue;
        const isCollapsed = ref(false);
        const globalSelectedRegion = ref('AUSTRALIA');
        const globalMapViewpoint = ref({
            center: [-26, 126.5],
            zoom: 5,
            lastSelectedRegion: 'AUSTRALIA'
        });

        const updateSidebarCollapsed = (value) => {
            isCollapsed.value = value;
        };

        provide('isCollapsed', isCollapsed);
        provide('globalSelectedRegion', globalSelectedRegion);
        provide('globalMapViewpoint', globalMapViewpoint);

        return {
            updateSidebarCollapsed,
            isCollapsed,
            globalSelectedRegion,
            globalMapViewpoint,
        };
    },
    template: `
    <div class="flex">
        <!-- Sidebar -->
        <div  class="bg-white pl-2 w-min-[50px] transform transition-all duration-300 ease-in-out"
            :class="{'w-[50px]': isCollapsed, 'w-[200px]': !isCollapsed}">
          <side-bar @update:isCollapsed="updateSidebarCollapsed"></side-bar>
        </div>
        <!-- Main content -->
        <div class="flex-1 bg-[#f8f9fe] mr-4 pl-4">
          <router-view></router-view>
        </div>
    </div>
    `
});

// Register other components
app.component("chart-container", window.Highchart);
app.component("side-bar", window.Sidebar);
app.component('map-geojson', window.map_geojson);
app.component('ranking-cards', window.RankingCards);
app.component('filterable-dropdown', window.FilterableDropdown);
app.component('regions-map', window.RegionsMap);

// Use modules
app.use(ElementPlus);
app.use(window.router);

// Mount the app
app.mount("#app");
```

## luto/tools/report/VUE_modules/README.md

````markdown
# VUE_LUTO - Land Use Trade-Offs (LUTO) 2.0 Dashboard

## Overview

VUE_LUTO is a web-based dashboard application for visualizing and analyzing results from the Land Use Trade-Offs (LUTO) 2.0 model. It provides interactive charts, maps, and data exploration tools for understanding the environmental, economic, and social impacts of different land use scenarios in Australia.

## Purpose

The LUTO model is designed to analyze trade-offs between different land uses in Australia, considering factors such as:
- **Economics**: Revenue, costs, and economic indicators
- **Area Analysis**: Land use distribution and changes
- **Greenhouse Gas (GHG) Emissions**: Carbon footprint and climate impacts
- **Water Usage**: Water consumption and management
- **Biodiversity**: Environmental conservation metrics

This dashboard provides an intuitive interface to explore model outputs and understand the implications of different policy scenarios.

## Technology Stack

- **Frontend Framework**: Vue.js 3.5.18 with Composition API
- **Routing**: Vue Router 4.5.1
- **Styling**: Tailwind CSS 3.4.16
- **UI Components**: Element Plus 2.10.4 for enhanced UI components
- **Charts**: Highcharts 12.3.0 with accessibility features
- **Maps**: Leaflet 1.9.4 for interactive Australian region mapping
- **Architecture**: Single Page Application (SPA) with no build process
- **Dependencies**: All libraries are locally hosted in the `lib/` directory for offline use

## Project Structure

```
VUE_LUTO/
├── components/                         # Reusable Vue components
│   ├── chart_container.js              # Highcharts wrapper component
│   ├── helpers.js                      # Utility functions for script/data loading
│   ├── map_geojson.js                  # Interactive map component
│   ├── ranking_cards.js                # Ranking cards component
│   ├── filterable_dropdown.js          # Searchable dropdown component
│   ├── regions_map.js                  # Region selection map component
│   └── sidebar.js                      # Navigation sidebar
├── views/                              # Page components (routes)
│   ├── Home.js                         # Main dashboard with overview
│   ├── Area.js                         # Area analysis view
│   ├── Economics.js                    # Economics analysis view
│   ├── GHG.js                          # Greenhouse Gas analysis view
│   ├── Water.js                        # Water usage analysis view
│   ├── Production.js                   # Production analysis view
│   ├── Settings.js                     # Application settings view
│   └── NotFound.js                     # 404 error page
├── services/                           # Service modules
│   ├── DataService.js                  # Data handling service
│   └── MapService.js                   # Map data and interactions service
├── routes/                             # Routing configuration
│   └── route.js                        # Vue Router setup
├── data/                               # Data files and model outputs
│   ├── chart_option/                   # Chart configuration templates
│   │   ├── Chart_default_options.js    # Default chart styles
│   │   └── chartMemLogOptions.js       # Memory log chart configuration
│   ├── geo/                            # Geographic data (Australian regions)
│   └── Supporting_info.js              # Consolidated model settings and information
├── lib/                                # Local library dependencies
│   ├── Highcharts-12.3.0/              # Highcharts library and modules
│   ├── vue.global.prod_3.5.18.js       # Vue.js library
│   ├── vue-router.global_4.5.1.js      # Vue Router library
│   └── tailwind_3.4.16.js              # Tailwind CSS library
├── assets/                             # Raw data assets (JSON format)
├── dataTransform/                      # Data transformation scripts
│   ├── 01_JSON2JS_dataTrans.py         # JSON to JS conversion utility
│   └── NRM_SIMPLIFY_FILTER/            # Geographic data processing tools
├── resources/                          # Static assets
│   ├── icons.js                        # SVG icons
│   ├── LUTO.png                        # Logo
│   └── Roboto-Light.ttf                # Custom font
├── index.html                          # Main HTML entry point
└── index.js                            # Application bootstrap

```

## Key Features

### 1. Interactive Dashboard (Home View)
- **Overview Charts**: Displays key metrics for different domains (economics, area, GHG, water, biodiversity)
- **Memory Usage Monitoring**: Real-time visualization of model execution memory consumption
- **Parameter Summary**: Searchable list of model run settings and parameters
- **Regional Selection**: Interactive map for selecting Australian regions

### 2. Area Analysis
- Detailed land use area breakdowns
- Temporal analysis of land use changes
- Multiple dataset visualization options

### 3. Interactive Map
- **Australian Regions**: Based on Natural Resource Management (NRM) regions
- **Hover Effects**: Region highlighting and tooltips
- **Region Selection**: Click to select regions for detailed analysis
- **Responsive Design**: Adapts to different screen sizes

### 4. Chart System
- **Highcharts Integration**: Professional-grade interactive charts
- **Export Capabilities**: PNG, JPEG, PDF, and CSV export options
- **Accessibility**: Screen reader support and keyboard navigation
- **Responsive Design**: Charts adapt to container sizes

## Data Architecture

### Dynamic Data Loading
The application uses a custom script loading system (`helpers.js`) that:
- Loads data files on-demand to optimize performance
- Manages script dependencies and loading order
- Provides error handling for failed data loads
- Supports timeout mechanisms for reliable loading

### Data Types
1. **Supporting Info** (`Supporting_info.js`): Consolidated information including model run settings
2. **Chart Data**: Time-series and categorical data organized by region and category
3. **Geographic Data** (`NRM_AUS.js`): GeoJSON data for Australian regions
4. **Chart Options**: Multiple files with specific chart configurations:
   - `Chart_default_options.js`: Default styling and configuration for charts
   - `chartMemLogOptions.js`: Memory log chart specific options

## Component Architecture

### Chart Container (`chart_container.js`)
- Wraps Highcharts functionality in a Vue component
- Manages chart lifecycle (creation, updates, destruction)
- Handles loading states and error conditions
- Supports reactive data updates

### Map Component (`map_geojson.js`)
- Integrates Leaflet maps with Vue reactivity
- Manages Australian region visualization
- Emits region selection events
- Handles map interactions and styling

### Sidebar Navigation (`sidebar.js`)
- Provides application navigation
- Displays LUTO branding
- Routes to different analysis views
- Responsive design for different screen sizes

## Setup and Usage

### Prerequisites
- A modern web browser with JavaScript enabled
- Python 3 (for local development server)

### Running Locally
1. Clone the repository:
   ```bash
   git clone https://github.com/JinzhuWANG/VUE_LUTO.git
   cd VUE_LUTO
   ```

2. Start a local web server:
   ```bash
   python3 -m http.server 8000
   ```

3. Open your browser and navigate to:
   ```
   http://localhost:8000
   ```

### Data Transformation
If you need to update data from raw JSON files:

1. Place your JSON files in the `assets/` directory
2. Run the transformation script:
   ```bash
   python dataTransform/01_JSON2JS_dataTrans.py
   ```
3. This will convert JSON files to JavaScript files in the `data/` directory with the following features:
   - Properly formatted with indentation for better readability
   - Assigned to window objects with the same name as the source file
   - Map-related files prefixed with "map_" for clearer identification

### Production Deployment
The application is a static web application that can be deployed to any web server:
- Upload all files to your web server
- Ensure the web server can serve `.js` files with the correct MIME type
- No build process or server-side rendering required

## Model Integration

The dashboard is designed to work with LUTO 2.0 model outputs. Key integration points:

### Model Run Parameters
- **Version**: Model version tracking
- **Scenarios**: SSP (Shared Socioeconomic Pathways) and RCP (Representative Concentration Pathways)
- **Policy Settings**: Carbon pricing, biodiversity targets, agricultural management
- **Constraints**: Water usage, GHG emission limits, land use restrictions

### Data Outputs
The model generates datasets for:
- Economic indicators (revenue, costs)
- Land use areas by category
- GHG emissions by source
- Water usage by sector
- Biodiversity quality scores

## Development Notes

### Code Style
- Uses Vue 3 Composition API for component logic
- ES6+ JavaScript features
- No TypeScript (pure JavaScript implementation)
- Consistent naming conventions (camelCase for variables, kebab-case for components)

### Performance Considerations
- Locally hosted libraries for offline use and faster loading
- Lazy loading of data files to reduce initial load time
- Chart reuse and proper cleanup to prevent memory leaks
- Efficient map rendering with minimal DOM manipulation
- Responsive design principles for various screen sizes
- Structured data organization by region for faster access

### Browser Support
- Modern browsers supporting ES6+
- Vue 3 compatibility requirements
- WebGL support recommended for optimal map performance

## Contributing

When contributing to this project:
1. Maintain the existing code style and architecture
2. Test across different browsers and screen sizes
3. Ensure new data files follow the existing naming conventions
4. Update documentation for any new features or changes

## License

This project is part of the LUTO (Land Use Trade-Offs) model system. Please refer to the main LUTO project for licensing information.

## Version History

### Latest Changes
- Refactored data structure with improved JS file formatting
- Updated JSON to JS conversion process with better indentation
- Updated map UI components and views for improved visualization
- Enhanced map integration with dynamic data loading capabilities
- Optimized map data loading and UI controls for better performance
- Improved responsive UI with better layout and spacing
- Added Production analysis view for agricultural production data
- Implemented filterable dropdown components for better data selection
- Migrated from CDN dependencies to local libraries for offline use

### Future Enhancements
- Add more detailed analysis views for each domain
- Implement scenario comparison functionality
- Add data download options for raw model outputs
- Improve accessibility features for all visualizations
````

## luto/tools/report/VUE_modules/resources/icons.js

```javascript
window.NavIcons = {
	home: `
<svg version="1.0" xmlns="http://www.w3.org/2000/svg"
 height="1em" viewBox="0 0 180.000000 164.000000"
 preserveAspectRatio="xMidYMid meet">

<g transform="translate(0.000000,164.000000) scale(0.100000,-0.100000)"
fill="#000000" stroke="none">
<path d="M775 1571 c-22 -11 -110 -76 -195 -147 -85 -70 -243 -199 -350 -287
-107 -87 -203 -168 -213 -179 -25 -30 -22 -84 8 -113 23 -24 31 -25 135 -25
l110 0 0 -308 0 -308 25 -51 c48 -95 124 -133 270 -133 78 0 96 3 119 21 l26
20 0 164 c0 91 5 176 11 192 36 95 156 141 247 94 86 -44 101 -87 102 -293 0
-206 -3 -202 154 -196 121 4 166 19 218 75 60 62 62 80 66 416 l4 307 107 0
c104 0 109 1 135 26 38 38 35 84 -6 122 -98 90 -719 588 -753 603 -55 25 -166
25 -220 0z"/>
</g>
</svg>`,
	area: `<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 width="100%" viewBox="0 0 81 81" enable-background="new 0 0 81 81" xml:space="preserve">
<path fill="#020202" opacity="1.000000" stroke="none" 
	d="
M82.000000,9.000000 
	C82.000000,30.687561 82.000000,52.375122 81.703552,74.695770 
	C78.604736,77.552567 75.802368,79.776283 73.000000,82.000000 
	C53.312439,82.000000 33.624878,82.000000 13.161839,81.841072 
	C5.872718,79.196129 2.898710,74.527313 2.958918,67.502090 
	C3.104225,50.547268 2.987344,33.590328 3.013211,16.634298 
	C3.028049,6.907153 7.958557,2.024664 17.759781,2.011843 
	C34.217113,1.990315 50.677742,2.194448 67.130219,1.910995 
	C73.517853,1.800945 78.425468,3.731785 82.000000,9.000000 
M32.074280,49.565006 
	C29.778584,52.098835 27.482889,54.632660 25.187193,57.166489 
	C24.106373,55.121582 24.395634,53.756798 24.026707,52.602360 
	C23.641806,51.397938 22.622726,50.396179 21.880905,49.305820 
	C20.940996,50.447651 19.798349,51.484982 19.136074,52.769909 
	C18.729027,53.559643 19.052788,54.728024 19.054880,55.726372 
	C19.079304,67.377144 17.990782,66.101936 29.544920,65.949799 
	C31.658989,65.921974 35.531830,64.612869 35.562725,63.782471 
	C35.725929,59.396088 31.813873,61.646149 29.644487,60.877838 
	C29.411552,60.795345 29.269600,60.455956 28.432192,59.454563 
	C30.957792,57.230476 33.798012,55.158680 36.065201,52.582573 
	C37.588501,50.851707 39.634087,46.948330 39.161247,46.516045 
	C35.860733,43.498608 34.661793,47.687363 32.074280,49.565006 
M54.091995,17.949978 
	C52.904350,18.811255 51.716702,19.672531 50.529053,20.533808 
	C52.808052,21.744450 55.087051,22.955091 57.653343,24.318350 
	C54.669743,27.186571 51.281967,30.137558 48.327400,33.472363 
	C47.455456,34.456524 47.807430,36.525055 47.598522,38.096653 
	C49.019474,37.712151 50.839191,37.753857 51.788708,36.865475 
	C54.997513,33.863285 57.897648,30.531183 61.436058,26.772539 
	C61.865185,28.492983 62.031197,28.924419 62.073467,29.367657 
	C62.281322,31.547077 61.390705,34.670841 64.922859,34.420017 
	C65.784996,34.358803 67.022682,31.159441 67.066971,29.377567 
	C67.351097,17.946754 67.257652,17.944431 54.091995,17.949978 
z"/>
<path fill="#FAFAFA" opacity="1.000000" stroke="none" 
	d="
M82.000000,8.505266 
	C78.425468,3.731785 73.517853,1.800945 67.130219,1.910995 
	C50.677742,2.194448 34.217113,1.990315 17.759781,2.011843 
	C7.958557,2.024664 3.028049,6.907153 3.013211,16.634298 
	C2.987344,33.590328 3.104225,50.547268 2.958918,67.502090 
	C2.898710,74.527313 5.872718,79.196129 12.693182,81.841072 
	C9.010786,82.000000 5.021573,82.000000 1.016180,82.000000 
	C1.016180,55.083603 1.016180,28.167196 1.016180,1.125393 
	C27.999516,1.125393 54.999718,1.125393 82.000000,1.125393 
	C82.000000,3.356469 82.000000,5.683501 82.000000,8.505266 
z"/>
<path fill="#EEEEEE" opacity="1.000000" stroke="none" 
	d="
M73.491051,82.000000 
	C75.802368,79.776283 78.604736,77.552567 81.703552,75.164429 
	C82.000000,77.260757 82.000000,79.521523 82.000000,82.000000 
	C79.329346,82.000000 76.655724,82.000000 73.491051,82.000000 
z"/>
<path fill="#F1F1F1" opacity="1.000000" stroke="none" 
	d="
M32.330761,49.320587 
	C34.661793,47.687363 35.860733,43.498608 39.161247,46.516045 
	C39.634087,46.948330 37.588501,50.851707 36.065201,52.582573 
	C33.798012,55.158680 30.957792,57.230476 28.432192,59.454563 
	C29.269600,60.455956 29.411552,60.795345 29.644487,60.877838 
	C31.813873,61.646149 35.725929,59.396088 35.562725,63.782471 
	C35.531830,64.612869 31.658989,65.921974 29.544920,65.949799 
	C17.990782,66.101936 19.079304,67.377144 19.054880,55.726372 
	C19.052788,54.728024 18.729027,53.559643 19.136074,52.769909 
	C19.798349,51.484982 20.940996,50.447651 21.880905,49.305820 
	C22.622726,50.396179 23.641806,51.397938 24.026707,52.602360 
	C24.395634,53.756798 24.106373,55.121582 25.187193,57.166489 
	C27.482889,54.632660 29.778584,52.098835 32.330761,49.320587 
z"/>
<path fill="#F2F2F2" opacity="1.000000" stroke="none" 
	d="
M54.528694,17.949089 
	C67.257652,17.944431 67.351097,17.946754 67.066971,29.377567 
	C67.022682,31.159441 65.784996,34.358803 64.922859,34.420017 
	C61.390705,34.670841 62.281322,31.547077 62.073467,29.367657 
	C62.031197,28.924419 61.865185,28.492983 61.436058,26.772539 
	C57.897648,30.531183 54.997513,33.863285 51.788708,36.865475 
	C50.839191,37.753857 49.019474,37.712151 47.598522,38.096653 
	C47.807430,36.525055 47.455456,34.456524 48.327400,33.472363 
	C51.281967,30.137558 54.669743,27.186571 57.653343,24.318350 
	C55.087051,22.955091 52.808052,21.744450 50.529053,20.533810 
	C51.716702,19.672531 52.904350,18.811255 54.528694,17.949089 
z"/>
</svg>
`,
	production: `
<svg xmlns="http://www.w3.org/2000/svg" height="1em" fill="currentColor" viewBox="0 0 512 512">
   <path d="M 416 96 Q 420 96 424 96 Q 396 65 352 64 Q 339 64 327 67 Q 313 37 286 19 Q 259 0 224 0 Q 189 0 162 19 Q 135 37 121 67 Q 109 64 96 64 Q 55 65 28 92 Q 1 119 0 160 Q 1 201 28 228 Q 55 255 96 256 L 169 256 L 169 256 L 85 171 L 85 171 Q 75 160 85 149 Q 96 139 107 149 L 208 249 L 208 249 L 208 112 L 208 112 Q 209 97 224 96 Q 239 97 240 112 L 240 256 L 240 256 L 292 256 L 292 256 Q 288 241 288 224 Q 289 170 325 133 Q 362 97 416 96 L 416 96 Z M 27 288 Q 16 288 8 296 L 8 296 L 8 296 Q 0 304 0 315 Q 1 369 30 410 Q 59 451 107 470 L 109 484 L 109 484 Q 114 510 140 512 L 372 512 L 372 512 Q 398 510 404 484 L 405 470 L 405 470 Q 453 451 482 410 Q 511 369 512 315 Q 512 304 504 296 Q 496 288 485 288 L 27 288 L 27 288 Z M 512 224 Q 511 183 484 156 L 484 156 L 484 156 Q 457 129 416 128 Q 375 129 348 156 Q 321 183 320 224 Q 320 241 326 256 L 507 256 L 507 256 Q 512 241 512 224 L 512 224 Z" />
</svg>
`,
	economy: `
<svg xmlns="http://www.w3.org/2000/svg" height="1em" fill="currentColor" viewBox="0 0 512 512">
   <path d="M 256 512 Q 326 511 384 478 L 384 478 L 384 478 Q 442 444 478 384 Q 512 323 512 256 Q 512 189 478 128 Q 442 68 384 34 Q 326 1 256 0 Q 186 1 128 34 Q 70 68 34 128 Q 0 189 0 256 Q 0 323 34 384 Q 70 444 128 478 Q 186 511 256 512 L 256 512 Z M 277 134 L 277 148 L 277 134 L 277 148 Q 291 150 306 154 Q 309 155 311 156 Q 330 163 327 183 Q 319 201 300 198 Q 299 197 298 197 Q 296 197 295 196 Q 285 193 274 191 Q 253 187 233 195 Q 224 199 221 206 Q 217 213 226 220 Q 241 228 258 232 Q 259 232 259 232 Q 261 233 263 233 Q 264 234 266 234 Q 292 240 316 254 Q 346 276 340 312 Q 332 346 302 357 Q 290 362 277 363 L 277 379 L 277 379 Q 275 398 255 400 Q 236 398 234 379 L 234 361 L 234 361 Q 212 356 191 349 Q 173 341 177 321 Q 185 303 204 308 Q 206 308 208 309 Q 210 309 212 310 Q 229 316 246 320 Q 272 323 286 317 Q 295 313 298 305 Q 300 296 292 290 Q 276 280 257 277 Q 254 276 251 275 Q 250 274 250 274 Q 225 269 202 256 Q 172 236 177 200 Q 186 167 216 155 Q 224 152 234 150 L 234 134 L 234 134 Q 236 114 255 112 Q 275 114 277 134 L 277 134 Z"/>
</svg>
`,
	GHG: `<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 height="1em" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve">
<path fill="currentColor" opacity="1.000000" stroke="none" 
	d="
M513.000000,320.000000 
	C513.000000,328.354218 513.000000,336.708466 512.607178,345.676971 
	C512.044006,348.428711 512.160278,350.635986 511.659149,352.692902 
	C506.286774,374.743500 495.030029,393.092102 476.714203,406.714355 
	C461.566437,417.980438 444.419556,424.818268 425.537262,424.865356 
	C315.372437,425.140045 205.206543,425.035370 95.041183,424.914734 
	C88.214272,424.907257 81.255348,424.306061 74.584976,422.902039 
	C40.910698,415.814087 17.825983,396.213470 5.949927,363.714203 
	C4.389306,359.443481 2.654258,355.236511 1.000000,351.000000 
	C1.000000,339.979095 1.000000,328.958221 1.374217,317.346161 
	C10.902787,278.320740 34.257385,253.662918 72.966232,243.455963 
	C67.363457,200.305420 80.342995,164.275330 117.695854,140.212280 
	C155.022110,116.166374 193.188110,119.033401 229.446060,141.229279 
	C237.627197,132.987061 245.235718,124.420876 253.769058,116.904663 
	C274.048035,99.042816 298.449280,90.888634 325.016296,89.117249 
	C339.084564,88.179222 352.947784,90.511070 366.409241,94.825844 
	C389.442963,102.208794 408.573608,115.308182 423.685394,134.201889 
	C440.844482,155.655289 449.483429,180.352112 449.763763,207.621841 
	C449.872986,218.251053 447.860626,229.014740 445.749542,239.502777 
	C444.805939,244.190765 445.962952,244.816650 449.879944,246.151840 
	C477.217346,255.470352 497.103882,272.902191 507.097687,300.516235 
	C509.403778,306.888245 511.050079,313.499054 513.000000,320.000000 
M271.433533,355.000000 
	C273.337799,354.666473 275.287018,354.493408 277.139191,353.974091 
	C292.199677,349.751556 303.351074,340.757660 308.854797,325.997192 
	C311.180023,319.761139 311.734528,312.856445 313.011993,306.239899 
	C315.420227,293.766357 314.383362,281.229584 311.784119,269.071716 
	C308.253448,252.557083 298.169342,240.835602 282.168274,234.613342 
	C272.525909,230.863770 262.727600,230.307129 252.466522,231.869919 
	C238.713104,233.964600 228.318909,240.893234 220.547394,252.014053 
	C215.082901,259.833618 212.644836,268.594879 211.787354,278.247437 
	C210.614609,291.449097 210.327454,304.519501 213.062027,317.454102 
	C218.919373,345.159302 245.002289,359.637634 271.433533,355.000000 
M167.781250,276.951172 
	C174.109741,276.967438 180.438202,276.991608 186.766708,276.998016 
	C194.827530,277.006165 194.824844,277.000275 194.007996,268.972565 
	C193.957672,268.478027 194.017822,267.973236 193.997452,267.474396 
	C193.599274,257.727966 189.362503,249.323257 182.394150,243.212616 
	C168.150864,230.722473 150.821808,228.143295 133.036407,232.675262 
	C110.690948,238.369186 99.498917,256.622559 98.195015,277.949127 
	C97.450874,290.120239 98.077736,302.462891 99.147186,314.635193 
	C100.518517,330.243256 109.030899,341.957825 122.396797,349.633881 
	C135.394516,357.098511 149.549255,357.494812 163.895844,353.973755 
	C182.117157,349.501740 195.980042,331.214233 194.839539,312.973724 
	C194.774689,311.936249 193.207199,310.160919 192.302307,310.137360 
	C183.889786,309.917938 175.469193,310.007599 167.006088,310.007599 
	C167.182693,316.942017 166.838608,323.154449 162.362885,328.095245 
	C156.630096,334.423737 149.127808,333.913452 141.883957,332.256653 
	C132.787140,330.176086 128.081436,323.190765 127.198555,314.597900 
	C126.053070,303.449310 126.117233,292.154419 126.109909,280.922180 
	C126.107109,276.627289 126.781296,272.146759 128.118622,268.069519 
	C132.947617,253.346939 152.618881,248.170013 162.374939,258.907623 
	C166.864044,263.848389 167.139771,270.080139 167.781250,276.951172 
M333.208801,335.227203 
	C332.632172,341.339325 332.055542,347.451447 331.457581,353.789612 
	C360.489899,353.789612 388.558716,353.789612 416.786377,353.789612 
	C416.786377,346.507263 416.786377,339.436218 416.786377,331.806915 
	C401.421051,331.806915 386.260345,331.806915 370.096039,331.806915 
	C379.738251,320.970428 388.751221,311.036591 397.541473,300.909424 
	C407.075623,289.925232 415.146362,278.411530 413.115295,262.509827 
	C411.985626,253.665100 408.302887,246.135834 401.880524,240.649399 
	C390.031464,230.526993 375.620880,228.805115 360.964447,232.164230 
	C340.623993,236.826080 328.006927,255.734268 331.556458,273.735840 
	C340.320190,273.735840 349.075226,273.735840 357.596588,273.735840 
	C358.093750,270.395905 358.583191,267.355530 358.992035,264.304352 
	C359.627563,259.561035 362.230286,255.600800 366.494965,254.424316 
	C371.058075,253.165497 376.313934,252.459061 380.632965,256.144592 
	C384.996735,259.868347 387.121552,268.497864 384.146515,274.170593 
	C380.732635,280.680023 377.180664,287.373688 372.393250,292.856140 
	C359.916321,307.144409 346.731415,320.814453 333.208801,335.227203 
z"/>
<path fill="#FFFFFF" opacity="1.000000" stroke="none" 
	d="
M513.000000,319.531342 
	C511.050079,313.499054 509.403778,306.888245 507.097687,300.516235 
	C497.103882,272.902191 477.217346,255.470352 449.879944,246.151840 
	C445.962952,244.816650 444.805939,244.190765 445.749542,239.502777 
	C447.860626,229.014740 449.872986,218.251053 449.763763,207.621841 
	C449.483429,180.352112 440.844482,155.655289 423.685394,134.201889 
	C408.573608,115.308182 389.442963,102.208794 366.409241,94.825844 
	C352.947784,90.511070 339.084564,88.179222 325.016296,89.117249 
	C298.449280,90.888634 274.048035,99.042816 253.769058,116.904663 
	C245.235718,124.420876 237.627197,132.987061 229.446060,141.229279 
	C193.188110,119.033401 155.022110,116.166374 117.695854,140.212280 
	C80.342995,164.275330 67.363457,200.305420 72.966232,243.455963 
	C34.257385,253.662918 10.902787,278.320740 1.374217,316.877502 
	C1.000000,211.706787 1.000000,106.413582 1.000000,1.060187 
	C171.561508,1.060187 342.123047,1.060187 513.000000,1.060187 
	C513.000000,107.020683 513.000000,213.041687 513.000000,319.531342 
z"/>
<path fill="#FFFFFF" opacity="1.000000" stroke="none" 
	d="
M1.000000,351.468658 
	C2.654258,355.236511 4.389306,359.443481 5.949927,363.714203 
	C17.825983,396.213470 40.910698,415.814087 74.584976,422.902039 
	C81.255348,424.306061 88.214272,424.907257 95.041183,424.914734 
	C205.206543,425.035370 315.372437,425.140045 425.537262,424.865356 
	C444.419556,424.818268 461.566437,417.980438 476.714203,406.714355 
	C495.030029,393.092102 506.286774,374.743500 511.659149,352.692902 
	C512.160278,350.635986 512.044006,348.428711 512.607178,346.145630 
	C513.000000,401.637695 513.000000,457.275391 513.000000,512.956543 
	C342.451141,512.956543 171.902298,512.956543 1.000000,512.956543 
	C1.000000,459.312958 1.000000,405.625122 1.000000,351.468658 
z"/>
<path fill="#FFFFFF" opacity="1.000000" stroke="none" 
	d="
M270.982361,355.000122 
	C245.002289,359.637634 218.919373,345.159302 213.062027,317.454102 
	C210.327454,304.519501 210.614609,291.449097 211.787354,278.247437 
	C212.644836,268.594879 215.082901,259.833618 220.547394,252.014053 
	C228.318909,240.893234 238.713104,233.964600 252.466522,231.869919 
	C262.727600,230.307129 272.525909,230.863770 282.168274,234.613342 
	C298.169342,240.835602 308.253448,252.557083 311.784119,269.071716 
	C314.383362,281.229584 315.420227,293.766357 313.011993,306.239899 
	C311.734528,312.856445 311.180023,319.761139 308.854797,325.997192 
	C303.351074,340.757660 292.199677,349.751556 277.139191,353.974091 
	C275.287018,354.493408 273.337799,354.666473 270.982361,355.000122 
M242.341949,266.129822 
	C237.823471,277.638214 238.836487,289.707581 239.144470,301.613129 
	C239.292435,307.332397 240.504837,313.144196 242.067474,318.679108 
	C244.502518,327.304138 250.840225,332.322357 258.415894,333.031036 
	C268.459808,333.970612 277.013824,331.472748 281.467865,321.784393 
	C283.555969,317.242340 284.199554,311.944977 284.976929,306.909515 
	C286.913330,294.366089 286.809814,281.886993 283.172119,269.559998 
	C280.702454,261.191162 275.336456,255.442688 266.898804,254.189728 
	C256.814789,252.692307 247.657928,254.964935 242.341949,266.129822 
z"/>
<path fill="#FFFFFF" opacity="1.000000" stroke="none" 
	d="
M167.423248,276.641205 
	C167.139771,270.080139 166.864044,263.848389 162.374939,258.907623 
	C152.618881,248.170013 132.947617,253.346939 128.118622,268.069519 
	C126.781296,272.146759 126.107109,276.627289 126.109909,280.922180 
	C126.117233,292.154419 126.053070,303.449310 127.198555,314.597900 
	C128.081436,323.190765 132.787140,330.176086 141.883957,332.256653 
	C149.127808,333.913452 156.630096,334.423737 162.362885,328.095245 
	C166.838608,323.154449 167.182693,316.942017 167.006088,310.007599 
	C175.469193,310.007599 183.889786,309.917938 192.302307,310.137360 
	C193.207199,310.160919 194.774689,311.936249 194.839539,312.973724 
	C195.980042,331.214233 182.117157,349.501740 163.895844,353.973755 
	C149.549255,357.494812 135.394516,357.098511 122.396797,349.633881 
	C109.030899,341.957825 100.518517,330.243256 99.147186,314.635193 
	C98.077736,302.462891 97.450874,290.120239 98.195015,277.949127 
	C99.498917,256.622559 110.690948,238.369186 133.036407,232.675262 
	C150.821808,228.143295 168.150864,230.722473 182.394150,243.212616 
	C189.362503,249.323257 193.599274,257.727966 193.997452,267.474396 
	C194.017822,267.973236 193.957672,268.478027 194.007996,268.972565 
	C194.824844,277.000275 194.827530,277.006165 186.766708,276.998016 
	C180.438202,276.991608 174.109741,276.967438 167.423248,276.641205 
z"/>
<path fill="#FFFFFF" opacity="1.000000" stroke="none" 
	d="
M333.518860,334.979126 
	C346.731415,320.814453 359.916321,307.144409 372.393250,292.856140 
	C377.180664,287.373688 380.732635,280.680023 384.146515,274.170593 
	C387.121552,268.497864 384.996735,259.868347 380.632965,256.144592 
	C376.313934,252.459061 371.058075,253.165497 366.494965,254.424316 
	C362.230286,255.600800 359.627563,259.561035 358.992035,264.304352 
	C358.583191,267.355530 358.093750,270.395905 357.596588,273.735840 
	C349.075226,273.735840 340.320190,273.735840 331.556458,273.735840 
	C328.006927,255.734268 340.623993,236.826080 360.964447,232.164230 
	C375.620880,228.805115 390.031464,230.526993 401.880524,240.649399 
	C408.302887,246.135834 411.985626,253.665100 413.115295,262.509827 
	C415.146362,278.411530 407.075623,289.925232 397.541473,300.909424 
	C388.751221,311.036591 379.738251,320.970428 370.096039,331.806915 
	C386.260345,331.806915 401.421051,331.806915 416.786377,331.806915 
	C416.786377,339.436218 416.786377,346.507263 416.786377,353.789612 
	C388.558716,353.789612 360.489899,353.789612 331.457581,353.789612 
	C332.055542,347.451447 332.632172,341.339325 333.518860,334.979126 
z"/>
<path fill="#000000" opacity="1.000000" stroke="none" 
	d="
M242.626221,265.855774 
	C247.657928,254.964935 256.814789,252.692307 266.898804,254.189728 
	C275.336456,255.442688 280.702454,261.191162 283.172119,269.559998 
	C286.809814,281.886993 286.913330,294.366089 284.976929,306.909515 
	C284.199554,311.944977 283.555969,317.242340 281.467865,321.784393 
	C277.013824,331.472748 268.459808,333.970612 258.415894,333.031036 
	C250.840225,332.322357 244.502518,327.304138 242.067474,318.679108 
	C240.504837,313.144196 239.292435,307.332397 239.144470,301.613129 
	C238.836487,289.707581 237.823471,277.638214 242.626221,265.855774 
z"/>
</svg>
`,
	water: `<svg version="1.0" xmlns="http://www.w3.org/2000/svg"
 height="1em" viewBox="0 0 317.000000 302.000000"
 preserveAspectRatio="xMidYMid meet">

<g transform="translate(0.000000,302.000000) scale(0.100000,-0.100000)"
fill="#000000" stroke="none">
<path d="M1514 2748 c-99 -91 -322 -368 -437 -541 -355 -536 -476 -1071 -325
-1435 105 -253 333 -448 612 -525 108 -29 365 -31 466 -3 356 98 604 348 675
681 45 208 1 517 -114 803 -108 271 -324 606 -567 883 -138 157 -165 179 -219
179 -39 0 -52 -6 -91 -42z m650 -1493 c38 -144 9 -326 -72 -451 -80 -123 -224
-224 -363 -254 -105 -23 -341 3 -364 40 -3 4 28 18 68 30 327 99 586 358 692
694 9 29 22 9 39 -59z"/>
</g>
</svg>`,
	biodiversity: `<svg version="1.0" xmlns="http://www.w3.org/2000/svg"
 height="1em" viewBox="0 0 283.000000 282.000000"
 preserveAspectRatio="xMidYMid meet">

<g transform="translate(0.000000,282.000000) scale(0.100000,-0.100000)"
fill="#000000" stroke="none">
<path d="M1544 2728 c-51 -45 -58 -70 -34 -119 16 -30 26 -39 46 -39 30 0 40
23 25 57 -11 23 -9 29 19 58 35 36 35 38 14 59 -21 22 -28 20 -70 -16z"/>
<path d="M1890 2597 c-14 -7 -35 -19 -47 -25 l-23 -12 34 -45 c19 -24 37 -58
41 -75 8 -35 18 -37 65 -9 48 28 60 47 60 89 0 64 -74 107 -130 77z"/>
<path d="M1269 2545 c-59 -16 -69 -22 -69 -44 0 -32 25 -45 61 -32 48 16 53
14 82 -29 22 -34 24 -45 16 -72 -24 -85 2 -172 67 -226 22 -18 56 -35 76 -38
31 -5 42 -14 64 -51 l26 -45 -31 -32 c-34 -35 -39 -57 -17 -75 19 -16 43 -3
85 44 36 42 39 71 10 120 -12 20 -20 37 -18 38 2 1 30 16 62 32 121 63 167
123 167 218 0 156 -157 252 -301 184 -30 -14 -73 -37 -96 -51 l-42 -26 -26 45
c-15 25 -31 45 -35 45 -5 0 -14 2 -22 4 -7 2 -34 -2 -59 -9z"/>
<path d="M741 2529 c-125 -50 -162 -210 -72 -313 45 -51 146 -71 214 -42 82
34 133 142 108 227 -31 102 -155 166 -250 128z"/>
<path d="M1289 2188 c-43 -26 -50 -37 -38 -60 13 -23 36 -23 77 2 36 22 42 54
14 69 -14 7 -27 5 -53 -11z"/>
<path d="M1783 2164 c-9 -24 26 -83 54 -90 26 -7 88 3 115 17 22 12 23 42 3
59 -11 9 -22 9 -52 -1 -34 -11 -38 -10 -51 10 -17 25 -60 28 -69 5z"/>
<path d="M675 2092 c-77 -26 -138 -66 -188 -122 -40 -45 -97 -143 -97 -167 0
-5 27 -14 60 -20 136 -26 258 -112 327 -232 l30 -53 37 60 c73 120 185 198
320 224 l64 12 -18 48 c-41 109 -138 202 -257 245 -80 29 -203 31 -278 5z"/>
<path d="M1625 1828 c4 -13 27 -62 52 -109 l45 -86 -45 -84 c-76 -143 -73
-155 28 -94 136 81 229 85 440 16 157 -52 220 -60 301 -37 57 17 164 73 164
87 0 3 -17 9 -39 13 -21 3 -49 15 -62 26 l-24 19 41 1 c57 0 174 37 181 58 9
23 -106 125 -187 165 -60 30 -72 32 -165 31 -90 0 -113 -4 -228 -42 -168 -55
-216 -60 -304 -34 -37 12 -93 37 -123 56 -65 42 -84 45 -75 14z m883 -122 c4
-33 -13 -56 -42 -56 -47 0 -63 57 -25 84 30 20 63 6 67 -28z"/>
<path d="M272 1701 c-18 -5 -53 -16 -77 -25 l-44 -17 52 -72 c126 -177 152
-209 199 -252 28 -25 78 -58 112 -74 87 -41 216 -66 216 -41 0 16 -146 155
-195 186 -25 16 -48 37 -51 47 -7 22 12 47 36 47 28 0 110 -61 188 -140 42
-42 72 -66 69 -55 -3 11 -8 38 -12 60 -12 71 -70 181 -124 235 -73 72 -142
102 -250 106 -47 2 -101 -1 -119 -5z"/>
<path d="M1135 1697 c-142 -48 -238 -155 -279 -314 -24 -92 -21 -98 27 -46 73
80 186 164 216 161 19 -2 27 -9 29 -28 2 -21 -8 -34 -62 -73 -36 -26 -93 -78
-127 -115 l-61 -67 30 -3 c43 -4 148 25 215 61 77 40 152 116 227 227 33 49
74 105 90 124 l31 34 -58 22 c-72 28 -219 36 -278 17z"/>
<path d="M333 1229 c21 -17 47 -49 59 -72 36 -72 61 -98 131 -134 201 -106
268 -284 146 -387 -29 -25 -39 -28 -84 -24 -43 4 -65 14 -140 66 -49 34 -96
62 -104 62 -9 0 -28 -8 -43 -18 l-28 -18 57 -84 c104 -151 255 -286 411 -366
51 -27 76 -35 79 -27 2 7 20 36 39 65 42 63 89 99 164 122 73 24 120 53 120
77 0 10 -5 38 -12 63 -10 39 -9 49 11 96 26 61 24 80 -23 153 -40 64 -56 108
-56 159 0 83 47 123 213 179 134 46 198 50 247 16 58 -38 74 -79 74 -177 -1
-47 -7 -111 -13 -143 -16 -73 -4 -113 49 -161 44 -40 85 -55 103 -37 7 7 12
42 13 82 0 61 3 73 26 95 21 21 35 26 76 26 99 -1 183 -61 197 -140 3 -23 -1
-68 -10 -113 -46 -207 -45 -213 37 -132 126 124 226 284 281 452 28 83 57 244
57 314 l0 37 -579 0 -579 0 -83 -44 c-99 -52 -166 -73 -277 -86 -154 -17 -338
20 -465 96 -38 22 -71 34 -95 34 l-37 0 38 -31z"/>
<path d="M130 1189 c0 -44 29 -203 49 -264 22 -71 51 -145 58 -145 2 0 21 10
41 22 53 30 94 19 200 -52 93 -63 128 -72 155 -42 21 23 22 84 2 122 -19 37
-84 89 -164 130 -64 34 -98 71 -154 164 -30 51 -61 70 -139 81 -46 7 -48 6
-48 -16z"/>
<path d="M1304 1070 c-121 -39 -158 -65 -162 -112 -3 -36 6 -59 63 -153 36
-60 40 -104 15 -164 -19 -42 -20 -55 -11 -82 36 -105 -10 -166 -168 -220 -63
-22 -104 -57 -132 -112 l-20 -37 26 -10 c57 -22 149 -41 246 -51 206 -21 431
21 619 116 130 67 169 96 159 120 -14 36 -9 118 11 203 25 104 25 123 0 154
-19 26 -102 54 -121 43 -5 -4 -9 -38 -9 -77 0 -66 -2 -72 -34 -104 -54 -54
-123 -43 -206 32 -81 73 -96 126 -74 264 19 116 14 170 -17 201 -26 26 -75 24
-185 -11z"/>
</g>
</svg>
    `,
	map: `<svg xmlns = "http://www.w3.org/2000/svg" height = "1em" fill = "currentColor" viewBox = "0 0 512 512" >
        <path d="M 362 137 Q 361 162 344 195 L 344 195 L 344 195 Q 328 228 305 259 L 305 259 L 305 259 Q 284 289 269 308 Q 264 314 256 314 Q 248 314 242 308 Q 227 289 206 259 Q 184 228 167 195 Q 150 162 149 137 Q 150 92 180 61 Q 210 31 256 30 Q 301 31 331 61 Q 361 92 362 137 L 362 137 Z M 369 208 Q 374 199 378 190 Q 378 189 378 188 Q 379 188 379 187 L 482 146 L 482 146 Q 494 141 502 148 Q 511 154 512 165 L 512 406 L 512 406 Q 511 420 498 426 L 369 477 L 369 477 L 369 208 L 369 208 Z M 122 153 Q 126 172 133 190 Q 137 199 142 208 L 142 432 L 142 432 L 29 477 L 29 477 Q 17 481 9 475 Q 0 469 0 457 L 0 217 L 0 217 Q 0 203 13 196 L 122 153 L 122 153 Z M 291 325 Q 312 300 341 257 L 341 478 L 341 478 L 170 429 L 170 429 L 170 257 L 170 257 Q 200 300 220 325 Q 235 342 256 342 Q 276 342 291 325 L 291 325 Z M 256 165 Q 276 164 287 148 Q 296 130 287 112 Q 276 95 256 94 Q 235 95 224 112 Q 216 130 224 148 Q 235 164 256 165 L 256 165 Z" />
		</svg>`,
	settings: `<svg version="1.1" id="Layer_1" x="0px" y="0px"
	 width="100%" viewBox="0 0 309 339" enable-background="new 0 0 309 339" xml:space="preserve">
<path fill="#FCFCFC" opacity="1.000000" stroke="none" 
	d="
M310.000000,118.000000 
	C310.000000,192.333328 310.000000,266.166656 310.000000,340.000000 
	C207.000031,340.000000 104.000061,340.000000 1.000071,340.000000 
	C1.000047,227.000046 1.000047,114.000107 1.000024,1.000117 
	C103.999931,1.000078 206.999863,1.000078 309.999878,1.000039 
	C310.000000,39.833332 310.000000,78.666664 310.000000,118.000000 
M15.046950,309.255737 
	C20.123007,317.365021 27.576181,320.613861 36.984505,320.580750 
	C68.979874,320.468140 100.975883,320.541534 132.971649,320.526764 
	C134.634048,320.526001 136.332199,320.554260 137.951782,320.244843 
	C142.222595,319.428864 145.204590,316.858246 146.586456,312.774384 
	C147.962723,308.707092 147.215652,304.883850 144.379944,301.548401 
	C141.503937,298.165558 137.684555,297.642853 133.531326,297.649811 
	C102.535515,297.701904 71.539581,297.677368 40.543686,297.676819 
	C38.782261,297.676788 37.020840,297.676819 35.181625,297.676819 
	C35.181625,209.007584 35.181625,121.084160 35.181625,32.850365 
	C111.842461,32.850365 188.221313,32.850365 265.235931,32.850365 
	C265.235931,34.886890 265.235931,36.664364 265.235931,38.441841 
	C265.235931,68.604515 265.235748,98.767197 265.236053,128.929871 
	C265.236115,138.095322 264.870850,147.282990 265.424194,156.414963 
	C265.636658,159.921371 267.227936,163.899765 269.475311,166.590256 
	C272.450592,170.152191 277.035095,170.579926 281.424469,168.524261 
	C286.599396,166.100677 288.299011,161.734879 288.292816,156.271194 
	C288.246368,115.443314 288.305695,74.615303 288.244843,33.787464 
	C288.223053,19.170490 278.753418,9.707223 264.121674,9.699059 
	C188.131744,9.656659 112.141785,9.659448 36.151859,9.695728 
	C21.255215,9.702841 11.842765,19.153719 11.836759,34.123974 
	C11.801723,121.445732 11.780049,208.767593 11.943048,296.089050 
	C11.950824,300.254486 13.751204,304.416534 15.046950,309.255737 
M244.188477,189.424316 
	C242.789078,190.827408 241.202469,192.089371 240.020996,193.656723 
	C232.904877,203.096970 223.419022,203.087036 216.183197,193.550110 
	C211.284775,187.093964 204.805679,185.509033 197.711166,189.326385 
	C191.996796,192.401108 186.397995,195.698975 180.828384,199.032303 
	C173.763901,203.260315 171.776016,209.767151 175.025436,217.474731 
	C179.645966,228.434601 174.765198,236.799759 163.024368,238.043381 
	C155.129135,238.879684 150.248703,243.953476 150.075470,251.822861 
	C149.928802,258.484375 149.933701,265.154083 150.076599,271.815765 
	C150.241272,279.492126 154.974365,285.255493 162.548904,285.412170 
	C173.253815,285.633636 180.563614,296.365204 174.958801,306.737091 
	C171.388000,313.344940 173.749451,320.174988 180.014893,324.090393 
	C185.939117,327.792603 191.986954,331.323242 198.153168,334.604767 
	C204.711853,338.095215 212.018509,336.780853 215.730545,330.424744 
	C221.183990,321.086853 234.557053,320.546875 240.410843,330.349609 
	C244.106461,336.538269 251.200500,338.108246 257.516479,334.832367 
	C264.009460,331.464752 270.367065,327.787506 276.534241,323.854279 
	C282.683167,319.932617 284.356384,313.497528 281.544403,306.812256 
	C276.575775,294.999756 281.018402,287.135193 293.534576,285.586792 
	C301.171173,284.642059 305.909088,279.669647 306.120697,271.939728 
	C306.307587,265.113739 306.332672,258.272156 306.098633,251.448807 
	C305.835297,243.771576 300.962921,238.866028 293.299713,238.055344 
	C281.485138,236.805496 276.488190,228.331497 281.206543,217.547211 
	C284.584656,209.826004 282.702209,203.447952 275.535736,199.101990 
	C270.128296,195.822754 264.569489,192.793976 259.100433,189.615234 
	C254.433167,186.902496 249.700119,186.491882 244.188477,189.424316 
M227.825592,86.504631 
	C227.825592,82.883812 227.825592,79.262993 227.825592,75.398346 
	C175.790588,75.398346 124.281387,75.398346 72.605286,75.398346 
	C72.605286,83.044724 72.605286,90.433617 72.605286,97.815353 
	C124.443169,97.815353 175.935181,97.815353 227.825577,97.815353 
	C227.825577,94.091080 227.825577,90.787971 227.825592,86.504631 
M180.499985,158.096664 
	C196.093079,158.096664 211.686157,158.096664 227.470840,158.096664 
	C227.470840,150.133881 227.470840,142.759827 227.470840,135.386780 
	C175.622757,135.386780 124.130165,135.386780 72.529472,135.386780 
	C72.529472,143.015991 72.529472,150.267578 72.529472,158.096680 
	C108.363335,158.096680 143.931656,158.096680 180.499985,158.096664 
M148.467514,219.062286 
	C151.752609,219.062286 155.037704,219.062286 158.451172,219.062286 
	C158.451172,211.197128 158.451172,203.829880 158.451172,196.425659 
	C129.612518,196.425659 101.125435,196.425659 72.509239,196.425659 
	C72.509239,204.090057 72.509239,211.336624 72.509239,219.062286 
	C97.661919,219.062286 122.568619,219.062286 148.467514,219.062286 
z"/>
<path fill="#050505" opacity="1.000000" stroke="none" 
	d="
M14.881865,308.917969 
	C13.751204,304.416534 11.950824,300.254486 11.943048,296.089050 
	C11.780049,208.767593 11.801723,121.445732 11.836759,34.123974 
	C11.842765,19.153719 21.255215,9.702841 36.151859,9.695728 
	C112.141785,9.659448 188.131744,9.656659 264.121674,9.699059 
	C278.753418,9.707223 288.223053,19.170490 288.244843,33.787464 
	C288.305695,74.615303 288.246368,115.443314 288.292816,156.271194 
	C288.299011,161.734879 286.599396,166.100677 281.424469,168.524261 
	C277.035095,170.579926 272.450592,170.152191 269.475311,166.590256 
	C267.227936,163.899765 265.636658,159.921371 265.424194,156.414963 
	C264.870850,147.282990 265.236115,138.095322 265.236053,128.929871 
	C265.235748,98.767197 265.235931,68.604515 265.235931,38.441841 
	C265.235931,36.664364 265.235931,34.886890 265.235931,32.850365 
	C188.221313,32.850365 111.842461,32.850365 35.181625,32.850365 
	C35.181625,121.084160 35.181625,209.007584 35.181625,297.676819 
	C37.020840,297.676819 38.782261,297.676788 40.543686,297.676819 
	C71.539581,297.677368 102.535515,297.701904 133.531326,297.649811 
	C137.684555,297.642853 141.503937,298.165558 144.379944,301.548401 
	C147.215652,304.883850 147.962723,308.707092 146.586456,312.774384 
	C145.204590,316.858246 142.222595,319.428864 137.951782,320.244843 
	C136.332199,320.554260 134.634048,320.526001 132.971649,320.526764 
	C100.975883,320.541534 68.979874,320.468140 36.984505,320.580750 
	C27.576181,320.613861 20.123007,317.365021 14.881865,308.917969 
z"/>
<path fill="#030303" opacity="1.000000" stroke="none" 
	d="
M244.510178,189.227600 
	C249.700119,186.491882 254.433167,186.902496 259.100433,189.615234 
	C264.569489,192.793976 270.128296,195.822754 275.535736,199.101990 
	C282.702209,203.447952 284.584656,209.826004 281.206543,217.547211 
	C276.488190,228.331497 281.485138,236.805496 293.299713,238.055344 
	C300.962921,238.866028 305.835297,243.771576 306.098633,251.448807 
	C306.332672,258.272156 306.307587,265.113739 306.120697,271.939728 
	C305.909088,279.669647 301.171173,284.642059 293.534576,285.586792 
	C281.018402,287.135193 276.575775,294.999756 281.544403,306.812256 
	C284.356384,313.497528 282.683167,319.932617 276.534241,323.854279 
	C270.367065,327.787506 264.009460,331.464752 257.516479,334.832367 
	C251.200500,338.108246 244.106461,336.538269 240.410843,330.349609 
	C234.557053,320.546875 221.183990,321.086853 215.730545,330.424744 
	C212.018509,336.780853 204.711853,338.095215 198.153168,334.604767 
	C191.986954,331.323242 185.939117,327.792603 180.014893,324.090393 
	C173.749451,320.174988 171.388000,313.344940 174.958801,306.737091 
	C180.563614,296.365204 173.253815,285.633636 162.548904,285.412170 
	C154.974365,285.255493 150.241272,279.492126 150.076599,271.815765 
	C149.933701,265.154083 149.928802,258.484375 150.075470,251.822861 
	C150.248703,243.953476 155.129135,238.879684 163.024368,238.043381 
	C174.765198,236.799759 179.645966,228.434601 175.025436,217.474731 
	C171.776016,209.767151 173.763901,203.260315 180.828384,199.032303 
	C186.397995,195.698975 191.996796,192.401108 197.711166,189.326385 
	C204.805679,185.509033 211.284775,187.093964 216.183197,193.550110 
	C223.419022,203.087036 232.904877,203.096970 240.020996,193.656723 
	C241.202469,192.089371 242.789078,190.827408 244.510178,189.227600 
M207.882446,241.380234 
	C198.147293,251.988129 196.598236,265.514099 203.785873,277.150543 
	C210.514313,288.043518 224.073959,293.127625 236.380280,289.371582 
	C247.578720,285.953644 255.724518,276.125641 256.809753,264.723053 
	C257.910797,253.153870 251.884216,241.855698 241.736450,236.464844 
	C230.805847,230.658112 218.547653,232.280151 207.882446,241.380234 
z"/>
<path fill="#060606" opacity="1.000000" stroke="none" 
	d="
M227.825592,86.994751 
	C227.825577,90.787971 227.825577,94.091080 227.825577,97.815353 
	C175.935181,97.815353 124.443169,97.815353 72.605286,97.815353 
	C72.605286,90.433617 72.605286,83.044724 72.605286,75.398346 
	C124.281387,75.398346 175.790588,75.398346 227.825592,75.398346 
	C227.825592,79.262993 227.825592,82.883812 227.825592,86.994751 
z"/>
<path fill="#060606" opacity="1.000000" stroke="none" 
	d="
M179.999969,158.096680 
	C143.931656,158.096680 108.363335,158.096680 72.529472,158.096680 
	C72.529472,150.267578 72.529472,143.015991 72.529472,135.386780 
	C124.130165,135.386780 175.622757,135.386780 227.470840,135.386780 
	C227.470840,142.759827 227.470840,150.133881 227.470840,158.096664 
	C211.686157,158.096664 196.093079,158.096664 179.999969,158.096680 
z"/>
<path fill="#060606" opacity="1.000000" stroke="none" 
	d="
M147.971420,219.062286 
	C122.568619,219.062286 97.661919,219.062286 72.509239,219.062286 
	C72.509239,211.336624 72.509239,204.090057 72.509239,196.425659 
	C101.125435,196.425659 129.612518,196.425659 158.451172,196.425659 
	C158.451172,203.829880 158.451172,211.197128 158.451172,219.062286 
	C155.037704,219.062286 151.752609,219.062286 147.971420,219.062286 
z"/>
<path fill="#FBFBFB" opacity="1.000000" stroke="none" 
	d="
M208.136215,241.128769 
	C218.547653,232.280151 230.805847,230.658112 241.736450,236.464844 
	C251.884216,241.855698 257.910797,253.153870 256.809753,264.723053 
	C255.724518,276.125641 247.578720,285.953644 236.380280,289.371582 
	C224.073959,293.127625 210.514313,288.043518 203.785873,277.150543 
	C196.598236,265.514099 198.147293,251.988129 208.136215,241.128769 
z"/>
</svg>`
};

window.CommonIcons = {
	Expand: `<svg height = "1em" viewBox="0 0 1024 1024"><path fill="currentColor" d="M128 192h768v128H128zm0 256h512v128H128zm0 256h768v128H128zm576-352 192 160-192 128z"></path></svg>`,
	Collapse: `<svg height = "1em" viewBox="0 0 1024 1024"><path fill="currentColor" d="M896 192H128v128h768zm0 256H384v128h512zm0 256H128v128h768zM320 384 128 512l192 128z"></path></svg>`,
};
```

## luto/tools/report/VUE_modules/routes/route.js

```javascript
const { createRouter, createWebHashHistory } = VueRouter;

// Define routes
const routes = [
  { path: "/", component: window.HomeView },
  { path: "/area", component: window.AreaView },
  { path: "/production", component: window.ProductionView },
  { path: "/economics", component: window.EconomicsView },
  { path: "/ghg", component: window.GHGView },
  { path: "/water", component: window.WaterView },
  { path: "/biodiversity", component: window.BiodiversityView },
  { path: "/settings", component: window.SettingsView },
  { path: "/map", component: window.MapView },
  { path: "/:pathMatch(.*)*", component: window.NotFound },
];

// Create router instance
window.router = createRouter({
  history: createWebHashHistory(),
  routes,
});
```

## luto/tools/report/VUE_modules/services/DataConstructor.js

```javascript
window.DataConstructor = class DataConstructor {
    constructor() {
        this.leafPaths = new Map();
        this.data = {};
    }

    /**
     * Load data and extract all leaf paths
     * @param {Object} dataObject - The hierarchical data object
     */
    loadData(dataObject) {
        this.data = dataObject;
        this.leafPaths.clear();
        this._extractLeafPaths(dataObject, []);
    }

    /**
     * Recursively extract all paths to leaf nodes (non-object values)
     * @param {any} obj - Current object being traversed
     * @param {Array} currentPath - Current path from root
     * @private
     */
    _extractLeafPaths(obj, currentPath) {
        if (obj === null || obj === undefined) {
            return;
        }

        // If it's not an object or is an array, treat it as a leaf
        if (typeof obj !== 'object' || Array.isArray(obj)) {
            const pathKey = currentPath.join('.');
            this.leafPaths.set(pathKey, {
                path: [...currentPath],
                value: obj
            });
            return;
        }

        // Recursively traverse object properties
        for (const [key, value] of Object.entries(obj)) {
            this._extractLeafPaths(value, [...currentPath, key]);
        }
    }

    /**
     * Query data using level parameters
     * @param {Object} queryParams - Object with level_1, level_2, etc. parameters
     * @returns {any} - The queried data or null if not found
     */
    query(queryParams) {
        // Build path from query parameters
        const path = this._buildPathFromQuery(queryParams);

        if (path.length === 0) {
            return null;
        }

        // Navigate to the data using the path
        return this._getValueByPath(this.data, path);
    }

    /**
     * Build path array from query parameters
     * @param {Object} queryParams - Query parameters object
     * @returns {Array} - Path array
     * @private
     */
    _buildPathFromQuery(queryParams) {
        const path = [];
        let level = 1;

        while (queryParams[`level_${level}`] !== undefined) {
            const value = queryParams[`level_${level}`];
            if (value !== null && value !== undefined && value !== '') {
                path.push(value);
            }
            level++;
        }

        return path;
    }

    /**
     * Get value by following a path through the object
     * @param {Object} obj - Object to navigate
     * @param {Array} path - Path to follow
     * @returns {any} - Value at path or null if not found
     * @private
     */
    _getValueByPath(obj, path) {
        let current = obj;

        for (const key of path) {
            if (current === null || current === undefined || typeof current !== 'object') {
                return null;
            }

            if (!(key in current)) {
                return null;
            }

            current = current[key];
        }

        return current;
    }

    /**
     * Get all leaf paths for debugging/inspection
     * @returns {Array} - Array of leaf path objects
     */
    getAllLeafPaths() {
        return Array.from(this.leafPaths.values());
    }

    /**
     * Find paths that match a partial query
     * @param {Object} queryParams - Partial query parameters
     * @returns {Array} - Array of matching leaf paths
     */
    findMatchingPaths(queryParams) {
        const queryPath = this._buildPathFromQuery(queryParams);
        const matches = [];

        for (const leafInfo of this.leafPaths.values()) {
            if (this._pathMatches(leafInfo.path, queryPath)) {
                matches.push(leafInfo);
            }
        }

        return matches;
    }

    /**
     * Check if a leaf path matches a query path (prefix match)
     * @param {Array} leafPath - Full path to leaf
     * @param {Array} queryPath - Query path (may be partial)
     * @returns {boolean} - True if matches
     * @private
     */
    _pathMatches(leafPath, queryPath) {
        if (queryPath.length > leafPath.length) {
            return false;
        }

        for (let i = 0; i < queryPath.length; i++) {
            if (leafPath[i] !== queryPath[i]) {
                return false;
            }
        }

        return true;
    }

    /**
     * Get available values at a specific level
     * @param {Object} queryParams - Query parameters for previous levels
     * @param {number} targetLevel - Level to get available values for (1-based)
     * @returns {Array} - Array of available values
     */
    getAvailableValues(queryParams, targetLevel) {
        const basePath = this._buildPathFromQuery(queryParams);
        const values = new Set();

        for (const leafInfo of this.leafPaths.values()) {
            if (this._pathMatches(leafInfo.path, basePath) &&
                leafInfo.path.length > targetLevel - 1) {
                values.add(leafInfo.path[targetLevel - 1]);
            }
        }

        return Array.from(values);
    }

    /**
     * Get available keys at the next level given current path
     * @param {Object} fixedLevels - Object with fixed level values (e.g., {level_1: "map_area_Am"})
     * @returns {Array} - Array of available keys for the next level
     */
    getAvailableKeysAtNextLevel(fixedLevels) {
        const currentPath = this._buildPathFromQuery(fixedLevels);
        const nextLevel = currentPath.length + 1;

        return this.getAvailableValues(fixedLevels, nextLevel);
    }

    /**
     * Get available keys at a specific level with a more intuitive interface
     * @param {Object} fixedLevels - Object with fixed level values
     * @param {number} targetLevel - Target level to get keys for (1-based, optional)
     * @returns {Array} - Array of available keys
     */
    getKeysAtLevel(fixedLevels, targetLevel = null) {
        if (targetLevel === null) {
            // If no target level specified, get keys for next level
            return this.getAvailableKeysAtNextLevel(fixedLevels);
        }

        return this.getAvailableValues(fixedLevels, targetLevel);
    }

    /**
     * Navigate through the data structure step by step
     * @param {Object} currentPath - Current path as key-value pairs
     * @returns {Object} - Object with available keys and current data
     */
    explore(currentPath = {}) {
        const pathArray = this._buildPathFromQuery(currentPath);
        const currentData = this._getValueByPath(this.data, pathArray);
        const nextLevelKeys = this.getAvailableKeysAtNextLevel(currentPath);

        return {
            currentPath: pathArray,
            currentData: currentData,
            nextLevelKeys: nextLevelKeys,
            isLeaf: nextLevelKeys.length === 0,
            dataType: typeof currentData
        };
    }

    /**
     * Query with flexible parameter names (backward compatibility)
     * @param {Object} params - Parameters object
     * @returns {any} - Queried data
     */
    flexQuery(params) {
        // Convert various parameter formats to level_N format
        const normalizedParams = {};

        // Handle level_1, level_2, etc.
        for (const [key, value] of Object.entries(params)) {
            if (key.startsWith('level_')) {
                normalizedParams[key] = value;
            }
        }

        // Handle positional parameters if level_N not provided
        if (Object.keys(normalizedParams).length === 0) {
            const values = Object.values(params);
            for (let i = 0; i < values.length; i++) {
                normalizedParams[`level_${i + 1}`] = values[i];
            }
        }

        return this.query(normalizedParams);
    }
}
```

## luto/tools/report/VUE_modules/services/DataService.js

```javascript
// Chart Data Service
// This service provides data about charts for different metrics and categories

window.DataService = {

  chartCategories: {
    Area: {
      Ag: {
        path: "data/Area_Ag.js",
        name: "Area_Ag",
      },
      "Ag Mgt": {
        path: "data/Area_Am.js",
        name: "Area_Am",
      },
      "Non-Ag": {
        path: "data/Area_NonAg.js",
        name: "Area_NonAg",
      },
      overview: {
        Category: {
          path: "data/Area_overview_2_Category.js",
          name: "Area_overview_2_Category",
        },
        "Land-use": {
          path: "data/Area_overview_1_Land-use.js",
          name: "Area_overview_1_Land-use",
        },
        Source: {
          path: "data/Area_overview_3_Source.js",
          name: "Area_overview_3_Source",
        },
      },
      ranking: {
        path: "data/Area_ranking.js",
        name: "Area_ranking",
      },
    },
    Biodiversity: {
      GBF2: {
        Ag: {
          path: "data/BIO_GBF2_split_Ag_1_Landuse.js",
          name: "BIO_GBF2_split_Ag_1_Landuse",
        },
        "Ag Mgt": {
          "Agri-Management": {
            path: "data/BIO_GBF2_split_Am_2_Agri-Management.js",
            name: "BIO_GBF2_split_Am_2_Agri-Management",
          },
          Landuse: {
            path: "data/BIO_GBF2_split_Am_1_Landuse.js",
            name: "BIO_GBF2_split_Am_1_Landuse",
          },
        },
        "Non-Ag": {
          path: "data/BIO_GBF2_split_NonAg_1_Landuse.js",
          name: "BIO_GBF2_split_NonAg_1_Landuse",
        },
        overview: {
          path: "data/BIO_GBF2_overview_1_Type.js",
          name: "BIO_GBF2_overview_1_Type",
        },
      },
      quality: {
        Ag: {
          path: "data/BIO_quality_split_Ag_1_Landuse.js",
          name: "BIO_quality_split_Ag_1_Landuse",
        },
        "Ag Mgt": {
          "Agri-Management": {
            path: "data/BIO_quality_split_Am_2_Agri-Management.js",
            name: "BIO_quality_split_Am_2_Agri-Management",
          },
          Landuse: {
            path: "data/BIO_quality_split_Am_1_Landuse.js",
            name: "BIO_quality_split_Am_1_Landuse",
          },
        },
        "Non-Ag": {
          path: "data/BIO_quality_split_NonAg_1_Landuse.js",
          name: "BIO_quality_split_NonAg_1_Landuse",
        },
        overview: {
          path: "data/BIO_quality_overview_1_Type.js",
          name: "BIO_quality_overview_1_Type",
        },
      },
      ranking: {
        path: "data/Biodiversity_ranking.js",
        name: "Biodiversity_ranking",
      },
    },
    Economics: {
      Ag: {
        path: "data/Economics_Ag.js",
        name: "Economics_Ag",
      },
      "Ag Mgt": {
        path: "data/Economics_Am.js",
        name: "Economics_Am",
      },
      "Non-Ag": {
        path: "data/Economics_overview_Non_Ag.js",
        name: "Economics_overview_Non_Ag",
      },
      overview: {
        Ag: {
          path: "data/Economics_overview_Ag.js",
          name: "Economics_overview_Ag",
        },
        "Ag Mgt": {
          path: "data/Economics_overview_Am.js",
          name: "Economics_overview_Am",
        },
        "Non-Ag": {
          path: "data/Economics_overview_Non_Ag.js",
          name: "Economics_overview_Non_Ag",
        },
        sum: {
          path: "data/Economics_overview_sum.js",
          name: "Economics_overview_sum",
        },
      },
      ranking: {
        path: "data/Economics_ranking.js",
        name: "Economics_ranking",
      },
    },
    GHG: {
      Ag: {
        path: "data/GHG_Ag.js",
        name: "GHG_Ag",
      },
      "Ag Mgt": {
        path: "data/GHG_Am.js",
        name: "GHG_Am",
      },
      "Non-Ag": {
        path: "data/GHG_NonAg.js",
        name: "GHG_NonAg",
      },
      overview: {
        path: "data/GHG_overview.js",
        name: "GHG_overview",
      },
      ranking: {
        path: "data/GHG_ranking.js",
        name: "GHG_ranking",
      },
    },
    Production: {
      Ag: {
        path: "data/Production_Ag.js",
        name: "Production_Ag",
      },
      "Ag Mgt": {
        path: "data/Production_Am.js",
        name: "Production_Am",
      },
      "Non-Ag": {
        path: "data/Production_NonAg.js",
        name: "Production_NonAg",
      },
      overview: {
        achieve: {
          path: "data/Production_overview_AUS_achive_percent.js",
          name: "Production_overview_AUS_achive_percent",
        },
        sum: {
          path: "data/Production_overview_sum.js",
          name: "Production_overview_sum",
        },
      },
    },
    Water: {
      NRM: {
        Ag: {
          path: "data/Water_Ag_NRM.js",
          name: "Water_Ag_NRM",
        },
        "Ag Mgt": {
          path: "data/Water_Am_NRM.js",
          name: "Water_Am_NRM",
        },
        "Non-Ag": {
          path: "data/Water_NonAg_NRM.js",
          name: "Water_NonAg_NRM",
        },
        overview: {
          Type: {
            path: "data/Water_overview_NRM_Type.js",
            name: "Water_overview_NRM_Type",
          },
        },
        ranking: {
          path: "data/Water_ranking_NRM.js",
          name: "Water_ranking_NRM",
        },
      },
      Watershed: {
        overview: {
          path: "data/Water_overview_watershed.js",
          name: "Water_overview_watershed",
        },
      },
    },
  },
};
```

## luto/tools/report/VUE_modules/services/MapService.js

```javascript
// Map Data Service
// This service provides data about maps for different regions and categories

window.MapService = {

  mapCategories: {
    'Area': {
      'Ag': { 'path': 'data/map_layers/map_area_Ag.js', 'name': 'map_area_Ag' },
      'Ag Mgt': { 'path': 'data/map_layers/map_area_Am.js', 'name': 'map_area_Am' },
      'Non-Ag': { 'path': 'data/map_layers/map_area_NonAg.js', 'name': 'map_area_NonAg' },
    },
    'Biodiversity': {
      'overall': {
        'Ag': { 'path': 'data/map_layers/map_bio_overall_Ag.js', 'name': 'map_bio_overall_Ag' },
        'Ag Mgt': { 'path': 'data/map_layers/map_bio_overall_Am.js', 'name': 'map_bio_overall_Am' },
        'Non-Ag': { 'path': 'data/map_layers/map_bio_overall_NonAg.js', 'name': 'map_bio_overall_NonAg' },
      },
      'GBF2': {
        'Ag': { 'path': 'data/map_layers/map_bio_GBF2_Ag.js', 'name': 'map_bio_GBF2_Ag' },
        'Ag Mgt': { 'path': 'data/map_layers/map_bio_GBF2_Am.js', 'name': 'map_bio_GBF2_Am' },
        'Non-Ag': { 'path': 'data/map_layers/map_bio_GBF2_NonAg.js', 'name': 'map_bio_GBF2_NonAg' },
      }
    },
    'Economics': {
      'Cost': {
        'Ag': { 'path': 'data/map_layers/map_cost_Ag.js', 'name': 'map_cost_Ag' },
        'Ag Mgt': { 'path': 'data/map_layers/map_cost_Am.js', 'name': 'map_cost_Am' },
        'Non-Ag': { 'path': 'data/map_layers/map_cost_NonAg.js', 'name': 'map_cost_NonAg' },
      },
      'Revenue': {
        'Ag': { 'path': 'data/map_layers/map_revenue_Ag.js', 'name': 'map_revenue_Ag' },
        'Ag Mgt': { 'path': 'data/map_layers/map_revenue_Am.js', 'name': 'map_revenue_Am' },
        'Non-Ag': { 'path': 'data/map_layers/map_revenue_NonAg.js', 'name': 'map_revenue_NonAg' },
      },
    },
    'GHG': {
      'Ag': { 'path': 'data/map_layers/map_GHG_Ag.js', 'name': 'map_GHG_Ag' },
      'Ag Mgt': { 'path': 'data/map_layers/map_GHG_Am.js', 'name': 'map_GHG_Am' },
      'Non-Ag': { 'path': 'data/map_layers/map_GHG_NonAg.js', 'name': 'map_GHG_NonAg' },
    },
    'Production': {
      'Ag': { 'path': 'data/map_layers/map_quantities_Ag.js', 'name': 'map_quantities_Ag' },
      'Ag Mgt': { 'path': 'data/map_layers/map_quantities_Am.js', 'name': 'map_quantities_Am' },
      'Non-Ag': { 'path': 'data/map_layers/map_quantities_NonAg.js', 'name': 'map_quantities_NonAg' },
    },
    'Water': {
      'Ag': { 'path': 'data/map_layers/map_water_yield_Ag.js', 'name': 'map_water_yield_Ag' },
      'Ag Mgt': { 'path': 'data/map_layers/map_water_yield_Am.js', 'name': 'map_water_yield_Am' },
      'Non-Ag': { 'path': 'data/map_layers/map_water_yield_NonAg.js', 'name': 'map_water_yield_NonAg' },
    },
    'Dvar': {
      'Ag': { 'path': 'data/map_layers/map_dvar_Ag.js', 'name': 'map_dvar_Ag' },
      'Ag Mgt': { 'path': 'data/map_layers/map_dvar_Am.js', 'name': 'map_dvar_Am' },
      'Non-Ag': { 'path': 'data/map_layers/map_dvar_NonAg.js', 'name': 'map_dvar_NonAg' },
      'Mosaic': { 'path': 'data/map_layers/map_dvar_mosaic.js', 'name': 'map_dvar_mosaic' },
    }
  }
}
```

## luto/tools/report/VUE_modules/views/Area.js

```javascript
window.AreaView = {
  setup() {
    const { ref, onMounted, inject, computed, watch, nextTick } = Vue;

    // Data|Map service
    const chartRegister = window.DataService.chartCategories["Area"];   // DataService has been registered in index.html      [DataService.js]
    const mapRegister = window.MapService.mapCategories["Area"];        // MapService was registered in the index.html        [MapService.js]
    const loadScript = window.loadScript;                               // DataConstructor has been registered in index.html  [helpers.js]

    // Global selection state
    const yearIndex = ref(0);
    const selectYear = ref(2020);
    const selectRegion = inject("globalSelectedRegion");

    // Available variables
    const availableYears = ref([]);
    const availableUnit = {
      Area: "Hectares",
      Economics: "AUD",
      GHG: "Mt CO2e",
      Water: "ML",
      Biodiversity: "Relative Percentage (Pre-1750 = 100%)",
    };

    // Available selections
    const availableCategories = ["Ag", "Ag Mgt", "Non-Ag"];
    const availableAgMgt = ref([]);
    const availableWater = ref([]);
    const availableLanduse = ref([]);

    // Map selection state
    const selectCategory = ref("");
    const selectAgMgt = ref("");
    const selectWater = ref("");
    const selectLanduse = ref("");

    // Previous selections memory
    const previousSelections = ref({
      "Ag": { water: "", landuse: "" },
      "Ag Mgt": { agMgt: "", water: "", landuse: "" },
      "Non-Ag": { landuse: "" }
    });


    // UI state
    const dataLoaded = ref(false);
    const isDrawerOpen = ref(false);
    const mapReady = computed(() => {
      if (!selectCategory.value || !selectWater.value || !selectLanduse.value) {
        return false;
      }
      if (selectCategory.value === "Ag Mgt" && !selectAgMgt.value) {
        return false;
      }
      const dataName = mapRegister[selectCategory.value]?.["name"];
      return dataName && window[dataName];
    });
    const chartReady = computed(() => {
      if (!selectCategory.value || !selectRegion.value || !selectWater.value || !selectLanduse.value) {
        return false;
      }
      if (selectCategory.value === "Ag Mgt" && !selectAgMgt.value) {
        return false;
      }
      const dataName = chartRegister[selectCategory.value]?.["name"];
      return dataName && window[dataName] && window[dataName][selectRegion.value];
    });


    //  Reactive data
    const mapData = computed(() => window[mapRegister[selectCategory.value]["name"]])
    const chartData = computed(() => window[chartRegister[selectCategory.value]["name"]][selectRegion.value])
    const selectMapData = computed(() => {
      if (!mapReady.value) {
        return {};
      }
      if (selectCategory.value === "Ag") {
        return mapData.value[selectWater.value][selectLanduse.value][selectYear.value];
      }
      else if (selectCategory.value === "Ag Mgt") {
        return mapData.value?.[selectAgMgt.value][selectWater.value][selectLanduse.value][selectYear.value];
      }
      else if (selectCategory.value === "Non-Ag") {
        return mapData.value[selectLanduse.value][selectYear.value];
      }
    });
    const selectChartData = computed(() => {
      if (!chartReady.value) {
        return {};
      }
      if (selectCategory.value === "Ag") {
        seriesData = chartData.value[selectWater.value];
      }
      else if (selectCategory.value === "Ag Mgt") {
        seriesData = chartData.value[selectAgMgt.value]?.[selectWater.value]
      } else if (selectCategory.value === "Non-Ag") {
        seriesData = chartData.value
      }

      return {
        ...window["Chart_default_options"],
        chart: {
          height: 440,
        },
        yAxis: {
          title: {
            text: availableUnit[selectCategory.value],
          },
        },
        series: seriesData || [],
        colors: window["Supporting_info"].colors,
      }
    });


    onMounted(async () => {
      await loadScript("./data/Supporting_info.js", "Supporting_info");
      await loadScript("./data/chart_option/Chart_default_options.js", "Chart_default_options");

      // Load data
      await loadScript(mapRegister["Ag"]["path"], mapRegister["Ag"]["name"]);
      await loadScript(mapRegister["Ag Mgt"]["path"], mapRegister["Ag Mgt"]["name"]);
      await loadScript(mapRegister["Non-Ag"]["path"], mapRegister["Non-Ag"]["name"]);
      await loadScript(chartRegister["Ag"]["path"], chartRegister["Ag"]["name"]);
      await loadScript(chartRegister["Ag Mgt"]["path"], chartRegister["Ag Mgt"]["name"]);
      await loadScript(chartRegister["Non-Ag"]["path"], chartRegister["Non-Ag"]["name"]);

      // Initial selections
      availableYears.value = window.Supporting_info.years;
      selectCategory.value = availableCategories[0];

      await nextTick(() => {
        dataLoaded.value = true;
      });

    });


    // Watchers and methods
    const toggleDrawer = () => {
      isDrawerOpen.value = !isDrawerOpen.value;
    };

    watch(yearIndex, (newIndex) => {
      selectYear.value = availableYears.value[newIndex];
    });

    // Progressive selection chain watchers
    watch(selectCategory, (newCategory, oldCategory) => {
      // Save previous selections before switching
      if (oldCategory) {
        if (oldCategory === "Ag") {
          previousSelections.value["Ag"] = { water: selectWater.value, landuse: selectLanduse.value };
        } else if (oldCategory === "Ag Mgt") {
          previousSelections.value["Ag Mgt"] = { agMgt: selectAgMgt.value, water: selectWater.value, landuse: selectLanduse.value };
        } else if (oldCategory === "Non-Ag") {
          previousSelections.value["Non-Ag"] = { landuse: selectLanduse.value };
        }
      }

      // Handle ALL downstream variables with cascading pattern
      if (newCategory === "Ag Mgt") {
        availableAgMgt.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]] || {});
        const prevAgMgt = previousSelections.value["Ag Mgt"].agMgt;
        selectAgMgt.value = (prevAgMgt && availableAgMgt.value.includes(prevAgMgt)) ? prevAgMgt : (availableAgMgt.value[0] || '');
        
        availableWater.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][selectAgMgt.value] || {});
        const prevWater = previousSelections.value["Ag Mgt"].water;
        selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || '');
        
        availableLanduse.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][selectAgMgt.value][selectWater.value] || {});
        const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || 'ALL');
      } else if (newCategory === "Ag") {
        availableWater.value = Object.keys(window[mapRegister["Ag"]["name"]] || {});
        const prevWater = previousSelections.value["Ag"].water;
        selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || '');
        
        availableLanduse.value = Object.keys(window[mapRegister["Ag"]["name"]][selectWater.value] || {});
        const prevLanduse = previousSelections.value["Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || 'ALL');
      } else if (newCategory === "Non-Ag") {
        availableLanduse.value = Object.keys(window[mapRegister["Non-Ag"]["name"]] || {});
        const prevLanduse = previousSelections.value["Non-Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || 'ALL');
      }
    });


    watch(selectWater, (newWater) => {
      // Save current water selection
      if (selectCategory.value === "Ag") {
        previousSelections.value["Ag"].water = newWater;
      } else if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].water = newWater;
      }

      // Handle ALL downstream variables
      if (selectCategory.value === "Ag") {
        availableLanduse.value = Object.keys(window[mapRegister["Ag"]["name"]][newWater] || {});
        const prevLanduse = previousSelections.value["Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || 'ALL');
      } else if (selectCategory.value === "Ag Mgt") {
        availableLanduse.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][selectAgMgt.value][newWater] || {});
        const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || 'ALL');
      }
    });

    watch(selectAgMgt, (newAgMgt) => {
      // Save current agMgt selection
      if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].agMgt = newAgMgt;
        
        // Handle ALL downstream variables with cascading pattern
        availableWater.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][newAgMgt] || {});
        const prevWater = previousSelections.value["Ag Mgt"].water;
        selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || '');
        
        availableLanduse.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][newAgMgt][selectWater.value] || {});
        const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || 'ALL');
      }
    });

    watch(selectLanduse, (newLanduse) => {
      // Save current landuse selection
      if (selectCategory.value === "Ag") {
        previousSelections.value["Ag"].landuse = newLanduse;
      } else if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].landuse = newLanduse;
      } else if (selectCategory.value === "Non-Ag") {
        previousSelections.value["Non-Ag"].landuse = newLanduse;
      }
    });



    return {
      yearIndex,
      selectYear,
      selectRegion,

      availableYears,
      availableCategories,
      availableAgMgt,
      availableWater,
      availableLanduse,

      selectCategory,
      selectAgMgt,
      selectWater,
      selectLanduse,

      selectMapData,
      selectChartData,

      dataLoaded,
      isDrawerOpen,
      toggleDrawer,
    };
  },
  template: `
    <div class="relative w-full h-screen">


      <!-- Region selection dropdown -->
      <div class="absolute w-[262px] top-32 left-[20px] z-50 bg-white/70 rounded-lg shadow-lg max-w-xs z-[9999]">
        <filterable-dropdown></filterable-dropdown>
      </div>

      <!-- Year slider -->
      <div class="absolute top-[200px] left-[20px] z-[1001] w-[262px] bg-white/70 p-2 rounded-lg items-center">
        <p class="text-[0.8rem]">Year: <strong>{{ selectYear }}</strong></p>
        <el-slider
          v-if="availableYears && availableYears.length > 0"
          v-model="yearIndex"
          size="small"
          :show-tooltip="false"
          :min="0"
          :max="availableYears.length - 1"
          :step="1"
          :format-tooltip="index => availableYears[index]"
          :marks="availableYears.reduce((acc, year, index) => ({ ...acc, [index]: year }), {})"
          @input="(index) => { yearIndex = index; selectYear = availableYears[index]; }"
        />
      </div>


      <!-- Data selection controls container -->
      <div class="absolute top-[285px] left-[20px] w-[320px] z-[1001] flex flex-col space-y-3 bg-white/70 p-2 rounded-lg">

        <!-- Category buttons (always visible) -->
        <div class="flex items-center">
          <div class="flex space-x-1">
            <span class="text-[0.8rem] mr-1 font-medium">Category:</span>
            <button v-for="(val, key) in availableCategories" :key="key"
              @click="selectCategory = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded"
              :class="{'bg-sky-500 text-white': selectCategory === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Ag Mgt options (only for Ag Mgt category) -->
        <div 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="selectCategory === 'Ag Mgt' && dataLoaded && availableAgMgt.length > 0" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Ag Mgt:</span>
            <button v-for="(val, key) in availableAgMgt" :key="key"
              @click="selectAgMgt = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectAgMgt === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Water options -->
        <div 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="selectCategory !== 'Non-Ag' && dataLoaded && availableWater.length > 0" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Water:</span>
            <button v-for="(val, key) in availableWater" :key="key"
              @click="selectWater = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectWater === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Landuse options -->
        <div 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="dataLoaded" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Landuse:</span>
            <button v-for="(val, key) in availableLanduse" :key="key"
              @click="selectLanduse = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectLanduse === val}">
              {{ val }}
            </button>
          </div>
        </div>
      </div>

      

      

      <!-- Map container with slide-out chart drawer -->
      <div style="position: relative; width: 100%; height: 100%; overflow: hidden;">

        <!-- Map component takes full space -->
        <regions-map 
          :mapData="selectMapData"
          style="width: 100%; height: 100%;">
        </regions-map>

        <!-- Drawer toggle button -->
        <button
          @click="toggleDrawer"
          class="absolute top-5 z-[1001] p-2.5 bg-white border border-gray-300 rounded cursor-pointer transition-all duration-300 ease-in-out"
          :class="isDrawerOpen ? 'right-[420px]' : 'right-5'">
          {{ isDrawerOpen ? '→' : '←' }}
        </button>
        
        <!-- Chart drawer positioned relative to map -->
        <div 
          :style="{
            position: 'absolute',
            height: '50px',
            top: '10px',
            bottom: '10px',
            right: isDrawerOpen ? '0px' : '-100%',
            width: '66.666%',
            background: 'transparent',
            transition: 'right 0.3s ease',
            zIndex: 1000,
            padding: '60px 20px 20px 20px',
            boxSizing: 'border-box'
          }">
          <chart-container 
            :chartData="selectChartData" 
            :selectedLanduse="selectLanduse"
            :draggable="true"
            :zoomable="true"
            style="width: 100%; height: 200px;">
          </chart-container>
        </div>
      </div>

    </div>
  `,
};
```

## luto/tools/report/VUE_modules/views/Biodiversity.js

```javascript
window.BiodiversityView = {
  setup() {
    const { ref, onMounted, inject, computed, watch, nextTick } = Vue;

    // Data|Map service - Only use GBF2 data as requested
    const chartRegister = window.DataService.chartCategories["Biodiversity"]["GBF2"];
    const mapRegister = window.MapService.mapCategories["Biodiversity"]["GBF2"];
    const loadScript = window.loadScript;

    // Global selection state
    const yearIndex = ref(0);
    const selectYear = ref(2020);
    const selectRegion = inject("globalSelectedRegion");

    // Available variables
    const availableYears = ref([]);
    const availableUnit = {
      Area: "Hectares",
      Economics: "AUD",
      GHG: "Mt CO2e",
      Water: "ML",
      Biodiversity: "Relative Percentage (Pre-1750 = 100%)",
    };

    // Available selections
    const availableCategories = ["Ag", "Ag Mgt", "Non-Ag"];
    const availableAgMgt = ref([]);
    const availableWater = ref([]);
    const availableLanduse = ref([]);

    // Map selection state
    const selectCategory = ref("");
    const selectAgMgt = ref("");
    const selectWater = ref("");
    const selectLanduse = ref("");

    // Previous selections memory
    const previousSelections = ref({
      "Ag": { water: "", landuse: "" },
      "Ag Mgt": { agMgt: "", water: "", landuse: "" },
      "Non-Ag": { landuse: "" }
    });

    // UI state
    const dataLoaded = ref(false);
    const isDrawerOpen = ref(false);
    const mapReady = computed(() => {
      if (!selectCategory.value || !selectLanduse.value) {
        return false;
      }
      if (selectCategory.value === "Non-Ag") {
        const dataName = mapRegister[selectCategory.value]?.["name"];
        return dataName && window[dataName];
      }
      if (!selectWater.value) {
        return false;
      }
      if (selectCategory.value === "Ag Mgt" && !selectAgMgt.value) {
        return false;
      }
      const dataName = mapRegister[selectCategory.value]?.["name"];
      return dataName && window[dataName];
    });
    const chartReady = computed(() => {
      if (!selectCategory.value || !selectRegion.value) {
        return false;
      }
      // Biodiversity chart data uses simplified Region → [series] structure
      let dataName;
      if (selectCategory.value === "Ag Mgt") {
        dataName = chartRegister["Ag Mgt"]["Landuse"]["name"];
      } else {
        dataName = chartRegister[selectCategory.value]?.["name"];
      }
      return dataName && window[dataName] && window[dataName][selectRegion.value];
    });

    // Reactive data
    const mapData = computed(() => window[mapRegister[selectCategory.value]["name"]]);
    const chartData = computed(() => {
      if (selectCategory.value === "Ag Mgt") {
        // For Ag Mgt, use the "Landuse" dataset so chart series names match landuse selections for highlighting
        const datasetName = chartRegister["Ag Mgt"]["Landuse"]["name"];
        return window[datasetName][selectRegion.value];
      } else {
        // For Ag and Non-Ag, use the direct dataset
        const datasetName = chartRegister[selectCategory.value]["name"];
        return window[datasetName][selectRegion.value];
      }
    });
    const selectMapData = computed(() => {
      if (!mapReady.value) {
        return {};
      }
      if (selectCategory.value === "Ag") {
        return mapData.value[selectWater.value][selectLanduse.value][selectYear.value];
      }
      else if (selectCategory.value === "Ag Mgt") {
        // Data hierarchy: AgMgt → Water → Landuse → Year
        return mapData.value?.[selectAgMgt.value][selectWater.value][selectLanduse.value][selectYear.value];
      }
      else if (selectCategory.value === "Non-Ag") {
        return mapData.value[selectLanduse.value][selectYear.value];
      }
    });
    const selectChartData = computed(() => {
      if (!chartReady.value) {
        return {};
      }
      // According to CLAUDE.md, biodiversity chart data follows simplified Region → [series] structure
      let seriesData = chartData.value || [];

      return {
        ...window["Chart_default_options"],
        chart: {
          height: 440,
        },
        yAxis: {
          title: {
            text: availableUnit["Biodiversity"],
          },
        },
        series: seriesData,
        colors: window["Supporting_info"].colors,
      };
    });

    onMounted(async () => {
      await loadScript("./data/Supporting_info.js", "Supporting_info");
      await loadScript("./data/chart_option/Chart_default_options.js", "Chart_default_options");

      // Load GBF2 data only (as requested - ignore quality data)
      await loadScript(mapRegister["Ag"]["path"], mapRegister["Ag"]["name"]);
      await loadScript(mapRegister["Ag Mgt"]["path"], mapRegister["Ag Mgt"]["name"]);
      await loadScript(mapRegister["Non-Ag"]["path"], mapRegister["Non-Ag"]["name"]);
      await loadScript(chartRegister["Ag"]["path"], chartRegister["Ag"]["name"]);
      // Load Ag Mgt Landuse chart dataset (for series highlighting with landuse selection)
      await loadScript(chartRegister["Ag Mgt"]["Landuse"]["path"], chartRegister["Ag Mgt"]["Landuse"]["name"]);
      await loadScript(chartRegister["Non-Ag"]["path"], chartRegister["Non-Ag"]["name"]);

      // Initial selections
      availableYears.value = window.Supporting_info.years;
      selectCategory.value = availableCategories[0];

      await nextTick(() => {
        dataLoaded.value = true;
      });
    });

    // Watchers and methods
    const toggleDrawer = () => {
      isDrawerOpen.value = !isDrawerOpen.value;
    };

    watch(yearIndex, (newIndex) => {
      selectYear.value = availableYears.value[newIndex];
    });

    // Progressive selection chain watchers
    watch(selectCategory, (newCategory, oldCategory) => {
      // Save previous selections before switching
      if (oldCategory) {
        if (oldCategory === "Ag") {
          previousSelections.value["Ag"] = { water: selectWater.value, landuse: selectLanduse.value };
        } else if (oldCategory === "Ag Mgt") {
          previousSelections.value["Ag Mgt"] = { agMgt: selectAgMgt.value, water: selectWater.value, landuse: selectLanduse.value };
        } else if (oldCategory === "Non-Ag") {
          previousSelections.value["Non-Ag"] = { landuse: selectLanduse.value };
        }
      }

      // Handle ALL downstream variables with cascading pattern
      if (newCategory === "Ag Mgt") {
        // Data hierarchy: AgMgt → Water → Landuse → Year
        availableAgMgt.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]] || {});
        const prevAgMgt = previousSelections.value["Ag Mgt"].agMgt;
        selectAgMgt.value = (prevAgMgt && availableAgMgt.value.includes(prevAgMgt)) ? prevAgMgt : (availableAgMgt.value[0] || '');
        
        availableWater.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][selectAgMgt.value] || {});
        const prevWater = previousSelections.value["Ag Mgt"].water;
        selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || '');
        
        availableLanduse.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][selectAgMgt.value][selectWater.value] || {});
        const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
      } else if (newCategory === "Ag") {
        // Clear AgMgt selections when switching away from Ag Mgt
        availableAgMgt.value = [];
        selectAgMgt.value = '';
        availableWater.value = Object.keys(window[mapRegister["Ag"]["name"]] || {});
        const prevWater = previousSelections.value["Ag"].water;
        selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || '');
        
        availableLanduse.value = Object.keys(window[mapRegister["Ag"]["name"]][selectWater.value] || {});
        const prevLanduse = previousSelections.value["Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || 'ALL');
      } else if (newCategory === "Non-Ag") {
        // Clear both AgMgt and Water selections for Non-Ag
        availableAgMgt.value = [];
        selectAgMgt.value = '';
        availableWater.value = [];
        selectWater.value = '';
        availableLanduse.value = Object.keys(window[mapRegister["Non-Ag"]["name"]] || {});
        const prevLanduse = previousSelections.value["Non-Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || 'ALL');
      }
    });

    watch(selectAgMgt, (newAgMgt) => {
      // Save current agMgt selection
      if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].agMgt = newAgMgt;
        
        // Handle ALL downstream variables with cascading pattern
        // Data hierarchy: AgMgt → Water → Landuse → Year
        availableWater.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][newAgMgt] || {});
        const prevWater = previousSelections.value["Ag Mgt"].water;
        selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || '');
        
        availableLanduse.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][newAgMgt][selectWater.value] || {});
        const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
      }
    });

    watch(selectWater, (newWater) => {
      // Save current water selection
      if (selectCategory.value === "Ag") {
        previousSelections.value["Ag"].water = newWater;
      } else if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].water = newWater;
      }

      // Handle downstream variables for Ag Mgt
      // Data hierarchy: AgMgt → Water → Landuse → Year
      if (selectCategory.value === "Ag Mgt") {
        availableLanduse.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][selectAgMgt.value][newWater] || {});
        const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
      } else if (selectCategory.value === "Ag") {
        // Handle Ag category: Water → Landuse → Year
        availableLanduse.value = Object.keys(window[mapRegister["Ag"]["name"]][newWater] || {});
        const prevLanduse = previousSelections.value["Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || 'ALL');
      }
    });

    watch(selectLanduse, (newLanduse) => {
      // Save current landuse selection
      if (selectCategory.value === "Ag") {
        previousSelections.value["Ag"].landuse = newLanduse;
      } else if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].landuse = newLanduse;
      } else if (selectCategory.value === "Non-Ag") {
        previousSelections.value["Non-Ag"].landuse = newLanduse;
      }
    });


    return {
      yearIndex,
      selectYear,
      selectRegion,

      availableYears,
      availableCategories,
      availableAgMgt,
      availableWater,
      availableLanduse,

      selectCategory,
      selectAgMgt,
      selectWater,
      selectLanduse,

      selectMapData,
      selectChartData,

      dataLoaded,
      isDrawerOpen,
      toggleDrawer,
    };
  },
  template: `
    <div class="relative w-full h-screen">

      <!-- Region selection dropdown -->
      <div class="absolute w-[262px] top-32 left-[20px] z-50 bg-white/70 rounded-lg shadow-lg max-w-xs z-[9999]">
        <filterable-dropdown></filterable-dropdown>
      </div>

      <!-- Year slider -->
      <div class="absolute top-[200px] left-[20px] z-[1001] w-[262px] bg-white/70 p-2 rounded-lg items-center">
        <p class="text-[0.8rem]">Year: <strong>{{ selectYear }}</strong></p>
        <el-slider
          v-if="availableYears && availableYears.length > 0"
          v-model="yearIndex"
          size="small"
          :show-tooltip="false"
          :min="0"
          :max="availableYears.length - 1"
          :step="1"
          :format-tooltip="index => availableYears[index]"
          :marks="availableYears.reduce((acc, year, index) => ({ ...acc, [index]: year }), {})"
          @input="(index) => { yearIndex = index; selectYear = availableYears[index]; }"
        />
      </div>

      <!-- Data selection controls container -->
      <div class="absolute top-[285px] left-[20px] w-[320px] z-[1001] flex flex-col space-y-3 bg-white/70 p-2 rounded-lg">

        <!-- Category buttons (always visible) -->
        <div class="flex items-center">
          <div class="flex space-x-1">
            <span class="text-[0.8rem] mr-1 font-medium">Category:</span>
            <button v-for="(val, key) in availableCategories" :key="key"
              @click="selectCategory = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded"
              :class="{'bg-sky-500 text-white': selectCategory === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Ag Mgt options (only for Ag Mgt category) -->
        <div v-if="selectCategory === 'Ag Mgt'" 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="dataLoaded && availableAgMgt.length > 0" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Ag Mgt:</span>
            <button v-for="(val, key) in availableAgMgt" :key="key"
              @click="selectAgMgt = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectAgMgt === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Water options (only for Ag and Ag Mgt) - comes before Landuse for Ag Mgt hierarchy: AgMgt → Water → Landuse -->
        <div v-if="selectCategory === 'Ag' || selectCategory === 'Ag Mgt'" 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="dataLoaded && availableWater.length > 0" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Water:</span>
            <button v-for="(val, key) in availableWater" :key="key"
              @click="selectWater = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectWater === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Landuse options -->
        <div 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="dataLoaded" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Landuse:</span>
            <button v-for="(val, key) in availableLanduse" :key="key"
              @click="selectLanduse = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectLanduse === val}">
              {{ val }}
            </button>
          </div>
        </div>
      </div>

      <!-- Map container with slide-out chart drawer -->
      <div style="position: relative; width: 100%; height: 100%; overflow: hidden;">

        <!-- Map component takes full space -->
        <regions-map 
          :mapData="selectMapData"
          style="width: 100%; height: 100%;">
        </regions-map>

        <!-- Drawer toggle button -->
        <button
          @click="toggleDrawer"
          class="absolute top-5 z-[1001] p-2.5 bg-white border border-gray-300 rounded cursor-pointer transition-all duration-300 ease-in-out"
          :class="isDrawerOpen ? 'right-[420px]' : 'right-5'">
          {{ isDrawerOpen ? '→' : '←' }}
        </button>
        
        <!-- Chart drawer positioned relative to map -->
        <div 
          :style="{
            position: 'absolute',
            height: '50px',
            top: '10px',
            bottom: '10px',
            right: isDrawerOpen ? '0px' : '-100%',
            width: '66.666%',
            background: 'transparent',
            transition: 'right 0.3s ease',
            zIndex: 1000,
            padding: '60px 20px 20px 20px',
            boxSizing: 'border-box'
          }">
          <chart-container 
            :chartData="selectChartData" 
            :selectedLanduse="selectLanduse"
            :draggable="true"
            :zoomable="true"
            style="width: 100%; height: 200px;">
          </chart-container>
        </div>
      </div>

    </div>
  `,
};
```

## luto/tools/report/VUE_modules/views/Economics.js

```javascript
window.EconomicsView = {
  setup() {
    const { ref, onMounted, inject, computed, watch, nextTick } = Vue;

    // Data|Map service
    const chartRegister = window.DataService.chartCategories["Economics"];
    const mapRegister = window.MapService.mapCategories["Economics"];
    const loadScript = window.loadScript;

    // Global selection state
    const yearIndex = ref(0);
    const selectYear = ref(2020);
    const selectRegion = inject("globalSelectedRegion");

    // Available variables
    const availableYears = ref([]);
    const availableUnit = {
      Area: "Hectares",
      Economics: "AUD",
      GHG: "Mt CO2e",
      Water: "ML",
      Biodiversity: "Relative Percentage (Pre-1750 = 100%)",
    };

    // Available selections for Economics
    const availableCostRevenue = ["Cost", "Revenue"];
    const availableCategories = ["Ag", "Ag Mgt", "Non-Ag"];
    const availableAgMgt = ref([]);
    const availableWater = ref([]);
    const availableLanduse = ref([]);

    // Map selection state (Cost/Revenue only affects map, not chart)
    const selectCostRevenue = ref("Cost");
    const selectCategory = ref("");
    const selectAgMgt = ref("");
    const selectWater = ref("");
    const selectLanduse = ref("");

    // Previous selections memory
    const previousSelections = ref({
      "Ag": { water: "", landuse: "" },
      "Ag Mgt": { agMgt: "", water: "", landuse: "" },
      "Non-Ag": { landuse: "" }
    });

    // UI state
    const dataLoaded = ref(false);
    const isDrawerOpen = ref(false);
    const mapReady = computed(() => {
      if (!selectCategory.value || !selectCostRevenue.value) {
        return false;
      }
      if (selectCategory.value === "Non-Ag") {
        return selectLanduse.value && mapRegister[selectCostRevenue.value]?.[selectCategory.value]?.name && window[mapRegister[selectCostRevenue.value][selectCategory.value].name];
      }
      if (!selectWater.value || !selectLanduse.value) {
        return false;
      }
      if (selectCategory.value === "Ag Mgt" && !selectAgMgt.value) {
        return false;
      }
      const dataName = mapRegister[selectCostRevenue.value]?.[selectCategory.value]?.name;
      return dataName && window[dataName];
    });
    const chartReady = computed(() => {
      if (!selectCategory.value || !selectRegion.value) {
        return false;
      }
      if (selectCategory.value === "Non-Ag") {
        const dataName = chartRegister[selectCategory.value]?.name;
        return dataName && window[dataName] && window[dataName][selectRegion.value];
      }
      if (selectCategory.value === "Ag" || selectCategory.value === "Ag Mgt") {
        // Both Ag and Ag Mgt charts use aggregated data, don't need Water/Landuse/AgMgt selections
        const dataName = chartRegister[selectCategory.value]?.name;
        return dataName && window[dataName] && window[dataName][selectRegion.value];
      }
      const dataName = chartRegister[selectCategory.value]?.name;
      return dataName && window[dataName] && window[dataName][selectRegion.value];
    });

    // Reactive data
    const mapData = computed(() => window[mapRegister[selectCostRevenue.value][selectCategory.value]?.name]);
    const chartData = computed(() => window[chartRegister[selectCategory.value]?.name]?.[selectRegion.value]);
    const selectMapData = computed(() => {
      if (!mapReady.value) {
        return {};
      }
      if (selectCategory.value === "Ag") {
        return mapData.value?.[selectWater.value]?.[selectLanduse.value]?.[selectYear.value] || {};
      }
      else if (selectCategory.value === "Ag Mgt") {
        return mapData.value?.[selectAgMgt.value]?.[selectWater.value]?.[selectLanduse.value]?.[selectYear.value] || {};
      }
      else if (selectCategory.value === "Non-Ag") {
        return mapData.value?.[selectLanduse.value]?.[selectYear.value] || {};
      }
      return {};
    });
    const selectChartData = computed(() => {
      if (!chartReady.value) {
        return {};
      }
      let seriesData;
      // Chart always shows BOTH cost and revenue (ignores selectCostRevenue)
      if (selectCategory.value === "Ag") {
        // Economics_Ag chart structure is Region → "ALL" → "ALL" → [series] (aggregated, same as Am)
        seriesData = chartData.value?.["ALL"]?.["ALL"];
      }
      else if (selectCategory.value === "Ag Mgt") {
        // Economics_Am chart structure is Region → "ALL" → "ALL" → [series] (aggregated)
        seriesData = chartData.value?.["ALL"]?.["ALL"];
      } else if (selectCategory.value === "Non-Ag") {
        seriesData = chartData.value;
      }

      return {
        ...window["Chart_default_options"],
        chart: {
          height: 440,
        },
        yAxis: {
          title: {
            text: availableUnit["Economics"],
          },
        },
        series: seriesData || [],
        colors: window["Supporting_info"].colors,
      };
    });

    onMounted(async () => {
      await loadScript("./data/Supporting_info.js", "Supporting_info");
      await loadScript("./data/chart_option/Chart_default_options.js", "Chart_default_options");

      // Load data
      await loadScript(mapRegister["Cost"]["Ag"]["path"], mapRegister["Cost"]["Ag"]["name"]);
      await loadScript(mapRegister["Cost"]["Ag Mgt"]["path"], mapRegister["Cost"]["Ag Mgt"]["name"]);
      await loadScript(mapRegister["Cost"]["Non-Ag"]["path"], mapRegister["Cost"]["Non-Ag"]["name"]);
      await loadScript(mapRegister["Revenue"]["Ag"]["path"], mapRegister["Revenue"]["Ag"]["name"]);
      await loadScript(mapRegister["Revenue"]["Ag Mgt"]["path"], mapRegister["Revenue"]["Ag Mgt"]["name"]);
      await loadScript(mapRegister["Revenue"]["Non-Ag"]["path"], mapRegister["Revenue"]["Non-Ag"]["name"]);
      await loadScript(chartRegister["Ag"]["path"], chartRegister["Ag"]["name"]);
      await loadScript(chartRegister["Ag Mgt"]["path"], chartRegister["Ag Mgt"]["name"]);
      await loadScript(chartRegister["Non-Ag"]["path"], chartRegister["Non-Ag"]["name"]);

      // Initial selections
      availableYears.value = window.Supporting_info.years;
      selectCategory.value = availableCategories[0];

      await nextTick(() => {
        dataLoaded.value = true;
      });
    });

    // Watchers and methods
    const toggleDrawer = () => {
      isDrawerOpen.value = !isDrawerOpen.value;
    };

    watch(yearIndex, (newIndex) => {
      selectYear.value = availableYears.value[newIndex];
    });

    // Progressive selection chain watchers (replaced by combined watcher below)

    // Combined watcher for Cost/Revenue changes - directly updates options
    watch([selectCostRevenue, selectCategory], ([newCostRevenue, newCategory], [oldCostRevenue, oldCategory]) => {
      if (!newCategory) return;

      // Save previous selections before switching (only when category changes)
      if (oldCategory && oldCategory !== newCategory) {
        if (oldCategory === "Ag") {
          previousSelections.value["Ag"] = { water: selectWater.value, landuse: selectLanduse.value };
        } else if (oldCategory === "Ag Mgt") {
          previousSelections.value["Ag Mgt"] = { agMgt: selectAgMgt.value, water: selectWater.value, landuse: selectLanduse.value };
        } else if (oldCategory === "Non-Ag") {
          previousSelections.value["Non-Ag"] = { landuse: selectLanduse.value };
        }
      }
      
      if (newCategory === "Ag Mgt") {
        const currentMapData = window[mapRegister[newCostRevenue]["Ag Mgt"]["name"]];
        const newAvailableAgMgt = Object.keys(currentMapData || {});
        availableAgMgt.value = newAvailableAgMgt;
        
        // Restore previous AgMgt selection if valid, otherwise use first available
        const prevAgMgt = previousSelections.value["Ag Mgt"].agMgt;
        selectAgMgt.value = (prevAgMgt && newAvailableAgMgt.includes(prevAgMgt)) ? prevAgMgt : (newAvailableAgMgt[0] || '');
        
        if (selectAgMgt.value) {
          availableWater.value = Object.keys(currentMapData[selectAgMgt.value] || {});
          const prevWater = previousSelections.value["Ag Mgt"].water;
          selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || '');
          
          availableLanduse.value = Object.keys(currentMapData[selectAgMgt.value][selectWater.value] || {});
          const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
          selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
        }
      } else if (newCategory === "Ag") {
        const currentMapData = window[mapRegister[newCostRevenue]["Ag"]["name"]];
        availableWater.value = Object.keys(currentMapData || {});
        const prevWater = previousSelections.value["Ag"].water;
        selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || '');
        
        availableLanduse.value = Object.keys(currentMapData[selectWater.value] || {});
        const prevLanduse = previousSelections.value["Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
      } else if (newCategory === "Non-Ag") {
        const currentMapData = window[mapRegister[newCostRevenue]["Non-Ag"]["name"]];
        availableLanduse.value = Object.keys(currentMapData || {});
        const prevLanduse = previousSelections.value["Non-Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
      }
    }, { immediate: true });

    watch(selectAgMgt, (newAgMgt) => {
      // Save current agMgt selection
      if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].agMgt = newAgMgt;
        
        // Handle ALL downstream variables with cascading pattern
        const currentMapData = window[mapRegister[selectCostRevenue.value]["Ag Mgt"]["name"]];
        availableWater.value = Object.keys(currentMapData[newAgMgt] || {});
        const prevWater = previousSelections.value["Ag Mgt"].water;
        selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || '');
        
        availableLanduse.value = Object.keys(currentMapData[newAgMgt][selectWater.value] || {});
        const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
      }
    });

    watch(selectWater, (newWater) => {
      // Save current water selection
      if (selectCategory.value === "Ag") {
        previousSelections.value["Ag"].water = newWater;
      } else if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].water = newWater;
      }

      // Handle downstream variables
      if (selectCategory.value === "Ag") {
        const currentMapData = window[mapRegister[selectCostRevenue.value]["Ag"]["name"]];
        availableLanduse.value = Object.keys(currentMapData[newWater] || {});
        const prevLanduse = previousSelections.value["Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
      } else if (selectCategory.value === "Ag Mgt") {
        const currentMapData = window[mapRegister[selectCostRevenue.value]["Ag Mgt"]["name"]];
        availableLanduse.value = Object.keys(currentMapData[selectAgMgt.value][newWater] || {});
        const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
      }
    });

    watch(selectLanduse, (newLanduse) => {
      // Save current landuse selection
      if (selectCategory.value === "Ag") {
        previousSelections.value["Ag"].landuse = newLanduse;
      } else if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].landuse = newLanduse;
      } else if (selectCategory.value === "Non-Ag") {
        previousSelections.value["Non-Ag"].landuse = newLanduse;
      }
    });

    return {
      yearIndex,
      selectYear,
      selectRegion,

      availableYears,
      availableCostRevenue,
      availableCategories,
      availableAgMgt,
      availableWater,
      availableLanduse,

      selectCostRevenue,
      selectCategory,
      selectAgMgt,
      selectWater,
      selectLanduse,

      selectMapData,
      selectChartData,

      dataLoaded,
      isDrawerOpen,
      toggleDrawer,
    };
  },

  template: `
    <div class="relative w-full h-screen">

      <!-- Region selection dropdown -->
      <div class="absolute w-[262px] top-32 left-[20px] z-50 bg-white/70 rounded-lg shadow-lg max-w-xs z-[9999]">
        <filterable-dropdown></filterable-dropdown>
      </div>

      <!-- Year slider -->
      <div class="absolute top-[200px] left-[20px] z-[1001] w-[262px] bg-white/70 p-2 rounded-lg items-center">
        <p class="text-[0.8rem]">Year: <strong>{{ selectYear }}</strong></p>
        <el-slider
          v-if="availableYears && availableYears.length > 0"
          v-model="yearIndex"
          size="small"
          :show-tooltip="false"
          :min="0"
          :max="availableYears.length - 1"
          :step="1"
          :format-tooltip="index => availableYears[index]"
          :marks="availableYears.reduce((acc, year, index) => ({ ...acc, [index]: year }), {})"
          @input="(index) => { yearIndex = index; selectYear = availableYears[index]; }"
        />
      </div>

      <!-- Data selection controls container -->
      <div class="absolute top-[285px] left-[20px] w-[320px] z-[1001] flex flex-col space-y-3 bg-white/70 p-2 rounded-lg">

        <!-- Cost/Revenue buttons (always visible, affects MAP only) -->
        <div class="flex items-center">
          <div class="flex space-x-1">
            <span class="text-[0.8rem] mr-1 font-medium">Map Type:</span>
            <button v-for="(val, key) in availableCostRevenue" :key="key"
              @click="selectCostRevenue = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded"
              :class="{'bg-sky-500 text-white': selectCostRevenue === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Category buttons (always visible) -->
        <div class="flex items-center border-t border-white/10 pt-1">
          <div class="flex space-x-1">
            <span class="text-[0.8rem] mr-1 font-medium">Category:</span>
            <button v-for="(val, key) in availableCategories" :key="key"
              @click="selectCategory = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded"
              :class="{'bg-sky-500 text-white': selectCategory === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Ag Mgt options (only for Ag Mgt category) -->
        <div v-if="selectCategory === 'Ag Mgt'"
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="dataLoaded && availableAgMgt.length > 0" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Ag Mgt:</span>
            <button v-for="(val, key) in availableAgMgt" :key="key"
              @click="selectAgMgt = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectAgMgt === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Water options -->
        <div 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="selectCategory !== 'Non-Ag' && dataLoaded && availableWater.length > 0" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Water:</span>
            <button v-for="(val, key) in availableWater" :key="key"
              @click="selectWater = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectWater === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Landuse options -->
        <div 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="dataLoaded" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Landuse:</span>
            <button v-for="(val, key) in availableLanduse" :key="key"
              @click="selectLanduse = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectLanduse === val}">
              {{ val }}
            </button>
          </div>
        </div>
      </div>

      
      <!-- Map container with slide-out chart drawer -->
      <div style="position: relative; width: 100%; height: 100%; overflow: hidden;">

        <!-- Map component takes full space -->
        <regions-map 
          :mapData="selectMapData"
          style="width: 100%; height: 100%;">
        </regions-map>

        <!-- Drawer toggle button -->
        <button
          @click="toggleDrawer"
          class="absolute top-5 z-[1001] p-2.5 bg-white border border-gray-300 rounded cursor-pointer transition-all duration-300 ease-in-out"
          :class="isDrawerOpen ? 'right-[420px]' : 'right-5'">
          {{ isDrawerOpen ? '→' : '←' }}
        </button>
        
        <!-- Chart drawer positioned relative to map -->
        <div 
          :style="{
            position: 'absolute',
            height: '50px',
            top: '10px',
            bottom: '10px',
            right: isDrawerOpen ? '0px' : '-100%',
            width: '66.666%',
            background: 'transparent',
            transition: 'right 0.3s ease',
            zIndex: 1000,
            padding: '60px 20px 20px 20px',
            boxSizing: 'border-box'
          }">
          <chart-container 
            :chartData="selectChartData" 
            :selectedLanduse="selectLanduse"
            :draggable="true"
            :zoomable="true"
            style="width: 100%; height: 200px;">
          </chart-container>
        </div>
      </div>

    </div>
  `,
};
```

## luto/tools/report/VUE_modules/views/GHG.js

```javascript
window.GHGView = {
  setup() {
    const { ref, onMounted, inject, computed, watch, nextTick } = Vue;

    // Data|Map service
    const chartRegister = window.DataService.chartCategories["GHG"];
    const mapRegister = window.MapService.mapCategories["GHG"];
    const loadScript = window.loadScript;

    // Global selection state
    const yearIndex = ref(0);
    const selectYear = ref(2020);
    const selectRegion = inject("globalSelectedRegion");

    // Available variables
    const availableYears = ref([]);
    const availableUnit = {
      Area: "Hectares",
      Economics: "AUD",
      GHG: "Mt CO2e",
      Water: "ML",
      Biodiversity: "Relative Percentage (Pre-1750 = 100%)",
    };

    // Available selections
    const availableCategories = ["Ag", "Ag Mgt", "Non-Ag"];
    const availableAgMgt = ref([]);
    const availableWater = ref([]);
    const availableLanduse = ref([]);

    // Map selection state
    const selectCategory = ref("");
    const selectAgMgt = ref("");
    const selectWater = ref("");
    const selectLanduse = ref("");

    // Previous selections memory
    const previousSelections = ref({
      "Ag": { water: "", landuse: "" },
      "Ag Mgt": { agMgt: "", water: "", landuse: "" },
      "Non-Ag": { landuse: "" }
    });

    // UI state
    const dataLoaded = ref(false);
    const isDrawerOpen = ref(false);
    const mapReady = computed(() => {
      if (!selectCategory.value || !selectLanduse.value) {
        return false;
      }
      // Non-Ag doesn't require water selection
      if (selectCategory.value !== "Non-Ag" && !selectWater.value) {
        return false;
      }
      if (selectCategory.value === "Ag Mgt" && !selectAgMgt.value) {
        return false;
      }
      const dataName = mapRegister[selectCategory.value]?.["name"];
      return dataName && window[dataName];
    });
    const chartReady = computed(() => {
      if (!selectCategory.value || !selectRegion.value) {
        return false;
      }
      // GHG charts need water selection for Ag and Ag Mgt, but not landuse
      if ((selectCategory.value === "Ag" || selectCategory.value === "Ag Mgt") && !selectWater.value) {
        return false;
      }
      // GHG Ag Mgt charts need AgMgt selection
      if (selectCategory.value === "Ag Mgt" && !selectAgMgt.value) {
        return false;
      }
      const dataName = chartRegister[selectCategory.value]?.["name"];
      return dataName && window[dataName] && window[dataName][selectRegion.value];
    });

    // Reactive data
    const mapData = computed(() => window[mapRegister[selectCategory.value]["name"]]);
    const chartData = computed(() => window[chartRegister[selectCategory.value]["name"]][selectRegion.value]);
    const selectMapData = computed(() => {
      if (!mapReady.value) {
        return {};
      }
      if (selectCategory.value === "Ag") {
        return mapData.value[selectWater.value][selectLanduse.value][selectYear.value];
      }
      else if (selectCategory.value === "Ag Mgt") {
        return mapData.value?.[selectAgMgt.value]?.[selectWater.value]?.[selectLanduse.value]?.[selectYear.value];
      }
      else if (selectCategory.value === "Non-Ag") {
        return mapData.value[selectLanduse.value][selectYear.value];
      }
    });
    const selectChartData = computed(() => {
      if (!chartReady.value) {
        return {};
      }
      let seriesData;
      if (selectCategory.value === "Ag") {
        // GHG_Ag structure: Region → "ALL" → Water → [series]
        seriesData = chartData.value["ALL"]?.[selectWater.value];
      }
      else if (selectCategory.value === "Ag Mgt") {
        // GHG_Am structure: Region → AgMgt → Water → [series]
        seriesData = chartData.value[selectAgMgt.value]?.[selectWater.value];
      } else if (selectCategory.value === "Non-Ag") {
        // GHG_NonAg structure: Region → [series]
        seriesData = chartData.value;
      }

      return {
        ...window["Chart_default_options"],
        chart: {
          height: 440,
        },
        yAxis: {
          title: {
            text: availableUnit["GHG"],
          },
        },
        series: seriesData || [],
        colors: window["Supporting_info"].colors,
      };
    });

    onMounted(async () => {
      await loadScript("./data/Supporting_info.js", "Supporting_info");
      await loadScript("./data/chart_option/Chart_default_options.js", "Chart_default_options");

      // Load data
      await loadScript(mapRegister["Ag"]["path"], mapRegister["Ag"]["name"]);
      await loadScript(mapRegister["Ag Mgt"]["path"], mapRegister["Ag Mgt"]["name"]);
      await loadScript(mapRegister["Non-Ag"]["path"], mapRegister["Non-Ag"]["name"]);
      await loadScript(chartRegister["Ag"]["path"], chartRegister["Ag"]["name"]);
      await loadScript(chartRegister["Ag Mgt"]["path"], chartRegister["Ag Mgt"]["name"]);
      await loadScript(chartRegister["Non-Ag"]["path"], chartRegister["Non-Ag"]["name"]);

      // Initial selections
      availableYears.value = window.Supporting_info.years;
      selectCategory.value = availableCategories[0];

      await nextTick(() => {
        dataLoaded.value = true;
      });
    });

    // Watchers and methods
    const toggleDrawer = () => {
      isDrawerOpen.value = !isDrawerOpen.value;
    };

    watch(yearIndex, (newIndex) => {
      selectYear.value = availableYears.value[newIndex];
    });

    // Progressive selection chain watchers
    watch(selectCategory, (newCategory, oldCategory) => {
      // Save previous selections before switching
      if (oldCategory) {
        if (oldCategory === "Ag") {
          previousSelections.value["Ag"] = { water: selectWater.value, landuse: selectLanduse.value };
        } else if (oldCategory === "Ag Mgt") {
          previousSelections.value["Ag Mgt"] = { agMgt: selectAgMgt.value, water: selectWater.value, landuse: selectLanduse.value };
        } else if (oldCategory === "Non-Ag") {
          previousSelections.value["Non-Ag"] = { landuse: selectLanduse.value };
        }
      }

      // Reset AgMgt array when not in Ag Mgt category
      if (newCategory !== "Ag Mgt") {
        availableAgMgt.value = [];
        selectAgMgt.value = "";
      }

      // Handle ALL downstream variables with cascading pattern
      if (newCategory === "Ag Mgt") {
        // Get AgMgt options from chart data for GHG Am
        const chartDataName = chartRegister["Ag Mgt"]?.["name"];
        if (window[chartDataName] && selectRegion.value) {
          availableAgMgt.value = Object.keys(window[chartDataName][selectRegion.value] || {});
          const prevAgMgt = previousSelections.value["Ag Mgt"].agMgt;
          selectAgMgt.value = (prevAgMgt && availableAgMgt.value.includes(prevAgMgt)) ? prevAgMgt : (availableAgMgt.value[0] || '');
          // Get water options from chart data
          if (selectAgMgt.value) {
            availableWater.value = Object.keys(window[chartDataName][selectRegion.value][selectAgMgt.value] || {});
            const prevWater = previousSelections.value["Ag Mgt"].water;
            selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || 'ALL');
          }
        }
        // Map data for landuse - need to go through water level first
        if (selectAgMgt.value && selectWater.value) {
          availableLanduse.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][selectAgMgt.value]?.[selectWater.value] || {});
          const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
          selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
        }
      } else if (newCategory === "Ag") {
        // GHG Ag chart data: Region → "ALL" → Water, so get water options from chart data
        const chartDataName = chartRegister["Ag"]?.["name"];
        if (window[chartDataName] && selectRegion.value) {
          availableWater.value = Object.keys(window[chartDataName][selectRegion.value]["ALL"] || {});
          const prevWater = previousSelections.value["Ag"].water;
          selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || 'ALL');
        }
        // Map data still follows standard pattern
        availableLanduse.value = Object.keys(window[mapRegister["Ag"]["name"]][selectWater.value] || {});
        const prevLanduse = previousSelections.value["Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || 'ALL');
      } else if (newCategory === "Non-Ag") {
        availableLanduse.value = Object.keys(window[mapRegister["Non-Ag"]["name"]] || {});
        const prevLanduse = previousSelections.value["Non-Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || 'ALL');
        // Clear water for Non-Ag since it doesn't use water
        availableWater.value = [];
        selectWater.value = '';
      }
    });

    watch(selectAgMgt, (newAgMgt) => {
      // Save current agMgt selection
      if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].agMgt = newAgMgt;
        
        // Handle ALL downstream variables with cascading pattern
        // Get water options from chart data for GHG Am
        const chartDataName = chartRegister["Ag Mgt"]?.["name"];
        if (window[chartDataName] && selectRegion.value && newAgMgt) {
          availableWater.value = Object.keys(window[chartDataName][selectRegion.value][newAgMgt] || {});
          const prevWater = previousSelections.value["Ag Mgt"].water;
          selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || 'ALL');
        }
        // Map data follows AgMgt → Water → Landuse pattern
        if (selectWater.value) {
          availableLanduse.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][newAgMgt]?.[selectWater.value] || {});
          const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
          selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
        }
      }
    });

    watch(selectWater, (newWater) => {
      // Save current water selection
      if (selectCategory.value === "Ag") {
        previousSelections.value["Ag"].water = newWater;
      } else if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].water = newWater;
      }

      // Handle ALL downstream variables
      if (selectCategory.value === "Ag") {
        availableLanduse.value = Object.keys(window[mapRegister["Ag"]["name"]][newWater] || {});
        const prevLanduse = previousSelections.value["Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || 'ALL');
      } else if (selectCategory.value === "Ag Mgt") {
        // For Ag Mgt, update landuse options when water changes
        if (selectAgMgt.value) {
          availableLanduse.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][selectAgMgt.value]?.[newWater] || {});
          const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
          selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
        }
      }
    });

    watch(selectLanduse, (newLanduse) => {
      // Save current landuse selection
      if (selectCategory.value === "Ag") {
        previousSelections.value["Ag"].landuse = newLanduse;
      } else if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].landuse = newLanduse;
      } else if (selectCategory.value === "Non-Ag") {
        previousSelections.value["Non-Ag"].landuse = newLanduse;
      }
    });

    return {
      yearIndex,
      selectYear,
      selectRegion,

      availableYears,
      availableCategories,
      availableAgMgt,
      availableWater,
      availableLanduse,

      selectCategory,
      selectAgMgt,
      selectWater,
      selectLanduse,

      selectMapData,
      selectChartData,

      dataLoaded,
      isDrawerOpen,
      toggleDrawer,
    };
  },
  template: `
    <div class="relative w-full h-screen">

      <!-- Region selection dropdown -->
      <div class="absolute w-[262px] top-32 left-[20px] z-50 bg-white/70 rounded-lg shadow-lg max-w-xs z-[9999]">
        <filterable-dropdown></filterable-dropdown>
      </div>

      <!-- Year slider -->
      <div class="absolute top-[200px] left-[20px] z-[1001] w-[262px] bg-white/70 p-2 rounded-lg items-center">
        <p class="text-[0.8rem]">Year: <strong>{{ selectYear }}</strong></p>
        <el-slider
          v-if="availableYears && availableYears.length > 0"
          v-model="yearIndex"
          size="small"
          :show-tooltip="false"
          :min="0"
          :max="availableYears.length - 1"
          :step="1"
          :format-tooltip="index => availableYears[index]"
          :marks="availableYears.reduce((acc, year, index) => ({ ...acc, [index]: year }), {})"
          @input="(index) => { yearIndex = index; selectYear = availableYears[index]; }"
        />
      </div>

      <!-- Data selection controls container -->
      <div class="absolute top-[285px] left-[20px] w-[320px] z-[1001] flex flex-col space-y-3 bg-white/70 p-2 rounded-lg">

        <!-- Category buttons (always visible) -->
        <div class="flex items-center">
          <div class="flex space-x-1">
            <span class="text-[0.8rem] mr-1 font-medium">Category:</span>
            <button v-for="(val, key) in availableCategories" :key="key"
              @click="selectCategory = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded"
              :class="{'bg-sky-500 text-white': selectCategory === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Ag Mgt options (only for Ag Mgt category) -->
        <div 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="dataLoaded && selectCategory === 'Ag Mgt' && availableAgMgt.length > 0" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Ag Mgt:</span>
            <button v-for="(val, key) in availableAgMgt" :key="key"
              @click="selectAgMgt = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectAgMgt === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Water options -->
        <div 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="selectCategory !== 'Non-Ag' && dataLoaded && availableWater.length > 0" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Water:</span>
            <button v-for="(val, key) in availableWater" :key="key"
              @click="selectWater = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectWater === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Landuse options -->
        <div 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="dataLoaded" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Landuse:</span>
            <button v-for="(val, key) in availableLanduse" :key="key"
              @click="selectLanduse = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectLanduse === val}">
              {{ val }}
            </button>
          </div>
        </div>
      </div>

      <!-- Map container with slide-out chart drawer -->
      <div style="position: relative; width: 100%; height: 100%; overflow: hidden;">

        <!-- Map component takes full space -->
        <regions-map 
          :mapData="selectMapData"
          style="width: 100%; height: 100%;">
        </regions-map>

        <!-- Drawer toggle button -->
        <button
          @click="toggleDrawer"
          class="absolute top-5 z-[1001] p-2.5 bg-white border border-gray-300 rounded cursor-pointer transition-all duration-300 ease-in-out"
          :class="isDrawerOpen ? 'right-[420px]' : 'right-5'">
          {{ isDrawerOpen ? '→' : '←' }}
        </button>
        
        <!-- Chart drawer positioned relative to map -->
        <div 
          :style="{
            position: 'absolute',
            height: '50px',
            top: '10px',
            bottom: '10px',
            right: isDrawerOpen ? '0px' : '-100%',
            width: '66.666%',
            background: 'transparent',
            transition: 'right 0.3s ease',
            zIndex: 1000,
            padding: '60px 20px 20px 20px',
            boxSizing: 'border-box'
          }">
          <chart-container 
            :chartData="selectChartData" 
            :selectedLanduse="selectLanduse"
            :draggable="true"
            :zoomable="true"
            style="width: 100%; height: 200px;">
          </chart-container>
        </div>
      </div>

    </div>
  `,
};
```

## luto/tools/report/VUE_modules/views/Home.js

```javascript
window.HomeView = {

  setup() {

    const { ref, onMounted, watch, computed, inject, nextTick } = Vue;

    // Data service
    const chartRegister = window.DataService.chartCategories;   // DataService has been registered in index.html      [DataService.js]
    const loadScript = window.loadScript;                       // DataConstructor has been registered in index.html  [helpers.js]

    // Global variables
    const selectRegion = inject('globalSelectedRegion');
    const ChartData = ref({});
    const rankingData = ref({});
    const colorsRanking = ref({});

    // Available selections
    const availableYears = ref([]);
    const availableChartCategories = ref([]);
    const availableChartSubCategories = ref([]);
    const availableUnit = {
      'Area': 'Hectares',
      'Economics': 'AUD',
      'GHG': 'Mt CO2e',
      'Water': 'ML',
      'Biodiversity': 'Relative Percentage (Pre-1750 = 100%)',
    };
    const RankSubcategoriesRename = {
      'Agricultural Landuse': 'Ag',
      'Agricultural Management': 'Ag Mgt',
      'Non-Agricultural Landuse': 'Non-Ag',
      'Non-Agricultural land-use': 'Non-Ag',
    };
    const availableRankSubcategories = ref([]);

    // Default selections
    const yearIndex = ref(0);
    const selectYear = ref(null);
    const selectChartCategory = ref('');
    const selectChartSubCategory = ref('');
    const selectRankingSubCategory = ref('');
    const selectRankingColors = ref({});


    //  Reactive data
    const selectChartData = computed(() => {
      if (window['Chart_default_options'] && selectChartCategory.value && selectChartSubCategory.value) {
        return {
          ...window['Chart_default_options'],
          chart: {
            height: 440,
          },
          yAxis: {
            title: {
              text: availableUnit[selectChartCategory.value]
            }
          },
          series: ChartData.value[selectChartCategory.value][selectChartSubCategory.value][selectRegion.value],
          colors: window['Supporting_info'].colors,
        };
      }
    });


    const runScenario = computed(() => {
      return !window.Supporting_info ? {} : {
        'SSP': window.Supporting_info.model_run_settings.filter(item => item.parameter === "SSP")[0]['val'],
        'GHG': window.Supporting_info.model_run_settings.filter(item => item.parameter === "GHG_EMISSIONS_LIMITS")[0]['val'],
        'BIO_CUT': window.Supporting_info.model_run_settings.filter(item => item.parameter === "GBF2_PRIORITY_DEGRADED_AREAS_PERCENTAGE_CUT")[0]['val'],
        'BIO_GBF2': window.Supporting_info.model_run_settings.filter(item => item.parameter === "BIODIVERSITY_TARGET_GBF_2")[0]['val'],
        'BIO_GBF3': window.Supporting_info.model_run_settings.filter(item => item.parameter === "BIODIVERSITY_TARGET_GBF_3")[0]['val'],
        'BIO_GBF4_SNES': window.Supporting_info.model_run_settings.filter(item => item.parameter === "BIODIVERSITY_TARGET_GBF_4_SNES")[0]['val'],
        'BIO_GBF4_ECNES': window.Supporting_info.model_run_settings.filter(item => item.parameter === "BIODIVERSITY_TARGET_GBF_4_ECNES")[0]['val'],
        'BIODIVERSITY_TARGET_GBF_8': window.Supporting_info.model_run_settings.filter(item => item.parameter === "BIODIVERSITY_TARGET_GBF_8")[0]['val'],
      };
    });


    // Process flag
    const dataLoaded = ref(false);


    onMounted(async () => {

      // Load required data
      await loadScript("./data/Supporting_info.js", 'Supporting_info');
      await loadScript("./data/chart_option/Chart_default_options.js", 'Chart_default_options');
      await loadScript("./data/geo/NRM_AUS.js", 'NRM_AUS');

      // Overview chart data
      const chartOverview_area = chartRegister['Area']['overview'];
      const chartOverview_economics = chartRegister['Economics']['overview'];
      const chartOverview_economics_ag = chartRegister['Economics']['Ag'];
      const chartOverview_economics_agMgt = chartRegister['Economics']['Ag Mgt'];
      const chartOverview_economics_Nonag = chartRegister['Economics']['Non-Ag'];
      const chartOverview_ghg = chartRegister['GHG']['overview'];
      const chartOverview_ghg_ag = chartRegister['GHG']['Ag'];
      const chartOverview_ghg_agMgt = chartRegister['GHG']['Ag Mgt'];
      const chartOverview_ghg_Nonag = chartRegister['GHG']['Non-Ag'];
      const chartOverview_water = chartRegister['Water']['NRM']['overview'];
      const chartOverview_bio_GBF2 = chartRegister['Biodiversity']['GBF2']['overview'];
      const rankingArea = chartRegister['Area']['ranking'];
      const rankingEconomics = chartRegister['Economics']['ranking'];
      const rankingGHG = chartRegister['GHG']['ranking'];
      const rankingWater = chartRegister['Water']['NRM']['ranking'];
      const rankingBiodiversity = chartRegister['Biodiversity']['ranking'];

      await loadScript(chartOverview_area['Source']['path'], chartOverview_area['Source']['name']);
      await loadScript(chartOverview_area['Category']['path'], chartOverview_area['Category']['name']);
      await loadScript(chartOverview_area['Land-use']['path'], chartOverview_area['Land-use']['name']);
      await loadScript(chartOverview_economics['sum']['path'], chartOverview_economics['sum']['name']);
      await loadScript(chartOverview_economics_ag['path'], chartOverview_economics_ag['name']);
      await loadScript(chartOverview_economics_agMgt['path'], chartOverview_economics_agMgt['name']);
      await loadScript(chartOverview_economics_Nonag['path'], chartOverview_economics_Nonag['name']);
      await loadScript(chartOverview_ghg['path'], chartOverview_ghg['name']);
      await loadScript(chartOverview_ghg_ag['path'], chartOverview_ghg_ag['name']);
      await loadScript(chartOverview_ghg_agMgt['path'], chartOverview_ghg_agMgt['name']);
      await loadScript(chartOverview_ghg_Nonag['path'], chartOverview_ghg_Nonag['name']);
      await loadScript(chartOverview_water['Type']['path'], chartOverview_water['Type']['name']);
      await loadScript(chartOverview_bio_GBF2['path'], chartOverview_bio_GBF2['name']);
      await loadScript(rankingArea['path'], rankingArea['name']);
      await loadScript(rankingEconomics['path'], rankingEconomics['name']);
      await loadScript(rankingGHG['path'], rankingGHG['name']);
      await loadScript(rankingWater['path'], rankingWater['name']);
      await loadScript(rankingBiodiversity['path'], rankingBiodiversity['name']);


      ChartData.value = {
        'Area': {
          'Source': window[chartOverview_area['Source']['name']],
          'Category': window[chartOverview_area['Category']['name']],
          'Land-use': window[chartOverview_area['Land-use']['name']],
        },
        'Economics': {
          'Overview': window[chartOverview_economics['sum']['name']],
          'Ag': window[chartOverview_economics_ag['name']],
          'Ag Mgt': window[chartOverview_economics_agMgt['name']],
          'Non-Ag': window[chartOverview_economics_Nonag['name']],
        },
        'GHG': {
          'Overview': window[chartOverview_ghg['name']],
          'Ag': window[chartOverview_ghg_ag['name']],
          'Ag Mgt': window[chartOverview_ghg_agMgt['name']],
          'Non-Ag': window[chartOverview_ghg_Nonag['name']],
        },
        'Water': {
          'Type': window[chartOverview_water['Type']['name']],
        },
        'Biodiversity': {
          'GBF2': window[chartOverview_bio_GBF2['name']],
        },
      };

      rankingData.value = {
        'Area': window[rankingArea['name']],
        'Economics': window[rankingEconomics['name']],
        'GHG': window[rankingGHG['name']],
        'Water': window[rankingWater['name']],
        'Biodiversity': window[rankingBiodiversity['name']],
      };



      //  Set initial values AFTER dataLoaded = true
      availableYears.value = window['Supporting_info']['years'];
      selectYear.value = availableYears.value[0];

      availableChartCategories.value = Object.keys(ChartData.value);
      selectChartCategory.value = availableChartCategories.value[0];

      selectChartSubCategory.value = Object.keys(ChartData.value[selectChartCategory.value])[0];
      selectRankingSubCategory.value = Object.keys(rankingData.value[selectChartCategory.value][selectRegion.value])[0];
      colorsRanking.value = window.Supporting_info.colors_ranking;

      await nextTick(() => {
        dataLoaded.value = true;
      });


    });

    watch(yearIndex, (newIndex) => {
      selectYear.value = availableYears.value[newIndex];
    });

    watch(selectChartCategory, (newCategory) => {
      availableChartSubCategories.value = Object.keys(ChartData.value[selectChartCategory.value])
      availableRankSubcategories.value = Object.keys(rankingData.value[selectChartCategory.value][selectRegion.value]).filter(key => key !== "Total");
      selectChartSubCategory.value = availableChartSubCategories.value[0];
      selectRankingSubCategory.value = availableRankSubcategories.value[0];
    });

    watch([selectYear, selectRankingSubCategory], (newValues, oldValues) => {
      const [newYear, newSubCategory] = newValues;
      selectRankingColors.value = Object.fromEntries(
        Object.entries(rankingData.value[selectChartCategory.value] || {}).map(([region, values]) => [
          region,
          values[newSubCategory]?.['color']?.[newYear] || {}
        ])
      );
    });

    return {
      yearIndex,
      runScenario,
      dataLoaded,

      ChartData,
      rankingData,
      RankSubcategoriesRename,
      colorsRanking,

      availableYears,
      availableChartCategories,
      availableChartSubCategories,
      availableRankSubcategories,

      selectYear,
      selectRegion,
      selectChartCategory,
      selectChartSubCategory,
      selectRankingSubCategory,
      selectChartData,
      selectRankingColors,
    };
  },

  // This template is a fallback that will be replaced by the loaded template
  template: `
    <div v-if="dataLoaded">

      <div class="flex flex-col">

        <!-- Rank cards -->
        <p class="text-[#505051] font-bold p-1 pt-8"> SSP - {{ runScenario.SSP }} | GHG - {{ runScenario.GHG }} | Biodiversity - {{ runScenario.BIO_GBF2 }}</p>
        <div class="mb-4 mr-4">
          <ranking-cards 
            :rankingData="rankingData"
            :selectRegion="selectRegion"
            :selectYear="selectYear">
          </ranking-cards>
        </div>


        <!-- Title for map and chart -->
        <div class="flex items-center justify-between">
          <p class="text-[#505051] w-[500px] text font-bold p-1 pt-8">Map and Statistics</p>
          <p class="flex-1 text-[#505051] font-bold ml-4 p-1 pt-8">{{ selectChartCategory }} overview for {{ selectRegion }}</p>
        </div>

        <!-- Container for Map and Chart -->
        <div class="flex mr-4 gap-4 mb-4 flex-row">


          <!-- Map, chart buttons, and year scroll -->
          <div class="flex flex-col rounded-[10px] bg-white shadow-md w-[500px] h-[500px] relative">

            <!-- Chart Primary Category Buttons -->
            <div class="flex items-center justify-between w-full">
              <p class="text-[0.8rem] ml-2">Region: <strong>{{ selectRegion }}</strong></p>
              <div class="flex items-center space-x-1 justify-end p-2">
                <button v-for="(data, key) in availableChartCategories" :key="key"
                  @click="selectChartCategory = data"
                  class="bg-[#e8eaed] text-[#1f1f1f] text-[0.8rem] px-1 py-1 rounded"
                  :class="{'bg-sky-500 text-white': selectChartCategory === data}">
                  {{ data }}
                </button>
              </div>
            </div>

            <!-- Horizontal Divider -->
            <hr class="border-gray-300 z-[100]">

            <!-- Ranking Subcategory Buttons -->
            <div class="flex items-center space-x-1 justify-end absolute top-[55px] left-[220px] z-[100]">
              <button v-for="(data, key) in availableRankSubcategories" :key="key"
                @click="selectRankingSubCategory = data"
                class="bg-[#e8eaed] text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded"
                :class="{'bg-sky-500 text-white': selectRankingSubCategory === data}">
                {{ RankSubcategoriesRename[data] || data }}
              </button>
            </div>

            <!-- Year scroll -->
            <div class="flex flex-col absolute top-[50px] left-[10px] w-[200px] z-[100]">
              <p class="text-[0.8rem]">Year: <strong>{{ selectYear }}</strong></p>
              <el-slider
                v-if="availableYears.length > 0"
                class="flex-1 max-w-[150px] pt-2 pl-2"
                v-model="yearIndex"
                size="small"
                :show-tooltip="false"
                :min="0"
                :max="availableYears.length - 1"
                :step="1"
                :format-tooltip="index => availableYears[index]"
                :marks="availableYears.reduce((acc, year, index) => ({ ...acc, [index]: year }), {})"
                @input="(index) => { yearIndex = index; }"
              />
            </div>

            <!-- Map -->
            <map-geojson 
              class="absolute top-[50px] left-0 w-full z-[10]"
              :height="'430px'"
              :selectRankingColors="selectRankingColors">
            </map-geojson>

            <!-- Legend -->
            <div v-if="colorsRanking" class="absolute bottom-[20px] left-[35px] z-[100]">
              <div class="font-bold text-sm mb-2 text-gray-600">Ranking</div>
              <div class="flex flex-row items-center">
                <div v-for="(color, label) in colorsRanking" :key="label" class="flex items-center mr-4 mb-1">
                    <span class="inline-block w-[12px] h-[12px] mr-[3px]" :style="{ backgroundColor: color }"></span>
                    <span class="text-sm text-gray-600">{{ label }}</span>
                </div>
              </div>
            </div>

          </div>


          <div class="relative flex flex-1 rounded-[10px] bg-white shadow-md h-[500px]">

            <!-- Chart subcategory buttons -->
            <div class="absolute flex flex-row space-x-1 mr-4 top-[9px] left-[10px] z-10">
              <button v-for="cat in availableChartSubCategories" :key="cat"
                @click="selectChartSubCategory = cat"
                class="bg-[#e8eaed] text-[#1f1f1f] text-[0.8rem] px-1 py-1 rounded"
                :class="{'bg-sky-500 text-white': selectChartSubCategory === cat}">
                {{ cat }}
              </button>
            </div>

            <chart-container
              class="w-full h-full pt-[50px]"
              :chartData="selectChartData">
            </chart-container>

          </div>


        </div>

        
      </div>
    </div>
  `,
};
```

## luto/tools/report/VUE_modules/views/Map.js

```javascript
window['MapView'] = {
    setup() {
        const { inject, ref, watch, onMounted, computed, nextTick } = Vue;

        // Data|Map service
        const mapRegister = window.MapService.mapCategories["Dvar"];        // MapService was registered in the index.html        [MapService.js]
        const loadScript = window.loadScript;                               // DataConstructor has been registered in index.html  [helpers.js]

        // Global selection state
        const yearIndex = ref(0);
        const selectYear = ref(2020);
        const selectRegion = inject("globalSelectedRegion");

        // Available variables
        const availableYears = ref([]);

        // Available selections
        const availableCategories = ["Land-use", "Water-supply", "Ag", "Ag Mgt", "Non-Ag"];
        const availableLanduse = ref([]);

        // Selection state
        const selectCategory = ref("");
        const selectLanduse = ref("");

        // Previous selections memory
        const previousSelections = ref({
            "Land-use": { landuse: "" },
            "Water-supply": { landuse: "" },
            "Ag": { landuse: "" },
            "Ag Mgt": { landuse: "" },
            "Non-Ag": { landuse: "" }
        });

        // UI state
        const dataLoaded = ref(false);
        const mapReady = computed(() => {
            if (!selectCategory.value || !selectLanduse.value) {
                return false;
            }
            return dvarMaps.value && dvarMaps.value[selectCategory.value];
        });

        // Reactive data
        const dvarMaps = ref({});
        const selectMapData = computed(() => {
            if (!mapReady.value) {
                return {};
            }
            return dvarMaps.value[selectCategory.value][selectLanduse.value][selectYear.value] || {};
        });

        // Legend data
        const selectLegend = computed(() => {
            if (!mapReady.value) {
                return {};
            }
            
            // Check if the currently selected map object has a legend
            const currentMapData = dvarMaps.value[selectCategory.value][selectLanduse.value][selectYear.value];
            
            if (currentMapData && currentMapData.legend) {
                return currentMapData.legend;
            }
            
            // No legend available for this map object
            return {};
        });

        onMounted(async () => {
            await loadScript("./data/Supporting_info.js", "Supporting_info");
            await loadScript(mapRegister["Ag"]['path'], mapRegister["Ag"]['name']);
            await loadScript(mapRegister["Ag Mgt"]['path'], mapRegister["Ag Mgt"]['name']);
            await loadScript(mapRegister["Non-Ag"]['path'], mapRegister["Non-Ag"]['name']);
            await loadScript(mapRegister["Mosaic"]['path'], mapRegister["Mosaic"]['name']);

            dvarMaps.value = {
                'Land-use': { 'Land-use': window[mapRegister["Mosaic"]['name']]['Land-use'] },
                'Water-supply': { 'Water-supply': window[mapRegister["Mosaic"]['name']]['Water-supply'] },
                'Ag': {
                    'ALL': window[mapRegister["Mosaic"]['name']]['Agricultural Land-use'],
                    ...window[mapRegister["Ag"]['name']]
                },
                'Ag Mgt': {
                    'ALL': window[mapRegister["Mosaic"]['name']]['Agricultural Management'],
                    ...window[mapRegister["Ag Mgt"]['name']]
                },
                'Non-Ag': {
                    'ALL': window[mapRegister["Mosaic"]['name']]['Non-agricultural Land-use'],
                    ...window[mapRegister["Non-Ag"]['name']]
                }
            };

            // Initial selections
            availableYears.value = window.Supporting_info.years;
            selectCategory.value = availableCategories[0];

            await nextTick(() => {
                dataLoaded.value = true;
            });
        });

        // Watchers
        watch(yearIndex, (newIndex) => {
            selectYear.value = availableYears.value[newIndex];
        });

        // Progressive selection watcher
        watch(selectCategory, (newCategory, oldCategory) => {
            // Save previous selections before switching
            if (oldCategory) {
                previousSelections.value[oldCategory] = { landuse: selectLanduse.value };
            }

            if (newCategory && dvarMaps.value[newCategory]) {
                availableLanduse.value = Object.keys(dvarMaps.value[newCategory] || {});
                const prevLanduse = previousSelections.value[newCategory].landuse;
                selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
            }
        });

        watch(selectLanduse, (newLanduse) => {
            // Save current landuse selection
            if (selectCategory.value) {
                previousSelections.value[selectCategory.value].landuse = newLanduse;
            }
        });

        return {
            yearIndex,
            selectYear,
            selectRegion,

            availableYears,
            availableCategories,
            availableLanduse,

            selectCategory,
            selectLanduse,

            selectMapData,
            selectLegend,

            dataLoaded,
            mapReady,
        };
    },
    template: `
    <div class="relative w-full h-screen">

        <!-- Region selection dropdown -->
        <div class="absolute w-[262px] top-32 left-[20px] z-50 bg-white/70 rounded-lg shadow-lg max-w-xs z-[9999]">
            <filterable-dropdown></filterable-dropdown>
        </div>

        <!-- Year slider -->
        <div class="absolute top-[200px] left-[20px] z-[1001] w-[262px] bg-white/70 p-2 rounded-lg items-center">
            <p class="text-[0.8rem]">Year: <strong>{{ selectYear }}</strong></p>
            <el-slider
                v-if="availableYears && availableYears.length > 0"
                v-model="yearIndex"
                size="small"
                :show-tooltip="false"
                :min="0"
                :max="availableYears.length - 1"
                :step="1"
                :format-tooltip="index => availableYears[index]"
                :marks="availableYears.reduce((acc, year, index) => ({ ...acc, [index]: year }), {})"
                @input="(index) => { yearIndex = index; selectYear = availableYears[index]; }"
            />
        </div>

        <!-- Data selection controls container -->
        <div class="absolute top-[285px] left-[20px] w-[320px] z-[1001] flex flex-col space-y-3 bg-white/70 p-2 rounded-lg">

            <!-- Category buttons -->
            <div class="flex items-center">
                <div class="flex space-x-1">
                    <span class="text-[0.8rem] mr-1 font-medium">Category:</span>
                    <button v-for="(val, key) in availableCategories" :key="key"
                        @click="selectCategory = val"
                        class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded"
                        :class="{'bg-sky-500 text-white': selectCategory === val}">
                        {{ val }}
                    </button>
                </div>
            </div>

            <!-- Landuse options -->
            <div class="flex items-start border-t border-white/10 pt-1">
                <div v-if="dataLoaded && availableLanduse.length > 0" class="flex flex-wrap gap-1 max-w-[300px]">
                    <span class="text-[0.8rem] mr-1 font-medium">{{ selectCategory === 'Ag Mgt' ? 'Ag Mgt' : 'Landuse' }}:</span>
                    <button v-for="(val, key) in availableLanduse" :key="key"
                        @click="selectLanduse = val"
                        class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
                        :class="{'bg-sky-500 text-white': selectLanduse === val}">
                        {{ val }}
                    </button>
                </div>
            </div>
        </div>

        <!-- Map container -->
        <regions-map 
            :mapData="selectMapData"
            style="width: 100%; height: 100%;">
        </regions-map>

        <!-- Legend -->
        <div v-if="selectLegend && Object.keys(selectLegend).length > 0" class="absolute top-[20px] right-[20px] z-[1001] bg-white/70 p-3 rounded-lg max-w-[250px]">
            <div class="font-bold text-sm mb-2 text-gray-600">{{ selectCategory }}</div>
            <div class="flex flex-col space-y-1">
                <div v-for="(color, label) in selectLegend" :key="label" class="flex items-center">
                    <span class="inline-block w-[12px] h-[12px] mr-[6px]" :style="{ backgroundColor: color }"></span>
                    <span class="text-xs text-gray-600">{{ label }}</span>
                </div>
            </div>
        </div>

    </div>
    `
};
```

## luto/tools/report/VUE_modules/views/NotFound.js

```javascript
window.NotFound = {
  setup() {
    return {};
  },
  template: `
    <div class="flex flex-col items-center justify-center h-screen">
      <h1 class="text-2xl font-bold mb-4 text-center">404 Not Found</h1>
      <p class="text-center">The page you are looking for does not exist.</p>
      <p class="mt-6">
        <router-link to="/">
          <button class="px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600 transition cursor-pointer">
            Go back to Home
          </button>
        </router-link>
      </p>
    </div>
  `,
};
```

## luto/tools/report/VUE_modules/views/Production.js

```javascript
window.ProductionView = {
  setup() {
    const { ref, onMounted, inject, computed, watch, nextTick } = Vue;

    // Data|Map service
    const chartRegister = window.DataService.chartCategories["Production"];
    const mapRegister = window.MapService.mapCategories["Production"];
    const loadScript = window.loadScript;

    // Global selection state
    const yearIndex = ref(0);
    const selectYear = ref(2020);
    const selectRegion = inject("globalSelectedRegion");

    // Available variables
    const availableYears = ref([]);
    const availableUnit = {
      Area: "Hectares",
      Economics: "AUD",
      GHG: "Mt CO2e",
      Water: "ML",
      Production: "Tonnes",
      Biodiversity: "Relative Percentage (Pre-1750 = 100%)",
    };

    // Available selections - Production now has Area-like structure
    const availableCategories = ["Ag", "Ag Mgt", "Non-Ag"];
    const availableAgMgt = ref([]);
    const availableWater = ref([]);
    const availableLanduse = ref([]);

    // Map selection state - now like Area
    const selectCategory = ref("");
    const selectAgMgt = ref("");
    const selectWater = ref("");
    const selectLanduse = ref("");

    // Previous selections memory
    const previousSelections = ref({
      "Ag": { water: "", landuse: "" },
      "Ag Mgt": { agMgt: "", water: "", landuse: "" },
      "Non-Ag": { landuse: "" }
    });

    // UI state
    const dataLoaded = ref(false);
    const isDrawerOpen = ref(false);
    const mapReady = computed(() => {
      if (!selectCategory.value || !selectLanduse.value) {
        return false;
      }
      if (selectCategory.value === "Non-Ag") {
        // Non-Ag: Landuse > Year (no Water level)
        const dataName = mapRegister[selectCategory.value]?.["name"];
        return dataName && window[dataName];
      }
      if (!selectWater.value) {
        return false;
      }
      if (selectCategory.value === "Ag Mgt" && !selectAgMgt.value) {
        return false;
      }
      const dataName = mapRegister[selectCategory.value]?.["name"];
      return dataName && window[dataName];
    });
    const chartReady = computed(() => {
      if (!selectCategory.value || !selectRegion.value) {
        return false;
      }
      if (selectCategory.value === "Non-Ag") {
        // Non-Ag is simple: Region > [series]
        const dataName = chartRegister[selectCategory.value]?.["name"];
        return dataName && window[dataName] && window[dataName][selectRegion.value];
      }
      if (!selectWater.value) {
        return false;
      }
      if (selectCategory.value === "Ag Mgt" && !selectAgMgt.value) {
        return false;
      }
      const dataName = chartRegister[selectCategory.value]?.["name"];
      return dataName && window[dataName] && window[dataName][selectRegion.value];
    });

    // Reactive data - Production now follows Area pattern
    const mapData = computed(() => window[mapRegister[selectCategory.value]["name"]]);
    const chartData = computed(() => window[chartRegister[selectCategory.value]["name"]][selectRegion.value]);
    const selectMapData = computed(() => {
      if (!mapReady.value) {
        return {};
      }
      if (selectCategory.value === "Ag") {
        // Ag: Water > Landuse > Year
        return mapData.value[selectWater.value][selectLanduse.value][selectYear.value];
      }
      else if (selectCategory.value === "Ag Mgt") {
        // Ag Mgt: AgMgt > Water > Landuse > Year
        return mapData.value?.[selectAgMgt.value][selectWater.value][selectLanduse.value][selectYear.value];
      }
      else if (selectCategory.value === "Non-Ag") {
        // Non-Ag: Landuse > Year (no Water level)
        return mapData.value[selectLanduse.value][selectYear.value];
      }
    });
    const selectChartData = computed(() => {
      if (!chartReady.value) {
        return {};
      }
      let seriesData;
      if (selectCategory.value === "Ag") {
        // Production_Ag: Region > Water > [series]
        seriesData = chartData.value[selectWater.value];
      }
      else if (selectCategory.value === "Ag Mgt") {
        // Production_Am: Region > AgMgt > Water > [series]
        seriesData = chartData.value[selectAgMgt.value]?.[selectWater.value];
      } else if (selectCategory.value === "Non-Ag") {
        // Production_NonAg: Region > [series] (direct series array)
        seriesData = chartData.value;
      }

      return {
        ...window["Chart_default_options"],
        chart: {
          height: 440,
        },
        yAxis: {
          title: {
            text: availableUnit["Production"],
          },
        },
        series: seriesData || [],
        colors: window["Supporting_info"].colors,
      };
    });

    onMounted(async () => {
      await loadScript("./data/Supporting_info.js", "Supporting_info");
      await loadScript("./data/chart_option/Chart_default_options.js", "Chart_default_options");

      // Load data
      await loadScript(mapRegister["Ag"]["path"], mapRegister["Ag"]["name"]);
      await loadScript(mapRegister["Ag Mgt"]["path"], mapRegister["Ag Mgt"]["name"]);
      await loadScript(mapRegister["Non-Ag"]["path"], mapRegister["Non-Ag"]["name"]);
      await loadScript(chartRegister["Ag"]["path"], chartRegister["Ag"]["name"]);
      await loadScript(chartRegister["Ag Mgt"]["path"], chartRegister["Ag Mgt"]["name"]);
      await loadScript(chartRegister["Non-Ag"]["path"], chartRegister["Non-Ag"]["name"]);

      // Initial selections
      availableYears.value = window.Supporting_info.years;
      selectCategory.value = availableCategories[0];

      await nextTick(() => {
        dataLoaded.value = true;
      });
    });

    // Watchers and methods
    const toggleDrawer = () => {
      isDrawerOpen.value = !isDrawerOpen.value;
    };

    watch(yearIndex, (newIndex) => {
      selectYear.value = availableYears.value[newIndex];
    });

    // Progressive selection chain watchers - now like Area
    watch(selectCategory, (newCategory, oldCategory) => {
      // Save previous selections before switching
      if (oldCategory) {
        if (oldCategory === "Ag") {
          previousSelections.value["Ag"] = { water: selectWater.value, landuse: selectLanduse.value };
        } else if (oldCategory === "Ag Mgt") {
          previousSelections.value["Ag Mgt"] = { agMgt: selectAgMgt.value, water: selectWater.value, landuse: selectLanduse.value };
        } else if (oldCategory === "Non-Ag") {
          previousSelections.value["Non-Ag"] = { landuse: selectLanduse.value };
        }
      }

      // Handle ALL downstream variables with cascading pattern
      if (newCategory === "Ag Mgt") {
        availableAgMgt.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]] || {});
        const prevAgMgt = previousSelections.value["Ag Mgt"].agMgt;
        selectAgMgt.value = (prevAgMgt && availableAgMgt.value.includes(prevAgMgt)) ? prevAgMgt : (availableAgMgt.value[0] || '');
        
        availableWater.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][selectAgMgt.value] || {});
        const prevWater = previousSelections.value["Ag Mgt"].water;
        selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || '');
        
        availableLanduse.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][selectAgMgt.value][selectWater.value] || {});
        const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
      } else if (newCategory === "Ag") {
        // Clear Ag Mgt data when switching to Ag
        availableAgMgt.value = [];
        selectAgMgt.value = '';
        availableWater.value = Object.keys(window[mapRegister["Ag"]["name"]] || {});
        const prevWater = previousSelections.value["Ag"].water;
        selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || '');
        
        availableLanduse.value = Object.keys(window[mapRegister["Ag"]["name"]][selectWater.value] || {});
        const prevLanduse = previousSelections.value["Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
      } else if (newCategory === "Non-Ag") {
        // Non-Ag has no Water level - clear both Ag Mgt and Water data
        availableAgMgt.value = [];
        selectAgMgt.value = '';
        availableWater.value = [];
        selectWater.value = '';
        availableLanduse.value = Object.keys(window[mapRegister["Non-Ag"]["name"]] || {});
        const prevLanduse = previousSelections.value["Non-Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
      }
    });

    watch(selectAgMgt, (newAgMgt) => {
      // Save current agMgt selection
      if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].agMgt = newAgMgt;
        
        // Handle ALL downstream variables with cascading pattern
        availableWater.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][newAgMgt] || {});
        const prevWater = previousSelections.value["Ag Mgt"].water;
        selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || '');
        
        availableLanduse.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][newAgMgt][selectWater.value] || {});
        const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
      }
    });

    watch(selectWater, (newWater) => {
      // Save current water selection
      if (selectCategory.value === "Ag") {
        previousSelections.value["Ag"].water = newWater;
      } else if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].water = newWater;
      }

      // Handle downstream variables
      if (selectCategory.value === "Ag") {
        availableLanduse.value = Object.keys(window[mapRegister["Ag"]["name"]][newWater] || {});
        const prevLanduse = previousSelections.value["Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
      } else if (selectCategory.value === "Ag Mgt") {
        availableLanduse.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][selectAgMgt.value][newWater] || {});
        const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
      }
    });

    watch(selectLanduse, (newLanduse) => {
      // Save current landuse selection
      if (selectCategory.value === "Ag") {
        previousSelections.value["Ag"].landuse = newLanduse;
      } else if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].landuse = newLanduse;
      } else if (selectCategory.value === "Non-Ag") {
        previousSelections.value["Non-Ag"].landuse = newLanduse;
      }
    });

    return {
      yearIndex,
      selectYear,
      selectRegion,

      availableYears,
      availableCategories,
      availableAgMgt,
      availableWater,
      availableLanduse,

      selectCategory,
      selectAgMgt,
      selectWater,
      selectLanduse,

      selectMapData,
      selectChartData,

      dataLoaded,
      isDrawerOpen,
      toggleDrawer,
    };
  },
  template: `
    <div class="relative w-full h-screen">

      <!-- Region selection dropdown -->
      <div class="absolute w-[262px] top-32 left-[20px] z-50 bg-white/70 rounded-lg shadow-lg max-w-xs z-[9999]">
        <filterable-dropdown></filterable-dropdown>
      </div>

      <!-- Year slider -->
      <div class="absolute top-[200px] left-[20px] z-[1001] w-[262px] bg-white/70 p-2 rounded-lg items-center">
        <p class="text-[0.8rem]">Year: <strong>{{ selectYear }}</strong></p>
        <el-slider
          v-if="availableYears && availableYears.length > 0"
          v-model="yearIndex"
          size="small"
          :show-tooltip="false"
          :min="0"
          :max="availableYears.length - 1"
          :step="1"
          :format-tooltip="index => availableYears[index]"
          :marks="availableYears.reduce((acc, year, index) => ({ ...acc, [index]: year }), {})"
          @input="(index) => { yearIndex = index; selectYear = availableYears[index]; }"
        />
      </div>

      <!-- Data selection controls container -->
      <div class="absolute top-[285px] left-[20px] w-[320px] z-[1001] flex flex-col space-y-3 bg-white/70 p-2 rounded-lg">

        <!-- Category buttons (always visible) -->
        <div class="flex items-center">
          <div class="flex space-x-1">
            <span class="text-[0.8rem] mr-1 font-medium">Category:</span>
            <button v-for="(val, key) in availableCategories" :key="key"
              @click="selectCategory = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded"
              :class="{'bg-sky-500 text-white': selectCategory === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Ag Mgt options (only for Ag Mgt category) -->
        <div 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="dataLoaded && selectCategory === 'Ag Mgt' && availableAgMgt.length > 0" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Ag Mgt:</span>
            <button v-for="(val, key) in availableAgMgt" :key="key"
              @click="selectAgMgt = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectAgMgt === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Water options (for Ag and Ag Mgt) -->
        <div 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="dataLoaded && (selectCategory === 'Ag' || selectCategory === 'Ag Mgt') && availableWater.length > 0" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Water:</span>
            <button v-for="(val, key) in availableWater" :key="key"
              @click="selectWater = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectWater === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Landuse options -->
        <div 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="dataLoaded" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Landuse:</span>
            <button v-for="(val, key) in availableLanduse" :key="key"
              @click="selectLanduse = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectLanduse === val}">
              {{ val }}
            </button>
          </div>
        </div>
      </div>

      <!-- Map container with slide-out chart drawer -->
      <div style="position: relative; width: 100%; height: 100%; overflow: hidden;">

        <!-- Map component takes full space -->
        <regions-map 
          :mapData="selectMapData"
          style="width: 100%; height: 100%;">
        </regions-map>

        <!-- Drawer toggle button -->
        <button
          @click="toggleDrawer"
          class="absolute top-5 z-[1001] p-2.5 bg-white border border-gray-300 rounded cursor-pointer transition-all duration-300 ease-in-out"
          :class="isDrawerOpen ? 'right-[420px]' : 'right-5'">
          {{ isDrawerOpen ? '→' : '←' }}
        </button>
        
        <!-- Chart drawer positioned relative to map -->
        <div 
          :style="{
            position: 'absolute',
            height: '50px',
            top: '10px',
            bottom: '10px',
            right: isDrawerOpen ? '0px' : '-100%',
            width: '66.666%',
            background: 'transparent',
            transition: 'right 0.3s ease',
            zIndex: 1000,
            padding: '60px 20px 20px 20px',
            boxSizing: 'border-box'
          }">
          <chart-container 
            :chartData="selectChartData" 
            :selectedLanduse="selectLanduse"
            :draggable="true"
            :zoomable="true"
            style="width: 100%; height: 200px;">
          </chart-container>
        </div>
      </div>

    </div>
  `,
};
```

## luto/tools/report/VUE_modules/views/Settings.js

```javascript
window.SettingsView = {
  setup(props, { emit }) {
    const { ref, onMounted, watch, computed } = Vue;
    const loadScript = window.loadScript;                       // DataConstructor has been registered in index.html [DataConstructor.js] [helpers.js]

    // Tab management
    const activeTab = ref('settings');

    // Settings related reactive variables
    const searchTerm = ref('');
    const activeFilter = ref('all');
    const modelRunSettings = ref([]);
    const chartMemLogData = ref({});

    // Categories definition for parameter organization
    const categories = {
      'Basic Configuration': {
        icon: '⚙️',
        keywords: ['VERSION', 'INPUT_DIR', 'OUTPUT_DIR', 'RAW_DATA', 'SSP', 'RCP', 'SCENARIO', 'OBJECTIVE', 'SIM_YEARS']
      },
      'Diet & Consumption': {
        icon: '🍽️',
        keywords: ['DIET_DOM', 'DIET_GLOB', 'WASTE', 'FEED_EFFICIENCY', 'CONVERGENCE', 'IMPORT_TREND', 'OFF_LAND_COMMODITIES', 'EGGS_AVG_WEIGHT']
      },
      'Economic Parameters': {
        icon: '💰',
        keywords: ['DISCOUNT_RATE', 'RESFACTOR', 'CARBON_PRICE', 'COST', 'AMORTISE', 'AMORTISATION', 'FENCING_COST', 'IRRIG_COST', 'MAINTENANCE', 'ECOSYSTEM_SERVICES']
      },
      'Risk & Environmental': {
        icon: '⚠️',
        keywords: ['RISK_OF_REVERSAL', 'FIRE_RISK', 'CO2_FERT', 'SOC_AMORTISATION']
      },
      'Biodiversity & Conservation': {
        icon: '🌿',
        keywords: ['BIO_CONTRIBUTION', 'GBF', 'BIODIVERSITY', 'HABITAT', 'CONNECTIVITY', 'EP_', 'RP_', 'DEGRADED_AREAS']
      },
      'Climate & GHG': {
        icon: '🌡️',
        keywords: ['GHG', 'CO2', 'CARBON', 'CLIMATE', 'EMISSIONS', 'SCOPE_1', 'CROP_GHG', 'LVSTK_GHG']
      },
      'Water Management': {
        icon: '💧',
        keywords: ['WATER', 'IRRIGATION', 'DRAINAGE', 'LIVESTOCK_DRINKING', 'LICENSE']
      },
      'Land Use & Planning': {
        icon: '🌾',
        keywords: ['LAND', 'AGRICULTURAL', 'NON_AG', 'PLANTING', 'AGROFORESTRY', 'NO_GO', 'REGIONAL_ADOPTION', 'CULL_MODE', 'MAX_LAND_USES']
      },
      'Carbon Plantings': {
        icon: '🌳',
        keywords: ['CP_BLOCK', 'CP_BELT', 'CARBON_PLANTING']
      },
      'Riparian & Agroforestry': {
        icon: '🌲',
        keywords: ['RIPARIAN', 'AF_', 'AGROFORESTRY', 'ROW_WIDTH', 'ROW_SPACING', 'PROPORTION', 'BUFFER_WIDTH', 'TORTUOSITY']
      },
      'Agricultural Management': {
        icon: '🚜',
        keywords: ['AG_MANAGEMENTS', 'HIR_', 'BEEF_HIR', 'SHEEP_HIR', 'SAVBURN', 'PRODUCTIVITY', 'EFFECT_YEARS', 'USE_THRESHOLD']
      },
      'Solver & Optimization': {
        icon: '🔧',
        keywords: ['SOLVER', 'WEIGHT', 'TOLERANCE', 'PRESOLVE', 'CROSSOVER', 'BARRIER', 'SCALE_FLAG', 'NUMERIC_FOCUS', 'BARHOMOGENOUS', 'CONSTRAINT_TYPE', 'PENALTY', 'ALPHA', 'BETA']
      },
      'Output & Processing': {
        icon: '📊',
        keywords: ['WRITE', 'OUTPUT', 'PARALLEL', 'GEOTIFFS', 'RESCALE_FACTOR', 'VERBOSE', 'KEEP_OUTPUTS', 'ROUND_DECMIALS']
      },
      'System Resources': {
        icon: '💻',
        keywords: ['THREADS', 'MEM', 'NCPUS', 'TIME', 'QUEUE', 'JOB_NAME', 'SOLVE_METHOD', 'AGGREGATE']
      },
      'Land Use Configuration': {
        icon: '🗺️',
        keywords: ['EXCLUDE_NO_GO', 'VECTORS', 'REVERSIBLE', 'BASE_CODE', 'PERCENTAGE']
      }
    };

    const filterButtons = ref([
      { key: 'all', label: 'All' },
      { key: 'BIO_', label: 'Biodiversity' },
      { key: 'GBF', label: 'GBF' },
      { key: 'GHG', label: 'GHG' },
      { key: 'WATER', label: 'Water' },
      { key: 'SOLVER', label: 'Solver' },
      { key: 'AG_', label: 'Agriculture' },
      { key: 'CP_', label: 'Carbon' },
      { key: 'COST', label: 'Costs' }
    ]);

    // Helper functions
    const categorizeParameters = (parameters) => {
      const categorized = {};
      const uncategorized = [];

      Object.keys(categories).forEach(cat => {
        categorized[cat] = [];
      });

      parameters.forEach(param => {
        let assigned = false;

        for (const [categoryName, categoryData] of Object.entries(categories)) {
          if (categoryData.keywords.some(keyword =>
            param.parameter.toUpperCase().includes(keyword.toUpperCase())
          )) {
            categorized[categoryName].push(param);
            assigned = true;
            break;
          }
        }

        if (!assigned) {
          uncategorized.push(param);
        }
      });

      if (uncategorized.length > 0) {
        categorized['Other'] = uncategorized;
      }

      return categorized;
    };

    const getValueClass = (value) => {
      const length = typeof value === 'string' ? value.length : 0;
      if (length > 200) {
        return 'bg-blue-50 text-blue-700 border border-blue-200';
      } else if (length > 50) {
        return 'bg-yellow-50 text-yellow-700 border border-yellow-200';
      } else {
        return 'bg-green-50 text-green-700 border border-green-200';
      }
    };

    // Computed properties
    const filteredParameters = computed(() => {
      let filtered = modelRunSettings.value;

      if (searchTerm.value) {
        filtered = filtered.filter(param =>
          param.parameter.toLowerCase().includes(searchTerm.value.toLowerCase()) ||
          param.val.toString().toLowerCase().includes(searchTerm.value.toLowerCase())
        );
      }

      if (activeFilter.value && activeFilter.value !== 'all') {
        filtered = filtered.filter(param =>
          param.parameter.includes(activeFilter.value)
        );
      }

      return filtered;
    });

    const filteredCategories = computed(() => {
      const categorized = categorizeParameters(filteredParameters.value);
      return Object.entries(categorized)
        .filter(([_, params]) => params.length > 0)
        .map(([name, params]) => ({
          name,
          icon: categories[name]?.icon || '📋',
          params
        }));
    });

    const stats = computed(() => {
      const totalParams = filteredParameters.value.length;
      const activeCategories = filteredCategories.value.length;
      const biodiversityParams = filteredParameters.value.filter(p => p.parameter.includes('BIO_')).length;
      const enabledFeatures = filteredParameters.value.filter(p =>
        p.val === 'on' || p.val === 'True' || p.val === 'true'
      ).length;

      return [
        { value: totalParams, label: 'Total Parameters' },
        { value: activeCategories, label: 'Active Categories' },
        { value: biodiversityParams, label: 'Biodiversity Params' },
        { value: enabledFeatures, label: 'Enabled Features' }
      ];
    });

    // Load scripts and data when the component is mounted
    onMounted(async () => {
      try {
        await loadScript("./data/Supporting_info.js", 'Supporting_info');
        await loadScript("./data/chart_option/Chart_default_options.js", 'Chart_default_options');
        await loadScript("./data/chart_option/chartMemLogOptions.js", 'chartMemLogOptions');

        modelRunSettings.value = window['Supporting_info']['model_run_settings'] || [];

        chartMemLogData.value = {
          ...window['Chart_default_options'],
          ...window['chartMemLogOptions'],
          series: window['Supporting_info'].mem_logs,
        };

      } catch (error) {
        console.error("Error loading dependencies for Settings view:", error);
      }
    });

    return {
      activeTab,
      searchTerm,
      activeFilter,
      filterButtons,
      filteredCategories,
      stats,
      getValueClass,
      chartMemLogData,
    };
  },

  template: `
    <div class="min-h-screen p-5" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);">
      <div class="max-w-7xl mx-auto" style="backdrop-filter: blur(16px); background: rgba(255, 255, 255, 0.95);" class="rounded-3xl p-8 shadow-2xl">
        
        <!-- Header -->
        <div class="text-center mb-10 p-6 rounded-2xl text-white shadow-lg" style="background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);">
          <h1 class="text-2xl md:text-3xl font-bold mb-3">Model Settings & Logs</h1>
          <p class="text-sm opacity-90"><strong>Configuration Overview and Memory Usage</strong></p>
        </div>

        <!-- Tab Navigation -->
        <div class="mb-8">
          <div class="flex space-x-1 bg-gray-100 p-1 rounded-lg">
            <button 
              @click="activeTab = 'settings'"
              :class="[
                'flex-1 py-2 px-3 rounded-md text-sm font-medium transition-all duration-200',
                activeTab === 'settings' 
                  ? 'bg-white text-blue-600 shadow-md' 
                  : 'text-gray-600 hover:text-gray-800'
              ]"
            >
              ⚙️ Model Settings
            </button>
            <button 
              @click="activeTab = 'memory'"
              :class="[
                'flex-1 py-2 px-3 rounded-md text-sm font-medium transition-all duration-200',
                activeTab === 'memory' 
                  ? 'bg-white text-blue-600 shadow-md' 
                  : 'text-gray-600 hover:text-gray-800'
              ]"
            >
              📊 Memory Log
            </button>
          </div>
        </div>

        <!-- Settings Tab Content -->
        <div v-if="activeTab === 'settings'">
          <!-- Statistics -->
          <div class="grid grid-cols-2 md:grid-cols-4 gap-5 mb-8">
            <div v-for="(stat, index) in stats" :key="index" 
                 class="text-white p-5 rounded-2xl text-center shadow-lg transition-all duration-300 hover:transform hover:translateY(-2px)"
                 style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);">
              <div class="text-xl md:text-2xl font-bold mb-2">{{ stat.value }}</div>
              <div class="text-xs opacity-90">{{ stat.label }}</div>
            </div>
          </div>

          <!-- Search and Filters -->
          <div class="mb-8 space-y-4">
            <div class="flex flex-col lg:flex-row gap-4 items-stretch lg:items-center">
              <input 
                v-model="searchTerm"
                type="text" 
                placeholder="🔍 Search parameters..."
                class="flex-1 min-w-64 px-3 py-2 border-2 border-gray-200 rounded-full text-sm transition-all duration-300 focus:outline-none focus:border-blue-400 focus:shadow-lg bg-white"
              >
              <div class="flex flex-wrap gap-3">
                <button 
                  v-for="filter in filterButtons" 
                  :key="filter.key"
                  @click="activeFilter = filter.key"
                  :class="[
                    'px-3 py-2 border-2 rounded-full cursor-pointer transition-all duration-300 hover:transform hover:translateY(-2px) text-xs',
                    activeFilter === filter.key 
                      ? 'bg-blue-500 text-white border-blue-500 shadow-lg' 
                      : 'bg-gray-50 text-gray-600 border-gray-200 hover:bg-blue-500 hover:text-white hover:border-blue-500'
                  ]"
                >
                  {{ filter.label }}
                </button>
              </div>
            </div>
          </div>

          <!-- Parameters Grid -->
          <div v-if="filteredCategories.length === 0" class="text-center text-gray-500 italic p-10 bg-gray-50 rounded-xl text-sm">
            No parameters found matching your search.
          </div>
          
          <div v-else class="grid grid-cols-1 lg:grid-cols-2 xl:grid-cols-3 gap-6">
            <div 
              v-for="(category, index) in filteredCategories" 
              :key="category.name"
              class="bg-white rounded-2xl p-6 shadow-lg border border-gray-100 transition-all duration-300 hover:transform hover:translateY(-5px)"
            >
              <h3 class="text-sm font-bold text-gray-800 mb-5 pb-3 border-b-2 border-blue-400 flex items-center gap-3">
                <span class="text-lg">{{ category.icon }}</span>
                {{ category.name }} ({{ category.params.length }})
              </h3>
              
              <div class="space-y-0">
                <div 
                  v-for="param in category.params" 
                  :key="param.parameter"
                  class="flex justify-between items-start gap-4 py-3 border-b border-gray-100 last:border-b-0 hover:bg-blue-50 hover:mx-[-1.5rem] hover:px-6 hover:rounded-lg transition-all duration-200 min-h-[3rem]"
                >
                  <span class="font-semibold text-gray-700 text-xs flex-1 min-w-0 max-w-[50%]" style="word-wrap: break-word; word-break: break-word; hyphens: auto; line-height: 1.4;">
                    {{ param.parameter }}
                  </span>
                  <span 
                    :class="[
                      'font-medium text-xs font-mono flex-1 min-w-0 max-w-[50%] px-2 py-1 rounded-lg',
                      getValueClass(param.val)
                    ]"
                    :title="param.val"
                    style="word-wrap: break-word; word-break: break-word; white-space: pre-wrap; line-height: 1.4; overflow-wrap: break-word;"
                  >
                    {{ param.val }}
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>

        <!-- Memory Log Tab Content -->
        <div v-if="activeTab === 'memory'" class="bg-white rounded-2xl p-6 shadow-lg">
          <div class="flex items-center justify-start mb-4">
            <span class="text-lg mr-3">📊</span>
            <h2 class="text-lg font-bold text-gray-800">Memory Usage Log</h2>
          </div>
          <hr class="border-gray-300 mb-6">
          <div class="h-[600px]">
            <chart-container class="w-full h-full rounded-lg" :chartData="chartMemLogData"/>
          </div>
        </div>

      </div>
    </div>
  `,
};
```

## luto/tools/report/VUE_modules/views/Test.js

```javascript
window.Test = {
  template: `
    <!-- Title for map and chart -->

        <div class="flex mr-4 gap-4 mb-4">

          <div class="flex flex-col rounded-[10px] bg-white shadow-md w-[500px]">


            <!-- Map -->
            <div class="relative">
              <div class="absolute flex-col w-full top-1 left-2 right-2 pr-4 justify-between items-center z-10">

              <div class="flex flex-col">
                <div class="flex items-center justify-between">
                  <p class="text-[0.8rem]">Year: <strong>{{ selectYear }}</strong></p>
                  <div class="flex space-x-1 mr-4">
                    <button v-for="cat in availableChartSubCategories" :key="cat"
                      @click="selectChartSubCategory = cat"
                      class="bg-[#e8eaed] text-[#1f1f1f] text-[0.6rem] px-1 rounded"
                      :class="{'bg-sky-500 text-white': selectChartSubCategory === cat}">
                      {{ cat }}
                    </button>
                  </div>
                </div>

                <el-slider
                  v-if="availableYears.length > 0"
                  class="flex-1 max-w-[150px] pt-2 pl-2"
                  v-model="yearIndex"
                  size="small"
                  :show-tooltip="false"
                  :min="0"
                  :max="availableYears.length - 1"
                  :step="1"
                  :format-tooltip="index => availableYears[index]"
                  :marks="availableYears.reduce((acc, year, index) => ({ ...acc, [index]: year }), {})"
                  @input="(index) => { yearIndex = index; }"
                />

                </div>
              </div>
              <map-geojson
                v-if="dataLoaded"
                :height="'530px'"
                :availableChartCategories="availableChartCategories"
                :selectYear="selectYear"
                :selectChartSubCategory="selectChartSubCategory"
                :legendObj="rankingColors"
              />
            </div>

          </div>

          <!-- Statistics Chart -->
          <chart-container
          v-if="dataLoaded"
          class="flex-1 rounded-[10px] bg-white shadow-md"
          :chartData="selectChartData"></chart-container>

        </div>
  `
};
```

## luto/tools/report/VUE_modules/views/Water.js

```javascript
window.WaterView = {
  setup() {
    const { ref, onMounted, inject, computed, watch, nextTick } = Vue;

    // Data|Map service
    const chartRegister = window.DataService.chartCategories["Water"];
    const mapRegister = window.MapService.mapCategories["Water"];
    const loadScript = window.loadScript;

    // Global selection state
    const yearIndex = ref(0);
    const selectYear = ref(2020);
    const selectRegion = inject("globalSelectedRegion");

    // Available variables
    const availableYears = ref([]);
    const availableUnit = {
      Area: "Hectares",
      Economics: "AUD",
      GHG: "Mt CO2e",
      Water: "ML",
      Biodiversity: "Relative Percentage (Pre-1750 = 100%)",
    };

    // Available selections
    const availableCategories = ["Ag", "Ag Mgt", "Non-Ag"];
    const availableAgMgt = ref([]);
    const availableWater = ref([]);
    const availableLanduse = ref([]);

    // Map selection state
    const selectCategory = ref("");
    const selectAgMgt = ref("");
    const selectWater = ref("");
    const selectLanduse = ref("");

    // Previous selections memory
    const previousSelections = ref({
      "Ag": { water: "", landuse: "" },
      "Ag Mgt": { agMgt: "", water: "", landuse: "" },
      "Non-Ag": { landuse: "" }
    });

    // UI state
    const dataLoaded = ref(false);
    const isDrawerOpen = ref(false);
    const mapReady = computed(() => {
      if (!selectCategory.value || !selectLanduse.value) {
        return false;
      }
      // Non-Ag doesn't require water selection
      if (selectCategory.value !== "Non-Ag" && !selectWater.value) {
        return false;
      }
      if (selectCategory.value === "Ag Mgt" && !selectAgMgt.value) {
        return false;
      }
      const dataName = mapRegister[selectCategory.value]?.["name"];
      return dataName && window[dataName];
    });
    const chartReady = computed(() => {
      if (!selectCategory.value || !selectRegion.value) {
        return false;
      }
      // Water charts need water selection for Ag and Ag Mgt, but not for Non-Ag
      if (selectCategory.value !== "Non-Ag" && !selectWater.value) {
        return false;
      }
      // All water charts need landuse selection
      if (!selectLanduse.value) {
        return false;
      }
      if (selectCategory.value === "Ag Mgt" && !selectAgMgt.value) {
        return false;
      }
      const dataName = chartRegister["NRM"][selectCategory.value]?.["name"];
      return dataName && window[dataName] && window[dataName][selectRegion.value];
    });

    // Reactive data
    const mapData = computed(() => window[mapRegister[selectCategory.value]["name"]]);
    const chartData = computed(() => window[chartRegister["NRM"][selectCategory.value]["name"]][selectRegion.value]);
    const selectMapData = computed(() => {
      if (!mapReady.value) {
        return {};
      }
      if (selectCategory.value === "Ag") {
        return mapData.value[selectWater.value][selectLanduse.value][selectYear.value];
      }
      else if (selectCategory.value === "Ag Mgt") {
        return mapData.value?.[selectAgMgt.value]?.[selectWater.value]?.[selectLanduse.value]?.[selectYear.value];
      }
      else if (selectCategory.value === "Non-Ag") {
        return mapData.value[selectLanduse.value][selectYear.value];
      }
    });
    const selectChartData = computed(() => {
      if (!chartReady.value) {
        return {};
      }
      let seriesData;
      if (selectCategory.value === "Ag") {
        seriesData = chartData.value[selectWater.value];
      }
      else if (selectCategory.value === "Ag Mgt") {
        seriesData = chartData.value[selectAgMgt.value]?.[selectWater.value];
      } else if (selectCategory.value === "Non-Ag") {
        seriesData = chartData.value;
      }

      return {
        ...window["Chart_default_options"],
        chart: {
          height: 440,
        },
        yAxis: {
          title: {
            text: availableUnit["Water"],
          },
        },
        series: seriesData || [],
        colors: window["Supporting_info"].colors,
      };
    });

    onMounted(async () => {
      await loadScript("./data/Supporting_info.js", "Supporting_info");
      await loadScript("./data/chart_option/Chart_default_options.js", "Chart_default_options");

      // Load data
      await loadScript(mapRegister["Ag"]["path"], mapRegister["Ag"]["name"]);
      await loadScript(mapRegister["Ag Mgt"]["path"], mapRegister["Ag Mgt"]["name"]);
      await loadScript(mapRegister["Non-Ag"]["path"], mapRegister["Non-Ag"]["name"]);
      await loadScript(chartRegister["NRM"]["Ag"]["path"], chartRegister["NRM"]["Ag"]["name"]);
      await loadScript(chartRegister["NRM"]["Ag Mgt"]["path"], chartRegister["NRM"]["Ag Mgt"]["name"]);
      await loadScript(chartRegister["NRM"]["Non-Ag"]["path"], chartRegister["NRM"]["Non-Ag"]["name"]);

      // Initial selections
      availableYears.value = window.Supporting_info.years;
      selectCategory.value = availableCategories[0];

      await nextTick(() => {
        dataLoaded.value = true;
      });
    });

    // Watchers and methods
    const toggleDrawer = () => {
      isDrawerOpen.value = !isDrawerOpen.value;
    };

    watch(yearIndex, (newIndex) => {
      selectYear.value = availableYears.value[newIndex];
    });

    // Progressive selection chain watchers
    watch(selectCategory, (newCategory, oldCategory) => {
      // Save previous selections before switching
      if (oldCategory) {
        if (oldCategory === "Ag") {
          previousSelections.value["Ag"] = { water: selectWater.value, landuse: selectLanduse.value };
        } else if (oldCategory === "Ag Mgt") {
          previousSelections.value["Ag Mgt"] = { agMgt: selectAgMgt.value, water: selectWater.value, landuse: selectLanduse.value };
        } else if (oldCategory === "Non-Ag") {
          previousSelections.value["Non-Ag"] = { landuse: selectLanduse.value };
        }
      }

      // Reset AgMgt array when not in Ag Mgt category
      if (newCategory !== "Ag Mgt") {
        availableAgMgt.value = [];
        selectAgMgt.value = "";
      }

      // Handle ALL downstream variables with cascading pattern
      if (newCategory === "Ag Mgt") {
        availableAgMgt.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]] || {});
        const prevAgMgt = previousSelections.value["Ag Mgt"].agMgt;
        selectAgMgt.value = (prevAgMgt && availableAgMgt.value.includes(prevAgMgt)) ? prevAgMgt : (availableAgMgt.value[0] || '');
        
        // Water map data structure: AgMgt → Water → Landuse → Year
        if (selectAgMgt.value) {
          availableWater.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][selectAgMgt.value] || {});
          const prevWater = previousSelections.value["Ag Mgt"].water;
          selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || '');
          
          if (selectWater.value) {
            availableLanduse.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][selectAgMgt.value][selectWater.value] || {});
            const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
            selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
          }
        }
      } else if (newCategory === "Ag") {
        availableWater.value = Object.keys(window[mapRegister["Ag"]["name"]] || {});
        const prevWater = previousSelections.value["Ag"].water;
        selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || '');
        
        availableLanduse.value = Object.keys(window[mapRegister["Ag"]["name"]][selectWater.value] || {});
        const prevLanduse = previousSelections.value["Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || 'ALL');
      } else if (newCategory === "Non-Ag") {
        availableLanduse.value = Object.keys(window[mapRegister["Non-Ag"]["name"]] || {});
        const prevLanduse = previousSelections.value["Non-Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || 'ALL');
        
        // Clear water for Non-Ag since it doesn't use water
        availableWater.value = [];
        selectWater.value = '';
      }
    });

    watch(selectAgMgt, (newAgMgt) => {
      // Save current agMgt selection
      if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].agMgt = newAgMgt;
        
        // Handle ALL downstream variables with cascading pattern
        // Water map data follows AgMgt → Water → Landuse pattern
        availableWater.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][newAgMgt] || {});
        const prevWater = previousSelections.value["Ag Mgt"].water;
        selectWater.value = (prevWater && availableWater.value.includes(prevWater)) ? prevWater : (availableWater.value[0] || '');
        
        if (selectWater.value) {
          availableLanduse.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][newAgMgt][selectWater.value] || {});
          const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
          selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
        }
      }
    });

    watch(selectWater, (newWater) => {
      // Save current water selection
      if (selectCategory.value === "Ag") {
        previousSelections.value["Ag"].water = newWater;
      } else if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].water = newWater;
      }

      // Handle ALL downstream variables
      if (selectCategory.value === "Ag") {
        availableLanduse.value = Object.keys(window[mapRegister["Ag"]["name"]][newWater] || {});
        const prevLanduse = previousSelections.value["Ag"].landuse;
        selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || 'ALL');
      } else if (selectCategory.value === "Ag Mgt") {
        // For Ag Mgt, update landuse options when water changes
        if (selectAgMgt.value) {
          availableLanduse.value = Object.keys(window[mapRegister["Ag Mgt"]["name"]][selectAgMgt.value]?.[newWater] || {});
          const prevLanduse = previousSelections.value["Ag Mgt"].landuse;
          selectLanduse.value = (prevLanduse && availableLanduse.value.includes(prevLanduse)) ? prevLanduse : (availableLanduse.value[0] || '');
        }
      }
    });

    watch(selectLanduse, (newLanduse) => {
      // Save current landuse selection
      if (selectCategory.value === "Ag") {
        previousSelections.value["Ag"].landuse = newLanduse;
      } else if (selectCategory.value === "Ag Mgt") {
        previousSelections.value["Ag Mgt"].landuse = newLanduse;
      } else if (selectCategory.value === "Non-Ag") {
        previousSelections.value["Non-Ag"].landuse = newLanduse;
      }
    });

    return {
      yearIndex,
      selectYear,
      selectRegion,

      availableYears,
      availableCategories,
      availableAgMgt,
      availableWater,
      availableLanduse,

      selectCategory,
      selectAgMgt,
      selectWater,
      selectLanduse,

      selectMapData,
      selectChartData,

      dataLoaded,
      isDrawerOpen,
      toggleDrawer,
    };
  },
  template: `
    <div class="relative w-full h-screen">

      <!-- Region selection dropdown -->
      <div class="absolute w-[262px] top-32 left-[20px] z-50 bg-white/70 rounded-lg shadow-lg max-w-xs z-[9999]">
        <filterable-dropdown></filterable-dropdown>
      </div>

      <!-- Year slider -->
      <div class="absolute top-[200px] left-[20px] z-[1001] w-[262px] bg-white/70 p-2 rounded-lg items-center">
        <p class="text-[0.8rem]">Year: <strong>{{ selectYear }}</strong></p>
        <el-slider
          v-if="availableYears && availableYears.length > 0"
          v-model="yearIndex"
          size="small"
          :show-tooltip="false"
          :min="0"
          :max="availableYears.length - 1"
          :step="1"
          :format-tooltip="index => availableYears[index]"
          :marks="availableYears.reduce((acc, year, index) => ({ ...acc, [index]: year }), {})"
          @input="(index) => { yearIndex = index; selectYear = availableYears[index]; }"
        />
      </div>

      <!-- Data selection controls container -->
      <div class="absolute top-[285px] left-[20px] w-[320px] z-[1001] flex flex-col space-y-3 bg-white/70 p-2 rounded-lg">

        <!-- Category buttons (always visible) -->
        <div class="flex items-center">
          <div class="flex space-x-1">
            <span class="text-[0.8rem] mr-1 font-medium">Category:</span>
            <button v-for="(val, key) in availableCategories" :key="key"
              @click="selectCategory = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded"
              :class="{'bg-sky-500 text-white': selectCategory === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Ag Mgt options (only for Ag Mgt category) -->
        <div 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="dataLoaded && selectCategory === 'Ag Mgt' && availableAgMgt.length > 0" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Ag Mgt:</span>
            <button v-for="(val, key) in availableAgMgt" :key="key"
              @click="selectAgMgt = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectAgMgt === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Water options -->
        <div 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="selectCategory !== 'Non-Ag' && dataLoaded && availableWater.length > 0" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Water:</span>
            <button v-for="(val, key) in availableWater" :key="key"
              @click="selectWater = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectWater === val}">
              {{ val }}
            </button>
          </div>
        </div>

        <!-- Landuse options -->
        <div 
          class="flex items-start border-t border-white/10 pt-1">
          <div v-if="dataLoaded" class="flex flex-wrap gap-1 max-w-[300px]">
            <span class="text-[0.8rem] mr-1 font-medium">Landuse:</span>
            <button v-for="(val, key) in availableLanduse" :key="key"
              @click="selectLanduse = val"
              class="bg-white text-[#1f1f1f] text-[0.6rem] px-1 py-1 rounded mb-1"
              :class="{'bg-sky-500 text-white': selectLanduse === val}">
              {{ val }}
            </button>
          </div>
        </div>
      </div>

      <!-- Map container with slide-out chart drawer -->
      <div style="position: relative; width: 100%; height: 100%; overflow: hidden;">

        <!-- Map component takes full space -->
        <regions-map 
          :mapData="selectMapData"
          style="width: 100%; height: 100%;">
        </regions-map>

        <!-- Drawer toggle button -->
        <button
          @click="toggleDrawer"
          class="absolute top-5 z-[1001] p-2.5 bg-white border border-gray-300 rounded cursor-pointer transition-all duration-300 ease-in-out"
          :class="isDrawerOpen ? 'right-[420px]' : 'right-5'">
          {{ isDrawerOpen ? '→' : '←' }}
        </button>
        
        <!-- Chart drawer positioned relative to map -->
        <div 
          :style="{
            position: 'absolute',
            height: '50px',
            top: '10px',
            bottom: '10px',
            right: isDrawerOpen ? '0px' : '-100%',
            width: '66.666%',
            background: 'transparent',
            transition: 'right 0.3s ease',
            zIndex: 1000,
            padding: '60px 20px 20px 20px',
            boxSizing: 'border-box'
          }">
          <chart-container 
            :chartData="selectChartData" 
            :selectedLanduse="selectLanduse"
            :draggable="true"
            :zoomable="true"
            style="width: 100%; height: 200px;">
          </chart-container>
        </div>
      </div>

    </div>
  `,
};
```

## luto/tools/spatializers.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.


import numpy as np
import luto.settings as settings
from scipy.ndimage import distance_transform_edt


def create_2d_map(data, map_:np.ndarray=None) -> np.ndarray:
    """
    Create a 2D map based on the given data and map.

    Args:
        data (Data): The input data used to create the map.
        map_ (np.ndarray, 1D array): The initial map to be modified.

    Returns:
        np.ndarray: The created 2D map.

    """
    
    if settings.RESFACTOR > 1:
        return get_coarse2D_map(data, map_)    
    else: 
        return get_fullres2D_map(data, map_)                       
                


def get_fullres2D_map(data, map_:np.ndarray)-> np.ndarray:
    """
    Returns the full resolution 2D map by filling the 1D `map_` to the 2D `NLUM_MASK`.

    Args:
        `data`(Data): The data object containing the NLUM_MASK and LUMAP_NO_RESFACTOR arrays.
        `map_`(np.ndarray): The 1D np.ndarray to be filled into the `NLUM_MASK` array.

    Returns
        np.ndarray : The restored 2D full resolution land-use map.
    """
    LUMAP_FullRes_2D = np.full(data.NLUM_MASK.shape, data.NODATA).astype(np.float32) 
    # Get the full resolution LUMAP_2D_RESFACTORED at the begining year, with -1 as Non-Agricultural Land, and -9999 as NoData
    np.place(LUMAP_FullRes_2D, data.NLUM_MASK, data.LUMAP_NO_RESFACTOR) 
    # Fill the LUMAP_FullRes_2D with map_ sequencialy by the row-col order of 1s in (LUMAP_FullRes_2D >=0) 
    np.place(LUMAP_FullRes_2D, LUMAP_FullRes_2D >=0, map_)
    return LUMAP_FullRes_2D



def get_coarse2D_map(data, map_:np.ndarray)-> np.ndarray:
    """
    Generate a coarse 2D map based on the input data.

    Args:
        `data` (Data): The input data used to create the map.
        `map_` (np.ndarray): The initial 1D map used to create a 2D map.
        
    Returns
        np.ndarray: The generated coarse 2D map.

    """
    
    # Fill the 1D map to the 2D map_resfactored.
    map_resfactored = data.LUMAP_2D_RESFACTORED.copy().astype(np.float32)
    np.place(map_resfactored, (map_resfactored != data.MASK_LU_CODE) & (map_resfactored != data.NODATA), map_.astype(np.float32))                    
    return map_resfactored
    

def upsample_array(data, map_:np.ndarray, factor:int) -> np.ndarray:
    """
    Upsamples the given array based on the provided map and factor.

    Parameters
    data (object): The input data to derive the original dense_2D shape from NLUM mask.
    map_ (2D, np.ndarray): The map used for upsampling.
    factor (int): The upsampling factor.

    Returns
    np.ndarray: The upsampled array.
    """
    dense_2D_shape = data.NLUM_MASK.shape
    dense_2D_map = np.repeat(np.repeat(map_, factor, axis=0), factor, axis=1)       # Simply repeate each cell by `factor` times at every row/col direction  
    
    # Adjust the dense_2D_map size if it exceeds the original shape
    if dense_2D_map.shape[0] > dense_2D_shape[0] or dense_2D_map.shape[1] > dense_2D_shape[1]:
        dense_2D_map = dense_2D_map[:dense_2D_shape[0], :dense_2D_shape[1]]
    
    # Pad the array if necessary
    if dense_2D_map.shape[0] < dense_2D_shape[0] or dense_2D_map.shape[1] < dense_2D_shape[1]:
        pad_height = dense_2D_shape[0] - dense_2D_map.shape[0]
        pad_width = dense_2D_shape[1] - dense_2D_map.shape[1]
        dense_2D_map = np.pad(
            dense_2D_map, 
            pad_width=((0, pad_height), (0, pad_width)), 
            mode='edge'
        )   
        
    return dense_2D_map
```

## luto/tools/write.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.



import os
import re
import shutil
import threading
import numpy as np
import pandas as pd
import rasterio
import xarray as xr

from joblib import Parallel, delayed

from luto import settings
from luto import tools
from luto.data import Data
from luto.tools.Manual_jupyter_books.helpers import arr_to_xr
from luto.tools.report.data_tools.parameters import GHG_NAMES
from luto.tools.spatializers import create_2d_map
from luto.tools.report.create_report_layers import save_report_layer
from luto.tools.report.create_report_data import save_report_data

import luto.economics.agricultural.quantity as ag_quantity                      
import luto.economics.agricultural.revenue as ag_revenue
import luto.economics.agricultural.cost as ag_cost
import luto.economics.agricultural.transitions as ag_transitions
import luto.economics.agricultural.ghg as ag_ghg
import luto.economics.agricultural.water as ag_water
import luto.economics.agricultural.biodiversity as ag_biodiversity

import luto.economics.non_agricultural.quantity as non_ag_quantity              
import luto.economics.non_agricultural.revenue as non_ag_revenue
import luto.economics.non_agricultural.cost as non_ag_cost
import luto.economics.non_agricultural.transitions as non_ag_transitions
import luto.economics.non_agricultural.ghg as non_ag_ghg
import luto.economics.non_agricultural.water as non_ag_water
import luto.economics.non_agricultural.biodiversity as non_ag_biodiversity


def write_outputs(data: Data):
    """Write outputs using dynamic timestamp from read_timestamp."""
    
    # Generate path using read_timestamp each time this function is called
    current_timestamp = tools.read_timestamp()
    log_path = f"{settings.OUTPUT_DIR}/{current_timestamp}_RF{settings.RESFACTOR}_{settings.SIM_YEARS[0]}-{settings.SIM_YEARS[-1]}/LUTO_RUN_"
    
    @tools.LogToFile(log_path)
    def _write_outputs():
        # Start recording memory usage
        stop_event = threading.Event()
        memory_thread = threading.Thread(target=tools.log_memory_usage, args=(f"{settings.OUTPUT_DIR}/{current_timestamp}_RF{settings.RESFACTOR}_{settings.SIM_YEARS[0]}-{settings.SIM_YEARS[-1]}", 'a', 1, stop_event))
        memory_thread.start()
        try:
            write_data(data)
            create_report(data)
        except Exception as e:
            print(f"An error occurred while writing outputs: {e}")
            raise e
        finally:
            # Ensure the memory logging thread is stopped
            stop_event.set()
            memory_thread.join()
    
    return _write_outputs()



def write_data(data: Data):
    years = [i for i in settings.SIM_YEARS if i<=data.last_year]
    paths = [f"{data.path}/out_{yr}" for yr in years]
    write_settings(data.path)
    # Wrap write to a list of delayed jobs
    jobs = [delayed(write_area_transition_start_end)(data, f'{data.path}/out_{years[-1]}', years[-1])]
    for (yr, path_yr) in zip(years, paths):
        jobs += write_output_single_year(data, yr, path_yr)
    # Filter out None values from the jobs list
    jobs = [job for job in jobs if job is not None]
    # Parallel write the outputs for each year
    num_jobs = (
        min(len(jobs), settings.WRITE_THREADS) 
        if settings.PARALLEL_WRITE else 1
    )
    for out in Parallel(n_jobs=num_jobs, return_as='generator')(jobs):
        print(out)


def write_settings(path):
    with open('luto/settings.py', 'r') as file:
        lines = file.readlines()
        parameter_reg = re.compile(r"^(\s*[A-Z].*?)\s*=")
        settings_order = [match[1].strip() for line in lines if (match := parameter_reg.match(line))]
        settings_dict = {i: getattr(settings, i) for i in dir(settings) if i.isupper()}
        settings_dict = {i: settings_dict[i] for i in settings_order if i in settings_dict}
    with open(os.path.join(path, 'model_run_settings.txt'), 'w') as f:
        f.writelines(f'{k}:{v}\n' for k, v in settings_dict.items())
    return "Settings written successfully"



def create_report(data: Data):
    """Create report using dynamic timestamp from read_timestamp."""
    
    # Generate path using read_timestamp each time this function is called
    current_timestamp = tools.read_timestamp()
    save_dir = f"{settings.OUTPUT_DIR}/{current_timestamp}_RF{settings.RESFACTOR}_{settings.SIM_YEARS[0]}-{settings.SIM_YEARS[-1]}"
    log_path = f"{save_dir}/LUTO_RUN_"
    
    @tools.LogToFile(log_path, mode='a')
    def _create_report():
        print('Creating report...')
        print(' --| Copying report template...')
        shutil.copytree('luto/tools/report/VUE_modules', f"{data.path}/DATA_REPORT", dirs_exist_ok=True)
        print(' --| Creating chart data...')
        save_report_data(data.path)
        print(' --| Creating map data...')
        save_report_layer(data, data.path)
        print(' --| Report created successfully!')
    
    return _create_report()


        
def save2nc(in_xr:xr.DataArray, save_path:str):
    encoding = {'data':{
        'dtype': 'float32',
        'zlib': True,
        'complevel': 4,
        'chunksizes': [v[0] for k, v in in_xr.chunksizes.items()]
    }}
    in_xr.name = 'data'
    in_xr = in_xr.drop_vars(set(in_xr.coords) - set(in_xr.dims))
    in_xr.astype('float32').to_netcdf(save_path, encoding=encoding, compute=True)



def write_output_single_year(data: Data, yr_cal, path_yr):
    """Wrap write tasks for a single year"""

    if not os.path.isdir(path_yr):
        os.mkdir(path_yr)
        
    tasks = [
        delayed(write_files)(data, yr_cal, path_yr),
        delayed(write_mosaic_map)(data, yr_cal, path_yr),
        delayed(write_dvar_area)(data, yr_cal, path_yr),
        delayed(write_crosstab)(data, yr_cal, path_yr),
        delayed(write_quantity)(data, yr_cal, path_yr),
        delayed(write_quantity_separate)(data, yr_cal, path_yr),
        delayed(write_revenue_cost_ag)(data, yr_cal, path_yr),
        delayed(write_revenue_cost_ag_man)(data, yr_cal, path_yr),
        delayed(write_revenue_cost_non_ag)(data, yr_cal, path_yr),
        delayed(write_transition_cost_ag2ag)(data, yr_cal, path_yr),
        delayed(write_transition_cost_to_ag2nonag)(data, yr_cal, path_yr),
        delayed(write_transition_cost_nonag2ag)(data, yr_cal, path_yr),
        delayed(write_transition_cost_apply_ag_man)(data),
        delayed(write_water)(data, yr_cal, path_yr),
        delayed(write_ghg)(data, yr_cal, path_yr),
        delayed(write_ghg_separate)(data, yr_cal, path_yr),
        delayed(write_ghg_offland_commodity)(data, yr_cal, path_yr),
        delayed(write_biodiversity_overall_quanlity_scores)(data, yr_cal, path_yr),
        delayed(write_biodiversity_GBF2_scores)(data, yr_cal, path_yr),
        delayed(write_biodiversity_GBF3_scores)(data, yr_cal, path_yr),
        delayed(write_biodiversity_GBF4_SNES_scores)(data, yr_cal, path_yr),
        delayed(write_biodiversity_GBF4_ECNES_scores)(data, yr_cal, path_yr),
        delayed(write_biodiversity_GBF8_scores_groups)(data, yr_cal, path_yr),
        delayed(write_biodiversity_GBF8_scores_species)(data, yr_cal, path_yr)
    ]

    return tasks



def write_files(data: Data, yr_cal, path):
    
    # Write raw dvars
    dvar_ag = tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]).chunk({'cell': min(1024, data.NCELLS)})
    dvar_non_ag = tools.non_ag_rk_to_xr(data, data.non_ag_dvars[yr_cal]).chunk({'cell': min(1024, data.NCELLS)})
    dvar_ag_man = tools.am_mrj_to_xr(data, data.ag_man_dvars[yr_cal]).chunk({'cell': min(1024, data.NCELLS)})
    
    # Expand dimension
    dvar_ag = xr.concat([dvar_ag, dvar_ag.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    dvar_ag_man = xr.concat([dvar_ag_man, dvar_ag_man.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    dvar_ag_man = xr.concat([dvar_ag_man, dvar_ag_man.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')
    
    save2nc(dvar_ag, os.path.join(path, f'xr_dvar_ag_{yr_cal}.nc'))
    save2nc(dvar_non_ag, os.path.join(path, f'xr_dvar_non_ag_{yr_cal}.nc'))
    save2nc(dvar_ag_man, os.path.join(path, f'xr_dvar_ag_man_{yr_cal}.nc'))

    # Write out raw numpy arrays for land-use and land management
    lumap_xr = arr_to_xr(data, data.lumaps[yr_cal]).chunk('auto')
    lmmap_xr = arr_to_xr(data, data.lmmaps[yr_cal]).chunk('auto')
    lumap_xr.to_netcdf(os.path.join(path, f'xr_map_lumap_{yr_cal}.nc'))
    lmmap_xr.to_netcdf(os.path.join(path, f'xr_map_lmmap_{yr_cal}.nc'))
    
    return f"Decision variables written for year {yr_cal}"


def write_mosaic_map(data: Data, yr_cal, path):
    
    # Individual maps
    ag_map = tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]).sum('lm').chunk({'cell': min(1024, data.NCELLS)})
    non_ag_map = tools.non_ag_rk_to_xr(data, data.non_ag_dvars[yr_cal]).chunk({'cell': min(1024, data.NCELLS)})
    am_map = tools.am_mrj_to_xr(data, data.ag_man_dvars[yr_cal]).sum(['lm','lu']).transpose('cell','am').chunk({'cell': min(1024, data.NCELLS)})

    ag_mask = (ag_map.sum('lu') > 0.01).values
    non_ag_mask = (non_ag_map.sum('lu') > 0.01).values
    am_mask = (am_map.sum('am') > 0.01).values

    ag_map = ag_map.where(ag_mask[:, None])                # Sum of ag land that is < 1% is set to NA
    non_ag_map = non_ag_map.where(non_ag_mask[:, None])    # Sum of non-ag land that is < 1% is set to NA
    am_map = am_map.where(am_mask[:, None])   

    save2nc(ag_map, os.path.join(path, f'xr_map_ag_{yr_cal}.nc'))
    save2nc(non_ag_map, os.path.join(path, f'xr_map_non_ag_{yr_cal}.nc'))
    save2nc(am_map, os.path.join(path, f'xr_map_am_{yr_cal}.nc'))

    # Mosaic maps
    ag_map_argmax = ag_map.argmax(dim='lu', skipna=False).where(ag_mask)
    non_ag_map_argmax = non_ag_map.argmax(dim='lu', skipna=False).where(non_ag_mask) + settings.NON_AGRICULTURAL_LU_BASE_CODE
    am_argmax = am_map.argmax(dim='am', skipna=False).where(am_mask)

    ag_map_argmax = arr_to_xr(data, ag_map_argmax)
    non_ag_map_argmax = arr_to_xr(data, non_ag_map_argmax)
    am_argmax = arr_to_xr(data, am_argmax)

    ag_map_argmax.to_netcdf(os.path.join(path, f'xr_map_ag_argmax_{yr_cal}.nc'))            # Save directly to netcdf to keep the crs
    non_ag_map_argmax.to_netcdf(os.path.join(path, f'xr_map_non_ag_argmax_{yr_cal}.nc'))
    am_argmax.to_netcdf(os.path.join(path, f'xr_map_am_argmax_{yr_cal}.nc'))

    return f"Mosaic maps written for year {yr_cal}"



def write_quantity(data: Data, yr_cal, path):
    
    simulated_year_list = sorted(list(data.lumaps.keys()))
    yr_idx = yr_cal - data.YR_CAL_BASE
    yr_idx_sim = sorted(list(data.lumaps.keys())).index(yr_cal)
    yr_cal_sim_pre = simulated_year_list[yr_idx_sim - 1]

    # Calculate data for quantity comparison between base year and target year
    if yr_cal > data.YR_CAL_BASE:
        # Check if yr_cal_sim_pre meets the requirement
        assert data.YR_CAL_BASE <= yr_cal_sim_pre < yr_cal, f"yr_cal_sim_pre ({yr_cal_sim_pre}) must be >= {data.YR_CAL_BASE} and < {yr_cal}"

        # Get commodity production quantities produced in base year and target year
        prod_base = np.array(data.prod_data[yr_cal_sim_pre]['Production'])
        prod_targ = np.array(data.prod_data[yr_cal]['Production'])
        demands = data.D_CY[yr_idx]  # Get commodity demands for target year

        # Calculate differences
        abs_diff = prod_targ - demands
        prop_diff = (prod_targ / demands) * 100

        # Create pandas dataframe
        df = pd.DataFrame({
            'Commodity': [i[0].capitalize() + i[1:] for i in data.COMMODITIES],
            'Prod_base_year (tonnes, KL)': prod_base,
            'Prod_targ_year (tonnes, KL)': prod_targ,
            'Demand (tonnes, KL)': demands,
            'Abs_diff (tonnes, KL)': abs_diff,
            'Prop_diff (%)': prop_diff
        })

        # Save files to disk
        df['Year'] = yr_cal
        df.to_csv(os.path.join(path, f'quantity_comparison_{yr_cal}.csv'), index=False)

    return f"Quantity comparison written for year {yr_cal}"


        
def write_quantity_separate(data: Data, yr_cal: int, path: str) -> np.ndarray:
    """
    Return total production of commodities for a specific year...

    'yr_cal' is calendar year

    Can return base year production (e.g., year = 2010) or can return production for
    a simulated year if one exists (i.e., year = 2030).

    Includes the impacts of land-use change, productivity increases, and
    climate change on yield.
    """
    if yr_cal == data.YR_CAL_BASE:
        ag_X_mrj = data.AG_L_MRJ
        non_ag_X_rk = data.NON_AG_L_RK
        ag_man_X_mrj = data.AG_MAN_L_MRJ_DICT
        
    else: # In this case, the dvars are already appended from the solver
        ag_X_mrj = data.ag_dvars[yr_cal]
        non_ag_X_rk = data.non_ag_dvars[yr_cal]
        ag_man_X_mrj = data.ag_man_dvars[yr_cal]

    # Calculate year index (i.e., number of years since 2010)
    yr_idx = yr_cal - data.YR_CAL_BASE
    lumap = data.lumaps[yr_cal]

    # Convert np.array to xr.DataArray; Chunk the data to reduce memory usage
    ag_X_mrj_xr = tools.ag_mrj_to_xr(data, ag_X_mrj).chunk({'cell': min(4096, data.NCELLS)})
    non_ag_X_rk_xr = tools.non_ag_rk_to_xr(data, non_ag_X_rk).chunk({'cell': min(4096, data.NCELLS)})
    ag_man_X_mrj_xr = tools.am_mrj_to_xr(data, ag_man_X_mrj).chunk({'cell': min(4096, data.NCELLS)})


    # Convert LU2PR and PR2CM to xr.DataArray 
    lu2pr_xr = xr.DataArray(
        data.LU2PR.astype(bool),
        dims=['product', 'lu'],
        coords={
            'product': data.PRODUCTS,
            'lu': data.AGRICULTURAL_LANDUSES
        },
    )

    pr2cm_xr = xr.DataArray(
        data.PR2CM.astype(bool),
        dims=['Commodity', 'product'],
        coords={
            'Commodity': data.COMMODITIES,
            'product': data.PRODUCTS
        },
    )

    # Get commodity matrices
    ag_q_mrp_xr = xr.DataArray(
        ag_quantity.get_quantity_matrices(data, yr_idx),
        dims=['lm','cell','product'],
        coords={
            'lm': data.LANDMANS,
            'cell': range(data.NCELLS),
            'product': data.PRODUCTS
        },
    ).assign_coords(
        region=('cell', data.REGION_NRM_NAME),
    )

    non_ag_crk_xr = xr.DataArray(
        non_ag_quantity.get_quantity_matrix(data, ag_q_mrp_xr, lumap),
        dims=['Commodity', 'cell', 'lu'],
        coords={
            'Commodity': data.COMMODITIES,
            'cell': range(data.NCELLS),
            'lu': data.NON_AGRICULTURAL_LANDUSES
        },
    ).assign_coords(
        region=('cell', data.REGION_NRM_NAME),
    )

    ag_man_q_mrp_xr = xr.DataArray(
        np.stack([arr for arr in ag_quantity.get_agricultural_management_quantity_matrices(data, ag_q_mrp_xr, yr_idx).values()]),
        dims=['am', 'lm', 'cell', 'product'],
        coords={'am': data.AG_MAN_DESC,
                'lm': data.LANDMANS,
                'cell': np.arange(data.NCELLS),
                'product': data.PRODUCTS}
    ).assign_coords(
        region=('cell', data.REGION_NRM_NAME),
    )

    # Expand dimension
    ag_X_mrj_xr = xr.concat([ag_X_mrj_xr, ag_X_mrj_xr.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    ag_man_X_mrj_xr = xr.concat([ag_man_X_mrj_xr, ag_man_X_mrj_xr.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    ag_man_X_mrj_xr = xr.concat([ag_man_X_mrj_xr, ag_man_X_mrj_xr.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')
    ag_q_mrp_xr = xr.concat([ag_q_mrp_xr, ag_q_mrp_xr.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    ag_man_q_mrp_xr = xr.concat([ag_man_q_mrp_xr, ag_man_q_mrp_xr.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    ag_man_q_mrp_xr = xr.concat([ag_man_q_mrp_xr, ag_man_q_mrp_xr.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')

    # Calculate the commodity production 
    ag_q_rc = (((ag_X_mrj_xr * lu2pr_xr).sum(dim=['lu']) * ag_q_mrp_xr) * pr2cm_xr).sum(dim='product')
    non_ag_p_rc = (non_ag_X_rk_xr * non_ag_crk_xr).sum(dim=['lu'])
    am_p_rc = (((ag_man_X_mrj_xr * lu2pr_xr).sum(['lu']) * ag_man_q_mrp_xr) * pr2cm_xr).sum('product')

    # Regional level aggregation
    ag_q_rc_df_region = ag_q_rc.groupby('region'
        ).sum('cell'
        ).to_dataframe('Production (t/KL)'
        ).reset_index(
        ).assign(Type='Agricultural'
        ).rename(columns={'lu': 'Land-use', 'lm':'Water_supply'}
        ).assign(Year=yr_cal
        ).replace({'dry':'Dryland', 'irr':'Irrigated'})
    non_ag_p_rc_df_region = non_ag_p_rc.groupby('region'
        ).sum('cell'
        ).to_dataframe('Production (t/KL)'
        ).assign(Type='Non-Agricultural'
        ).reset_index()
    am_p_rc_df_region = am_p_rc.groupby('region'
        ).sum('cell'
        ).to_dataframe('Production (t/KL)'
        ).reset_index(
        ).assign(Type='Agricultural Management'
        ).rename(columns={'lu': 'Land-use', 'lm':'Water_supply'}
        ).assign(Year=yr_cal
        ).replace({'dry':'Dryland', 'irr':'Irrigated'})
    
    # Australia level aggregation
    ag_q_rc_df_AUS = ag_q_rc.sum('cell'
        ).to_dataframe('Production (t/KL)'
        ).reset_index(
        ).assign(Type='Agricultural'
        ).rename(columns={'lu': 'Land-use', 'lm':'Water_supply'}
        ).assign(Year=yr_cal, region='AUSTRALIA'
        ).replace({'dry':'Dryland', 'irr':'Irrigated'})
    non_ag_p_rc_df_AUS = non_ag_p_rc.sum('cell'
        ).to_dataframe('Production (t/KL)'
        ).assign(Type='Non-Agricultural', region='AUSTRALIA'
        ).reset_index()
    am_p_rc_df_AUS = am_p_rc.sum('cell'
        ).to_dataframe('Production (t/KL)'
        ).reset_index(
        ).assign(Type='Agricultural Management'
        ).rename(columns={'lu': 'Land-use', 'lm':'Water_supply'}
        ).assign(Year=yr_cal, region='AUSTRALIA'
        ).replace({'dry':'Dryland', 'irr':'Irrigated'})
    
    # Save the production dataframes to csv
    quantity_df_AUS = pd.concat([ag_q_rc_df_AUS, non_ag_p_rc_df_AUS, am_p_rc_df_AUS], ignore_index=True).query('`Production (t/KL)` > 1e-2')
    quantity_df_region = pd.concat([ag_q_rc_df_region, non_ag_p_rc_df_region, am_p_rc_df_region], ignore_index=True).query('`Production (t/KL)` > 1e-2')
    pd.concat([quantity_df_AUS, quantity_df_region]).to_csv(os.path.join(path, f'quantity_production_t_separate_{yr_cal}.csv'), index=False)
    
    save2nc(ag_q_rc, os.path.join(path, f'xr_quantities_agricultural_{yr_cal}.nc'))
    save2nc(non_ag_p_rc, os.path.join(path, f'xr_quantities_non_agricultural_{yr_cal}.nc'))
    save2nc(am_p_rc, os.path.join(path, f'xr_quantities_agricultural_management_{yr_cal}.nc'))

    return f"Separate quantity production written for year {yr_cal}"


def write_revenue_cost_ag(data: Data, yr_cal, path):
    """Calculate agricultural revenue. Takes a simulation object, a target calendar
       year (e.g., 2030), and an output path as input."""

    
    yr_idx = yr_cal - data.YR_CAL_BASE
    ag_dvar_mrj = tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]).chunk({'cell': min(1024, data.NCELLS)})

    # Get agricultural revenue/cost for year in mrjs format
    ag_rev_df_rjms = ag_revenue.get_rev_matrices(data, yr_idx, aggregate=False)
    ag_cost_df_rjms = ag_cost.get_cost_matrices(data, yr_idx, aggregate=False)
    ag_rev_rjms = ag_rev_df_rjms.reindex(columns=pd.MultiIndex.from_product(ag_rev_df_rjms.columns.levels), fill_value=0).values.reshape(-1, *ag_rev_df_rjms.columns.levshape)
    ag_cost_rjms = ag_cost_df_rjms.reindex(columns=pd.MultiIndex.from_product(ag_cost_df_rjms.columns.levels), fill_value=0).values.reshape(-1, *ag_cost_df_rjms.columns.levshape)

    # Convert the ag_rev_rjms and ag_cost_rjms to xarray DataArray, 
    # and assign region names to the cell dimension
    ag_rev_rjms = xr.DataArray(
            ag_rev_rjms,
            dims=['cell', 'lu', 'lm', 'source'],
            coords={
                'cell': range(data.NCELLS),
                'lu': data.AGRICULTURAL_LANDUSES,
                'lm': data.LANDMANS,
                'source': ag_rev_df_rjms.columns.levels[2]
            }
        ).assign_coords(
            region = ('cell', data.REGION_NRM_NAME),
        )
    ag_cost_rjms = xr.DataArray(
            ag_cost_rjms,
            dims=['cell', 'lu', 'lm', 'source'],
            coords={
                'cell': range(data.NCELLS),
                'lu': data.AGRICULTURAL_LANDUSES,
                'lm': data.LANDMANS,
                'source': ag_cost_df_rjms.columns.levels[2]
            }
        ).assign_coords(
            region = ('cell', data.REGION_NRM_NAME),
        )


    # Expand dimension
    ag_dvar_mrj = xr.concat([ag_dvar_mrj, ag_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    ag_rev_rjms = xr.concat([ag_rev_rjms, ag_rev_rjms.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    ag_rev_rjms = xr.concat([ag_rev_rjms, ag_rev_rjms.sum(dim='source', keepdims=True).assign_coords(source=['ALL'])], dim='source')
    ag_cost_rjms = xr.concat([ag_cost_rjms, ag_cost_rjms.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    ag_cost_rjms = xr.concat([ag_cost_rjms, ag_cost_rjms.sum(dim='source', keepdims=True).assign_coords(source=['ALL'])], dim='source')

    # Multiply the ag_dvar_mrj with the ag_rev_mrj to get the ag_rev_jm
    xr_ag_rev = ag_dvar_mrj * ag_rev_rjms
    xr_ag_cost = ag_dvar_mrj * ag_cost_rjms
    
    # Regional level aggregation
    ag_rev_jms_region = xr_ag_rev.groupby('region').sum(dim='cell').to_dataframe('Value ($)').reset_index()
    ag_cost_jms_region = xr_ag_cost.groupby('region').sum(dim='cell').to_dataframe('Value ($)').reset_index()

    ag_rev_jms_region = ag_rev_jms_region.rename(columns={
            'lu': 'Land-use',
            'lm': 'Water_supply',
            'source': 'Type'
        }).replace({
            'dry': 'Dryland',
            'irr': 'Irrigated'
        }).assign(Year=yr_cal)
    ag_cost_jms_region = ag_cost_jms_region.rename(columns={
            'lu': 'Land-use',
            'lm': 'Water_supply',
            'source': 'Type'
        }).replace({
            'dry': 'Dryland',
            'irr': 'Irrigated'
        }).assign(Year=yr_cal)
        
    # Australia level aggregation
    ag_rev_jms_AUS = xr_ag_rev.sum(dim='cell').to_dataframe('Value ($)').reset_index()
    ag_cost_jms_AUS = xr_ag_cost.sum(dim='cell').to_dataframe('Value ($)').reset_index()

    ag_rev_jms_AUS = ag_rev_jms_AUS.rename(columns={
            'lu': 'Land-use',
            'lm': 'Water_supply',
            'source': 'Type'
        }).replace({
            'dry': 'Dryland',
            'irr': 'Irrigated'
        }).assign(Year=yr_cal, region='AUSTRALIA')
    ag_cost_jms_AUS = ag_cost_jms_AUS.rename(columns={
            'lu': 'Land-use',
            'lm': 'Water_supply',
            'source': 'Type'
        }).replace({
            'dry': 'Dryland',
            'irr': 'Irrigated'
        }).assign(Year=yr_cal, region='AUSTRALIA')
        
    # Save to disk
    pd.concat([ag_rev_jms_AUS, ag_rev_jms_region]).to_csv(os.path.join(path, f'revenue_ag_{yr_cal}.csv'), index=False)
    pd.concat([ag_cost_jms_AUS, ag_cost_jms_region]).to_csv(os.path.join(path, f'cost_ag_{yr_cal}.csv'), index=False)
    
    save2nc(xr_ag_rev, os.path.join(path, f'xr_revenue_ag_{yr_cal}.nc'))
    save2nc(xr_ag_cost, os.path.join(path, f'xr_cost_ag_{yr_cal}.nc'))

    return f"Agricultural revenue and cost written for year {yr_cal}"



def write_revenue_cost_ag_man(data: Data, yr_cal, path):
    """Calculate agricultural management revenue and cost."""

    
    yr_idx = yr_cal - data.YR_CAL_BASE

    # Get the ag-man dvars
    am_dvar_mrj = tools.am_mrj_to_xr(data, data.ag_man_dvars[yr_cal]
        ).assign_coords(region = ('cell', data.REGION_NRM_NAME),
        ).chunk({'cell': min(1024, data.NCELLS)})

    # Get the revenue/cost matrices for each agricultural land-use
    ag_rev_mrj = ag_revenue.get_rev_matrices(data, yr_idx)
    ag_cost_mrj = ag_cost.get_cost_matrices(data, yr_idx)
    am_revenue_mat = tools.am_mrj_to_xr(data, ag_revenue.get_agricultural_management_revenue_matrices(data, ag_rev_mrj, yr_idx))
    am_cost_mat = tools.am_mrj_to_xr(data, ag_cost.get_agricultural_management_cost_matrices(data, ag_cost_mrj, yr_idx))
    
    # Expand dimension
    am_dvar_mrj = xr.concat([am_dvar_mrj, am_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    am_dvar_mrj = xr.concat([am_dvar_mrj, am_dvar_mrj.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')
    am_revenue_mat = xr.concat([am_revenue_mat, am_revenue_mat.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    am_revenue_mat = xr.concat([am_revenue_mat, am_revenue_mat.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')
    am_cost_mat = xr.concat([am_cost_mat, am_cost_mat.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    am_cost_mat = xr.concat([am_cost_mat, am_cost_mat.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')

    # Multiply the am_dvar_mrj with the am_revenue_mat to get the revenue and cost
    xr_revenue_am = am_dvar_mrj * am_revenue_mat
    xr_cost_am = am_dvar_mrj * am_cost_mat
    
    # Regional level aggregation
    revenue_am_df_region = xr_revenue_am.groupby('region'
        ).sum(dim='cell'
        ).to_dataframe('Value ($)'
        ).reset_index(
        ).assign(Year = yr_cal
        ).rename(
            columns={
                'lu': 'Land-use',
                'lm': 'Water_supply',
                'am': 'Management Type'
        }).replace(
            {'dry': 'Dryland', 'irr': 'Irrigated'}
        )
    cost_am_df_region = xr_cost_am.groupby('region'
        ).sum(dim='cell'
        ).to_dataframe('Value ($)'
        ).reset_index(
        ).assign(Year = yr_cal
        ).rename(
            columns={
                'lu': 'Land-use',
                'lm': 'Water_supply',
                'am': 'Management Type'
        }).replace(
            {'dry': 'Dryland', 'irr': 'Irrigated'}
        )

    # Australia level aggregation
    revenue_am_df_AUS = xr_revenue_am.sum(dim='cell'
        ).to_dataframe('Value ($)'
        ).reset_index(
        ).assign(Year = yr_cal, region='AUSTRALIA'
        ).rename(
            columns={
                'lu': 'Land-use',
                'lm': 'Water_supply',
                'am': 'Management Type'
        }).replace(
            {'dry': 'Dryland', 'irr': 'Irrigated'}
        )
    cost_am_df_AUS = xr_cost_am.sum(dim='cell'
        ).to_dataframe('Value ($)'
        ).reset_index(
        ).assign(Year = yr_cal, region='AUSTRALIA'
        ).rename(
            columns={
                'lu': 'Land-use',
                'lm': 'Water_supply',
                'am': 'Management Type'
        }).replace(
            {'dry': 'Dryland', 'irr': 'Irrigated'}
        )

    # Save to disk
    pd.concat([revenue_am_df_AUS, revenue_am_df_region]).to_csv(os.path.join(path, f'revenue_agricultural_management_{yr_cal}.csv'), index=False)
    pd.concat([cost_am_df_AUS, cost_am_df_region]).to_csv(os.path.join(path, f'cost_agricultural_management_{yr_cal}.csv'), index=False)
    
    save2nc(xr_revenue_am, os.path.join(path, f'xr_revenue_agricultural_management_{yr_cal}.nc'))
    save2nc(xr_cost_am, os.path.join(path, f'xr_cost_agricultural_management_{yr_cal}.nc'))
    
    return f"Agricultural Management revenue and cost written for year {yr_cal}"


def write_revenue_cost_non_ag(data: Data, yr_cal, path):
    """Calculate non_agricultural cost. """

        
    yr_idx = yr_cal - data.YR_CAL_BASE

    non_ag_dvar = tools.non_ag_rk_to_xr(data, data.non_ag_dvars[yr_cal]
        ).assign_coords( region=('cell', data.REGION_NRM_NAME)
        ).chunk({'cell': min(1024, data.NCELLS)})


    # Get the non-agricultural revenue/cost matrices
    non_ag_rev_mat = tools.non_ag_rk_to_xr(
        data, 
        non_ag_revenue.get_rev_matrix(data, yr_cal, ag_revenue.get_rev_matrices(data, yr_idx), data.lumaps[yr_cal]) 
    )   
    non_ag_cost_mat = tools.non_ag_rk_to_xr(
        data, 
        non_ag_cost.get_cost_matrix(data, ag_cost.get_cost_matrices(data, yr_idx), data.lumaps[yr_cal], yr_cal)    
    )   

    xr_revenue_non_ag = non_ag_dvar * non_ag_rev_mat
    xr_cost_non_ag = non_ag_dvar * non_ag_cost_mat

    # Regional level aggregation
    rev_non_ag_df_region = xr_revenue_non_ag.groupby('region'
        ).sum(dim='cell'
        ).to_dataframe('Value ($)'
        ).reset_index(
        ).assign(Year=yr_cal
        ).rename(columns={'lu': 'Land-use'})
    cost_non_ag_df_region = xr_cost_non_ag.groupby('region'
        ).sum(dim='cell'
        ).to_dataframe('Value ($)'
        ).reset_index(
        ).assign(Year=yr_cal
        ).rename(columns={'lu': 'Land-use'})

    # Australia level aggregation
    rev_non_ag_df_AUS = xr_revenue_non_ag.sum(dim='cell'
        ).to_dataframe('Value ($)'
        ).reset_index(
        ).assign(Year=yr_cal, region='AUSTRALIA'
        ).rename(columns={'lu': 'Land-use'})
    cost_non_ag_df_AUS = xr_cost_non_ag.sum(dim='cell'
        ).to_dataframe('Value ($)'
        ).reset_index(
        ).assign(Year=yr_cal, region='AUSTRALIA'
        ).rename(columns={'lu': 'Land-use'})

    # Save to disk
    pd.concat([rev_non_ag_df_AUS, rev_non_ag_df_region]).to_csv(os.path.join(path, f'revenue_non_ag_{yr_cal}.csv'), index = False)
    pd.concat([cost_non_ag_df_AUS, cost_non_ag_df_region]).to_csv(os.path.join(path, f'cost_non_ag_{yr_cal}.csv'), index = False)
    
    save2nc(xr_revenue_non_ag, os.path.join(path, f'xr_revenue_non_ag_{yr_cal}.nc'))
    save2nc(xr_cost_non_ag, os.path.join(path, f'xr_cost_non_ag_{yr_cal}.nc'))

    return f"Non-agricultural revenue and cost written for year {yr_cal}"



def write_transition_cost_ag2ag(data: Data, yr_cal, path, yr_cal_sim_pre=None):
    """Calculate transition cost."""

    
    simulated_year_list = sorted(list(data.lumaps.keys()))
    yr_idx = yr_cal - data.YR_CAL_BASE

    # Get index of yr_cal in simulated_year_list (e.g., if yr_cal is 2050 then yr_idx_sim = 2 if snapshot)
    yr_idx_sim = simulated_year_list.index(yr_cal)
    yr_cal_sim_pre = simulated_year_list[yr_idx_sim - 1] if yr_cal_sim_pre is None else yr_cal_sim_pre

    # Get the decision variables for agricultural land-use
    ag_dvar_mrj_target = tools.ag_mrj_to_xr(data, tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]).assign_coords(region=('cell', data.REGION_NRM_NAME)))
    ag_dvar_mrj_base = tools.ag_mrj_to_xr(data, (tools.lumap2ag_l_mrj(data.lumaps[yr_cal_sim_pre], data.lmmaps[yr_cal_sim_pre])))

    ag_dvar_mrj_target = ag_dvar_mrj_target.rename({'lm': 'To water-supply', 'lu': 'To land-use'}
        ).assign_coords( region=('cell', data.REGION_NRM_NAME)
        ).chunk({'cell': min(1024, data.NCELLS)})

    ag_dvar_mrj_base = ag_dvar_mrj_base.rename({'lm': 'From water-supply', 'lu': 'From land-use'}
        ).assign_coords( region=('cell', data.REGION_NRM_NAME)
        ).chunk({'cell': min(1024, data.NCELLS)})

    # Get the transition cost matrices for agricultural land-use
    if yr_idx == 0:
        ag_transitions_cost_mat = {'Establishment cost': np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS)).astype(np.float32)}
    else:
        # Get the transition cost matrices for agricultural land-use
        ag_transitions_cost_mat = ag_transitions.get_transition_matrices_ag2ag_from_base_year(data, yr_idx, yr_cal_sim_pre, separate=True)
        
    ag_transitions_cost_mat = xr.DataArray(
        np.stack(list(ag_transitions_cost_mat.values())),
        coords={
            'Type': list(ag_transitions_cost_mat.keys()),
            'To water-supply': data.LANDMANS,
            'cell': range(data.NCELLS),
            'To land-use': data.AGRICULTURAL_LANDUSES
        }
    )

    cost_xr = ag_dvar_mrj_base * ag_dvar_mrj_target * ag_transitions_cost_mat
    cost_df = cost_xr.groupby('region'
        ).sum(dim='cell'
        ).to_dataframe('Cost ($)'
        ).reset_index(
        ).assign(
            Year=yr_cal
        ).query('`Cost ($)` > 0')
                

    # Save the cost DataFrames
    cost_df = cost_df.replace({'dry':'Dryland', 'irr':'Irrigated'})
    cost_df.to_csv(os.path.join(path, f'cost_transition_ag2ag_{yr_cal}.csv'), index=False)
    
    save2nc(cost_xr, os.path.join(path, f'xr_cost_transition_ag2ag_{yr_cal}.nc'))

    return f"Agricultural to agricultural transition cost written for year {yr_cal}"




def write_transition_cost_to_ag2nonag(data: Data, yr_cal, path, yr_cal_sim_pre=None):
    """Calculate transition cost."""

    
    # Retrieve list of simulation years (e.g., [2010, 2050] for snapshot or [2010, 2011, 2012] for timeseries)
    simulated_year_list = sorted(list(data.lumaps.keys()))
    yr_idx = yr_cal - data.YR_CAL_BASE

    # Get index of yr_cal in simulated_year_list (e.g., if yr_cal is 2050 then yr_idx_sim = 2 if snapshot)
    yr_idx_sim = simulated_year_list.index(yr_cal)
    yr_cal_sim_pre = simulated_year_list[yr_idx_sim - 1] if yr_cal_sim_pre is None else yr_cal_sim_pre

    # Get the non-agricultural decision variable
    ag_dvar_base = tools.ag_mrj_to_xr(data, tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]
        ).assign_coords(region=('cell', data.REGION_NRM_NAME)))
    non_ag_dvar_target = tools.non_ag_rk_to_xr(data, tools.non_ag_rk_to_xr(data, data.non_ag_dvars[yr_cal])
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))

    ag_dvar_base = ag_dvar_base.rename({'lm': 'From water-supply', 'lu': 'From land-use'}).chunk({'cell': min(1024, data.NCELLS)})
    non_ag_dvar_target = non_ag_dvar_target.rename({'lu': 'To land-use'}).chunk({'cell': min(1024, data.NCELLS)})


    # Get the transition cost matirces for non-agricultural land-use
    if yr_idx == 0:
        non_ag_transitions_cost_mat = {
            k:{'Transition cost':np.zeros(data.NCELLS).astype(np.float32)}
            for k in settings.NON_AG_LAND_USES.keys()
        }
    else:
        non_ag_transitions_cost_mat = non_ag_transitions.get_transition_matrix_ag2nonag(
            data, yr_idx, data.lumaps[yr_cal_sim_pre], data.lmmaps[yr_cal_sim_pre], separate=True
        )

    non_ag_transitions_flat = {}
    for lu, sub_dict in non_ag_transitions_cost_mat.items():
        for source, arr in sub_dict.items():
            non_ag_transitions_flat[(lu, source)] = arr
            
    non_ag_transitions_flat = xr.DataArray(
        np.stack(list(non_ag_transitions_flat.values())),
        coords={
            'lu_source': pd.MultiIndex.from_tuples(
                list(non_ag_transitions_flat.keys()),
                names= ('To land-use', 'Cost type')
            ),
            'cell': range(data.NCELLS),
        }
    )

    cost_xr = ag_dvar_base * non_ag_transitions_flat.unstack('lu_source') * non_ag_dvar_target
    cost_df = cost_xr.groupby('region'
            ).sum(dim='cell'
            ).to_dataframe('Cost ($)'
            ).reset_index(
            ).assign(
                Year=yr_cal
            ).query('`Cost ($)` > 0')
    cost_df = cost_df.replace({'dry':'Dryland', 'irr':'Irrigated'})    
    cost_df.to_csv(os.path.join(path, f'cost_transition_ag2non_ag_{yr_cal}.csv'), index=False)
    
    save2nc(cost_xr, os.path.join(path, f'xr_transition_cost_ag2non_ag_{yr_cal}.nc'))
    
    return f"Agricultural to non-agricultural transition cost written for year {yr_cal}"



def write_transition_cost_apply_ag_man(data: Data):
    
    # The agricultural management transition cost are all zeros, so skip the calculation here
    # am_cost = ag_transitions.get_agricultural_management_transition_matrices(data)
    
    return "Agricultural Management transition cost processing completed"


def write_transition_cost_nonag2ag(data: Data, yr_cal, path, yr_cal_sim_pre=None):
    """Calculate transition cost."""

    
    simulated_year_list = sorted(list(data.lumaps.keys()))
    yr_idx = yr_cal - data.YR_CAL_BASE

    # Get index of yr_cal in simulated_year_list (e.g., if yr_cal is 2050 then yr_idx_sim = 2 if snapshot)
    yr_idx_sim = simulated_year_list.index(yr_cal)
    yr_cal_sim_pre = simulated_year_list[yr_idx_sim - 1] if yr_cal_sim_pre is None else yr_cal_sim_pre

    # Get the decision variables for agricultural land-use
    ag_dvar = tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]).assign_coords(region=('cell', data.REGION_NRM_NAME))

    # Get the transition cost matrices for non-agricultural land-use
    if yr_idx == 0:
        non_ag_transitions_cost_mat = {
            k:{'Transition cost (Non-Ag2Ag)':np.zeros((data.NLMS, data.NCELLS, data.N_AG_LUS)).astype(np.float32)}
            for k in settings.NON_AG_LAND_USES.keys()
        }
    else:
        non_ag_transitions_cost_mat = non_ag_transitions.get_transition_matrix_nonag2ag(
            data,
            yr_idx,
            data.lumaps[yr_cal_sim_pre],
            data.lmmaps[yr_cal_sim_pre],
            separate=True
        )

    cost_dfs = []
    for from_lu_desc, from_lu_idx in data.DESC2NONAGLU.items():
        for to_lu, to_lu_idx  in data.DESC2AGLU.items():
            for to_lm_idx, to_lm in enumerate(data.LANDMANS):
                for cost_type in non_ag_transitions_cost_mat[from_lu_desc].keys():
                    
                    
                    from_lu_cells = data.lumaps[yr_cal_sim_pre] == from_lu_idx          # Get the land-use index of the from land-use (r)
                    to_lu_cells = data.lumaps[yr_cal] == to_lu_idx                      # Get the land-use index of the to land-use (r*)
                    to_lm_cells = data.lmmaps[yr_cal] == to_lm_idx                      # Get the land-management index of the from land-management (r)
                    trans_cells =  from_lu_cells & to_lu_cells & to_lm_cells            # Get the land-use index of the from land-use (r*)
                    
                    if trans_cells.sum() == 0:
                        cost_dfs.append(
                            pd.DataFrame(
                                [{
                                    'region': data.REGION_NRM_NAME.iloc[0],
                                    'From land-use': from_lu_desc,
                                    'To land-use': to_lu,
                                    'To water-supply': to_lm,
                                    'Cost type': cost_type,
                                    'Cost ($)': 0,
                                    'Year': yr_cal
                                }]
                            )
                        )
                    else:
                        arr_dvar = ag_dvar[to_lm_idx, trans_cells, to_lu_idx]
                        arr_trans = non_ag_transitions_cost_mat[from_lu_desc][cost_type][to_lm_idx, trans_cells, to_lu_idx]
                        
                        cost_dfs.append(
                            (arr_dvar * arr_trans).groupby('region'
                            ).sum(dim='cell'
                            ).to_dataframe('Cost ($)'
                            ).reset_index(
                            ).rename(columns={'lu': 'To land-use', 'lm': 'To water-supply'}
                            ).assign(**{
                                'From land-use': from_lu_desc,
                                'Cost type': cost_type,
                                'Year': yr_cal
                            })
                        )
                    

    cost_df = pd.concat(cost_dfs, axis=0)
    cost_df = cost_df.replace({'dry':'Dryland', 'irr':'Irrigated'})
    cost_df.to_csv(os.path.join(path, f'cost_transition_non_ag2_ag_{yr_cal}.csv'), index=False)

    return f"Non-agricultural to agricultural transition cost written for year {yr_cal}"



def write_dvar_area(data: Data, yr_cal, path):
    
    # Get dvars
    ag_dvar_mrj = tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]
        ).assign_coords({'region': ('cell', data.REGION_NRM_NAME)}
        ).chunk({'cell': min(1024, data.NCELLS)})
    non_ag_rj = tools.non_ag_rk_to_xr(data, data.non_ag_dvars[yr_cal]
        ).assign_coords({'region': ('cell', data.REGION_NRM_NAME)}
        ).chunk({'cell': min(1024, data.NCELLS)})
    am_dvar_mrj = tools.am_mrj_to_xr(data, data.ag_man_dvars[yr_cal]
        ).assign_coords({'region': ('cell', data.REGION_NRM_NAME)}
        ).chunk({'cell': min(1024, data.NCELLS)})
        
    # Expand dimension
    ag_dvar_mrj = xr.concat([ag_dvar_mrj, ag_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    am_dvar_mrj = xr.concat([am_dvar_mrj, am_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    am_dvar_mrj = xr.concat([am_dvar_mrj, am_dvar_mrj.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')

    # Calculate the real area in hectares
    real_area_r = xr.DataArray(data.REAL_AREA, dims=['cell'], coords={'cell': range(data.NCELLS)})
    
    area_ag = (ag_dvar_mrj * real_area_r)
    area_non_ag = (non_ag_rj * real_area_r)
    area_am = (am_dvar_mrj * real_area_r)

    # Region level aggregation
    df_ag_area_region = area_ag.groupby('region'
        ).sum(dim='cell'
        ).to_dataframe('Area (ha)'
        ).reset_index(
        ).rename(columns={'lu': 'Land-use', 'lm':'Water_supply'}
        ).assign(Year=yr_cal
        ).replace({'dry':'Dryland', 'irr':'Irrigated'}
        ).query('`Area (ha)` > 1e-6')
    df_non_ag_area_region = area_non_ag.groupby('region'
        ).sum(dim='cell'
        ).to_dataframe('Area (ha)'
        ).reset_index(
        ).rename(columns={'lu': 'Land-use'}
        ).assign(Year=yr_cal
        ).query('`Area (ha)` > 1e-6')
    df_am_area_region = area_am.groupby('region'
        ).sum(dim='cell'
        ).to_dataframe('Area (ha)'
        ).reset_index(
        ).rename(columns={'lu': 'Land-use', 'lm':'Water_supply', 'am': 'Type'}
        ).assign(Year=yr_cal
        ).replace({'dry':'Dryland', 'irr':'Irrigated'}
        ).query('`Area (ha)` > 1e-6')
        
    # Australia level aggregation
    df_ag_area_AUS = area_ag.sum(dim='cell'
        ).to_dataframe('Area (ha)'
        ).reset_index(
        ).rename(columns={'lu': 'Land-use', 'lm':'Water_supply'}
        ).assign(Year=yr_cal, region='AUSTRALIA'
        ).replace({'dry':'Dryland', 'irr':'Irrigated'}
        ).query('`Area (ha)` > 1e-6')
    df_non_ag_area_AUS = area_non_ag.sum(dim='cell'
        ).to_dataframe('Area (ha)'
        ).reset_index(
        ).rename(columns={'lu': 'Land-use'}
        ).assign(Year=yr_cal, region='AUSTRALIA'
        ).query('`Area (ha)` > 1e-6')
    df_am_area_AUS = area_am.sum(dim='cell'
        ).to_dataframe('Area (ha)'
        ).reset_index(
        ).rename(columns={'lu': 'Land-use', 'lm':'Water_supply', 'am': 'Type'}
        ).assign(Year=yr_cal, region='AUSTRALIA'
        ).replace({'dry':'Dryland', 'irr':'Irrigated'}
        ).query('`Area (ha)` > 1e-6')
                                 

    pd.concat([df_ag_area_AUS, df_ag_area_region]).to_csv(os.path.join(path, f'area_agricultural_landuse_{yr_cal}.csv'), index = False)
    pd.concat([df_non_ag_area_AUS, df_non_ag_area_region]).to_csv(os.path.join(path, f'area_non_agricultural_landuse_{yr_cal}.csv'), index = False)
    pd.concat([df_am_area_AUS, df_am_area_region]).to_csv(os.path.join(path, f'area_agricultural_management_{yr_cal}.csv'), index = False)
    
    save2nc(area_ag, os.path.join(path, f'xr_area_agricultural_landuse_{yr_cal}.nc'))
    save2nc(area_non_ag, os.path.join(path, f'xr_area_non_agricultural_landuse_{yr_cal}.nc'))
    save2nc(area_am, os.path.join(path, f'xr_area_agricultural_management_{yr_cal}.nc'))

    return f"Decision variable areas written for year {yr_cal}"



def write_area_transition_start_end(data: Data, path, yr_cal_end):

    
    # Get the end year
    yr_cal_start = data.YR_CAL_BASE

    real_area_r = xr.DataArray(data.REAL_AREA, dims=['cell'], coords={'cell': range(data.NCELLS)})

    # Get the decision variables for the start year
    ag_dvar_base_mrj = tools.ag_mrj_to_xr(data, tools.lumap2ag_l_mrj(data.lumaps[yr_cal_start], data.lmmaps[yr_cal_start])
        ).assign_coords({'region': ('cell', data.REGION_NRM_NAME)}
        ).rename({'lu':'From Land-use', 'lm':'From Water_supply'}
        ).chunk({'cell': min(1024, data.NCELLS)})

    ag_dvar_target_mrj = tools.ag_mrj_to_xr(
        data, tools.lumap2ag_l_mrj(data.lumaps[yr_cal_start], data.lmmaps[yr_cal_start])
        ).rename({'lu':'To Land-use', 'lm':'To Water_supply'}
        ).chunk({'cell': min(1024, data.NCELLS)})
        
    non_ag_dvar_target_rk = tools.non_ag_rk_to_xr(
        data, data.non_ag_dvars[yr_cal_end]
        ).rename({'lu':'To Land-use'}
        ).chunk({'cell': min(1024, data.NCELLS)})
        
    xr_ag2ag = ag_dvar_base_mrj * ag_dvar_target_mrj * real_area_r
    xr_ag2non_ag = ag_dvar_base_mrj * non_ag_dvar_target_rk * real_area_r
        
    transition_ag2ag = xr_ag2ag.groupby('region'
        ).sum(dim='cell'
        ).to_dataframe('Area (ha)'
        ).reset_index(
        ).groupby(['region', 'From Land-use', 'To Land-use']
        ).sum(
        ).reset_index(
        ).filter(['region', 'From Land-use', 'To Land-use', 'Area (ha)'])
    transition_ag2non_ag = xr_ag2non_ag.groupby('region'
        ).sum(dim='cell'
        ).to_dataframe('Area (ha)'
        ).reset_index(
        ).groupby(['region', 'From Land-use', 'To Land-use']
        ).sum(
        ).reset_index(
        ).filter(['region', 'From Land-use', 'To Land-use', 'Area (ha)'])

    # Write the transition matrix to a csv file
    pd.concat([transition_ag2ag, transition_ag2non_ag]
        ).to_csv(os.path.join(path, f'transition_matrix_start_end.csv'), index=False)
    
    save2nc(xr_ag2ag, os.path.join(path, f'xr_transition_area_ag2ag_start_end.nc'))
    save2nc(xr_ag2non_ag, os.path.join(path, f'xr_transition_area_ag2non_ag_start_end.nc'))

    return f"Area transition matrix written from year {data.YR_CAL_BASE} to {yr_cal_end}"





def write_crosstab(data: Data, yr_cal, path):
    """Write out land-use and production data"""

    if yr_cal > data.YR_CAL_BASE:

    
        simulated_year_list = sorted(list(data.lumaps.keys()))
        yr_idx_sim = simulated_year_list.index(yr_cal)
        yr_cal_sim_pre = simulated_year_list[yr_idx_sim - 1]
        
        # Check if yr_cal_sim_pre meets the requirement
        assert yr_cal_sim_pre >= data.YR_CAL_BASE and yr_cal_sim_pre < yr_cal,\
            f"yr_cal_sim_pre ({yr_cal_sim_pre}) must be >= {data.YR_CAL_BASE} and < {yr_cal}"

        lumap_pre = data.lumaps[yr_cal_sim_pre]
        lumap = data.lumaps[yr_cal]
        
        crosstab = pd.crosstab(lumap_pre,  [lumap, data.REGION_NRM_NAME], values=data.REAL_AREA, aggfunc=lambda x:x.sum(), margins = False
            ).unstack(
            ).reset_index(
            ).rename(
                columns={
                    'row_0': 'From land-use', 
                    'NRM_NAME': 'region', 
                    'col_0':'To land-use', 
                    0: 'Area (ha)'
                }
            ).dropna(
            ).replace({'From land-use': data.ALLLU2DESC, 'To land-use': data.ALLLU2DESC})
            
        switches = (crosstab.groupby('From land-use')['Area (ha)'].sum() - crosstab.groupby('To land-use')['Area (ha)'].sum()
            ).reset_index(
            ).rename(columns={'index':'Landuse'})
        
        
        crosstab['Year'] = yr_cal
        switches['Year'] = yr_cal
   
        crosstab.to_csv(os.path.join(path, f'crosstab-lumap_{yr_cal}.csv'), index=False)
        switches.to_csv(os.path.join(path, f'switches-lumap_{yr_cal}.csv'), index=False)

    return f"Land-use cross-tabulation and switches written for year {yr_cal}"




def write_ghg(data: Data, yr_cal, path):
    """Calculate total GHG emissions from on-land agricultural sector.
        Takes a simulation object, a target calendar year (e.g., 2030),
        and an output path as input."""

    if settings.GHG_EMISSIONS_LIMITS == 'off':
        return 'GHG emissions calculation skipped as GHG_EMISSIONS_LIMITS is set to "off"'

    
    yr_idx = yr_cal - data.YR_CAL_BASE

    # Get GHG emissions limits used as constraints in model
    ghg_limits = data.GHG_TARGETS[yr_cal]

    # Get GHG emissions from model
    if yr_cal >= data.YR_CAL_BASE + 1:
        ghg_emissions = data.prod_data[yr_cal]['GHG']
    else:
        ghg_emissions = (ag_ghg.get_ghg_matrices(data, yr_idx, aggregate=True) * data.ag_dvars[settings.SIM_YEARS[0]]).sum()

    # Save GHG emissions to file
    df = pd.DataFrame({
        'Variable':['GHG_EMISSIONS_LIMIT_TCO2e','GHG_EMISSIONS_TCO2e'],
        'Emissions (t CO2e)':[ghg_limits, ghg_emissions]
        })
    df['Year'] = yr_cal
    df.to_csv(os.path.join(path, f'GHG_emissions_{yr_cal}.csv'), index=False)
    
    return f"GHG emissions written for year {yr_cal}"





def write_ghg_separate(data: Data, yr_cal, path):

    if settings.GHG_EMISSIONS_LIMITS == 'off':
        return 'GHG emissions calculation skipped as GHG_EMISSIONS_LIMITS is set to "off"'

    
    # Convert calendar year to year index.
    yr_idx = yr_cal - data.YR_CAL_BASE

    # -------------------------------------------------------#
    # Get greenhouse gas emissions from agricultural landuse #
    # -------------------------------------------------------#

    # Get the ghg_df
    ag_g_xr = xr.Dataset(ag_ghg.get_ghg_matrices(data, yr_idx, aggregate=False)
        ).rename({'dim_0':'cell'})
    ag_dvar_mrj = tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]
        ).assign_coords(region=('cell', data.REGION_NRM_NAME)
        ).chunk({'cell': min(1024, data.NCELLS)})


    mindex = pd.MultiIndex.from_tuples(ag_g_xr.data_vars.keys(), names=['GHG_source', 'lm', 'lu'])
    mindex_coords = xr.Coordinates.from_pandas_multiindex(mindex, 'variable')
    ag_g_rsmj = ag_g_xr.to_dataarray().assign_coords(mindex_coords).chunk({'cell': min(1024, data.NCELLS)}).unstack()
    ag_g_rsmj['GHG_source'] = ag_g_rsmj['GHG_source'].to_series().replace(GHG_NAMES)
    
    # Expand dimension
    ag_dvar_mrj = xr.concat([ag_dvar_mrj, ag_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    ag_g_rsmj = xr.concat([ag_g_rsmj, ag_g_rsmj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    ag_g_rsmj = xr.concat([ag_g_rsmj, ag_g_rsmj.sum(dim='GHG_source', keepdims=True).assign_coords(GHG_source=['ALL'])], dim='GHG_source')

    ghg_e = ag_g_rsmj * ag_dvar_mrj 
    
    # Regional level aggregation
    ghg_df_region = ghg_e.groupby('region'
        ).sum('cell'
        ).to_dataframe('Value (t CO2e)'
        ).reset_index(
        ).rename(columns={'lu':'Land-use', 'lm':'Water_supply', 'GHG_source':'Source'}
        ).assign(Year=yr_cal, Type='Agricultural land-use',
        ).replace({'dry':'Dryland', 'irr':'Irrigated'}
        ).query('abs(`Value (t CO2e)`) > 1e-3') 
    
    # Australia level aggregation
    ghg_df_AUS = ghg_e.sum('cell'
        ).to_dataframe('Value (t CO2e)'
        ).reset_index(
        ).rename(columns={'lu':'Land-use', 'lm':'Water_supply', 'GHG_source':'Source'}
        ).assign(Year=yr_cal, Type='Agricultural land-use', region='AUSTRALIA'
        ).replace({'dry':'Dryland', 'irr':'Irrigated'}
        ).query('abs(`Value (t CO2e)`) > 1e-3') 
    
    # Save table to disk
    pd.concat([ghg_df_AUS, ghg_df_region]).to_csv(os.path.join(path, f'GHG_emissions_separate_agricultural_landuse_{yr_cal}.csv'), index=False)

    save2nc(ghg_e, os.path.join(path, 'xr_GHG_ag.nc'))


    # -----------------------------------------------------------#
    # Get greenhouse gas emissions from non-agricultural landuse #
    # -----------------------------------------------------------#
    
    # Get the non_ag GHG reduction
    non_ag_dvar_rk = tools.non_ag_rk_to_xr(data,data.non_ag_dvars[yr_cal]
        ).assign_coords(region=('cell', data.REGION_NRM_NAME)
        ).chunk({'cell': min(1024, data.NCELLS)})
        
    non_ag_g_rk = tools.non_ag_rk_to_xr(
        data,
        non_ag_ghg.get_ghg_matrix(
            data, 
            ag_ghg.get_ghg_matrices(data, yr_idx, aggregate=True), 
            data.lumaps[yr_cal]
        )
    )

    # Calculate GHG emissions for non-agricultural land use
    xr_ghg_non_ag = non_ag_dvar_rk * non_ag_g_rk
    
    # Regional level aggregation
    ghg_df_region = xr_ghg_non_ag.groupby('region'
        ).sum('cell'
        ).to_dataframe('Value (t CO2e)'
        ).reset_index(
        ).rename(columns={'lu': 'Land-use'}
        ).assign(Year=yr_cal, Type='Non-Agricultural land-use'
        ).replace({'dry': 'Dryland', 'irr': 'Irrigated'}
        ).query('abs(`Value (t CO2e)`) > 1e-3') 
        
    # Australia level aggregation
    ghg_df_AUS = xr_ghg_non_ag.sum('cell'
        ).to_dataframe('Value (t CO2e)'
        ).reset_index(
        ).rename(columns={'lu': 'Land-use'}
        ).assign(Year=yr_cal, Type='Non-Agricultural land-use', region='AUSTRALIA'
        ).replace({'dry': 'Dryland', 'irr': 'Irrigated'}
        ).query('abs(`Value (t CO2e)`) > 1e-3') 
        
    # Save table to disk
    pd.concat([ghg_df_AUS, ghg_df_region]).to_csv(os.path.join(path, f'GHG_emissions_separate_no_ag_reduction_{yr_cal}.csv'), index=False)
    
    # Save xarray data to netCDF
    save2nc(xr_ghg_non_ag, os.path.join(path, f'xr_GHG_non_ag_{yr_cal}.nc'))
    
    
    # -------------------------------------------------------------------#
    # Get greenhouse gas emissions from agricultural management          #
    # -------------------------------------------------------------------#

    # Get the ag_man_g_mrj
    ag_man_dvar_mrj = tools.am_mrj_to_xr(data, data.ag_man_dvars[yr_cal]
        ).assign_coords(region=('cell', data.REGION_NRM_NAME)
        ).chunk({'cell': min(1024, data.NCELLS)})

    ag_man_g_mrj = tools.am_mrj_to_xr(
        data, 
        ag_ghg.get_agricultural_management_ghg_matrices(data, yr_idx)
    )

    # Expand dimension
    ag_man_dvar_mrj = xr.concat([ag_man_dvar_mrj, ag_man_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    ag_man_dvar_mrj = xr.concat([ag_man_dvar_mrj, ag_man_dvar_mrj.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')
    ag_man_g_mrj = xr.concat([ag_man_g_mrj, ag_man_g_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    ag_man_g_mrj = xr.concat([ag_man_g_mrj, ag_man_g_mrj.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')

    # Calculate GHG emissions for agricultural management
    xr_ghg_ag_man = ag_man_dvar_mrj * ag_man_g_mrj

    # Regional level aggregation
    ghg_df_region = xr_ghg_ag_man.groupby('region'
        ).sum('cell'
        ).to_dataframe('Value (t CO2e)'
        ).reset_index(
        ).rename(columns={'lm': 'Water_supply', 'lu': 'Land-use', 'am': 'Agricultural Management Type'}
        ).assign(Year=yr_cal, Type='Agricultural Management'
        ).replace({'dry': 'Dryland', 'irr': 'Irrigated'}
        ).query('abs(`Value (t CO2e)`) > 1e-3') 
        
    # Australia level aggregation
    ghg_df_AUS = xr_ghg_ag_man.sum('cell'
        ).to_dataframe('Value (t CO2e)'
        ).reset_index(
        ).rename(columns={'lm': 'Water_supply', 'lu': 'Land-use', 'am': 'Agricultural Management Type'}
        ).assign(Year=yr_cal, Type='Agricultural Management', region='AUSTRALIA'
        ).replace({'dry': 'Dryland', 'irr': 'Irrigated'}
        ).query('abs(`Value (t CO2e)`) > 1e-3') 
        
    # Save table to disk
    pd.concat([ghg_df_AUS, ghg_df_region]).to_csv(os.path.join(path, f'GHG_emissions_separate_agricultural_management_{yr_cal}.csv'), index=False)
    
    # Save xarray data to netCDF
    save2nc(xr_ghg_ag_man, os.path.join(path, f'xr_GHG_ag_management_{yr_cal}.nc'))


    # -------------------------------------------------------------------#
    # Get greenhouse gas emissions from landuse transformation penalties #
    # -------------------------------------------------------------------#

    # Retrieve list of simulation years (e.g., [2010, 2050] for snapshot or [2010, 2011, 2012] for timeseries)
    simulated_year_list = sorted(list(data.lumaps.keys()))
    yr_idx_sim = simulated_year_list.index(yr_cal)

    # Get index of year previous to yr_cal in simulated_year_list (e.g., if yr_cal is 2050 then yr_cal_sim_pre = 2010 if snapshot)
    if yr_cal == data.YR_CAL_BASE:
        pass
    else:
        yr_cal_sim_pre = simulated_year_list[yr_idx_sim - 1]
        ghg_t_dict = ag_ghg.get_ghg_transition_emissions(data, data.lumaps[yr_cal_sim_pre], separate=True)
        ghg_t_smrj = xr.DataArray(
            np.stack(list(ghg_t_dict.values()), axis=0),
            dims=['Type', 'lm', 'cell', 'lu'],
            coords={
                'Type': list(ghg_t_dict.keys()),
                'lm': data.LANDMANS,
                'cell': range(data.NCELLS),
                'lu': data.AGRICULTURAL_LANDUSES
            }
        )

        # Calculate GHG emissions for transition penalties
        xr_ghg_transition = ghg_t_smrj * ag_dvar_mrj
        
        # Regional level aggregation
        ghg_df_region = xr_ghg_transition.groupby('region'
            ).sum('cell'
            ).to_dataframe('Value (t CO2e)'
            ).reset_index(
            ).rename(columns={'lu': 'Land-use', 'lm': 'Water_supply'}
            ).assign(Year=yr_cal
            ).replace({'dry': 'Dryland', 'irr': 'Irrigated'}
            ).query('abs(`Value (t CO2e)`) > 1e-3')

        # Australia level aggregation
        ghg_df_AUS = xr_ghg_transition.sum('cell'
            ).to_dataframe('Value (t CO2e)'
            ).reset_index(
            ).rename(columns={'lu': 'Land-use', 'lm': 'Water_supply'}
            ).assign(Year=yr_cal, region='AUSTRALIA'
            ).replace({'dry': 'Dryland', 'irr': 'Irrigated'}
            ).query('abs(`Value (t CO2e)`) > 1e-3')

        # Save table to disk
        pd.concat([ghg_df_AUS, ghg_df_region]).to_csv(os.path.join(path, f'GHG_emissions_separate_transition_penalty_{yr_cal}.csv'), index=False)
        
        # Save xarray data to netCDF
        save2nc(xr_ghg_transition, os.path.join(path, f'xr_transition_GHG_{yr_cal}.nc'))

    return f"Separate GHG emissions written for year {yr_cal}"




def write_ghg_offland_commodity(data: Data, yr_cal, path):
    """Write out offland commodity GHG emissions"""

    if settings.GHG_EMISSIONS_LIMITS == 'off':
        return

    
    # Get the offland commodity data
    offland_ghg = data.OFF_LAND_GHG_EMISSION.query(f'YEAR == {yr_cal}').rename(columns={'YEAR':'Year'})

    # Save to disk
    offland_ghg.to_csv(os.path.join(path, f'GHG_emissions_offland_commodity_{yr_cal}.csv'), index = False)

    return f"Offland commodity GHG emissions written for year {yr_cal}"




def write_water(data: Data, yr_cal, path):
    """Calculate water yield totals. Takes a Data Object, a calendar year (e.g., 2030), and an output path as input."""

    yr_idx = yr_cal - data.YR_CAL_BASE
    region2code = {v: k for k, v in data.WATER_REGION_NAMES.items()}

    # Get the decision variables
    ag_dvar_mrj = tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]
        ).assign_coords(region_water=('cell', data.WATER_REGION_ID), region_NRM=('cell', data.REGION_NRM_NAME)
        ).chunk({'cell': min(1024, data.NCELLS)})
    non_ag_dvar_rj = tools.non_ag_rk_to_xr(data, data.non_ag_dvars[yr_cal]
        ).assign_coords(region_water=('cell', data.WATER_REGION_ID), region_NRM=('cell', data.REGION_NRM_NAME)
        ).chunk({'cell': min(1024, data.NCELLS)})
    am_dvar_mrj = tools.am_mrj_to_xr(data, data.ag_man_dvars[yr_cal]
        ).assign_coords(region_water=('cell', data.WATER_REGION_ID), region_NRM=('cell', data.REGION_NRM_NAME)
        ).chunk({'cell': min(1024, data.NCELLS)})
        
    # Get water target and domestic use
    w_limit_inside_luto = xr.DataArray(
        list(data.WATER_YIELD_TARGETS.values()),
        dims=['region_water'],
        coords={'region_water': list(data.WATER_YIELD_TARGETS.keys())}
    )
    domestic_water_use = xr.DataArray(
        list(data.WATER_USE_DOMESTIC.values()), 
        dims=['region_water'],
        coords={'region_water': list(data.WATER_USE_DOMESTIC.keys())}
    )

    # Expand dimension
    ag_dvar_mrj = xr.concat([ag_dvar_mrj, ag_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    am_dvar_mrj = xr.concat([am_dvar_mrj, am_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    am_dvar_mrj = xr.concat([am_dvar_mrj, am_dvar_mrj.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')


    # ------------------------------- Get water yield without CCI -----------------------------------

    # Get water yield matrix 
    if settings.WATER_CLIMATE_CHANGE_IMPACT == 'on':
        ag_w_mrj = tools.ag_mrj_to_xr(
            data, 
            ag_water.get_water_net_yield_matrices(data, yr_idx)
        )
        non_ag_w_rk = tools.non_ag_rk_to_xr(
            data, 
            non_ag_water.get_w_net_yield_matrix(data, ag_w_mrj.values, data.lumaps[yr_cal], yr_idx)
        )
        ag_man_w_mrj = tools.am_mrj_to_xr(  # Ag-man water yield only related to water requirement, that not affected by climate change
            data, 
            ag_water.get_agricultural_management_water_matrices(data, yr_idx) 
        )
    elif settings.WATER_CLIMATE_CHANGE_IMPACT == 'off':
        ag_w_mrj = tools.ag_mrj_to_xr(
            data, 
            ag_water.get_water_net_yield_matrices(data, yr_idx, data.WATER_YIELD_HIST_DR, data.WATER_YIELD_HIST_SR)
        )
        non_ag_w_rk = tools.non_ag_rk_to_xr(
            data, 
            non_ag_water.get_w_net_yield_matrix(data, ag_w_mrj.values, data.lumaps[yr_cal], yr_idx, data.WATER_YIELD_HIST_DR, data.WATER_YIELD_HIST_SR)
        )
        ag_man_w_mrj = tools.am_mrj_to_xr(  # Ag-man water yield only related to water requirement, that not affected by climate change
            data, 
            ag_water.get_agricultural_management_water_matrices(data, yr_idx) 
        )
    else:
        raise ValueError("Invalid setting for WATER_CLIMATE_CHANGE_IMPACT, only 'on' or 'off' allowed.")

    # Expand dimension
    ag_w_mrj = xr.concat([ag_w_mrj, ag_w_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    ag_man_w_mrj = xr.concat([ag_man_w_mrj, ag_man_w_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    ag_man_w_mrj = xr.concat([ag_man_w_mrj, ag_man_w_mrj.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')


    # Calculate water net yield inside LUTO study region
    xr_ag_wny = ag_dvar_mrj * ag_w_mrj
    xr_non_ag_wny = non_ag_dvar_rj * non_ag_w_rk
    xr_am_wny = ag_man_w_mrj * am_dvar_mrj

    ag_wny = xr_ag_wny.groupby('region_water'
        ).sum(['cell']
        ).to_dataframe('Water Net Yield (ML)'
        ).reset_index(
        ).assign(Type='Agricultural Landuse'
        ).replace({'region_water': data.WATER_REGION_NAMES})
    non_ag_wny = xr_non_ag_wny.groupby('region_water'
        ).sum(['cell']
        ).to_dataframe('Water Net Yield (ML)'
        ).reset_index(
        ).assign(Type='Non-Agricultural Landuse'
        ).replace({'region_water': data.WATER_REGION_NAMES})
    am_wny = xr_am_wny.groupby('region_water'
        ).sum(['cell']
        ).to_dataframe('Water Net Yield (ML)'
        ).reset_index(
        ).assign(Type='Agricultural Management'
        ).replace({'region_water': data.WATER_REGION_NAMES})
    wny_inside_luto = pd.concat([ag_wny, non_ag_wny, am_wny], ignore_index=True
        ).assign(Year=yr_cal
        ).rename(columns={
            'region_water': 'Region',
            'lu':'Landuse',
            'am':'Agri-Management',
            'lm':'Water Supply'}
        ).replace({'dry':'Dryland', 'irr':'Irrigated'}
        ).dropna(axis=0, how='all')
        
    wny_inside_luto.to_csv(os.path.join(path, f'water_yield_separate_watershed_{yr_cal}.csv'), index=False)


    # ------------------------------- Get water yield outside LUTO study region -----------------------------------
    wny_outside_luto_study_area = xr.DataArray(
        list(data.WATER_OUTSIDE_LUTO_BY_CCI.loc[data.YR_CAL_BASE].to_dict().values()),
        dims=['region_water'],
        coords={'region_water': list(data.WATER_REGION_INDEX_R.keys())},
    )


    # ------------------------------- Get water yield change (delta) under CCI -----------------------------------

    # Get CCI matrix
    if settings.WATER_CLIMATE_CHANGE_IMPACT == 'on':
        ag_w_mrj_base = tools.ag_mrj_to_xr(data, ag_water.get_water_net_yield_matrices(data, 0))
        ag_w_mrj_base = xr.concat([ag_w_mrj_base, ag_w_mrj_base.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
        wny_outside_luto_study_area_base = np.array(list(data.WATER_OUTSIDE_LUTO_BY_CCI.loc[data.YR_CAL_BASE].to_dict().values()))
    elif settings.WATER_CLIMATE_CHANGE_IMPACT == 'off':
        ag_w_mrj_base = tools.ag_mrj_to_xr(data, ag_water.get_water_net_yield_matrices(data, 0, data.WATER_YIELD_HIST_DR, data.WATER_YIELD_HIST_SR))
        ag_w_mrj_base = xr.concat([ag_w_mrj_base, ag_w_mrj_base.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
        wny_outside_luto_study_area_base = np.array(list(data.WATER_OUTSIDE_LUTO_HIST.to_dict().values()))

    ag_w_mrj_CCI = ag_w_mrj - ag_w_mrj_base
    wny_outside_luto_study_area_CCI = wny_outside_luto_study_area - wny_outside_luto_study_area_base



    # Calculate water net yield (delta) under CCI; 
    #   we use BASE_YEAR (2010) dvar_mrj to calculate CCI, 
    #   because the CCI calculated with base year (previouse year) 
    #   dvar_mrj includes wny from land-use change
    xr_ag_dvar_BASE = tools.ag_mrj_to_xr(data, data.AG_L_MRJ).assign_coords(region_water=('cell', data.WATER_REGION_ID), region_NRM=('cell', data.REGION_NRM_NAME))
    xr_ag_dvar_BASE = xr.concat([xr_ag_dvar_BASE, xr_ag_dvar_BASE.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')

    xr_ag_wny_CCI = xr_ag_dvar_BASE * ag_w_mrj_CCI


    # Get the CCI impact (delta)
    CCI_impact = (
        xr_ag_wny_CCI.groupby('region_water').sum(['cell','lm', 'lu']) 
        + wny_outside_luto_study_area_CCI
    )

    # ------------------------------- Organise water yield components -----------------------------------

    # Water net yield for watershed regions
    wny_inside_luto_sum = wny_inside_luto\
        .query('`Water Supply` != "ALL" and `Agri-Management` != "ALL"')\
        .groupby('Region')[['Water Net Yield (ML)']]\
        .sum()
    wny_inside_luto_sum = xr.DataArray(
        wny_inside_luto_sum['Water Net Yield (ML)'].values, 
        dims=['region_water'], 
        coords={'region_water': [region2code[i] for i in wny_inside_luto_sum.index.values]}
    )
    wny_watershed_sum = wny_inside_luto_sum + wny_outside_luto_study_area - domestic_water_use  # CCI delta already include in the wny_inside_luto_sum

    w_limit_region = w_limit_inside_luto + wny_outside_luto_study_area - domestic_water_use     # CCI delta already include in the w_limit_inside_luto

    water_other_records = xr.Dataset(
            {   
                'Water yield inside LUTO (ML)': wny_inside_luto_sum,
                'Water yield outside LUTO (ML)': wny_outside_luto_study_area,
                'Climate Change Impact (ML)': CCI_impact,
                'Domestic Water Use (ML)': domestic_water_use,
                'Water Net Yield (ML)': wny_watershed_sum,
                'Water Yield Limit (ML)': w_limit_region,
            },
        ).to_dataframe(
        ).reset_index(
        ).rename(columns={'region_water': 'Region'}
        ).replace({'Region': data.WATER_REGION_NAMES}
        ).assign(Year=yr_cal)
        
    water_other_records.to_csv(os.path.join(path, f'water_yield_limits_and_public_land_{yr_cal}.csv'), index=False)

    # Water yield for NRM region
    ag_wny = (ag_w_mrj * ag_dvar_mrj
        ).groupby('region_NRM'
        ).sum(['cell']
        ).to_dataframe('Water Net Yield (ML)'
        ).reset_index(
        ).assign(Type='Agricultural Landuse'
        ).replace({'region_NRM': data.WATER_REGION_NAMES})
    non_ag_wny = (non_ag_w_rk * non_ag_dvar_rj
        ).groupby('region_NRM'
        ).sum(['cell']
        ).to_dataframe('Water Net Yield (ML)'
        ).reset_index(
        ).assign(Type='Non-Agricultural Landuse'
        ).replace({'region_NRM': data.WATER_REGION_NAMES})
    am_wny = (am_dvar_mrj * ag_man_w_mrj
        ).groupby('region_NRM'
        ).sum(['cell']
        ).to_dataframe('Water Net Yield (ML)'
        ).reset_index(
        ).assign(Type='Agricultural Management'
        ).replace({'region_NRM': data.WATER_REGION_NAMES})
    wny_NRM = pd.concat([ag_wny, non_ag_wny, am_wny], ignore_index=True
        ).assign(Year=yr_cal
        ).rename(columns={
            'region_water': 'Region',
            'lu':'Landuse',
            'am':'Agri-Management',
            'lm':'Water Supply'}
        ).replace({'dry':'Dryland', 'irr':'Irrigated'}
        ).dropna(axis=0, how='all')
        
    wny_NRM.to_csv(os.path.join(path, f'water_yield_separate_NRM_{yr_cal}.csv'), index=False)
    
    
    save2nc(xr_ag_wny, os.path.join(path, f'xr_water_yield_ag_{yr_cal}.nc'))
    save2nc(xr_non_ag_wny, os.path.join(path, f'xr_water_yield_non_ag_{yr_cal}.nc'))
    save2nc(xr_am_wny, os.path.join(path, f'xr_water_yield_ag_management_{yr_cal}.nc'))


    # ------------ Write the original targets for watershed regions being relaxed under CCI -----------------
    water_relaxed_region_raw_targets = pd.DataFrame(
        [[k, v, data.WATER_REGION_NAMES[k]] for k, v in data.WATER_RELAXED_REGION_RAW_TARGETS.items()], 
        columns=['Region Id', 'Target', 'Region Name']
    )
    water_relaxed_region_raw_targets['Year'] = yr_cal
    water_relaxed_region_raw_targets.to_csv(os.path.join(path, f'water_yield_relaxed_region_raw_{yr_cal}.csv'), index=False)

    return f"Water yield data written for year {yr_cal}"


def write_biodiversity_overall_quanlity_scores(data: Data, yr_cal, path):
    
    yr_idx_previouse = sorted(data.lumaps.keys()).index(yr_cal) - 1
    yr_cal_previouse = sorted(data.lumaps.keys())[yr_idx_previouse]
    yr_idx = yr_cal - data.YR_CAL_BASE

    # Get the biodiversity scores b_mrj
    bio_ag_priority_mrj =  tools.ag_mrj_to_xr(data, ag_biodiversity.get_bio_overall_priority_score_matrices_mrj(data))   
    bio_am_priority_amrj = tools.am_mrj_to_xr(data, ag_biodiversity.get_agricultural_management_biodiversity_matrices(data, bio_ag_priority_mrj.values, yr_idx))
    bio_non_ag_priority_rk = tools.non_ag_rk_to_xr(data, non_ag_biodiversity.get_breq_matrix(data,bio_ag_priority_mrj.values, data.lumaps[yr_cal_previouse]))

    if yr_idx_previouse < 0: # this means now is the base year, hence no ag-man and non-ag applied
        bio_am_priority_amrj *= 0.0
        bio_non_ag_priority_rk *= 0.0


    # Get the decision variables for the year
    ag_dvar_mrj = tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    ag_mam_dvar_mrj =  tools.am_mrj_to_xr(data, data.ag_man_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    non_ag_dvar_rk = tools.non_ag_rk_to_xr(data, data.non_ag_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))


    # Calculate the biodiversity scores
    base_yr_score = np.einsum('mrj,mrj->', bio_ag_priority_mrj, data.AG_L_MRJ)
    
    # Expand dimension
    ag_dvar_mrj = xr.concat([ag_dvar_mrj, ag_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    ag_mam_dvar_mrj = xr.concat([ag_mam_dvar_mrj, ag_mam_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    ag_mam_dvar_mrj = xr.concat([ag_mam_dvar_mrj, ag_mam_dvar_mrj.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')
    bio_ag_priority_mrj = xr.concat([bio_ag_priority_mrj, bio_ag_priority_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    bio_am_priority_amrj = xr.concat([bio_am_priority_amrj, bio_am_priority_amrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    bio_am_priority_amrj = xr.concat([bio_am_priority_amrj, bio_am_priority_amrj.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')

    # Calculate xarray biodiversity scores
    xr_priority_ag = ag_dvar_mrj * bio_ag_priority_mrj
    xr_priority_non_ag = non_ag_dvar_rk * bio_non_ag_priority_rk
    xr_priority_am = ag_mam_dvar_mrj * bio_am_priority_amrj

    priority_ag = (xr_priority_ag
        ).groupby('region'
        ).sum(['cell','lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).assign(Relative_Contribution_Percentage = lambda x:( (x['Area Weighted Score (ha)'] / base_yr_score) * 100) 
        ).assign(Type='Agricultural Landuse', Year=yr_cal)

    priority_non_ag = (xr_priority_non_ag
        ).groupby('region'
        ).sum(['cell']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).assign(Relative_Contribution_Percentage = lambda x:( x['Area Weighted Score (ha)'] / base_yr_score * 100)
        ).assign(Type='Non-Agricultural land-use', Year=yr_cal)

    priority_am = (xr_priority_am
        ).groupby('region'
        ).sum(['cell','lm'], skipna=False
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).assign(Relative_Contribution_Percentage = lambda x:( x['Area Weighted Score (ha)'] / base_yr_score * 100)
        ).dropna(
        ).assign(Type='Agricultural Management', Year=yr_cal)


    # Save the biodiversity scores
    df = pd.concat([ priority_ag, priority_non_ag, priority_am], axis=0
        ).rename(columns={
            'lu':'Landuse',
            'am':'Agri-Management',
            'Relative_Contribution_Percentage':'Contribution Relative to Base Year Level (%)'}
        ).reset_index(drop=True).to_csv( os.path.join(path, f'biodiversity_overall_priority_scores_{yr_cal}.csv'), index=False)
    
    # Save xarray data to netCDF
    save2nc(xr_priority_ag, os.path.join(path, f'xr_biodiversity_overall_priority_ag_{yr_cal}.nc'))
    save2nc(xr_priority_non_ag, os.path.join(path, f'xr_biodiversity_overall_priority_non_ag_{yr_cal}.nc'))
    save2nc(xr_priority_am, os.path.join(path, f'xr_biodiversity_overall_priority_ag_management_{yr_cal}.nc'))
    
    return f"Biodiversity overall priority scores written for year {yr_cal}"




def write_biodiversity_GBF2_scores(data: Data, yr_cal, path):

    # Do nothing if biodiversity limits are off and no need to report
    if settings.BIODIVERSITY_TARGET_GBF_2 == 'off':
        return

        
    # Unpack the ag managements and land uses
    am_lu_unpack = [(am, l) for am, lus in data.AG_MAN_LU_DESC.items() for l in lus]

    # Get decision variables for the year
    ag_dvar_mrj = tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    non_ag_dvar_rk = tools.non_ag_rk_to_xr(data, data.non_ag_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    am_dvar_amrj = tools.am_mrj_to_xr(data, data.ag_man_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))


    # Get the priority degraded areas score
    priority_degraded_area_score_r = xr.DataArray(
        data.BIO_PRIORITY_DEGRADED_AREAS_R,
        dims=['cell'],
        coords={'cell':range(data.NCELLS)}
    )

    # Get the impacts of each ag/non-ag/am to vegetation matrices
    ag_impact_j = xr.DataArray(
        ag_biodiversity.get_ag_biodiversity_contribution(data),
        dims=['lu'],
        coords={'lu':data.AGRICULTURAL_LANDUSES}
    )
    non_ag_impact_k = xr.DataArray(
        list(non_ag_biodiversity.get_non_ag_lu_biodiv_contribution(data).values()),
        dims=['lu'],
        coords={'lu':data.NON_AGRICULTURAL_LANDUSES}
    )
    am_impact_raj = xr.DataArray(
        np.stack([arr for _, v in ag_biodiversity.get_ag_management_biodiversity_contribution(data, yr_cal).items() for arr in v.values()]), 
        dims=['idx', 'cell'], 
        coords={
            'idx': pd.MultiIndex.from_tuples(am_lu_unpack, names=['am', 'lu']),
            'cell': range(data.NCELLS)}
    ).unstack()

    # Expand dimension
    ag_dvar_mrj = xr.concat([ag_dvar_mrj, ag_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    am_dvar_amrj = xr.concat([am_dvar_amrj, am_dvar_amrj.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')
    am_dvar_amrj = xr.concat([am_dvar_amrj, am_dvar_amrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    am_impact_raj = xr.concat([am_impact_raj, am_impact_raj.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')


    # Get the total area of the priority degraded areas
    total_priority_degraded_area = data.BIO_PRIORITY_DEGRADED_AREAS_R.sum()

    # Calculate xarray biodiversity GBF2 scores
    xr_gbf2_ag = priority_degraded_area_score_r * ag_impact_j * ag_dvar_mrj
    xr_gbf2_non_ag = priority_degraded_area_score_r * non_ag_impact_k * non_ag_dvar_rk
    xr_gbf2_am = priority_degraded_area_score_r * am_impact_raj * am_dvar_amrj

    # Regional level aggregation
    GBF2_score_ag_region = xr_gbf2_ag.groupby('region'
        ).sum(['cell','lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).assign(Relative_Contribution_Percentage = lambda x:((x['Area Weighted Score (ha)'] / total_priority_degraded_area) * 100)
        ).assign(Type='Agricultural Landuse', Year=yr_cal)
    GBF2_score_non_ag_region = xr_gbf2_non_ag.groupby('region'
        ).sum(['cell']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).assign(Relative_Contribution_Percentage = lambda x:(x['Area Weighted Score (ha)'] / total_priority_degraded_area * 100)
        ).assign(Type='Non-Agricultural land-use', Year=yr_cal)  
    GBF2_score_am_region = xr_gbf2_am.groupby('region'
        ).sum(['cell','lm'], skipna=False
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(allow_duplicates=True
        ).T.drop_duplicates(
        ).T.assign(Relative_Contribution_Percentage = lambda x:(x['Area Weighted Score (ha)'] / total_priority_degraded_area * 100)
        ).assign(Type='Agricultural Management', Year=yr_cal)
        
    # Australia level aggregation
    GBF2_score_ag_AUS = xr_gbf2_ag.sum(['cell','lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).assign(Relative_Contribution_Percentage = lambda x:((x['Area Weighted Score (ha)'] / total_priority_degraded_area) * 100)
        ).assign(Type='Agricultural Landuse', Year=yr_cal, region='Australia')
    GBF2_score_non_ag_AUS = xr_gbf2_non_ag.sum(['cell']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).assign(Relative_Contribution_Percentage = lambda x:(x['Area Weighted Score (ha)'] / total_priority_degraded_area * 100)
        ).assign(Type='Non-Agricultural land-use', Year=yr_cal, region='Australia')  
    GBF2_score_am_AUS = xr_gbf2_am.sum(['cell','lm'], skipna=False
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(allow_duplicates=True
        ).T.drop_duplicates(
        ).T.assign(Relative_Contribution_Percentage = lambda x:(x['Area Weighted Score (ha)'] / total_priority_degraded_area * 100)
        ).assign(Type='Agricultural Management', Year=yr_cal, region='Australia')
        
    # Combine regional and Australia level data
    GBF2_score_ag = pd.concat([GBF2_score_ag_region, GBF2_score_ag_AUS], axis=0)
    GBF2_score_non_ag = pd.concat([GBF2_score_non_ag_region, GBF2_score_non_ag_AUS], axis=0)
    GBF2_score_am = pd.concat([GBF2_score_am_region, GBF2_score_am_AUS], axis=0)
        
    # Fill nan to empty dataframes
    if GBF2_score_ag.empty:
        GBF2_score_ag.loc[0] = 0
        GBF2_score_ag = GBF2_score_ag.astype({'Type':str, 'lu':str,'Year':'int'})
        GBF2_score_ag.loc[0, ['Type', 'lu' ,'Year']] = ['Agricultural Landuse', 'Apples', yr_cal]

    if GBF2_score_non_ag.empty:
        GBF2_score_non_ag.loc[0] = 0
        GBF2_score_non_ag = GBF2_score_non_ag.astype({'Type':str, 'lu':str,'Year':'int'})
        GBF2_score_non_ag.loc[0, ['Type', 'lu' ,'Year']] = ['Agricultural Management', 'Apples', yr_cal]

    if GBF2_score_am.empty:
        GBF2_score_am.loc[0] = 0
        GBF2_score_am = GBF2_score_am.astype({'Type':str, 'lu':str,'Year':'int'})
        GBF2_score_am.loc[0, ['Type', 'lu' ,'Year']] = ['Non-Agricultural land-use', 'Environmental Plantings', yr_cal]
        
    # Save to disk  
    pd.concat([
            GBF2_score_ag,
            GBF2_score_non_ag,
            GBF2_score_am], axis=0
        ).assign( Priority_Target=(data.get_GBF2_target_for_yr_cal(yr_cal) / total_priority_degraded_area) * 100,
        ).rename(columns={
            'lu':'Landuse',
            'am':'Agri-Management',
            'Relative_Contribution_Percentage':'Contribution Relative to Pre-1750 Level (%)',
            'Priority_Target':'Priority Target (%)'}
        ).reset_index(drop=True
        ).to_csv(os.path.join(path, f'biodiversity_GBF2_priority_scores_{yr_cal}.csv'), index=False)

    # Save xarray data to netCDF
    save2nc(xr_gbf2_ag, os.path.join(path, f'xr_biodiversity_GBF2_priority_ag_{yr_cal}.nc'))
    save2nc(xr_gbf2_non_ag, os.path.join(path, f'xr_biodiversity_GBF2_priority_non_ag_{yr_cal}.nc'))
    save2nc(xr_gbf2_am, os.path.join(path, f'xr_biodiversity_GBF2_priority_ag_management_{yr_cal}.nc'))
    
    return f"Biodiversity GBF2 priority scores written for year {yr_cal}"



def write_biodiversity_GBF3_scores(data: Data, yr_cal: int, path) -> None:
        
    # Do nothing if biodiversity limits are off and no need to report
    if settings.BIODIVERSITY_TARGET_GBF_3 == 'off':
        return "Biodiversity GBF3 scores skipped (target is off)"
    
        
    # Unpack the agricultural management land-use
    am_lu_unpack = [(am, l) for am, lus in data.AG_MAN_LU_DESC.items() for l in lus]

    # Get decision variables for the year
    ag_dvar_mrj = tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    non_ag_dvar_rk = tools.non_ag_rk_to_xr(data, data.non_ag_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    am_dvar_amrj = tools.am_mrj_to_xr(data, data.ag_man_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    
    # Expand dimension
    ag_dvar_mrj = xr.concat([ag_dvar_mrj, ag_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    am_dvar_amrj = xr.concat([am_dvar_amrj, am_dvar_amrj.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')
    am_dvar_amrj = xr.concat([am_dvar_amrj, am_dvar_amrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')


    # Get vegetation matrices for the year
    vegetation_score_vr = xr.DataArray(
        ag_biodiversity.get_GBF3_major_vegetation_matrices_vr(data), 
        dims=['group','cell'], 
        coords={'group':list(data.BIO_GBF3_ID2DESC.values()),  'cell':range(data.NCELLS)}
    ).chunk({'cell': min(1024, data.NCELLS), 'group': 1})

    # Get the impacts of each ag/non-ag/am to vegetation matrices
    ag_impact_j = xr.DataArray(
        ag_biodiversity.get_ag_biodiversity_contribution(data),
        dims=['lu'],
        coords={'lu':data.AGRICULTURAL_LANDUSES}
    )
    non_ag_impact_k = xr.DataArray(
        list(non_ag_biodiversity.get_non_ag_lu_biodiv_contribution(data).values()),
        dims=['lu'],
        coords={'lu':data.NON_AGRICULTURAL_LANDUSES}
    )
    am_impact_amr = xr.DataArray(
        np.stack([arr for _, v in ag_biodiversity.get_ag_management_biodiversity_contribution(data, yr_cal).items() for arr in v.values()]), 
        dims=['idx', 'cell'], 
        coords={
            'idx': pd.MultiIndex.from_tuples(am_lu_unpack, names=['am', 'lu']),
            'cell': range(data.NCELLS)}
    ).unstack()

    # Expand dimension
    am_impact_amr = xr.concat([am_impact_amr, am_impact_amr.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')
    
    # Get the base year biodiversity scores
    veg_base_score_score = pd.DataFrame({
            'group': data.BIO_GBF3_ID2DESC.values(), 
            'BASE_OUTSIDE_SCORE': data.BIO_GBF3_BASELINE_SCORE_OUTSIDE_LUTO, 
            'BASE_TOTAL_SCORE': data.BIO_GBF3_BASELINE_SCORE_ALL_AUSTRALIA,
            'TARGET_INSIDE_SCORE': data.get_GBF3_limit_score_inside_LUTO_by_yr(yr_cal)}
        ).eval('Target_by_Percent = (TARGET_INSIDE_SCORE + BASE_OUTSIDE_SCORE) / BASE_TOTAL_SCORE * 100')

    # Calculate xarray biodiversity GBF3 scores
    xr_gbf3_ag = vegetation_score_vr * ag_impact_j * ag_dvar_mrj
    xr_gbf3_am = vegetation_score_vr * am_impact_amr * am_dvar_amrj
    xr_gbf3_non_ag = vegetation_score_vr * non_ag_impact_k * non_ag_dvar_rk
    
    # Regional level aggregation
    GBF3_score_ag_region = xr_gbf3_ag.groupby('region'
        ).sum(['cell','lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(veg_base_score_score
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Landuse', Year=yr_cal)

    GBF3_score_am_region = xr_gbf3_am.groupby('region'
        ).sum(['cell','lm'], skipna=False
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(allow_duplicates=True
        ).T.drop_duplicates(
        ).T.merge(veg_base_score_score,
        ).astype({'Area Weighted Score (ha)': 'float', 'BASE_TOTAL_SCORE': 'float'}
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Management', Year=yr_cal)
        
    GBF3_score_non_ag_region = xr_gbf3_non_ag.groupby('region'
        ).sum(['cell']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(veg_base_score_score,
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Non-Agricultural land-use', Year=yr_cal)

    # Australia level aggregation
    GBF3_score_ag_AUS = xr_gbf3_ag.sum(['cell','lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(veg_base_score_score
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Landuse', Year=yr_cal, region='Australia')

    GBF3_score_am_AUS = xr_gbf3_am.sum(['cell','lm'], skipna=False
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(allow_duplicates=True
        ).T.drop_duplicates(
        ).T.merge(veg_base_score_score,
        ).astype({'Area Weighted Score (ha)': 'float', 'BASE_TOTAL_SCORE': 'float'}
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Management', Year=yr_cal, region='Australia')

    GBF3_score_non_ag_AUS = xr_gbf3_non_ag.sum(['cell']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(veg_base_score_score,
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Non-Agricultural land-use', Year=yr_cal, region='Australia')

    # Combine regional and Australia level data
    GBF3_score_ag = pd.concat([GBF3_score_ag_region, GBF3_score_ag_AUS], axis=0)
    GBF3_score_am = pd.concat([GBF3_score_am_region, GBF3_score_am_AUS], axis=0)
    GBF3_score_non_ag = pd.concat([GBF3_score_non_ag_region, GBF3_score_non_ag_AUS], axis=0)

    # Concatenate the dataframes, rename the columns, and reset the index, then save to a csv file
    veg_base_score_score = veg_base_score_score.assign(
            Type='Outside LUTO study area', 
            Year=yr_cal, 
            lu='Outside LUTO study area',
        ).eval('Relative_Contribution_Percentage = BASE_OUTSIDE_SCORE / BASE_TOTAL_SCORE * 100')
    
    pd.concat([
        GBF3_score_ag, 
        GBF3_score_am, 
        GBF3_score_non_ag,
        veg_base_score_score],axis=0
        ).rename(columns={
            'lu':'Landuse',
            'am':'Agri-Management',
            'group':'Vegetation Group',
            'Relative_Contribution_Percentage':'Contribution Relative to Pre-1750 Level (%)'}
        ).reset_index(drop=True
        ).query('`Area Weighted Score (ha)` > 0'
        ).to_csv(os.path.join(path, f'biodiversity_GBF3_scores_{yr_cal}.csv'), index=False)
        
    # Save xarray data to netCDF
    save2nc(xr_gbf3_ag, os.path.join(path, f'xr_biodiversity_GBF3_vegetation_ag_{yr_cal}.nc'))
    save2nc(xr_gbf3_non_ag, os.path.join(path, f'xr_biodiversity_GBF3_vegetation_non_ag_{yr_cal}.nc'))
    save2nc(xr_gbf3_am, os.path.join(path, f'xr_biodiversity_GBF3_vegetation_ag_management_{yr_cal}.nc'))
    
    return f"Biodiversity GBF3 scores written for year {yr_cal}"




def write_biodiversity_GBF4_SNES_scores(data: Data, yr_cal: int, path) -> None:
    if not settings.BIODIVERSITY_TARGET_GBF_4_SNES == "on":
        return "Biodiversity GBF4 SNES scores skipped (target is off)"

        
    # Unpack the agricultural management land-use
    am_lu_unpack = [(am, l) for am, lus in data.AG_MAN_LU_DESC.items() for l in lus]

    # Get decision variables for the year
    ag_dvar_mrj = tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    non_ag_dvar_rk = tools.non_ag_rk_to_xr(data, data.non_ag_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    am_dvar_amrj = tools.am_mrj_to_xr(data, data.ag_man_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    
    # Expand dimension
    ag_dvar_mrj = xr.concat([ag_dvar_mrj, ag_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    am_dvar_amrj = xr.concat([am_dvar_amrj, am_dvar_amrj.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')
    am_dvar_amrj = xr.concat([am_dvar_amrj, am_dvar_amrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')

    # Get the biodiversity scores for the year
    bio_snes_sr = xr.DataArray(
        ag_biodiversity.get_GBF4_SNES_matrix_sr(data), 
        dims=['species','cell'], 
        coords={'species':data.BIO_GBF4_SNES_SEL_ALL, 'cell':np.arange(data.NCELLS)}
    )

    # Apply habitat contribution from ag/am/non-ag land-use to biodiversity scores
    ag_impact_j = xr.DataArray(
        ag_biodiversity.get_ag_biodiversity_contribution(data),
        dims=['lu'],
        coords={'lu':data.AGRICULTURAL_LANDUSES}
    )
    non_ag_impact_k = xr.DataArray(
        list(non_ag_biodiversity.get_non_ag_lu_biodiv_contribution(data).values()),
        dims=['lu'],
        coords={'lu':data.NON_AGRICULTURAL_LANDUSES}
    )
    am_impact_amr = xr.DataArray(
        np.stack([arr for _, v in ag_biodiversity.get_ag_management_biodiversity_contribution(data, yr_cal).items() for arr in v.values()]), 
        dims=['idx', 'cell'], 
        coords={
            'idx': pd.MultiIndex.from_tuples(am_lu_unpack, names=['am', 'lu']),
            'cell': np.arange(data.NCELLS)}
    ).unstack()

    # Expand dimension
    am_impact_amr = xr.concat([am_impact_amr, am_impact_amr.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')

    # Get the base year biodiversity scores
    bio_snes_scores = pd.read_csv(settings.INPUT_DIR + '/BIODIVERSITY_GBF4_TARGET_SNES.csv')
    idx_row = [bio_snes_scores.query('SCIENTIFIC_NAME == @i').index[0] for i in data.BIO_GBF4_SNES_SEL_ALL]
    idx_all_score = [bio_snes_scores.columns.get_loc(f'HABITAT_SIGNIFICANCE_BASELINE_ALL_AUSTRALIA_{col}') for col in data.BIO_GBF4_PRESENCE_SNES_SEL]
    idx_outside_score =  [bio_snes_scores.columns.get_loc(f'HABITAT_SIGNIFICANCE_BASELINE_OUT_LUTO_NATURAL_{col}') for col in data.BIO_GBF4_PRESENCE_SNES_SEL]

    base_yr_score = pd.DataFrame({
            'species': data.BIO_GBF4_SNES_SEL_ALL, 
            'BASE_TOTAL_SCORE': [bio_snes_scores.iloc[row, col] for row, col in zip(idx_row, idx_all_score)],
            'BASE_OUTSIDE_SCORE': [bio_snes_scores.iloc[row, col] for row, col in zip(idx_row, idx_outside_score)],
            'TARGET_INSIDE_SCORE': data.get_GBF4_SNES_target_inside_LUTO_by_year(yr_cal)}
    ).eval('Target_by_Percent = (TARGET_INSIDE_SCORE + BASE_OUTSIDE_SCORE) / BASE_TOTAL_SCORE * 100')

    # Calculate the biodiversity scores
    # Calculate xarray biodiversity GBF4 SNES scores
    xr_gbf4_snes_ag = bio_snes_sr * ag_impact_j * ag_dvar_mrj
    xr_gbf4_snes_am = bio_snes_sr * am_impact_amr * am_dvar_amrj
    xr_gbf4_snes_non_ag = bio_snes_sr * non_ag_impact_k * non_ag_dvar_rk
    
    # Regional level aggregation
    GBF4_score_ag_region = xr_gbf4_snes_ag.groupby('region'
        ).sum(['cell','lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(base_yr_score
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Landuse', Year=yr_cal)
        
    GBF4_score_am_region = xr_gbf4_snes_am.groupby('region'
        ).sum(['cell','lm'], skipna=False).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(allow_duplicates=True
        ).T.drop_duplicates(
        ).T.merge(base_yr_score,
        ).astype({'Area Weighted Score (ha)': 'float', 'BASE_TOTAL_SCORE': 'float'}
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Management', Year=yr_cal)
        
    GBF4_score_non_ag_region = xr_gbf4_snes_non_ag.groupby('region'
        ).sum(['cell']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(base_yr_score,
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Non-Agricultural land-use', Year=yr_cal)

    # Australia level aggregation
    GBF4_score_ag_AUS = xr_gbf4_snes_ag.sum(['cell','lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(base_yr_score
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Landuse', Year=yr_cal, region='Australia')
        
    GBF4_score_am_AUS = xr_gbf4_snes_am.sum(['cell','lm'], skipna=False).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(allow_duplicates=True
        ).T.drop_duplicates(
        ).T.merge(base_yr_score,
        ).astype({'Area Weighted Score (ha)': 'float', 'BASE_TOTAL_SCORE': 'float'}
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Management', Year=yr_cal, region='Australia')
        
    GBF4_score_non_ag_AUS = xr_gbf4_snes_non_ag.sum(['cell']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(base_yr_score,
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Non-Agricultural land-use', Year=yr_cal, region='Australia')

    # Combine regional and Australia level data
    GBF4_score_ag = pd.concat([GBF4_score_ag_region, GBF4_score_ag_AUS], axis=0)
    GBF4_score_am = pd.concat([GBF4_score_am_region, GBF4_score_am_AUS], axis=0)
    GBF4_score_non_ag = pd.concat([GBF4_score_non_ag_region, GBF4_score_non_ag_AUS], axis=0)
        
    
    # Concatenate the dataframes, rename the columns, and reset the index, then save to a csv file
    base_yr_score = base_yr_score.assign(Type='Outside LUTO study area', Year=yr_cal, lu='Outside LUTO study area'
        ).eval('Relative_Contribution_Percentage = BASE_OUTSIDE_SCORE / BASE_TOTAL_SCORE * 100')
    
    pd.concat([
            GBF4_score_ag, 
            GBF4_score_am, 
            GBF4_score_non_ag,
            base_yr_score], axis=0
        ).rename(columns={
            'lu':'Landuse',
            'am':'Agri-Management',
            'Relative_Contribution_Percentage':'Contribution Relative to Pre-1750 Level (%)',
            'Target_by_Percent':'Target by Percent (%)'}).reset_index(drop=True
        ).query('`Area Weighted Score (ha)` > 0'
        ).to_csv(os.path.join(path, f'biodiversity_GBF4_SNES_scores_{yr_cal}.csv'), index=False)
            
    # Save xarray data to netCDF
    save2nc(xr_gbf4_snes_ag, os.path.join(path, f'xr_biodiversity_GBF4_SNES_ag_{yr_cal}.nc'))
    save2nc(xr_gbf4_snes_non_ag, os.path.join(path, f'xr_biodiversity_GBF4_SNES_non_ag_{yr_cal}.nc'))
    save2nc(xr_gbf4_snes_am, os.path.join(path, f'xr_biodiversity_GBF4_SNES_ag_management_{yr_cal}.nc'))
    
    return f"Biodiversity GBF4 SNES scores written for year {yr_cal}"





def write_biodiversity_GBF4_ECNES_scores(data: Data, yr_cal: int, path) -> None:
    
    if not settings.BIODIVERSITY_TARGET_GBF_4_ECNES == "on":
        return "Biodiversity GBF4 ECNES scores skipped (target is off)"
    
        
    # Unpack the agricultural management land-use
    am_lu_unpack = [(am, l) for am, lus in data.AG_MAN_LU_DESC.items() for l in lus]

    # Get decision variables for the year
    ag_dvar_mrj = tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    non_ag_dvar_rk = tools.non_ag_rk_to_xr(data, data.non_ag_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    am_dvar_amrj = tools.am_mrj_to_xr(data, data.ag_man_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    
    # Expand dimension
    ag_dvar_mrj = xr.concat([ag_dvar_mrj, ag_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    am_dvar_amrj = xr.concat([am_dvar_amrj, am_dvar_amrj.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')
    am_dvar_amrj = xr.concat([am_dvar_amrj, am_dvar_amrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')

    # Get the biodiversity scores for the year
    bio_ecnes_sr = xr.DataArray(
        ag_biodiversity.get_GBF4_ECNES_matrix_sr(data), 
        dims=['species','cell'], 
        coords={'species':data.BIO_GBF4_ECNES_SEL_ALL, 'cell':np.arange(data.NCELLS)}
    ).chunk({'cell': min(1024, data.NCELLS), 'species': 1})

    # Apply habitat contribution from ag/am/non-ag land-use to biodiversity scores
    ag_impact_j = xr.DataArray(
        ag_biodiversity.get_ag_biodiversity_contribution(data),
        dims=['lu'],
        coords={'lu':data.AGRICULTURAL_LANDUSES}
    )
    non_ag_impact_k = xr.DataArray(
        list(non_ag_biodiversity.get_non_ag_lu_biodiv_contribution(data).values()),
        dims=['lu'],
        coords={'lu': data.NON_AGRICULTURAL_LANDUSES}
    )
    am_impact_amr = xr.DataArray(
        np.stack([arr for _, v in ag_biodiversity.get_ag_management_biodiversity_contribution(data, yr_cal).items() for arr in v.values()]),
        dims=['idx', 'cell'],
        coords={
            'idx': pd.MultiIndex.from_tuples(am_lu_unpack, names=['am', 'lu']),
            'cell': np.arange(data.NCELLS)
        }
    ).unstack()

    # Expand dimension
    am_impact_amr = xr.concat([am_impact_amr, am_impact_amr.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')

    # Get the base year biodiversity scores
    bio_ecnes_scores = pd.read_csv(settings.INPUT_DIR + '/BIODIVERSITY_GBF4_TARGET_ECNES.csv')
    idx_row = [bio_ecnes_scores.query('COMMUNITY == @i').index[0] for i in data.BIO_GBF4_ECNES_SEL_ALL]
    idx_all_score = [bio_ecnes_scores.columns.get_loc(f'HABITAT_SIGNIFICANCE_BASELINE_ALL_AUSTRALIA_{col}') for col in data.BIO_GBF4_PRESENCE_ECNES_SEL]
    idx_outside_score = [bio_ecnes_scores.columns.get_loc(f'HABITAT_SIGNIFICANCE_BASELINE_OUT_LUTO_NATURAL_{col}') for col in data.BIO_GBF4_PRESENCE_ECNES_SEL]

    base_yr_score = pd.DataFrame({
        'species': data.BIO_GBF4_ECNES_SEL_ALL,
        'BASE_TOTAL_SCORE': [bio_ecnes_scores.iloc[row, col] for row, col in zip(idx_row, idx_all_score)],
        'BASE_OUTSIDE_SCORE': [bio_ecnes_scores.iloc[row, col] for row, col in zip(idx_row, idx_outside_score)],
        'TARGET_INSIDE_SCORE': data.get_GBF4_ECNES_target_inside_LUTO_by_year(yr_cal)
    }).eval('Target_by_Percent = (TARGET_INSIDE_SCORE + BASE_OUTSIDE_SCORE) / BASE_TOTAL_SCORE * 100')

    # Calculate the biodiversity scores
    # Calculate xarray biodiversity GBF4 ECNES scores
    xr_gbf4_ecnes_ag = bio_ecnes_sr * ag_impact_j * ag_dvar_mrj
    xr_gbf4_ecnes_am = bio_ecnes_sr * am_impact_amr * am_dvar_amrj
    xr_gbf4_ecnes_non_ag = bio_ecnes_sr * non_ag_impact_k * non_ag_dvar_rk
    
    # Regional level aggregation
    GBF4_score_ag_region = xr_gbf4_ecnes_ag.groupby('region'
        ).sum(['cell', 'lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(base_yr_score
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Landuse', Year=yr_cal)

    GBF4_score_am_region = xr_gbf4_ecnes_am.groupby('region'
        ).sum(['cell', 'lm'], skipna=False).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(allow_duplicates=True
        ).T.drop_duplicates(
        ).T.merge(base_yr_score,
        ).astype({'Area Weighted Score (ha)': 'float', 'BASE_TOTAL_SCORE': 'float'}
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Management', Year=yr_cal)

    GBF4_score_non_ag_region = xr_gbf4_ecnes_non_ag.groupby('region'
        ).sum(['cell']).to_dataframe('Area Weighted Score (ha)').reset_index(
        ).merge(base_yr_score,
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Non-Agricultural land-use', Year=yr_cal)

    # Australia level aggregation
    GBF4_score_ag_AUS = xr_gbf4_ecnes_ag.sum(['cell', 'lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(base_yr_score
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Landuse', Year=yr_cal, region='Australia')

    GBF4_score_am_AUS = xr_gbf4_ecnes_am.sum(['cell', 'lm'], skipna=False).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(allow_duplicates=True
        ).T.drop_duplicates(
        ).T.merge(base_yr_score,
        ).astype({'Area Weighted Score (ha)': 'float', 'BASE_TOTAL_SCORE': 'float'}
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Management', Year=yr_cal, region='Australia')

    GBF4_score_non_ag_AUS = xr_gbf4_ecnes_non_ag.sum(['cell']).to_dataframe('Area Weighted Score (ha)').reset_index(
        ).merge(base_yr_score,
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Non-Agricultural land-use', Year=yr_cal, region='Australia')

    # Combine regional and Australia level data
    GBF4_score_ag = pd.concat([GBF4_score_ag_region, GBF4_score_ag_AUS], axis=0)
    GBF4_score_am = pd.concat([GBF4_score_am_region, GBF4_score_am_AUS], axis=0)
    GBF4_score_non_ag = pd.concat([GBF4_score_non_ag_region, GBF4_score_non_ag_AUS], axis=0)

    # Concatenate the dataframes, rename the columns, and reset the index, then save to a csv file
    base_yr_score = base_yr_score.assign(Type='Outside LUTO study area', Year=yr_cal, lu='Outside LUTO study area'
        ).eval('Relative_Contribution_Percentage = BASE_OUTSIDE_SCORE / BASE_TOTAL_SCORE * 100')
    
    pd.concat([
            GBF4_score_ag,
            GBF4_score_am,
            GBF4_score_non_ag,
            base_yr_score], axis=0
        ).rename(columns={
            'lu':'Landuse',
            'am':'Agri-Management',
            'Relative_Contribution_Percentage': 'Contribution Relative to Pre-1750 Level (%)',
            'Target_by_Percent': 'Target by Percent (%)'}
        ).reset_index(drop=True
        ).query('`Area Weighted Score (ha)` > 0'
        ).to_csv(os.path.join(path, f'biodiversity_GBF4_ECNES_scores_{yr_cal}.csv'), index=False)
        
    # Save xarray data to netCDF
    save2nc(xr_gbf4_ecnes_ag, os.path.join(path, f'xr_biodiversity_GBF4_ECNES_ag_{yr_cal}.nc'))
    save2nc(xr_gbf4_ecnes_non_ag, os.path.join(path, f'xr_biodiversity_GBF4_ECNES_non_ag_{yr_cal}.nc'))
    save2nc(xr_gbf4_ecnes_am, os.path.join(path, f'xr_biodiversity_GBF4_ECNES_ag_management_{yr_cal}.nc'))
    
    return f"Biodiversity GBF4 ECNES scores written for year {yr_cal}"




def write_biodiversity_GBF8_scores_groups(data: Data, yr_cal, path):
    
    # Do nothing if biodiversity limits are off and no need to report
    if not settings.BIODIVERSITY_TARGET_GBF_8 == 'on':
        return "Biodiversity GBF8 groups scores skipped (target is off)"

        
    # Unpack the agricultural management land-use
    am_lu_unpack = [(am, l) for am, lus in data.AG_MAN_LU_DESC.items() for l in lus]

    # Get decision variables for the year
    ag_dvar_mrj = tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    non_ag_dvar_rk = tools.non_ag_rk_to_xr(data, data.non_ag_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    am_dvar_amrj = tools.am_mrj_to_xr(data, data.ag_man_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    
    # Expand dimension
    ag_dvar_mrj = xr.concat([ag_dvar_mrj, ag_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    am_dvar_amrj = xr.concat([am_dvar_amrj, am_dvar_amrj.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')
    am_dvar_amrj = xr.concat([am_dvar_amrj, am_dvar_amrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')

    # Get biodiversity scores for selected species
    bio_scores_sr = xr.DataArray(
        data.get_GBF8_bio_layers_by_yr(yr_cal, level='group') * data.REAL_AREA[None,:],
        dims=['group','cell'],
        coords={
            'group': data.BIO_GBF8_GROUPS_NAMES,
            'cell': np.arange(data.NCELLS)}
    ).chunk({'cell': min(1024, data.NCELLS), 'group': 1})  # Chunking to save mem use
        
    # Get the habitat contribution for ag/non-ag/am land-use to biodiversity scores
    ag_impact_j = xr.DataArray(
        ag_biodiversity.get_ag_biodiversity_contribution(data),
        dims=['lu'],
        coords={'lu':data.AGRICULTURAL_LANDUSES}
    )
    non_ag_impact_k = xr.DataArray(
        list(non_ag_biodiversity.get_non_ag_lu_biodiv_contribution(data).values()),
        dims=['lu'],
        coords={'lu': data.NON_AGRICULTURAL_LANDUSES}
    )
    am_impact_amr = xr.DataArray(
        np.stack([arr for _, v in ag_biodiversity.get_ag_management_biodiversity_contribution(data, yr_cal).items() for arr in v.values()]),
        dims=['idx', 'cell'],
        coords={
            'idx': pd.MultiIndex.from_tuples(am_lu_unpack, names=['am', 'lu']),
            'cell': np.arange(data.NCELLS)}
    ).unstack()

    # Expand dimension
    am_impact_amr = xr.concat([am_impact_amr, am_impact_amr.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')

    # Get the base year biodiversity scores
    base_yr_score = pd.DataFrame({
            'group': data.BIO_GBF8_GROUPS_NAMES, 
            'BASE_OUTSIDE_SCORE': data.get_GBF8_score_outside_natural_LUTO_by_yr(yr_cal, level='group'),
            'BASE_TOTAL_SCORE': data.BIO_GBF8_BASELINE_SCORE_GROUPS['HABITAT_SUITABILITY_BASELINE_SCORE_ALL_AUSTRALIA']}
        ).eval('Relative_Contribution_Percentage = BASE_OUTSIDE_SCORE / BASE_TOTAL_SCORE * 100')

    # Calculate GBF8 scores for groups
    # Calculate xarray biodiversity GBF8 group scores
    xr_gbf8_groups_ag = bio_scores_sr * ag_impact_j * ag_dvar_mrj
    xr_gbf8_groups_am = am_dvar_amrj * bio_scores_sr * am_impact_amr
    xr_gbf8_groups_non_ag = non_ag_dvar_rk * bio_scores_sr * non_ag_impact_k
    
    # Regional level aggregation
    GBF8_scores_groups_ag_region = xr_gbf8_groups_ag.groupby('region'
        ).sum(['cell', 'lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(base_yr_score
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Landuse', Year=yr_cal)
        
    GBF8_scores_groups_am_region = xr_gbf8_groups_am.groupby('region'
        ).sum(['cell', 'lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(allow_duplicates=True
        ).T.drop_duplicates(
        ).T.merge(base_yr_score
        ).astype({'Area Weighted Score (ha)': 'float', 'BASE_TOTAL_SCORE': 'float'}
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Management', Year=yr_cal)
        
    GBF8_scores_groups_non_ag_region = xr_gbf8_groups_non_ag.groupby('region'
        ).sum(['cell']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(base_yr_score
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Non-Agricultural land-use', Year=yr_cal)

    # Australia level aggregation
    GBF8_scores_groups_ag_AUS = xr_gbf8_groups_ag.sum(['cell', 'lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(base_yr_score
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Landuse', Year=yr_cal, region='Australia')
        
    GBF8_scores_groups_am_AUS = xr_gbf8_groups_am.sum(['cell', 'lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(allow_duplicates=True
        ).T.drop_duplicates(
        ).T.merge(base_yr_score
        ).astype({'Area Weighted Score (ha)': 'float', 'BASE_TOTAL_SCORE': 'float'}
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Management', Year=yr_cal, region='Australia')
        
    GBF8_scores_groups_non_ag_AUS = xr_gbf8_groups_non_ag.sum(['cell']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(base_yr_score
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Non-Agricultural land-use', Year=yr_cal, region='Australia')

    # Combine regional and Australia level data
    GBF8_scores_groups_ag = pd.concat([GBF8_scores_groups_ag_region, GBF8_scores_groups_ag_AUS], axis=0)
    GBF8_scores_groups_am = pd.concat([GBF8_scores_groups_am_region, GBF8_scores_groups_am_AUS], axis=0)
    GBF8_scores_groups_non_ag = pd.concat([GBF8_scores_groups_non_ag_region, GBF8_scores_groups_non_ag_AUS], axis=0)

    # Concatenate the dataframes, rename the columns, and reset the index, then save to a csv file
    base_yr_score = base_yr_score.assign(Type='Outside LUTO study area', Year=yr_cal) 

    pd.concat([
        GBF8_scores_groups_ag, 
        GBF8_scores_groups_am, 
        GBF8_scores_groups_non_ag,
        base_yr_score], axis=0
        ).rename(columns={
            'group': 'Group',
            'lu': 'Landuse',
            'am': 'Agri-Management',
            'Relative_Contribution_Percentage': 'Contribution Relative to Pre-1750 Level (%)'}
        ).reset_index(drop=True
        ).query('`Area Weighted Score (ha)` > 0'
        ).to_csv(os.path.join(path, f'biodiversity_GBF8_groups_scores_{yr_cal}.csv'), index=False)

    # Save xarray data to netCDF
    save2nc(xr_gbf8_groups_ag, os.path.join(path, f'xr_biodiversity_GBF8_groups_ag_{yr_cal}.nc'))
    save2nc(xr_gbf8_groups_non_ag, os.path.join(path, f'xr_biodiversity_GBF8_groups_non_ag_{yr_cal}.nc'))
    save2nc(xr_gbf8_groups_am, os.path.join(path, f'xr_biodiversity_GBF8_groups_ag_management_{yr_cal}.nc'))
    
    return f"Biodiversity GBF8 groups scores written for year {yr_cal}"




def write_biodiversity_GBF8_scores_species(data: Data, yr_cal, path):
    # Caculate the biodiversity scores for species, if user selected any species
    if (not settings.BIODIVERSITY_TARGET_GBF_8 == 'on') or (len(data.BIO_GBF8_SEL_SPECIES) == 0):
        return "Biodiversity GBF8 species scores skipped (target is off)"
    
        
    # Unpack the agricultural management land-use
    am_lu_unpack = [(am, l) for am, lus in data.AG_MAN_LU_DESC.items() for l in lus]

    # Get decision variables for the year
    ag_dvar_mrj = tools.ag_mrj_to_xr(data, data.ag_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    non_ag_dvar_rk = tools.non_ag_rk_to_xr(data, data.non_ag_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    am_dvar_amrj = tools.am_mrj_to_xr(data, data.ag_man_dvars[yr_cal]
        ).chunk({'cell': min(1024, data.NCELLS)}
        ).assign_coords(region=('cell', data.REGION_NRM_NAME))
    
    # Expand dimension
    ag_dvar_mrj = xr.concat([ag_dvar_mrj, ag_dvar_mrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')
    am_dvar_amrj = xr.concat([am_dvar_amrj, am_dvar_amrj.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')
    am_dvar_amrj = xr.concat([am_dvar_amrj, am_dvar_amrj.sum(dim='lm', keepdims=True).assign_coords(lm=['ALL'])], dim='lm')

    # Get biodiversity scores for selected species
    bio_scores_sr = xr.DataArray(
        data.get_GBF8_bio_layers_by_yr(yr_cal, level='species') * data.REAL_AREA[None, :],
        dims=['species', 'cell'],
        coords={
            'species': data.BIO_GBF8_SEL_SPECIES,
            'cell': np.arange(data.NCELLS)}
    ).chunk({'cell': min(1024, data.NCELLS), 'species': 1})  # Chunking to save mem use

    # Get the habitat contribution for ag/non-ag/am land-use to biodiversity scores
    ag_impact_j = xr.DataArray(
        ag_biodiversity.get_ag_biodiversity_contribution(data),
        dims=['lu'],
        coords={'lu':data.AGRICULTURAL_LANDUSES}
    )
    non_ag_impact_k = xr.DataArray(
        list(non_ag_biodiversity.get_non_ag_lu_biodiv_contribution(data).values()),
        dims=['lu'],
        coords={'lu': data.NON_AGRICULTURAL_LANDUSES}
    )
    am_impact_amr = xr.DataArray(
        np.stack([arr for _, v in ag_biodiversity.get_ag_management_biodiversity_contribution(data, yr_cal).items() for arr in v.values()]),
        dims=['idx', 'cell'],
        coords={
            'idx': pd.MultiIndex.from_tuples(am_lu_unpack, names=['am', 'lu']),
            'cell': np.arange(data.NCELLS)}
    ).unstack()

    # Expand dimension
    am_impact_amr = xr.concat([am_impact_amr, am_impact_amr.sum(dim='am', keepdims=True).assign_coords(am=['ALL'])], dim='am')

    # Get the base year biodiversity scores
    base_yr_score = pd.DataFrame({
            'species': data.BIO_GBF8_SEL_SPECIES,
            'BASE_OUTSIDE_SCORE': data.get_GBF8_score_outside_natural_LUTO_by_yr(yr_cal),
            'BASE_TOTAL_SCORE': data.BIO_GBF8_BASELINE_SCORE_AND_TARGET_PERCENT_SPECIES['HABITAT_SUITABILITY_BASELINE_SCORE_ALL_AUSTRALIA'],
            'TARGET_INSIDE_SCORE': data.get_GBF8_target_inside_LUTO_by_yr(yr_cal),}
        ).eval('Target_by_Percent = (TARGET_INSIDE_SCORE + BASE_OUTSIDE_SCORE) / BASE_TOTAL_SCORE * 100')

    # Calculate GBF8 scores for species
    # Calculate xarray biodiversity GBF8 species scores
    xr_gbf8_species_ag = bio_scores_sr * ag_impact_j * ag_dvar_mrj
    xr_gbf8_species_am = am_dvar_amrj * bio_scores_sr * am_impact_amr
    xr_gbf8_species_non_ag = non_ag_dvar_rk * bio_scores_sr * non_ag_impact_k
    
    # Regional level aggregation
    GBF8_scores_species_ag_region = xr_gbf8_species_ag.groupby('region'
        ).sum(['cell', 'lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(base_yr_score
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Landuse', Year=yr_cal)

    GBF8_scores_species_am_region = xr_gbf8_species_am.groupby('region'
        ).sum(['cell', 'lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(allow_duplicates=True
        ).T.drop_duplicates(
        ).T.merge(base_yr_score
        ).astype({'Area Weighted Score (ha)': 'float', 'BASE_TOTAL_SCORE': 'float'}
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Management', Year=yr_cal)

    GBF8_scores_species_non_ag_region = xr_gbf8_species_non_ag.groupby('region'
        ).sum(['cell']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(base_yr_score
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Non-Agricultural land-use', Year=yr_cal)

    # Australia level aggregation
    GBF8_scores_species_ag_AUS = xr_gbf8_species_ag.sum(['cell', 'lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(base_yr_score
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Landuse', Year=yr_cal, region='Australia')

    GBF8_scores_species_am_AUS = xr_gbf8_species_am.sum(['cell', 'lm']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(allow_duplicates=True
        ).T.drop_duplicates(
        ).T.merge(base_yr_score
        ).astype({'Area Weighted Score (ha)': 'float', 'BASE_TOTAL_SCORE': 'float'}
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Agricultural Management', Year=yr_cal, region='Australia')

    GBF8_scores_species_non_ag_AUS = xr_gbf8_species_non_ag.sum(['cell']
        ).to_dataframe('Area Weighted Score (ha)'
        ).reset_index(
        ).merge(base_yr_score
        ).eval('Relative_Contribution_Percentage = `Area Weighted Score (ha)` / BASE_TOTAL_SCORE * 100'
        ).assign(Type='Non-Agricultural land-use', Year=yr_cal, region='Australia')

    # Combine regional and Australia level data
    GBF8_scores_species_ag = pd.concat([GBF8_scores_species_ag_region, GBF8_scores_species_ag_AUS], axis=0)
    GBF8_scores_species_am = pd.concat([GBF8_scores_species_am_region, GBF8_scores_species_am_AUS], axis=0)
    GBF8_scores_species_non_ag = pd.concat([GBF8_scores_species_non_ag_region, GBF8_scores_species_non_ag_AUS], axis=0)

    # Concatenate the dataframes, rename the columns, and reset the index, then save to a csv file
    base_yr_score = base_yr_score.assign(Type='Outside LUTO study area', Year=yr_cal, lu='Outside LUTO study area'
        ).eval('Relative_Contribution_Percentage = BASE_OUTSIDE_SCORE / BASE_TOTAL_SCORE * 100')

    pd.concat([
        GBF8_scores_species_ag,
        GBF8_scores_species_am,
        GBF8_scores_species_non_ag,
        base_yr_score], axis=0
        ).rename(columns={
            'species': 'Species',
            'lu': 'Landuse',
            'am': 'Agri-Management',
            'Relative_Contribution_Percentage': 'Contribution Relative to Pre-1750 Level (%)'}
        ).reset_index(drop=True
        ).query('`Area Weighted Score (ha)` > 0'
        ).to_csv(os.path.join(path, f'biodiversity_GBF8_species_scores_{yr_cal}.csv'), index=False)
        
    # Save xarray data to netCDF
    save2nc(xr_gbf8_species_ag, os.path.join(path, f'xr_biodiversity_GBF8_species_ag_{yr_cal}.nc'))
    save2nc(xr_gbf8_species_non_ag, os.path.join(path, f'xr_biodiversity_GBF8_species_non_ag_{yr_cal}.nc'))
    save2nc(xr_gbf8_species_am, os.path.join(path, f'xr_biodiversity_GBF8_species_ag_management_{yr_cal}.nc'))
    
    return f"Biodiversity GBF8 species scores written for year {yr_cal}"
```

## luto/tools/__init__.py

```python
# Copyright 2025 Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., 
# van Schoten, N., Hadjikakou, M., Sanson, J.,  Zyngier, R., Marcos-Martinez, R.,  
# Navarro, J.,  Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., 
# Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.
#
# This file is part of LUTO2 - Version 2 of the Australian Land-Use Trade-Offs model
#
# LUTO2 is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# LUTO2 is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# LUTO2. If not, see <https://www.gnu.org/licenses/>.



"""
Pure helper functions and other tools.
"""

import gc
import sys
import os.path
import threading
import time
import traceback
import functools
import tracemalloc

import pandas as pd
import numpy as np
import psutil
import xarray as xr
import numpy_financial as npf
import matplotlib.patches as patches

from typing import Tuple
from datetime import datetime
from matplotlib import pyplot as plt

import luto.settings as settings
import luto.economics.agricultural.water as ag_water
import luto.economics.non_agricultural.water as non_ag_water


def write_timestamp():
    timestamp = datetime.now().strftime('%Y_%m_%d__%H_%M_%S')
    timestamp_path = os.path.join(settings.OUTPUT_DIR, '.timestamp')
        
    with open(timestamp_path, 'w') as f: f.write(timestamp)
    return timestamp

def read_timestamp():
    timestamp_path = os.path.join(settings.OUTPUT_DIR, '.timestamp')
    if os.path.exists(timestamp_path):
        with open(timestamp_path, 'r') as f: timestamp = f.read()
    else:
        raise FileNotFoundError(f"Timestamp file not found at {timestamp_path}")
    return timestamp


def amortise(cost, rate=settings.DISCOUNT_RATE, horizon=settings.AMORTISATION_PERIOD):
    """Return NPV of future `cost` amortised to annual value at discount `rate` over `horizon` years."""
    if settings.AMORTISE_UPFRONT_COSTS: 
        return -1 * npf.pmt(rate, horizon, pv=cost, fv=0, when='begin')
    else: 
        return cost


def lumap2ag_l_mrj(lumap, lmmap):
    """
    Return land-use maps in decision-variable (X_mrj) format.
    Where 'm' is land mgt, 'r' is cell, and 'j' is agricultural land-use.

    Cells used for non-agricultural land uses will have value 0 for all agricultural
    land uses, i.e. all r.
    """
    # Set up a container array of shape m, r, j.
    x_mrj = np.zeros((2, lumap.shape[0], 28), dtype=bool)   # TODO - remove 2

    # Populate the 3D land-use, land mgt mask.
    for j in range(28):
        # One boolean map for each land use.
        jmap = np.where(lumap == j, True, False).astype(bool)
        # Keep only dryland version.
        x_mrj[0, :, j] = np.where(lmmap == False, jmap, False)
        # Keep only irrigated version.
        x_mrj[1, :, j] = np.where(lmmap == True, jmap, False)

    return x_mrj.astype(bool)


def lumap2non_ag_l_mk(lumap, num_non_ag_land_uses: int):
    """
    Convert the land-use map to a decision variable X_rk, where 'r' indexes cell and
    'k' indexes non-agricultural land use.

    Cells used for agricultural purposes have value 0 for all k.
    """
    base_code = settings.NON_AGRICULTURAL_LU_BASE_CODE
    non_ag_lu_codes = list(range(base_code, base_code + num_non_ag_land_uses))

    # Set up a container array of shape r, k.
    x_rk = np.zeros((lumap.shape[0], num_non_ag_land_uses), dtype=bool)

    for i,k in enumerate(non_ag_lu_codes):
        kmap = np.where(lumap == k, True, False)
        x_rk[:, i] = kmap

    return x_rk.astype(bool)


def get_ag_and_non_ag_cells(lumap) -> Tuple[np.ndarray, np.ndarray]:
    """
    Splits the index of cells based on whether that cell is used for agricultural
    land, given the lumap.

    Returns
    -------
    ( np.ndarray, np.ndarray )
        Two numpy arrays containing the split cell index.
    """
    non_ag_base = settings.NON_AGRICULTURAL_LU_BASE_CODE
    all_cells = np.array(range(lumap.shape[0]))

    # get all agricultural and non agricultural cells
    non_agricultural_cells = np.nonzero(lumap >= non_ag_base)[0]
    agricultural_cells = np.nonzero(
        ~np.isin(all_cells, non_agricultural_cells)
    )[0]

    return agricultural_cells, non_agricultural_cells


def get_env_plantings_cells(lumap) -> np.ndarray:
    """
    Get an array with cells used for environmental plantings
    """
    return np.nonzero(lumap == settings.NON_AGRICULTURAL_LU_BASE_CODE + 0)[0]


def get_riparian_plantings_cells(lumap) -> np.ndarray:
    """
    Get an array with cells used for riparian plantings
    """
    return np.nonzero(lumap == settings.NON_AGRICULTURAL_LU_BASE_CODE + 1)[0]


def get_sheep_agroforestry_cells(lumap) -> np.ndarray:
    """
    Get an array with cells used for riparian plantings
    """
    return np.nonzero(lumap == settings.NON_AGRICULTURAL_LU_BASE_CODE + 2)[0]


def get_beef_agroforestry_cells(lumap) -> np.ndarray:
    """
    Get an array with cells used for riparian plantings
    """
    return np.nonzero(lumap == settings.NON_AGRICULTURAL_LU_BASE_CODE + 3)[0]


def get_agroforestry_cells(lumap) -> np.ndarray:
    """
    Get an array with cells that currently use agroforestry (either sheep or beef)
    """
    agroforestry_lus = [settings.NON_AGRICULTURAL_LU_BASE_CODE + 2, settings.NON_AGRICULTURAL_LU_BASE_CODE + 3]
    return np.nonzero(np.isin(lumap, agroforestry_lus))[0]


def get_carbon_plantings_block_cells(lumap) -> np.ndarray:
    """
    Get an array with all cells being used for carbon plantings (block)
    """
    return np.nonzero(lumap == settings.NON_AGRICULTURAL_LU_BASE_CODE + 4)[0]


def get_sheep_carbon_plantings_belt_cells(lumap) -> np.ndarray:
    """
    Get an array with all cells being used for sheep carbon plantings (belt)
    """
    return np.nonzero(lumap == settings.NON_AGRICULTURAL_LU_BASE_CODE + 5)[0]


def get_beef_carbon_plantings_belt_cells(lumap) -> np.ndarray:
    """
    Get an array with all cells being used for beef carbon plantings (belt)
    """
    return np.nonzero(lumap == settings.NON_AGRICULTURAL_LU_BASE_CODE + 6)[0]


def get_carbon_plantings_belt_cells(lumap) -> np.ndarray:
    """
    Get an array with cells used that currently use carbon plantings belt (either sheep or beef)
    """

    cp_belt_lus = [settings.NON_AGRICULTURAL_LU_BASE_CODE + 5, settings.NON_AGRICULTURAL_LU_BASE_CODE + 6]
    return np.nonzero(np.isin(lumap, cp_belt_lus))[0]


def get_beccs_cells(lumap) -> np.ndarray:
    """
    Get an array with all cells being used for carbon plantings (block)
    """
    return np.nonzero(lumap == settings.NON_AGRICULTURAL_LU_BASE_CODE + 7)[0]


def get_destocked_land_cells(lumap) -> np.ndarray:
    """
    Get an array with all destocked land cells
    """
    return np.nonzero(lumap == settings.NON_AGRICULTURAL_LU_BASE_CODE + 8)[0]


def get_unallocated_natural_lu_cells(data, lumap) -> np.ndarray:
    """
    Gets all cells being used for unallocated natural land uses.
    """
    return np.nonzero(np.isin(lumap, data.DESC2AGLU["Unallocated - natural land"]))[0]

def get_lvstk_natural_lu_cells(data, lumap) -> np.ndarray:
    """
    Gets all cells being used for livestock natural land uses.
    """
    return np.nonzero(np.isin(lumap, data.LU_LVSTK_NATURAL))[0]


def get_non_ag_natural_lu_cells(data, lumap) -> np.ndarray:
    """
    Gets all cells being used for non-agricultural natural land uses.
    """
    return np.nonzero(np.isin(lumap, data.NON_AG_LU_NATURAL))[0]


def get_ag_and_non_ag_natural_lu_cells(data, lumap) -> np.ndarray:
    """
    Gets all cells being used for natural land uses, both agricultural and non-agricultural.
    """
    return np.nonzero(np.isin(lumap, data.LU_NATURAL + data.NON_AG_LU_NATURAL))[0]


def get_ag_cells(lumap) -> np.ndarray:
    """
    Get an array containing the index of all agricultural cells
    """
    return np.nonzero(lumap < settings.NON_AGRICULTURAL_LU_BASE_CODE)[0]


def get_non_ag_cells(lumap) -> np.ndarray:
    """
    Get an array containing the index of all non-agricultural cells
    """
    return np.nonzero(lumap >= settings.NON_AGRICULTURAL_LU_BASE_CODE)[0]


def get_ag_to_ag_water_delta_matrix(w_mrj, l_mrj, data, yr_idx):
    """
    Gets the water delta matrix ($/cell) that applies the cost of installing/removing irrigation to
    base transition costs. Includes the costs of water license fees.

    Parameters
     w_mrj (numpy.ndarray, <unit:ML/cell>): Water requirements matrix for target year.
     l_mrj (numpy.ndarray): Land-use and land management matrix for the base_year.
     data (object): Data object containing necessary information.

    Returns
     w_delta_mrj (numpy.ndarray, <unit:$/cell>).
    """
    yr_cal = data.YR_CAL_BASE + yr_idx
    
    # Get water requirements from current agriculture, converting water requirements for LVSTK from ML per head to ML per cell (inc. REAL_AREA).
    # Sum total water requirements of current land-use and land management
    w_r = (w_mrj * l_mrj).sum(axis=0).sum(axis=1)

    # Net water requirements calculated as the diff in water requirements between current land-use and all other land-uses j.
    w_net_mrj = w_mrj - w_r[:, np.newaxis]

    # Water license cost calculated as net water requirements (ML/cell) x licence price ($/ML).
    w_delta_mrj = w_net_mrj * data.WATER_LICENCE_PRICE[:, np.newaxis] * data.WATER_LICENSE_COST_MULTS[yr_cal] * settings.INCLUDE_WATER_LICENSE_COSTS

    # When land-use changes from dryland to irrigated add <settings.NEW_IRRIG_COST> per hectare for establishing irrigation infrastructure
    new_irrig = (
        settings.NEW_IRRIG_COST
        * data.IRRIG_COST_MULTS[yr_cal]
        * data.REAL_AREA[:, np.newaxis]  # <unit:$/cell>
    )
    w_delta_mrj[1] = np.where(l_mrj[0], w_delta_mrj[1] + new_irrig, w_delta_mrj[1])

    # When land-use changes from irrigated to dryland add <settings.REMOVE_IRRIG_COST> per hectare for removing irrigation infrastructure
    remove_irrig = (
        settings.REMOVE_IRRIG_COST
        * data.IRRIG_COST_MULTS[yr_cal]
        * data.REAL_AREA[:, np.newaxis]  # <unit:$/cell>
    )
    w_delta_mrj[0] = np.where(l_mrj[1], w_delta_mrj[0] + remove_irrig, w_delta_mrj[0])
    
    # Amortise upfront costs to annualised costs
    w_delta_mrj = amortise(w_delta_mrj)
    
    return w_delta_mrj  # <unit:$/cell>

def get_ag_to_non_ag_water_delta_matrix(data, yr_idx, lumap, lmmap)->tuple[np.ndarray, np.ndarray]:
    """
    Gets the water delta matrix ($/cell) that applies the cost of installing/removing irrigation to
    base transition costs. Includes the costs of water license fees.
    
    Parameters
     data (object): Data object containing necessary information.
     yr_idx (int): Index of the target year.
     lumap (numpy.ndarray): Land-use map.
     lmmap (numpy.ndarray): Land management map.
    
    Returns
     w_rm_irrig_cost_r (numpy.ndarray) : Cost of removing irrigation for each cell.
     
     
    """
    
    yr_cal = data.YR_CAL_BASE + yr_idx
    l_mrj = lumap2ag_l_mrj(lumap, lmmap)
    non_ag_cells = get_non_ag_cells(lumap)
    
    w_req_mrj = ag_water.get_wreq_matrices(data, yr_idx).astype(np.float32)     # <unit: ML/CELL>
    w_req_r = (w_req_mrj * l_mrj).sum(axis=0).sum(axis=1)
    w_yield_r = non_ag_water.get_w_net_yield_env_planting(data, yr_idx)  # <unit: ML/CELL>
    w_delta_r = - (w_req_r + w_yield_r)
    
    w_license_cost_r = w_delta_r * data.WATER_LICENCE_PRICE * data.WATER_LICENSE_COST_MULTS[yr_cal] * settings.INCLUDE_WATER_LICENSE_COSTS     # <unit: $/CELL>
    w_rm_irrig_cost_r = np.where(lmmap == 1, settings.REMOVE_IRRIG_COST * data.IRRIG_COST_MULTS[yr_cal], 0) * data.REAL_AREA                   # <unit: $/CELL>

    return w_rm_irrig_cost_r


def am_name_snake_case(am_name):
    """Get snake_case version of the AM name"""
    return am_name.lower().replace(' ', '_')


def get_exclusions_for_excluding_all_natural_cells(data, lumap) -> np.ndarray:
    """
    A number of non-agricultural land uses can only be applied to cells that
    don't already utilise a natural land use. This function gets the exclusion
    matrix for all such non-ag land uses, returning an array valued 0 at the 
    indices of cells that use natural land uses, and 1 everywhere else.

    Parameters
     data: The data object containing information about the cells.
     lumap: The land use map.

    Returns
     exclude: An array of shape (NCELLS,) with values 0 at the indices of cells
               that use natural land uses, and 1 everywhere else.
    """
    exclude = np.ones(data.NCELLS)

    natural_lu_cells = get_ag_and_non_ag_natural_lu_cells(data, lumap)
    exclude[natural_lu_cells] = 0

    return exclude


def get_exclusions_agroforestry_base(data, lumap) -> np.ndarray:
    """
    Return a 1-D array indexed by r that represents how much agroforestry can possibly 
    be done at each cell.

    Parameters
     data: The data object containing information about the landscape.
     lumap: The land use map.

    Returns
     exclude: A 1-D array.
    """
    exclude = (np.ones(data.NCELLS) * settings.AF_PROPORTION).astype(np.float32)

    # Ensure cells being used for agroforestry may retain that LU
    exclude[get_agroforestry_cells(lumap)] = settings.AF_PROPORTION

    return exclude


def get_exclusions_carbon_plantings_belt_base(data, lumap) -> np.ndarray:
    """
    Return a 1-D array indexed by r that represents how much carbon plantings (belt) can possibly 
    be done at each cell.

    Parameters
     data (Data): The data object containing information about the cells.
     lumap (np.ndarray): The land use map.

    Returns
     exclude: A 1-D array
    """
    exclude = (np.ones(data.NCELLS) * settings.CP_BELT_PROPORTION).astype(np.float32)

    # Ensure cells being used for carbon plantings (belt) may retain that LU
    exclude[get_carbon_plantings_belt_cells(lumap)] = settings.CP_BELT_PROPORTION

    return exclude


def get_sheep_code(data):
    """
    Get the land use code (j) for 'Sheep - modified land'
    """
    return data.DESC2AGLU['Sheep - modified land']


def get_beef_code(data):
    """
    Get the land use code (j) for 'Beef - modified land'
    """
    return data.DESC2AGLU['Beef - modified land']


def get_natural_sheep_code(data):
    """
    Get the land use code (j) for 'Sheep - natural land'
    """
    return data.DESC2AGLU['Sheep - natural land']


def get_natural_beef_code(data):
    """
    Get the land use code (j) for 'Beef - modified land'
    """
    return data.DESC2AGLU['Beef - natural land']


def get_unallocated_natural_land_code(data):
    """
    Get the land use code (j) for 'Unallocated - natural land'
    """
    return data.DESC2AGLU['Unallocated - natural land']


def get_cells_using_ag_landuse(lumap: np.ndarray, j: int) -> np.ndarray:
    """
    Gets the cells in the given 'lumap' using the land use indexed by 'j'
    """
    return np.where(lumap == j)[0]


def ag_mrj_to_xr(data, arr):
    return xr.DataArray(
        arr,
        dims=['lm', 'cell', 'lu'],
        coords={'lm': data.LANDMANS,
                'cell': np.arange(data.NCELLS),
                'lu': data.AGRICULTURAL_LANDUSES}
    )

def non_ag_rk_to_xr(data, arr):
    return xr.DataArray(
        arr,
        dims=['cell', 'lu'],
        coords={'cell': np.arange(data.NCELLS),
                'lu': data.NON_AGRICULTURAL_LANDUSES}
    )

def am_mrj_to_xr(data, am_mrj_dict):
    emp_arr_xr = xr.DataArray(
        np.full((data.N_AG_MANS, data.NLMS, data.NCELLS, data.N_AG_LUS), np.nan),
        dims=['am', 'lm', 'cell', 'lu'],
        coords={'am': data.AG_MAN_DESC,
                'lm': data.LANDMANS,
                'cell': np.arange(data.NCELLS),
                'lu': data.AGRICULTURAL_LANDUSES}
    )

    for am,lu in data.AG_MAN_LU_DESC.items():
        if emp_arr_xr.loc[am, :, :, lu].shape == am_mrj_dict[am].shape:
            # If the shape is the same, just assign the value
            emp_arr_xr.loc[am, :, :, lu] = am_mrj_dict[am]  
        else:
            # Otherwise, assign the array at index of the land use
            lu_idx = [data.DESC2AGLU[i] for i in settings.AG_MANAGEMENTS_TO_LAND_USES[am]]
            emp_arr_xr.loc[am, :, :, lu] = am_mrj_dict[am][:,:, lu_idx]   
    return emp_arr_xr


def map_desc_to_dvar_index(category: str,
                           desc2idx: dict,
                           dvar_arr: np.ndarray):
    '''Input:
        category: str, the category of the dvar, e.g., 'Agriculture/Non-Agriculture',
        desc2idx: dict, the mapping between lu_desc and dvar index, e.g., {'Apples': 0 ...},
        dvar_arr: np.ndarray, the dvar array with shape (r,{j|k}), where r is the number of pixels,
                  and {j|k} is the dimension of ag-landuses or non-ag-landuses.

    Return:
        pd.DataFrame, with columns of ['Category','lu_desc','dvar_idx','dvar'].'''

    df = pd.DataFrame({'Category': category,
                       'lu_desc': desc2idx.keys(),
                       'dvar_idx': desc2idx.values()})

    df['dvar'] = [dvar_arr[:, j] for j in df['dvar_idx']]

    return df.reindex(columns=['Category', 'lu_desc', 'dvar_idx', 'dvar'])


def plot_t_mat(t_mat:xr.DataArray):
    
    '''
    Plot the transition matrix with hatched rectangles for NaN values.
    
    Parameters
    ----------
    t_mat : xr.DataArray
        The transition matrix to plot.
        
    '''
 
    # Set up plot
    fig, ax = plt.subplots(figsize=(8, 8))

    # Plot with imshow for correct alignment
    im = ax.imshow(t_mat.values, cmap='viridis', origin='upper')

    # Set tick positions and labels
    ax.set_xticks(np.arange(len(t_mat.coords['to_lu'])))
    ax.set_yticks(np.arange(len(t_mat.coords['from_lu'])))
    ax.set_xticklabels(t_mat.coords['to_lu'].values, rotation=90)
    ax.set_yticklabels(t_mat.coords['from_lu'].values)

    # Move x labels to top
    ax.xaxis.set_label_position('top')
    ax.xaxis.tick_top()

    # Draw hatched rectangles over NaNs
    nrows, ncols = t_mat.shape
    for i in range(nrows):
        for j in range(ncols):
            if np.isnan(t_mat[i, j]):
                rect = patches.Rectangle((j - 0.5, i - 0.5), 1, 1, hatch='////', fill=False, edgecolor='gray', linewidth=0.0)
                ax.add_patch(rect)

def set_path() -> str:
        """Create a folder for storing outputs and return folder name."""
        years = [i for i in settings.SIM_YEARS]
        path = f"{settings.OUTPUT_DIR}/{read_timestamp()}_RF{settings.RESFACTOR}_{years[0]}-{years[-1]}"
        paths = (
            [path]
            + [f"{path}/out_{yr}" for yr in years]
            + [f"{path}/out_{yr}/lucc_separate" for yr in years[1:]]
        )

        for p in paths:
            if not os.path.exists(p):
                os.mkdir(p)
  

class LogToFile:
    def __init__(self, log_path, mode:str='a'):
        self.log_path_stdout = f"{log_path}_stdout.log"
        self.log_path_stderr = f"{log_path}_stderr.log"
        self.mode = mode

    def __call__(self, func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            with open(self.log_path_stdout, self.mode) as file_stdout, open(self.log_path_stderr, self.mode) as file_stderr:
                original_stdout = sys.stdout
                original_stderr = sys.stderr
                try:
                    sys.stdout = self.StreamToLogger(file_stdout, original_stdout)
                    sys.stderr = self.StreamToLogger(file_stderr, original_stderr)
                    return func(*args, **kwargs)
                except Exception as e:
                    # Capture the full traceback
                    exc_info = traceback.format_exc()
                    # Log the traceback to stderr log before re-raising the exception
                    sys.stderr.write(exc_info + '\n')
                    raise  # Re-raise the caught exception to propagate it
                finally:
                    # Reset stdout and stderr
                    sys.stdout = original_stdout
                    sys.stderr = original_stderr
        return wrapper

    class StreamToLogger(object):
        def __init__(self, file, orig_stream=None):
            self.file = file
            self.orig_stream = orig_stream

        def write(self, buf):
            if buf.strip():  # Check if buf is just whitespace/newline
                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                formatted_buf = f"{timestamp} - {buf}"
            else:
                formatted_buf = buf  # If buf is just a newline/whitespace, don't prepend timestamp

            # Write to the original stream if it exists
            if self.orig_stream:
                self.orig_stream.write(formatted_buf)
            
            # Write to the log file
            self.file.write(formatted_buf)

        def flush(self):
            # Ensure content is written to disk
            self.file.flush()
            
            

def log_memory_usage(output_dir=settings.OUTPUT_DIR, mode='a', interval=1, stop_event=None):
    '''
    Log the memory usage of the current process to a file with enhanced accuracy.
    Parameters
        output_dir (str): The directory to save the memory log file.
        mode (str): The mode to open the file. Default is 'a' (append).
        interval (int): The interval in seconds to log the memory usage.
    '''
    
    with open(f'{output_dir}/RES_{settings.RESFACTOR}_mem_log.txt', mode=mode) as file:
        while not stop_event.is_set():
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            process = psutil.Process(os.getpid())
            
            # Get working set memory (most accurate) - ensure consistency across all processes
            memory_info = process.memory_info()
            
            # Check if working set is available on this system
            has_wset = hasattr(memory_info, 'wset')
            
            if has_wset:
                wset_memory = memory_info.wset
            else:
                wset_memory = memory_info.rss
            
            # Include child processes using the SAME metric type
            children = process.children(recursive=True)
            if children:
                for child in children:
                    try:
                        child_memory_info = child.memory_info()
                        if has_wset and hasattr(child_memory_info, 'wset'):
                            wset_memory += child_memory_info.wset
                        else:
                            # Use RSS for consistency if wset not available
                            wset_memory += child_memory_info.rss
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        continue
            
            # Write working set memory info (most accurate)
            wset_gb = wset_memory / (1024 * 1024 * 1024)
            
            file.write(f'{timestamp}\t{wset_gb:.3f}\n')
            file.flush()
            time.sleep(interval)


# Enhanced memory monitoring helper functions            
memory_log = []
monitoring = False
monitor_thread = None
baseline_memory = 0  # Store the baseline memory at start

def monitor_memory(interval=0.01):
    """
    Memory monitoring focused on Working Set delta from baseline.
    Runs in a thread, logs memory usage every `interval` seconds.
    """
    process = psutil.Process(os.getpid())
    
    while monitoring:
        try:
            memory_info = process.memory_info()
            
            # Check if working set is available and use consistently
            has_wset = hasattr(memory_info, 'wset')
            
            if has_wset:
                current_wset_mb = memory_info.wset / 1024 ** 2
            else:
                current_wset_mb = memory_info.rss / 1024 ** 2
            
            # Calculate delta from baseline
            delta_mb = current_wset_mb - baseline_memory
            
            # Store delta memory info
            memory_log.append({
                'time': time.time(),
                'wset_mb': current_wset_mb,
                'delta_mb': delta_mb
            })
            
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            break
            
        time.sleep(interval)

def start_memory_monitor():
    """
    Start Working Set memory monitoring with baseline measurement.
    Clears previous logs and starts monitoring from current memory usage.
    """
    global monitoring, monitor_thread, baseline_memory
    
    # Clear previous log
    memory_log.clear()
    
    # Force garbage collection to get clean baseline
    gc.collect()
    
    # Get baseline memory usage
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    
    has_wset = hasattr(memory_info, 'wset')
    if has_wset:
        baseline_memory = memory_info.wset / 1024 ** 2
    else:
        baseline_memory = memory_info.rss / 1024 ** 2
        
    # Start monitoring
    monitoring = True
    monitor_thread = threading.Thread(target=monitor_memory, daemon=True)
    monitor_thread.start()
    
    print("Delta memory monitoring started")

def stop_memory_monitor():
    """
    Stop memory monitoring and return delta analysis.
    Returns a plot showing only the incremental memory usage.
    """
    global monitoring
    
    monitoring = False
    if monitor_thread:
        monitor_thread.join()
    
    if not memory_log:
        print("No memory data collected")
        return None
    
    # Convert to DataFrame
    df = pd.DataFrame(memory_log)
    df['Time'] = df['time'] - df['time'].min()

    # Delta memory plot (main focus)
    plt.plot(df['Time'], df['delta_mb'])
    plt.xlabel('Time (s)')
    plt.ylabel('Delta Memory (MB)')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    return plt
```

## README.md

````markdown
# LUTO 2: The Land-Use Trade-Offs Model Version 2

[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)

## Introduction
The Land Use Trade-Offs model v2 (LUTO2) is an integrated land systems model designed to simulate the optimal spatial arrangement of land use and land management decisions over time in Australia. It aims to achieve climate and biodiversity targets without compromising economic growth, food production or water security. The model is implemented as a Python package, offering users the flexibility to run interactively or to execute batch processes through scripted automation.

LUTO2 was developed through a collaboration between Deakin University and Climateworks Centre, with research contributions from CSIRO. The model is a cornerstone of Climateworks’ Land Use Futures program, which supports Australia’s transition to sustainable food and land systems. The technical development of LUTO2 is led by Professor Brett Bryan at Deakin University. LUTO2 continues the approach to land-use change modelling of its predecessor, the original LUTO, which was developed by CSIRO from 2010 - 2015 (see also Pedigree, below) and published under the GNU GPLv3 in 2021.

## Pedigree
LUTO2 builds on the approach and pedigree of nearly two decades of land-use modelling expertise starting with the original LUTO model. The original LUTO model was developed by CSIRO for the Australian National Outlook in 2015 and was groundbreaking for quantifying and projecting land use changes and their sustainability impacts in Australia, illustrated by its published works in *Nature* in 2015 and 2017.

LUTO2 represents a generational leap in sophistication and functionality for national-scale land-use change modelling in Australia. Both LUTO versions are optimisation models but different commercial solvers are used (CPLEX in original LUTO, GUROBI in LUTO2). The spatial domains are different in extent, with LUTO2's being nearly 5 times as large. The data requirements to run LUTO2 are consequently different and heavier. There is no backwards compatibility whatsoever.

The original LUTO model is available online and should be cited as:
> Bryan, Brett; Nolan, Martin; Stock, Florian; Graham, Paul; Dunstall, Simon; Ernst, Andreas; Connor, Jeff (2021): Land Use Trade-Offs (LUTO) Model. v1. CSIRO. Software Collection. https://doi.org/10.25919/y8ee-sk45.

This new version represents an entirely new model featuring a complete rewrite of the codebase and comprehensive upgrades to data and functionality. Enhancements to the original model include extended spatial coverage and timespan (2010 to 2100), a complete refresh of input data, additional land-use options and sustainability indicators and management solutions, the ability to model demand-side solutions, and additional environmental indicators and reporting. Due to LUTO2’s model complexity, the computational requirements to run the model are far more intensive.

LUTO2’s modelling approach, indicators and solutions have been guided by extensive stakeholder consultation (documented here: https://doi.org/10.1007/s11625-024-01574-7) following principles of participatory model co-design.

## Authors
Coordinating lead author: **Bryan, B.A.**  

Lead authors (in order of contribution): **Williams, N., Archibald, C.L., de Haan, F., Wang, J., van Schoten, N., Hadjikakou, M., Sanson, J., Zyngier, R., Marcos-Martinez, R., Navarro, J., Gao, L., Aghighi, H.**  

Other significant contributors (in alphabetical order): **Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., Thiruvady, D.R.**

## Documentation
Documentation, including instructions on how to set up and run LUTO2, can be found at `docs/luto2-overview.pdf`.

LUTO2 comes with a full diagram to illustrate its data preparation, workflow, and code logics. The diagram link can be found in this link.  
*Replace with updated documentation currently in preparation when ready.*

## Project Structure

The LUTO2 codebase is organized into the following structure:

```
luto/                                # Main package directory
├── data.py                          # Core data management and loading
├── simulation.py                    # Main simulation engine
├── settings.py                      # Configuration parameters
├── dataprep.py                      # Data preprocessing utilities
├── helpers.py                       # Utility functions
├── economics/                       # Economic models and calculations
│   ├── agricultural/                # Agricultural economics modules
│   ├── non_agricultural/            # Non-agricultural economics modules
│   └── off_land_commodity/          # Off-land commodity economics
├── solvers/                         # Optimization solvers and algorithms
├── tests/                           # Unit and integration tests
└── tools/                           # Utility tools and scripts
    ├── create_task_runs/            # Task execution and batch processing
    ├── Manual_jupyter_books/        # Documentation notebooks
    ├── report/                      # Reporting and visualization tools
    │   ├── data_tools/              # Data processing for reports
    │   └── map_tools/               # Spatial visualization utilities
    ├── plotmap.py                   # Mapping utilities
    ├── spatializers.py              # Spatial data processing
    └── write.py                     # Output writing functions

input/                               # Input data directory (requires separate download)
output/                              # Simulation outputs directory
docs/                                # Documentation files
```

## Troubleshooting

### Common Issues

**Memory Errors:**
- Ensure you have at least 32 GB RAM available
- Close other applications during simulation
- Consider running smaller scenarios first

**GUROBI License Issues:**
- Verify your license file location
- Check license expiration date
- Ensure your license supports the required model size

**Data Loading Errors:**
- Verify all required input files are present in `/input/`
- Check file permissions
- Ensure sufficient disk space


### Getting Help

1. Check the documentation in `docs/luto2-overview.pdf`
2. Review log files in `/output/<run_dir>/logs/`
3. Contact the development team: **b.bryan@deakin.edu.au**
4. Submit issues on GitHub: [github.com/land-use-trade-offs/luto-2.0](https://github.com/land-use-trade-offs/luto-2.0)

## System Requirements

**Minimum Requirements:**
- Python 3.10 or higher
- 16 GB RAM (32 GB recommended for large simulations)
- 50 GB available disk space for input data and outputs
- GUROBI optimization solver license (academic licenses available)

**Supported Operating Systems:**
- Windows 10/11
- macOS 10.15+
- Linux (Ubuntu 18.04+, CentOS 7+)

## Installation and Setup

### 1. Clone the Repository
```bash
git clone https://github.com/land-use-trade-offs/luto-2.0.git
cd luto-2.0
```

### 2. Set Up Conda Environment
```bash
# Create and activate the LUTO environment
conda env create -f luto/tools/create_task_runs/bash_scripts/conda_env.yml
conda activate luto
```

### 3. Configure GUROBI Solver
LUTO2 requires GUROBI for optimization. Follow these steps:
```bash
# 1) Set up your GUROBI license (academic license available at gurobi.com)
# 2) Place your gurobi.lic file in the appropriate directory
```

### 4. Obtain Input Data
The LUTO2 input database is approximately 40 GB and contains sensitive data. 
Please contact **b.bryan@deakin.edu.au** to request access to the input dataset.

## Running LUTO2

### Basic Simulation
```python
import luto.simulation as sim

# Load input data and settings
data = sim.load_data()

# Run simulation with default parameters
results = sim.run(data=data)
```

### Advanced Configuration
```python
import luto.simulation as sim
import luto.settings as settings

# Customize simulation settings
settings.RESFACTOR = 10                             # 10 makes the spatial resolution to ~10km. 
settings.SIM_YEARS = [2010, 2020, 2030, 2040, 2050]

settings.WATER_LIMITS = 'on'                        # 'on' or 'off'. 
settings.GHG_EMISSIONS_LIMITS = 'high'              # 'off', 'low', 'medium', or 'high'
settings.BIODIVERSITY_TARGET_GBF_2 = 'high'         # 'off', 'low', 'medium', or 'high'
settingsBIODIVERSITY_TARGET_GBF_3  = 'off'          # 'off', 'medium', 'high', or 'USER_DEFINED'   
settings.BIODIVERSITY_TARGET_GBF_4_SNES =  'off'    # 'on' or 'off'.
settings.BIODIVERSITY_TARGET_GBF_4_ECNES = 'off'    # 'on' or 'off'.
settings.BIODIVERSITY_TARGET_GBF_8 = 'off'          # 'on' or 'off'.

# Load data with custom parameters
data = sim.load_data()

# Run simulation
sim.run(data=data)
```

### Viewing Results
After execution, results are saved in the `/output/<timestamp>/` directory:

1. **Interactive HTML Report:** 
   ```
   /output/<run_dir>/DATA_REPORT/REPORT_HTML/index.html
   ```
   This provides a comprehensive overview with interactive visualizations.

2. **Spatial Outputs:** GeoTIFF files for mapping and spatial analysis
3. **Data Tables:** CSV files with detailed numerical results
4. **Logs:** Execution logs for debugging and performance analysis

## Configuration

LUTO2 behavior can be customized through the `luto.settings` module. Key parameters include:

### Core Simulation Parameters
- `SIM_YEARS`: Simulation time period (default: 2020-2050 in 5-year steps)
- `SCENARIO`: Shared Socioeconomic Pathway (SSP1-SSP5)
- `RCP`: Representative Concentration Pathway (e.g., 'rcp4p5')
- `OBJECTIVE`: Optimization objective ('maxprofit' or 'mincost')

### Environmental Constraints
- `GHG_EMISSIONS_LIMITS`: Greenhouse gas emission targets ('off', 'low', 'medium', 'high')
- `WATER_LIMITS`: Whether to enforce water yield constraints ('on' or 'off')
- `BIODIVERSITY_TARGET_GBF_2`: Global Biodiversity Framework Target 2 ('off', 'low', 'medium', 'high')
- `BIODIVERSITY_TARGET_GBF_3`: Conservation targets for vegetation types ('off', 'medium', 'high')

### Land Use Options
- `NON_AG_LAND_USES`: Enable/disable non-agricultural land uses (Environmental Plantings, Carbon Plantings, etc.)
- `AG_MANAGEMENTS`: Enable/disable agricultural management practices (Precision Agriculture, Biochar, etc.)
- `EXCLUDE_NO_GO_LU`: Whether to exclude certain land uses from specific areas

### Economic Parameters
- `CARBON_PRICES_FIELD`: Carbon pricing scenario ('Default', 'CONSTANT', etc.)
- `AMORTISE_UPFRONT_COSTS`: Whether to amortize establishment costs
- `DISCOUNT_RATE`: Discount rate for economic calculations (default: 7%)

### Solver Configuration
- `SOLVE_METHOD`: GUROBI algorithm selection (default: 2 for barrier method)
- `THREADS`: Number of parallel threads for optimization
- `FEASIBILITY_TOLERANCE`: Solver tolerance settings
- `VERBOSE`: Control solver output verbosity

### Output Control
- `PARALLEL_WRITE`: Use parallel processing for output generation
- `RESFACTOR`: Spatial resolution factor (1 = full resolution, >1 = coarser)

Refer to `luto/settings.py` for a complete list of configurable parameters and detailed descriptions.

## Copyright
Copyright 2024-now **Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., van Schoten, N., Hadjikakou, M., Sanson, J., Zyngier, R., Marcos-Martinez, R., Navarro, J., Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R.**  

Copyright 2021-2023 **Fjalar J. de Haan and Brett A. Bryan, Deakin University.** (see `CITATION.cff`).

## License
LUTO2 is free software: you can redistribute it and/or modify it under the terms of the **GNU General Public License** as published by the **Free Software Foundation**, either version 3 of the License, or (at your option) any later version.

This program is distributed in the hope that it will be useful, but **without any warranty**; without even the implied warranty of **merchantability** or **fitness for a particular purpose**. See the **GNU General Public License** for more details.

You should have received a copy of the **GNU General Public License** along with this program. If not, see <https://www.gnu.org/licenses/>.

## Citation
> Bryan, B.A., Williams, N., Archibald, C.L., de Haan, F., Wang, J., van Schoten, N., Hadjikakou, M., Sanson, J., Zyngier, R., Marcos-Martinez, R., Navarro, J., Gao, L., Aghighi, H., Armstrong, T., Bohl, H., Jaffe, P., Khan, M.S., Moallemi, E.A., Nazari, A., Pan, X., Steyl, D., and Thiruvady, D.R. (2025). The Land-Use Trade-Offs Model Version 2 (LUTO2): an integrated land system model for Australia. Software Collection. https://github.com/land-use-trade-offs/luto-2.0

## Contributing

We welcome contributions to LUTO2! Please follow these guidelines:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

For major changes, please open an issue first to discuss proposed modifications.

## Acknowledgments

LUTO2 was developed through a collaboration between:
- **Deakin University** - Centre for Integrative Ecology
- **Climateworks Centre** - Land Use Futures program
- **CSIRO** - Research contributions

This work is supported by funding from various Australian research councils and industry partners. We acknowledge the traditional custodians of the lands on which this research was conducted.
````

## requirements.txt

```text
numpy==1.26.4
pandas==2.2.2
rasterio==1.3.9
scipy==1.13.0
matplotlib==3.8.4
h5py==3.11.0
openpyxl==3.1.2
pytest==8.2.1
pytables==3.9.2
hypothesis==6.102.4
lxml==5.2.2
folium==0.16.0
contextily==1.6.0
imageio==2.34.1
geopandas==0.14.4
ipython==8.24.0
rioxarray==0.15.5
xarray==2024.5.0
dask==2024.5.1
h5netcdf==1.3.0
netcdf4=1.7.2
ipykernel==6.29.4
sparse==0.15.4
nbformat==5.10.4
dill==0.3.8
# Below can only be installed with pip
gurobipy==11.0.2
numpy_financial==1.0.0
tables==3.9.2
```

## Statistics

- Total Files: 89
- Total Characters: 6297099
- Total Tokens: 0
